Training log data for domain tyreworld:
printing the data chronological
Epoch 1:
Training data for problem d-01.pddl in epoch 1:
model creation time: 6.5187883377075195s
problem epoch data for epoch 1, problem epoch 1
	sampling search time: 2.0193123817443848s
	during this search the following actions were chosen:
		close boot was chosen with probability 0.000000
	training time: 36.58729600906372s
	during the training the following losses were computed:
		loss: 4.269400
		loss: 4.097800
		loss: 3.966000
		loss: 3.861700
		loss: 3.778600
		loss: 3.711500
		loss: 3.653100
		loss: 3.596300
		loss: 3.538900
		loss: 3.479800
		loss: 3.422400
		loss: 3.368000
		loss: 3.317000
		loss: 3.269000
		loss: 3.224400
		loss: 3.183000
		loss: 3.143800
		loss: 3.105000
		loss: 3.065600
		loss: 3.027200
		loss: 2.989800
		loss: 2.953200
		loss: 2.917500
		loss: 2.883600
		loss: 2.851500
		loss: 2.820400
		loss: 2.790200
		loss: 2.761800
		loss: 2.735100
		loss: 2.709700
		loss: 2.686700
		loss: 2.665800
		loss: 2.646300
		loss: 2.628200
		loss: 2.611500
		loss: 2.595300
		loss: 2.580300
		loss: 2.565900
		loss: 2.552100
		loss: 2.539400
		loss: 2.527300
		loss: 2.516000
		loss: 2.505300
		loss: 2.495100
		loss: 2.485800
		loss: 2.476900
		loss: 2.468800
		loss: 2.461200
		loss: 2.454000
		loss: 2.447200
		loss: 2.440800
		loss: 2.434600
		loss: 2.428700
		loss: 2.423000
		loss: 2.417500
		loss: 2.412200
		loss: 2.407000
		loss: 2.401900
		loss: 2.397100
		loss: 2.392300
		loss: 2.387800
		loss: 2.383400
		loss: 2.379200
		loss: 2.375000
		loss: 2.371000
		loss: 2.367100
		loss: 2.363200
		loss: 2.359400
		loss: 2.355600
		loss: 2.351900
		loss: 2.348300
		loss: 2.344800
		loss: 2.341300
		loss: 2.337800
		loss: 2.334500
		loss: 2.331100
		loss: 2.327800
		loss: 2.324500
		loss: 2.321300
		loss: 2.318000
		loss: 2.314900
		loss: 2.311700
		loss: 2.308600
		loss: 2.305400
		loss: 2.302300
		loss: 2.299200
		loss: 2.296200
		loss: 2.293100
		loss: 2.290100
		loss: 2.287100
		loss: 2.284100
		loss: 2.281200
		loss: 2.278200
		loss: 2.275300
		loss: 2.272300
		loss: 2.269400
		loss: 2.266500
		loss: 2.263600
		loss: 2.260700
		loss: 2.257900
	Overall the loss development was 4.269400 -> 2.257900
problem epoch data for epoch 1, problem epoch 2
	sampling search time: 1.9202759265899658s
	during this search the following actions were chosen:
		close boot was chosen with probability 0.000000
	training time: 10.12761926651001s
	during the training the following losses were computed:
		loss: 2.255000
		loss: 2.252200
		loss: 2.249300
		loss: 2.246500
		loss: 2.243700
		loss: 2.240900
		loss: 2.238100
		loss: 2.235400
		loss: 2.232600
		loss: 2.229900
		loss: 2.227100
		loss: 2.224400
		loss: 2.221700
		loss: 2.219000
		loss: 2.216300
		loss: 2.213600
		loss: 2.210900
		loss: 2.208200
		loss: 2.205600
		loss: 2.202900
		loss: 2.200300
		loss: 2.197700
		loss: 2.195100
		loss: 2.192600
		loss: 2.190100
		loss: 2.187900
		loss: 2.185800
		loss: 2.183600
		loss: 2.180700
		loss: 2.177300
		loss: 2.174600
		loss: 2.172700
		loss: 2.170400
		loss: 2.167500
		loss: 2.164700
		loss: 2.162600
		loss: 2.160300
		loss: 2.157600
		loss: 2.155000
		loss: 2.152800
		loss: 2.150500
		loss: 2.147900
		loss: 2.145500
		loss: 2.143300
		loss: 2.141000
		loss: 2.138500
		loss: 2.136100
		loss: 2.133900
		loss: 2.131600
		loss: 2.129200
		loss: 2.126900
		loss: 2.124600
		loss: 2.122400
		loss: 2.120100
		loss: 2.117800
		loss: 2.115600
		loss: 2.113400
		loss: 2.111100
		loss: 2.108900
		loss: 2.106700
		loss: 2.104500
		loss: 2.102300
		loss: 2.100100
		loss: 2.097900
		loss: 2.095800
		loss: 2.093600
		loss: 2.091500
		loss: 2.089300
		loss: 2.087200
		loss: 2.085100
		loss: 2.083000
		loss: 2.080900
		loss: 2.078800
		loss: 2.076700
		loss: 2.074700
		loss: 2.072600
		loss: 2.070600
		loss: 2.068500
		loss: 2.066500
		loss: 2.064500
		loss: 2.062500
		loss: 2.060400
		loss: 2.058500
		loss: 2.056500
		loss: 2.054500
		loss: 2.052500
		loss: 2.050600
		loss: 2.048600
		loss: 2.046700
		loss: 2.044700
		loss: 2.042800
		loss: 2.040900
		loss: 2.039000
		loss: 2.037100
		loss: 2.035200
		loss: 2.033300
		loss: 2.031400
		loss: 2.029500
		loss: 2.027700
		loss: 2.025800
	Overall the loss development was 2.255000 -> 2.025800
problem epoch data for epoch 1, problem epoch 3
	sampling search time: 1.8838589191436768s
	during this search the following actions were chosen:
		close boot was chosen with probability 0.000000
	training time: 10.126681804656982s
	during the training the following losses were computed:
		loss: 2.024000
		loss: 2.022100
		loss: 2.020300
		loss: 2.018500
		loss: 2.016700
		loss: 2.014900
		loss: 2.013100
		loss: 2.011300
		loss: 2.009500
		loss: 2.007800
		loss: 2.006000
		loss: 2.004200
		loss: 2.002500
		loss: 2.000800
		loss: 1.999100
		loss: 1.997400
		loss: 1.995900
		loss: 1.994500
		loss: 1.993500
		loss: 1.992800
		loss: 1.991700
		loss: 1.989200
		loss: 1.986000
		loss: 1.984000
		loss: 1.983400
		loss: 1.982200
		loss: 1.979600
		loss: 1.977500
		loss: 1.976600
		loss: 1.975300
		loss: 1.973000
		loss: 1.971200
		loss: 1.970200
		loss: 1.968600
		loss: 1.966600
		loss: 1.965100
		loss: 1.963900
		loss: 1.962300
		loss: 1.960500
		loss: 1.959100
		loss: 1.957800
		loss: 1.956100
		loss: 1.954500
		loss: 1.953200
		loss: 1.951800
		loss: 1.950100
		loss: 1.948700
		loss: 1.947300
		loss: 1.945900
		loss: 1.944400
		loss: 1.942900
		loss: 1.941600
		loss: 1.940100
		loss: 1.938700
		loss: 1.937300
		loss: 1.936000
		loss: 1.934500
		loss: 1.933100
		loss: 1.931800
		loss: 1.930400
		loss: 1.929100
		loss: 1.927700
		loss: 1.926400
		loss: 1.925000
		loss: 1.923700
		loss: 1.922300
		loss: 1.921000
		loss: 1.919700
		loss: 1.918400
		loss: 1.917100
		loss: 1.915800
		loss: 1.914500
		loss: 1.913200
		loss: 1.911900
		loss: 1.910700
		loss: 1.909400
		loss: 1.908100
		loss: 1.906900
		loss: 1.905600
		loss: 1.904400
		loss: 1.903200
		loss: 1.901900
		loss: 1.900700
		loss: 1.899500
		loss: 1.898300
		loss: 1.897100
		loss: 1.895900
		loss: 1.894700
		loss: 1.893500
		loss: 1.892300
		loss: 1.891100
		loss: 1.889900
		loss: 1.888800
		loss: 1.887600
		loss: 1.886400
		loss: 1.885300
		loss: 1.884200
		loss: 1.883000
		loss: 1.881900
		loss: 1.880700
	Overall the loss development was 2.024000 -> 1.880700
In the epoch 1 for problem d-01.pddl 0 explorations in the sampling searches reached a goal
Training data for problem d-02.pddl in epoch 1:
model creation time: 15.522695064544678s
problem epoch data for epoch 1, problem epoch 1
	sampling search time: 210.1372742652893s
	during this search the following actions were chosen:
		open boot was chosen with probability 1.000000
		fetch jack boot was chosen with probability 0.478482
		fetch wrench boot was chosen with probability 0.846999
		fetch pump boot was chosen with probability 0.414732
		loosen nuts1 the-hub1 was chosen with probability 0.439103
		loosen nuts2 the-hub2 was chosen with probability 0.868758
		fetch r1 boot was chosen with probability 0.854113
		fetch r2 boot was chosen with probability 0.696939
		jack-up the-hub1 was chosen with probability 0.731925
		undo nuts1 the-hub1 was chosen with probability 0.999996
		remove-wheel w1 the-hub1 was chosen with probability 0.992804
		put-on-wheel r1 the-hub1 was chosen with probability 0.973549
		remove-wheel r1 the-hub1 was chosen with probability 0.376962
	training time: 62.96095323562622s
	during the training the following losses were computed:
		loss: 3.524700
		loss: 3.448200
		loss: 3.391500
		loss: 3.367900
		loss: 3.340400
		loss: 3.313800
		loss: 3.301300
		loss: 3.288100
		loss: 3.271800
		loss: 3.260100
		loss: 3.251000
		loss: 3.237600
		loss: 3.220800
		loss: 3.206800
		loss: 3.197500
		loss: 3.189500
		loss: 3.180600
		loss: 3.172100
		loss: 3.165200
		loss: 3.159200
		loss: 3.153300
		loss: 3.147300
		loss: 3.141800
		loss: 3.137000
		loss: 3.133100
		loss: 3.128700
		loss: 3.123700
		loss: 3.118800
		loss: 3.114500
		loss: 3.110200
		loss: 3.106100
		loss: 3.102800
		loss: 3.100000
		loss: 3.096600
		loss: 3.093000
		loss: 3.090000
		loss: 3.087100
		loss: 3.084200
		loss: 3.081600
		loss: 3.079000
		loss: 3.076200
		loss: 3.073600
		loss: 3.071500
		loss: 3.069500
		loss: 3.067300
		loss: 3.065300
		loss: 3.063400
		loss: 3.061500
		loss: 3.059800
		loss: 3.058200
		loss: 3.056400
		loss: 3.054700
		loss: 3.053000
		loss: 3.051500
		loss: 3.050000
		loss: 3.048500
		loss: 3.047100
		loss: 3.045700
		loss: 3.044200
		loss: 3.042900
		loss: 3.041600
		loss: 3.040300
		loss: 3.039100
		loss: 3.037800
		loss: 3.036600
		loss: 3.035400
		loss: 3.034300
		loss: 3.033100
		loss: 3.032000
		loss: 3.030900
		loss: 3.029800
		loss: 3.028700
		loss: 3.027700
		loss: 3.026600
		loss: 3.025500
		loss: 3.024500
		loss: 3.023500
		loss: 3.022500
		loss: 3.021500
		loss: 3.020500
		loss: 3.019600
		loss: 3.018600
		loss: 3.017700
		loss: 3.016700
		loss: 3.015800
		loss: 3.014900
		loss: 3.014000
		loss: 3.013100
		loss: 3.012200
		loss: 3.011300
		loss: 3.010400
		loss: 3.009500
		loss: 3.008700
		loss: 3.007800
		loss: 3.006900
		loss: 3.006100
		loss: 3.005200
		loss: 3.004400
		loss: 3.003600
		loss: 3.002700
	Overall the loss development was 3.524700 -> 3.002700
problem epoch data for epoch 1, problem epoch 2
	sampling search time: 33.3199999332428s
	during this search the following actions were chosen:
		close boot was chosen with probability 0.000000
	training time: 10.984565258026123s
	during the training the following losses were computed:
		loss: 3.001900
		loss: 3.001100
		loss: 3.000300
		loss: 2.999500
		loss: 2.998700
		loss: 2.997900
		loss: 2.997100
		loss: 2.996400
		loss: 2.995600
		loss: 2.994800
		loss: 2.994100
		loss: 2.993300
		loss: 2.992500
		loss: 2.991800
		loss: 2.991000
		loss: 2.990300
		loss: 2.989500
		loss: 2.988800
		loss: 2.988100
		loss: 2.987300
		loss: 2.986600
		loss: 2.985900
		loss: 2.985200
		loss: 2.984500
		loss: 2.983700
		loss: 2.983000
		loss: 2.982300
		loss: 2.981600
		loss: 2.980900
		loss: 2.980200
		loss: 2.979500
		loss: 2.978900
		loss: 2.978200
		loss: 2.977500
		loss: 2.976800
		loss: 2.976100
		loss: 2.975500
		loss: 2.974800
		loss: 2.974100
		loss: 2.973500
		loss: 2.972800
		loss: 2.972200
		loss: 2.971500
		loss: 2.970900
		loss: 2.970200
		loss: 2.969600
		loss: 2.969000
		loss: 2.968300
		loss: 2.967700
		loss: 2.967100
		loss: 2.966400
		loss: 2.965800
		loss: 2.965200
		loss: 2.964600
		loss: 2.964000
		loss: 2.963400
		loss: 2.962800
		loss: 2.962200
		loss: 2.961500
		loss: 2.960900
		loss: 2.960300
		loss: 2.959800
		loss: 2.959200
		loss: 2.958600
		loss: 2.958000
		loss: 2.957400
		loss: 2.956800
		loss: 2.956200
		loss: 2.955700
		loss: 2.955100
		loss: 2.954500
		loss: 2.954000
		loss: 2.953400
		loss: 2.952800
		loss: 2.952300
		loss: 2.951700
		loss: 2.951200
		loss: 2.950600
		loss: 2.950100
		loss: 2.949500
		loss: 2.949000
		loss: 2.948400
		loss: 2.947900
		loss: 2.947400
		loss: 2.946800
		loss: 2.946300
		loss: 2.945800
		loss: 2.945200
		loss: 2.944700
		loss: 2.944200
		loss: 2.943700
		loss: 2.943200
		loss: 2.942600
		loss: 2.942100
		loss: 2.941600
		loss: 2.941100
		loss: 2.940600
		loss: 2.940100
		loss: 2.939600
		loss: 2.939100
	Overall the loss development was 3.001900 -> 2.939100
problem epoch data for epoch 1, problem epoch 3
	sampling search time: 208.32382941246033s
	during this search the following actions were chosen:
		open boot was chosen with probability 1.000000
		fetch wrench boot was chosen with probability 0.455245
		fetch jack boot was chosen with probability 0.561647
		loosen nuts1 the-hub1 was chosen with probability 0.529901
		loosen nuts2 the-hub2 was chosen with probability 0.810396
		fetch r2 boot was chosen with probability 0.484994
		fetch r1 boot was chosen with probability 0.771649
		fetch pump boot was chosen with probability 0.501806
		jack-up the-hub1 was chosen with probability 0.954553
		undo nuts1 the-hub1 was chosen with probability 1.000000
		remove-wheel w1 the-hub1 was chosen with probability 0.991621
		put-on-wheel r1 the-hub1 was chosen with probability 0.999522
		inflate r1 was chosen with probability 0.497224
		inflate r2 was chosen with probability 0.992506
		remove-wheel r1 the-hub1 was chosen with probability 0.965582
		put-on-wheel r1 the-hub1 was chosen with probability 0.999664
	training time: 17.898688793182373s
	during the training the following losses were computed:
		loss: 2.640200
		loss: 3.136500
		loss: 3.094100
		loss: 3.132900
		loss: 3.212500
		loss: 3.131900
		loss: 3.003400
		loss: 3.132600
		loss: 3.261500
		loss: 3.130800
		loss: 3.035400
		loss: 3.129400
		loss: 3.274100
		loss: 3.128900
		loss: 3.188700
		loss: 3.127000
		loss: 3.126100
		loss: 3.126100
		loss: 3.505800
		loss: 3.127700
		loss: 2.900300
		loss: 3.125800
		loss: 2.630200
		loss: 3.127000
		loss: 3.248700
		loss: 3.124200
		loss: 2.752100
		loss: 3.125000
		loss: 3.185900
		loss: 3.123100
		loss: 3.419700
		loss: 3.124100
		loss: 3.079400
		loss: 3.121600
		loss: 2.755600
		loss: 3.124400
		loss: 2.821100
		loss: 3.123700
		loss: 2.954500
		loss: 3.121900
		loss: 3.221700
		loss: 3.118100
		loss: 2.550900
		loss: 3.116000
		loss: 2.991900
		loss: 3.119100
		loss: 2.994900
		loss: 3.117500
		loss: 3.052300
		loss: 3.115200
		loss: 2.922000
		loss: 3.115700
		loss: 2.740900
		loss: 3.114900
		loss: 3.503600
		loss: 3.109400
		loss: 3.221200
		loss: 3.110300
		loss: 3.162700
		loss: 3.110000
		loss: 3.512700
		loss: 3.112100
		loss: 3.310300
		loss: 3.108000
		loss: 2.872000
		loss: 3.110400
		loss: 2.914200
		loss: 3.108300
		loss: 3.299300
		loss: 3.109500
		loss: 3.266300
		loss: 3.106000
		loss: 3.274100
		loss: 3.105900
		loss: 3.364300
		loss: 3.104900
		loss: 3.059900
		loss: 3.105300
		loss: 2.734100
		loss: 3.102100
		loss: 3.402200
		loss: 3.102000
		loss: 3.331800
		loss: 3.104500
		loss: 3.061500
		loss: 3.102300
		loss: 3.478000
		loss: 3.104100
		loss: 3.358400
		loss: 3.102700
		loss: 3.368200
		loss: 3.099000
		loss: 3.131000
		loss: 3.099800
		loss: 3.303400
		loss: 3.100400
		loss: 3.262400
		loss: 3.098100
		loss: 3.431000
		loss: 3.096400
		loss: 2.952800
		loss: 3.097100
		loss: 3.176000
		loss: 3.098000
		loss: 3.125800
		loss: 3.097100
		loss: 2.625500
		loss: 3.094000
		loss: 3.527800
		loss: 3.093600
		loss: 3.138200
		loss: 3.095100
		loss: 3.352200
		loss: 3.093500
		loss: 2.759200
		loss: 3.092800
		loss: 3.477300
		loss: 3.091900
		loss: 2.936600
		loss: 3.092600
		loss: 2.744600
		loss: 3.091200
		loss: 2.825500
		loss: 3.094400
		loss: 3.152800
		loss: 3.092700
		loss: 3.171800
		loss: 3.092200
		loss: 2.911000
		loss: 3.090500
		loss: 2.705500
		loss: 3.088700
		loss: 3.323900
		loss: 3.091300
		loss: 3.675100
		loss: 3.086400
		loss: 2.973100
		loss: 3.090200
		loss: 2.948600
		loss: 3.090000
		loss: 3.217200
		loss: 3.089300
		loss: 3.073800
		loss: 3.088100
		loss: 3.697700
		loss: 3.091100
		loss: 3.629900
		loss: 3.083600
		loss: 3.184600
		loss: 3.086800
		loss: 3.336500
		loss: 3.087200
		loss: 2.763800
		loss: 3.083600
		loss: 2.895000
		loss: 3.086300
		loss: 3.233100
		loss: 3.083900
		loss: 3.365800
		loss: 3.082700
		loss: 2.788700
		loss: 3.085800
		loss: 2.845200
		loss: 3.082200
		loss: 3.159400
		loss: 3.083400
		loss: 3.057500
		loss: 3.082500
		loss: 2.609600
		loss: 3.079200
		loss: 3.107700
		loss: 3.081500
		loss: 3.279100
		loss: 3.080200
		loss: 3.141200
		loss: 3.081200
		loss: 3.356900
		loss: 3.079000
		loss: 3.110100
		loss: 3.080600
		loss: 3.100500
		loss: 3.080100
		loss: 3.107000
		loss: 3.079600
		loss: 3.203900
		loss: 3.078300
		loss: 2.787800
		loss: 3.080500
		loss: 3.605900
		loss: 3.075100
		loss: 3.096100
		loss: 3.077600
		loss: 3.054400
		loss: 3.077100
		loss: 3.474800
		loss: 3.079100
		loss: 2.722900
		loss: 3.078700
		loss: 2.713100
		loss: 3.078500
	Overall the loss development was 2.640200 -> 3.078500
In the epoch 1 for problem d-02.pddl 0 explorations in the sampling searches reached a goal
Success rate: 0

Epoch 2:
Training data for problem d-01.pddl in epoch 2:
model creation time: 7.943400144577026s
problem epoch data for epoch 2, problem epoch 1
	sampling search time: 2.0740413665771484s
	during this search the following actions were chosen:
		close boot was chosen with probability 0.000000
	training time: 37.432552337646484s
	during the training the following losses were computed:
		loss: 1.747500
		loss: 1.768100
		loss: 1.721200
		loss: 1.743100
		loss: 1.737100
		loss: 1.713700
		loss: 1.716800
		loss: 1.725800
		loss: 1.719300
		loss: 1.714000
		loss: 1.718100
		loss: 1.718600
		loss: 1.712200
		loss: 1.709500
		loss: 1.713400
		loss: 1.715000
		loss: 1.711000
		loss: 1.707500
		loss: 1.708300
		loss: 1.709000
		loss: 1.707100
		loss: 1.706000
		loss: 1.707400
		loss: 1.707900
		loss: 1.705800
		loss: 1.704200
		loss: 1.704800
		loss: 1.705500
		loss: 1.704600
		loss: 1.703800
		loss: 1.703900
		loss: 1.703700
		loss: 1.702600
		loss: 1.702200
		loss: 1.702700
		loss: 1.702500
		loss: 1.701700
		loss: 1.701300
		loss: 1.701400
		loss: 1.701100
		loss: 1.700700
		loss: 1.700600
		loss: 1.700600
		loss: 1.700100
		loss: 1.699700
		loss: 1.699700
		loss: 1.699500
		loss: 1.699100
		loss: 1.698900
		loss: 1.698800
		loss: 1.698500
		loss: 1.698200
		loss: 1.698100
		loss: 1.697900
		loss: 1.697600
		loss: 1.697500
		loss: 1.697300
		loss: 1.697000
		loss: 1.696800
		loss: 1.696700
		loss: 1.696500
		loss: 1.696200
		loss: 1.696100
		loss: 1.695900
		loss: 1.695600
		loss: 1.695500
		loss: 1.695300
		loss: 1.695100
		loss: 1.694900
		loss: 1.694700
		loss: 1.694500
		loss: 1.694300
		loss: 1.694100
		loss: 1.693900
		loss: 1.693700
		loss: 1.693600
		loss: 1.693400
		loss: 1.693200
		loss: 1.693000
		loss: 1.692800
		loss: 1.692600
		loss: 1.692400
		loss: 1.692300
		loss: 1.692100
		loss: 1.691900
		loss: 1.691700
		loss: 1.691500
		loss: 1.691300
		loss: 1.691200
		loss: 1.691000
		loss: 1.690800
		loss: 1.690600
		loss: 1.690500
		loss: 1.690300
		loss: 1.690100
		loss: 1.689900
		loss: 1.689700
		loss: 1.689600
		loss: 1.689400
		loss: 1.689200
	Overall the loss development was 1.747500 -> 1.689200
problem epoch data for epoch 2, problem epoch 2
	sampling search time: 1.885120153427124s
	during this search the following actions were chosen:
		close boot was chosen with probability 0.000000
	training time: 10.127346277236938s
	during the training the following losses were computed:
		loss: 1.689000
		loss: 1.688900
		loss: 1.688700
		loss: 1.688500
		loss: 1.688400
		loss: 1.688200
		loss: 1.688000
		loss: 1.687800
		loss: 1.687700
		loss: 1.687500
		loss: 1.687300
		loss: 1.687200
		loss: 1.687000
		loss: 1.686800
		loss: 1.686700
		loss: 1.686500
		loss: 1.686300
		loss: 1.686200
		loss: 1.686000
		loss: 1.685800
		loss: 1.685700
		loss: 1.685500
		loss: 1.685300
		loss: 1.685200
		loss: 1.685000
		loss: 1.684900
		loss: 1.684700
		loss: 1.684500
		loss: 1.684400
		loss: 1.684200
		loss: 1.684100
		loss: 1.683900
		loss: 1.683700
		loss: 1.683600
		loss: 1.683400
		loss: 1.683300
		loss: 1.683100
		loss: 1.683000
		loss: 1.682800
		loss: 1.682700
		loss: 1.682500
		loss: 1.682300
		loss: 1.682200
		loss: 1.682000
		loss: 1.681900
		loss: 1.681700
		loss: 1.681600
		loss: 1.681400
		loss: 1.681300
		loss: 1.681100
		loss: 1.681000
		loss: 1.680800
		loss: 1.680700
		loss: 1.680500
		loss: 1.680400
		loss: 1.680300
		loss: 1.680100
		loss: 1.680000
		loss: 1.679800
		loss: 1.679700
		loss: 1.679500
		loss: 1.679400
		loss: 1.679200
		loss: 1.679100
		loss: 1.678900
		loss: 1.678800
		loss: 1.678700
		loss: 1.678500
		loss: 1.678400
		loss: 1.678200
		loss: 1.678100
		loss: 1.678000
		loss: 1.677800
		loss: 1.677700
		loss: 1.677500
		loss: 1.677400
		loss: 1.677300
		loss: 1.677100
		loss: 1.677000
		loss: 1.676900
		loss: 1.676700
		loss: 1.676600
		loss: 1.676400
		loss: 1.676300
		loss: 1.676200
		loss: 1.676000
		loss: 1.675900
		loss: 1.675800
		loss: 1.675600
		loss: 1.675500
		loss: 1.675400
		loss: 1.675200
		loss: 1.675100
		loss: 1.675000
		loss: 1.674800
		loss: 1.674700
		loss: 1.674600
		loss: 1.674500
		loss: 1.674300
		loss: 1.674200
	Overall the loss development was 1.689000 -> 1.674200
problem epoch data for epoch 2, problem epoch 3
	sampling search time: 1.9273953437805176s
	during this search the following actions were chosen:
		close boot was chosen with probability 0.000000
	training time: 10.127983808517456s
	during the training the following losses were computed:
		loss: 1.674100
		loss: 1.673900
		loss: 1.673800
		loss: 1.673700
		loss: 1.673600
		loss: 1.673400
		loss: 1.673300
		loss: 1.673200
		loss: 1.673100
		loss: 1.672900
		loss: 1.672800
		loss: 1.672700
		loss: 1.672600
		loss: 1.672400
		loss: 1.672300
		loss: 1.672200
		loss: 1.672100
		loss: 1.671900
		loss: 1.671800
		loss: 1.671700
		loss: 1.671600
		loss: 1.671400
		loss: 1.671300
		loss: 1.671200
		loss: 1.671100
		loss: 1.671000
		loss: 1.670800
		loss: 1.670700
		loss: 1.670600
		loss: 1.670500
		loss: 1.670400
		loss: 1.670200
		loss: 1.670100
		loss: 1.670000
		loss: 1.669900
		loss: 1.669800
		loss: 1.669700
		loss: 1.669500
		loss: 1.669400
		loss: 1.669300
		loss: 1.669200
		loss: 1.669100
		loss: 1.669000
		loss: 1.668900
		loss: 1.668700
		loss: 1.668600
		loss: 1.668500
		loss: 1.668400
		loss: 1.668300
		loss: 1.668200
		loss: 1.668100
		loss: 1.667900
		loss: 1.667800
		loss: 1.667700
		loss: 1.667600
		loss: 1.667500
		loss: 1.667400
		loss: 1.667300
		loss: 1.667200
		loss: 1.667100
		loss: 1.667000
		loss: 1.666800
		loss: 1.666700
		loss: 1.666600
		loss: 1.666500
		loss: 1.666400
		loss: 1.666300
		loss: 1.666200
		loss: 1.666100
		loss: 1.666000
		loss: 1.665900
		loss: 1.665800
		loss: 1.665700
		loss: 1.665600
		loss: 1.665400
		loss: 1.665300
		loss: 1.665200
		loss: 1.665100
		loss: 1.665000
		loss: 1.664900
		loss: 1.664800
		loss: 1.664700
		loss: 1.664600
		loss: 1.664500
		loss: 1.664400
		loss: 1.664300
		loss: 1.664200
		loss: 1.664100
		loss: 1.664000
		loss: 1.663900
		loss: 1.663800
		loss: 1.663700
		loss: 1.663600
		loss: 1.663500
		loss: 1.663400
		loss: 1.663300
		loss: 1.663200
		loss: 1.663100
		loss: 1.663000
		loss: 1.662900
	Overall the loss development was 1.674100 -> 1.662900
In the epoch 2 for problem d-01.pddl 0 explorations in the sampling searches reached a goal
Training data for problem d-02.pddl in epoch 2:
model creation time: 15.483796119689941s
problem epoch data for epoch 2, problem epoch 1
	sampling search time: 33.19925284385681s
	during this search the following actions were chosen:
		close boot was chosen with probability 0.000000
	training time: 61.99370360374451s
	during the training the following losses were computed:
		loss: 2.644300
		loss: 2.686600
		loss: 2.600100
		loss: 2.633200
		loss: 2.616500
		loss: 2.586000
		loss: 2.589700
		loss: 2.597700
		loss: 2.583900
		loss: 2.567600
		loss: 2.568900
		loss: 2.576300
		loss: 2.571500
		loss: 2.559400
		loss: 2.555300
		loss: 2.560700
		loss: 2.563000
		loss: 2.556800
		loss: 2.549600
		loss: 2.548600
		loss: 2.550900
		loss: 2.549900
		loss: 2.545900
		loss: 2.544000
		loss: 2.544500
		loss: 2.543800
		loss: 2.540800
		loss: 2.538900
		loss: 2.539800
		loss: 2.540800
		loss: 2.539300
		loss: 2.536900
		loss: 2.536200
		loss: 2.536700
		loss: 2.536300
		loss: 2.534800
		loss: 2.534000
		loss: 2.534200
		loss: 2.533900
		loss: 2.532900
		loss: 2.532400
		loss: 2.532300
		loss: 2.531800
		loss: 2.530900
		loss: 2.530600
		loss: 2.530700
		loss: 2.530400
		loss: 2.529600
		loss: 2.529300
		loss: 2.529300
		loss: 2.529000
		loss: 2.528500
		loss: 2.528300
		loss: 2.528100
		loss: 2.527800
		loss: 2.527500
		loss: 2.527400
		loss: 2.527200
		loss: 2.526900
		loss: 2.526700
		loss: 2.526600
		loss: 2.526400
		loss: 2.526200
		loss: 2.526100
		loss: 2.526000
		loss: 2.525800
		loss: 2.525600
		loss: 2.525500
		loss: 2.525400
		loss: 2.525300
		loss: 2.525200
		loss: 2.525100
		loss: 2.524900
		loss: 2.524800
		loss: 2.524800
		loss: 2.524700
		loss: 2.524600
		loss: 2.524500
		loss: 2.524400
		loss: 2.524300
		loss: 2.524200
		loss: 2.524100
		loss: 2.524100
		loss: 2.524000
		loss: 2.523900
		loss: 2.523800
		loss: 2.523800
		loss: 2.523700
		loss: 2.523600
		loss: 2.523600
		loss: 2.523500
		loss: 2.523400
		loss: 2.523400
		loss: 2.523300
		loss: 2.523200
		loss: 2.523200
		loss: 2.523100
		loss: 2.523000
		loss: 2.523000
		loss: 2.522900
	Overall the loss development was 2.644300 -> 2.522900
problem epoch data for epoch 2, problem epoch 2
	sampling search time: 210.6102614402771s
	during this search the following actions were chosen:
		open boot was chosen with probability 1.000000
		fetch wrench boot was chosen with probability 0.448077
		fetch jack boot was chosen with probability 0.824442
		fetch r1 boot was chosen with probability 0.247757
		loosen nuts1 the-hub1 was chosen with probability 0.359208
		loosen nuts2 the-hub2 was chosen with probability 0.488867
		fetch r2 boot was chosen with probability 0.812921
		fetch pump boot was chosen with probability 0.969065
		jack-up the-hub1 was chosen with probability 0.975947
		undo nuts1 the-hub1 was chosen with probability 1.000000
		remove-wheel w1 the-hub1 was chosen with probability 0.999018
		put-on-wheel r1 the-hub1 was chosen with probability 0.999331
		put-away w1 boot was chosen with probability 0.625586
		inflate r1 was chosen with probability 0.479719
		inflate r2 was chosen with probability 0.934467
		remove-wheel r1 the-hub1 was chosen with probability 1.000000
		put-on-wheel r1 the-hub1 was chosen with probability 0.997172
	training time: 10.377200365066528s
	during the training the following losses were computed:
		loss: 2.658800
		loss: 2.630200
		loss: 2.603900
		loss: 2.584300
		loss: 2.562800
		loss: 2.542800
		loss: 2.531300
		loss: 2.527200
		loss: 2.527100
		loss: 2.530200
		loss: 2.533500
		loss: 2.532800
		loss: 2.529900
		loss: 2.528100
		loss: 2.526200
		loss: 2.522200
		loss: 2.517700
		loss: 2.515200
		loss: 2.514500
		loss: 2.514000
		loss: 2.513400
		loss: 2.512400
		loss: 2.510700
		loss: 2.508900
		loss: 2.507800
		loss: 2.506800
		loss: 2.505400
		loss: 2.504000
		loss: 2.503700
		loss: 2.503700
		loss: 2.503500
		loss: 2.503200
		loss: 2.502900
		loss: 2.502500
		loss: 2.502000
		loss: 2.501500
		loss: 2.500900
		loss: 2.500200
		loss: 2.499600
		loss: 2.499400
		loss: 2.499200
		loss: 2.499000
		loss: 2.498800
		loss: 2.498700
		loss: 2.498600
		loss: 2.498400
		loss: 2.498100
		loss: 2.497800
		loss: 2.497500
		loss: 2.497200
		loss: 2.497000
		loss: 2.496800
		loss: 2.496600
		loss: 2.496500
		loss: 2.496500
		loss: 2.496300
		loss: 2.496200
		loss: 2.496100
		loss: 2.495900
		loss: 2.495800
		loss: 2.495600
		loss: 2.495500
		loss: 2.495300
		loss: 2.495200
		loss: 2.495100
		loss: 2.495000
		loss: 2.494900
		loss: 2.494800
		loss: 2.494700
		loss: 2.494500
		loss: 2.494400
		loss: 2.494300
		loss: 2.494200
		loss: 2.494200
		loss: 2.494100
		loss: 2.494000
		loss: 2.493900
		loss: 2.493800
		loss: 2.493700
		loss: 2.493600
		loss: 2.493500
		loss: 2.493400
		loss: 2.493300
		loss: 2.493200
		loss: 2.493100
		loss: 2.493000
		loss: 2.493000
		loss: 2.492900
		loss: 2.492800
		loss: 2.492700
		loss: 2.492600
		loss: 2.492500
		loss: 2.492400
		loss: 2.492400
		loss: 2.492300
		loss: 2.492200
		loss: 2.492100
		loss: 2.492100
		loss: 2.492000
		loss: 2.491900
	Overall the loss development was 2.658800 -> 2.491900
problem epoch data for epoch 2, problem epoch 3
	sampling search time: 33.20264029502869s
	during this search the following actions were chosen:
		close boot was chosen with probability 0.000000
	training time: 10.3802490234375s
	during the training the following losses were computed:
		loss: 2.491800
		loss: 2.491800
		loss: 2.491700
		loss: 2.491600
		loss: 2.491500
		loss: 2.491500
		loss: 2.491400
		loss: 2.491300
		loss: 2.491300
		loss: 2.491200
		loss: 2.491100
		loss: 2.491100
		loss: 2.491000
		loss: 2.491000
		loss: 2.490900
		loss: 2.490800
		loss: 2.490800
		loss: 2.490700
		loss: 2.490700
		loss: 2.490600
		loss: 2.490500
		loss: 2.490500
		loss: 2.490400
		loss: 2.490400
		loss: 2.490300
		loss: 2.490300
		loss: 2.490200
		loss: 2.490200
		loss: 2.490100
		loss: 2.490100
		loss: 2.490000
		loss: 2.490000
		loss: 2.489900
		loss: 2.489900
		loss: 2.489800
		loss: 2.489800
		loss: 2.489700
		loss: 2.489700
		loss: 2.489600
		loss: 2.489600
		loss: 2.489500
		loss: 2.489500
		loss: 2.489400
		loss: 2.489400
		loss: 2.489300
		loss: 2.489300
		loss: 2.489200
		loss: 2.489200
		loss: 2.489100
		loss: 2.489100
		loss: 2.489000
		loss: 2.489000
		loss: 2.488900
		loss: 2.488900
		loss: 2.488800
		loss: 2.488800
		loss: 2.488800
		loss: 2.488700
		loss: 2.488700
		loss: 2.488600
		loss: 2.488600
		loss: 2.488500
		loss: 2.488500
		loss: 2.488400
		loss: 2.488400
		loss: 2.488300
		loss: 2.488300
		loss: 2.488200
		loss: 2.488200
		loss: 2.488200
		loss: 2.488100
		loss: 2.488100
		loss: 2.488000
		loss: 2.488000
		loss: 2.487900
		loss: 2.487900
		loss: 2.487800
		loss: 2.487800
		loss: 2.487800
		loss: 2.487700
		loss: 2.487700
		loss: 2.487600
		loss: 2.487600
		loss: 2.487500
		loss: 2.487500
		loss: 2.487400
		loss: 2.487400
		loss: 2.487400
		loss: 2.487300
		loss: 2.487300
		loss: 2.487200
		loss: 2.487200
		loss: 2.487100
		loss: 2.487100
		loss: 2.487100
		loss: 2.487000
		loss: 2.487000
		loss: 2.486900
		loss: 2.486900
		loss: 2.486800
	Overall the loss development was 2.491800 -> 2.486800
In the epoch 2 for problem d-02.pddl 0 explorations in the sampling searches reached a goal
Success rate: 0

Epoch 3:
Training data for problem d-01.pddl in epoch 3:
model creation time: 7.39979362487793s
problem epoch data for epoch 3, problem epoch 1
	sampling search time: 1.9688489437103271s
	during this search the following actions were chosen:
		close boot was chosen with probability 0.000000
	training time: 37.71442437171936s
	during the training the following losses were computed:
		loss: 1.682100
		loss: 1.794300
		loss: 1.681000
		loss: 1.712900
		loss: 1.729600
		loss: 1.690100
		loss: 1.665900
		loss: 1.682900
		loss: 1.699300
		loss: 1.690600
		loss: 1.672000
		loss: 1.665100
		loss: 1.673100
		loss: 1.680900
		loss: 1.677800
		loss: 1.668600
		loss: 1.664400
		loss: 1.667600
		loss: 1.671300
		loss: 1.669700
		loss: 1.665200
		loss: 1.662900
		loss: 1.664500
		loss: 1.666500
		loss: 1.665600
		loss: 1.662700
		loss: 1.661200
		loss: 1.662300
		loss: 1.663900
		loss: 1.663300
		loss: 1.661300
		loss: 1.660300
		loss: 1.661000
		loss: 1.662000
		loss: 1.661600
		loss: 1.660400
		loss: 1.659900
		loss: 1.660400
		loss: 1.660800
		loss: 1.660300
		loss: 1.659500
		loss: 1.659300
		loss: 1.659800
		loss: 1.660000
		loss: 1.659500
		loss: 1.658900
		loss: 1.659000
		loss: 1.659300
		loss: 1.659300
		loss: 1.658900
		loss: 1.658600
		loss: 1.658700
		loss: 1.658800
		loss: 1.658700
		loss: 1.658400
		loss: 1.658400
		loss: 1.658400
		loss: 1.658300
		loss: 1.658200
		loss: 1.658100
		loss: 1.658100
		loss: 1.658100
		loss: 1.658000
		loss: 1.657900
		loss: 1.657800
		loss: 1.657800
		loss: 1.657700
		loss: 1.657600
		loss: 1.657600
		loss: 1.657600
		loss: 1.657500
		loss: 1.657400
		loss: 1.657400
		loss: 1.657300
		loss: 1.657300
		loss: 1.657200
		loss: 1.657200
		loss: 1.657100
		loss: 1.657100
		loss: 1.657000
		loss: 1.656900
		loss: 1.656900
		loss: 1.656800
		loss: 1.656800
		loss: 1.656700
		loss: 1.656700
		loss: 1.656600
		loss: 1.656600
		loss: 1.656500
		loss: 1.656500
		loss: 1.656400
		loss: 1.656400
		loss: 1.656300
		loss: 1.656300
		loss: 1.656200
		loss: 1.656200
		loss: 1.656100
		loss: 1.656100
		loss: 1.656000
		loss: 1.656000
	Overall the loss development was 1.682100 -> 1.656000
problem epoch data for epoch 3, problem epoch 2
	sampling search time: 1.9326634407043457s
	during this search the following actions were chosen:
		close boot was chosen with probability 0.000000
	training time: 10.126650333404541s
	during the training the following losses were computed:
		loss: 1.655900
		loss: 1.655900
		loss: 1.655800
		loss: 1.655800
		loss: 1.655700
		loss: 1.655700
		loss: 1.655600
		loss: 1.655600
		loss: 1.655500
		loss: 1.655500
		loss: 1.655400
		loss: 1.655400
		loss: 1.655300
		loss: 1.655300
		loss: 1.655200
		loss: 1.655200
		loss: 1.655200
		loss: 1.655100
		loss: 1.655100
		loss: 1.655000
		loss: 1.655000
		loss: 1.654900
		loss: 1.654900
		loss: 1.654800
		loss: 1.654800
		loss: 1.654700
		loss: 1.654700
		loss: 1.654600
		loss: 1.654600
		loss: 1.654500
		loss: 1.654500
		loss: 1.654500
		loss: 1.654400
		loss: 1.654400
		loss: 1.654300
		loss: 1.654300
		loss: 1.654200
		loss: 1.654200
		loss: 1.654100
		loss: 1.654100
		loss: 1.654000
		loss: 1.654000
		loss: 1.654000
		loss: 1.653900
		loss: 1.653900
		loss: 1.653800
		loss: 1.653800
		loss: 1.653700
		loss: 1.653700
		loss: 1.653600
		loss: 1.653600
		loss: 1.653500
		loss: 1.653500
		loss: 1.653500
		loss: 1.653400
		loss: 1.653400
		loss: 1.653300
		loss: 1.653300
		loss: 1.653200
		loss: 1.653200
		loss: 1.653200
		loss: 1.653100
		loss: 1.653100
		loss: 1.653000
		loss: 1.653000
		loss: 1.652900
		loss: 1.652900
		loss: 1.652900
		loss: 1.652800
		loss: 1.652800
		loss: 1.652700
		loss: 1.652700
		loss: 1.652600
		loss: 1.652600
		loss: 1.652500
		loss: 1.652500
		loss: 1.652500
		loss: 1.652400
		loss: 1.652400
		loss: 1.652300
		loss: 1.652300
		loss: 1.652300
		loss: 1.652200
		loss: 1.652200
		loss: 1.652100
		loss: 1.652100
		loss: 1.652000
		loss: 1.652000
		loss: 1.652000
		loss: 1.651900
		loss: 1.651900
		loss: 1.651800
		loss: 1.651800
		loss: 1.651700
		loss: 1.651700
		loss: 1.651700
		loss: 1.651600
		loss: 1.651600
		loss: 1.651500
		loss: 1.651500
	Overall the loss development was 1.655900 -> 1.651500
problem epoch data for epoch 3, problem epoch 3
	sampling search time: 1.9369688034057617s
	during this search the following actions were chosen:
		close boot was chosen with probability 0.000000
	training time: 10.12701416015625s
	during the training the following losses were computed:
		loss: 1.651500
		loss: 1.651400
		loss: 1.651400
		loss: 1.651300
		loss: 1.651300
		loss: 1.651300
		loss: 1.651200
		loss: 1.651200
		loss: 1.651100
		loss: 1.651100
		loss: 1.651000
		loss: 1.651000
		loss: 1.651000
		loss: 1.650900
		loss: 1.650900
		loss: 1.650800
		loss: 1.650800
		loss: 1.650800
		loss: 1.650700
		loss: 1.650700
		loss: 1.650600
		loss: 1.650600
		loss: 1.650600
		loss: 1.650500
		loss: 1.650500
		loss: 1.650400
		loss: 1.650400
		loss: 1.650400
		loss: 1.650300
		loss: 1.650300
		loss: 1.650200
		loss: 1.650200
		loss: 1.650200
		loss: 1.650100
		loss: 1.650100
		loss: 1.650000
		loss: 1.650000
		loss: 1.650000
		loss: 1.649900
		loss: 1.649900
		loss: 1.649800
		loss: 1.649800
		loss: 1.649800
		loss: 1.649700
		loss: 1.649700
		loss: 1.649600
		loss: 1.649600
		loss: 1.649600
		loss: 1.649500
		loss: 1.649500
		loss: 1.649400
		loss: 1.649400
		loss: 1.649400
		loss: 1.649300
		loss: 1.649300
		loss: 1.649300
		loss: 1.649200
		loss: 1.649200
		loss: 1.649100
		loss: 1.649100
		loss: 1.649100
		loss: 1.649000
		loss: 1.649000
		loss: 1.648900
		loss: 1.648900
		loss: 1.648900
		loss: 1.648800
		loss: 1.648800
		loss: 1.648700
		loss: 1.648700
		loss: 1.648700
		loss: 1.648600
		loss: 1.648600
		loss: 1.648600
		loss: 1.648500
		loss: 1.648500
		loss: 1.648400
		loss: 1.648400
		loss: 1.648400
		loss: 1.648300
		loss: 1.648300
		loss: 1.648200
		loss: 1.648200
		loss: 1.648200
		loss: 1.648100
		loss: 1.648100
		loss: 1.648100
		loss: 1.648000
		loss: 1.648000
		loss: 1.647900
		loss: 1.647900
		loss: 1.647900
		loss: 1.647800
		loss: 1.647800
		loss: 1.647800
		loss: 1.647700
		loss: 1.647700
		loss: 1.647600
		loss: 1.647600
		loss: 1.647600
	Overall the loss development was 1.651500 -> 1.647600
In the epoch 3 for problem d-01.pddl 0 explorations in the sampling searches reached a goal
Training data for problem d-02.pddl in epoch 3:
model creation time: 15.877518892288208s
problem epoch data for epoch 3, problem epoch 1
	sampling search time: 213.81457805633545s
	during this search the following actions were chosen:
		open boot was chosen with probability 1.000000
		fetch wrench boot was chosen with probability 0.514589
		fetch jack boot was chosen with probability 0.836729
		fetch pump boot was chosen with probability 0.291767
		loosen nuts1 the-hub1 was chosen with probability 0.348325
		loosen nuts2 the-hub2 was chosen with probability 0.621926
		fetch r2 boot was chosen with probability 0.600033
		fetch r1 boot was chosen with probability 0.977340
		jack-up the-hub1 was chosen with probability 0.944609
		undo nuts1 the-hub1 was chosen with probability 0.999999
		remove-wheel w1 the-hub1 was chosen with probability 0.997253
		put-on-wheel r1 the-hub1 was chosen with probability 0.944791
		put-away w1 boot was chosen with probability 0.717063
		inflate r1 was chosen with probability 0.456435
		inflate r2 was chosen with probability 0.863288
		remove-wheel r1 the-hub1 was chosen with probability 1.000000
		put-on-wheel r2 the-hub1 was chosen with probability 0.603178
		remove-wheel r2 the-hub1 was chosen with probability 1.000000
	training time: 63.48181080818176s
	during the training the following losses were computed:
		loss: 3.120700
		loss: 3.064200
		loss: 2.997500
		loss: 2.946100
		loss: 2.921400
		loss: 2.901700
		loss: 2.886400
		loss: 2.880900
		loss: 2.877700
		loss: 2.870800
		loss: 2.864300
		loss: 2.860300
		loss: 2.856300
		loss: 2.852600
		loss: 2.851700
		loss: 2.852800
		loss: 2.852900
		loss: 2.851900
		loss: 2.851000
		loss: 2.848700
		loss: 2.844900
		loss: 2.841500
		loss: 2.839000
		loss: 2.836300
		loss: 2.833700
		loss: 2.832200
		loss: 2.831200
		loss: 2.829900
		loss: 2.828600
		loss: 2.827500
		loss: 2.826100
		loss: 2.824800
		loss: 2.824100
		loss: 2.823400
		loss: 2.822800
		loss: 2.822400
		loss: 2.822000
		loss: 2.821200
		loss: 2.820400
		loss: 2.819600
		loss: 2.818700
		loss: 2.817900
		loss: 2.817300
		loss: 2.816800
		loss: 2.816300
		loss: 2.815900
		loss: 2.815500
		loss: 2.815100
		loss: 2.814800
		loss: 2.814400
		loss: 2.814200
		loss: 2.814000
		loss: 2.813700
		loss: 2.813400
		loss: 2.813100
		loss: 2.812700
		loss: 2.812400
		loss: 2.812100
		loss: 2.811800
		loss: 2.811600
		loss: 2.811400
		loss: 2.811200
		loss: 2.811000
		loss: 2.810800
		loss: 2.810600
		loss: 2.810400
		loss: 2.810300
		loss: 2.810100
		loss: 2.809900
		loss: 2.809800
		loss: 2.809600
		loss: 2.809400
		loss: 2.809300
		loss: 2.809100
		loss: 2.809000
		loss: 2.808800
		loss: 2.808700
		loss: 2.808600
		loss: 2.808500
		loss: 2.808300
		loss: 2.808200
		loss: 2.808100
		loss: 2.808000
		loss: 2.807800
		loss: 2.807700
		loss: 2.807600
		loss: 2.807500
		loss: 2.807400
		loss: 2.807300
		loss: 2.807200
		loss: 2.807100
		loss: 2.807000
		loss: 2.806900
		loss: 2.806800
		loss: 2.806700
		loss: 2.806600
		loss: 2.806500
		loss: 2.806500
		loss: 2.806400
		loss: 2.806300
	Overall the loss development was 3.120700 -> 2.806300
problem epoch data for epoch 3, problem epoch 2
	sampling search time: 33.2514374256134s
	during this search the following actions were chosen:
		close boot was chosen with probability 0.000000
	training time: 11.17875337600708s
	during the training the following losses were computed:
		loss: 2.806200
		loss: 2.806100
		loss: 2.806000
		loss: 2.806000
		loss: 2.805900
		loss: 2.805800
		loss: 2.805700
		loss: 2.805700
		loss: 2.805600
		loss: 2.805500
		loss: 2.805500
		loss: 2.805400
		loss: 2.805300
		loss: 2.805300
		loss: 2.805200
		loss: 2.805100
		loss: 2.805100
		loss: 2.805000
		loss: 2.804900
		loss: 2.804900
		loss: 2.804800
		loss: 2.804700
		loss: 2.804700
		loss: 2.804600
		loss: 2.804600
		loss: 2.804500
		loss: 2.804400
		loss: 2.804400
		loss: 2.804300
		loss: 2.804300
		loss: 2.804200
		loss: 2.804200
		loss: 2.804100
		loss: 2.804000
		loss: 2.804000
		loss: 2.803900
		loss: 2.803900
		loss: 2.803800
		loss: 2.803800
		loss: 2.803700
		loss: 2.803700
		loss: 2.803600
		loss: 2.803600
		loss: 2.803500
		loss: 2.803500
		loss: 2.803400
		loss: 2.803400
		loss: 2.803300
		loss: 2.803300
		loss: 2.803200
		loss: 2.803200
		loss: 2.803100
		loss: 2.803000
		loss: 2.803000
		loss: 2.802900
		loss: 2.802900
		loss: 2.802800
		loss: 2.802800
		loss: 2.802700
		loss: 2.802700
		loss: 2.802600
		loss: 2.802600
		loss: 2.802600
		loss: 2.802500
		loss: 2.802500
		loss: 2.802400
		loss: 2.802400
		loss: 2.802300
		loss: 2.802300
		loss: 2.802200
		loss: 2.802200
		loss: 2.802100
		loss: 2.802100
		loss: 2.802000
		loss: 2.802000
		loss: 2.801900
		loss: 2.801900
		loss: 2.801800
		loss: 2.801800
		loss: 2.801700
		loss: 2.801700
		loss: 2.801600
		loss: 2.801600
		loss: 2.801500
		loss: 2.801500
		loss: 2.801400
		loss: 2.801400
		loss: 2.801400
		loss: 2.801300
		loss: 2.801300
		loss: 2.801200
		loss: 2.801200
		loss: 2.801100
		loss: 2.801100
		loss: 2.801000
		loss: 2.801000
		loss: 2.800900
		loss: 2.800900
		loss: 2.800800
		loss: 2.800800
	Overall the loss development was 2.806200 -> 2.800800
problem epoch data for epoch 3, problem epoch 3
	sampling search time: 206.63451385498047s
	during this search the following actions were chosen:
		open boot was chosen with probability 1.000000
		fetch wrench boot was chosen with probability 0.412180
		fetch jack boot was chosen with probability 0.827244
		fetch r1 boot was chosen with probability 0.296580
		fetch r2 boot was chosen with probability 0.450354
		fetch pump boot was chosen with probability 0.498634
		loosen nuts1 the-hub1 was chosen with probability 0.554938
		loosen nuts2 the-hub2 was chosen with probability 0.993928
		inflate r1 was chosen with probability 0.496135
		inflate r2 was chosen with probability 0.893801
		jack-up the-hub1 was chosen with probability 0.992811
		undo nuts1 the-hub1 was chosen with probability 1.000000
		remove-wheel w1 the-hub1 was chosen with probability 1.000000
		put-on-wheel r1 the-hub1 was chosen with probability 0.998308
		remove-wheel r1 the-hub1 was chosen with probability 0.999923
	training time: 16.79767394065857s
	during the training the following losses were computed:
		loss: 3.879000
		loss: 2.839400
		loss: 3.052600
		loss: 2.834200
		loss: 2.940200
		loss: 2.832000
		loss: 3.100000
		loss: 2.834300
		loss: 2.917700
		loss: 2.832000
		loss: 2.487800
		loss: 2.834900
		loss: 3.007500
		loss: 2.834000
		loss: 2.490800
		loss: 2.830400
		loss: 3.002900
		loss: 2.831300
		loss: 3.014600
		loss: 2.833900
		loss: 2.641500
		loss: 2.833700
		loss: 2.528600
		loss: 2.834700
		loss: 3.005200
		loss: 2.834100
		loss: 2.944800
		loss: 2.831600
		loss: 2.409600
		loss: 2.835200
		loss: 2.837800
		loss: 2.832800
		loss: 2.287900
		loss: 2.828800
		loss: 3.238300
		loss: 2.834400
		loss: 2.492500
		loss: 2.835000
		loss: 2.906800
		loss: 2.831600
		loss: 2.304900
		loss: 2.828600
		loss: 2.770800
		loss: 2.831800
		loss: 3.091800
		loss: 2.829800
		loss: 2.794900
		loss: 2.831400
		loss: 2.808000
		loss: 2.831800
		loss: 2.970300
		loss: 2.830400
		loss: 2.927300
		loss: 2.830600
		loss: 2.887800
		loss: 2.831800
		loss: 2.752400
		loss: 2.830800
		loss: 2.639600
		loss: 2.832300
		loss: 2.970200
		loss: 2.831900
		loss: 3.082400
		loss: 2.829200
		loss: 3.376200
		loss: 2.828100
		loss: 2.638800
		loss: 2.832700
		loss: 2.667200
		loss: 2.829800
		loss: 2.512800
		loss: 2.829400
		loss: 2.818200
		loss: 2.830800
		loss: 2.894900
		loss: 2.831400
		loss: 2.262500
		loss: 2.827200
		loss: 2.993000
		loss: 2.829300
		loss: 3.039100
		loss: 2.831400
		loss: 2.547200
		loss: 2.828300
		loss: 2.834900
		loss: 2.830200
		loss: 2.661600
		loss: 2.828700
		loss: 2.799600
		loss: 2.829800
		loss: 2.414000
		loss: 2.826800
		loss: 2.831500
		loss: 2.829600
		loss: 3.213000
		loss: 2.831800
		loss: 2.203400
		loss: 2.825400
		loss: 3.227900
		loss: 2.827000
		loss: 2.480200
		loss: 2.827000
		loss: 2.638600
		loss: 2.827800
		loss: 2.860100
		loss: 2.828800
		loss: 2.493800
		loss: 2.831400
		loss: 2.784000
		loss: 2.828800
		loss: 2.756100
		loss: 2.830000
		loss: 3.012500
		loss: 2.828700
		loss: 3.006900
		loss: 2.830700
		loss: 2.898500
		loss: 2.829300
		loss: 2.988000
		loss: 2.827800
		loss: 3.169400
		loss: 2.830900
		loss: 2.788000
		loss: 2.828300
		loss: 2.965100
		loss: 2.827400
		loss: 2.883100
		loss: 2.827900
		loss: 2.922400
		loss: 2.827500
		loss: 3.226100
		loss: 2.825700
		loss: 2.509700
		loss: 2.826300
		loss: 3.040500
		loss: 2.829500
		loss: 2.612700
		loss: 2.826700
		loss: 2.870200
		loss: 2.827800
		loss: 2.652600
		loss: 2.829000
		loss: 3.284000
		loss: 2.831000
		loss: 3.021700
		loss: 2.827100
		loss: 2.719500
		loss: 2.829400
		loss: 2.723500
		loss: 2.829600
		loss: 2.786600
		loss: 2.827900
		loss: 2.866900
		loss: 2.827900
		loss: 2.944200
		loss: 2.827600
		loss: 2.794400
		loss: 2.828300
		loss: 2.949100
		loss: 2.827600
		loss: 2.469700
		loss: 2.825800
		loss: 3.413200
		loss: 2.831700
		loss: 3.479400
		loss: 2.824900
		loss: 3.116300
		loss: 2.831900
		loss: 3.346800
		loss: 2.829200
		loss: 2.765400
		loss: 2.830000
		loss: 2.482300
		loss: 2.831300
		loss: 2.772400
		loss: 2.828100
		loss: 3.221800
		loss: 2.826300
		loss: 2.367700
		loss: 2.832000
		loss: 3.320400
		loss: 2.834000
		loss: 2.710300
		loss: 2.832800
		loss: 2.670900
		loss: 2.833700
		loss: 2.725200
		loss: 2.833000
		loss: 2.367300
		loss: 2.830400
		loss: 2.774200
		loss: 2.832700
		loss: 2.585300
		loss: 2.832600
		loss: 3.136800
		loss: 2.827000
		loss: 2.646500
		loss: 2.829400
		loss: 2.977400
		loss: 2.827400
	Overall the loss development was 3.879000 -> 2.827400
In the epoch 3 for problem d-02.pddl 0 explorations in the sampling searches reached a goal
Success rate: 0

Epoch 4:
Training data for problem d-01.pddl in epoch 4:
model creation time: 7.909289360046387s
problem epoch data for epoch 4, problem epoch 1
	sampling search time: 2.061312437057495s
	during this search the following actions were chosen:
		close boot was chosen with probability 0.000000
	training time: 37.483853578567505s
	during the training the following losses were computed:
		loss: 1.683300
		loss: 1.680900
		loss: 1.686700
		loss: 1.658000
		loss: 1.656100
		loss: 1.661100
		loss: 1.652200
		loss: 1.653400
		loss: 1.653600
		loss: 1.648100
		loss: 1.647800
		loss: 1.650100
		loss: 1.647500
		loss: 1.645600
		loss: 1.648300
		loss: 1.649000
		loss: 1.645900
		loss: 1.644500
		loss: 1.645400
		loss: 1.645100
		loss: 1.644400
		loss: 1.645000
		loss: 1.644800
		loss: 1.643100
		loss: 1.642700
		loss: 1.643500
		loss: 1.643200
		loss: 1.642300
		loss: 1.642300
		loss: 1.642200
		loss: 1.641700
		loss: 1.641800
		loss: 1.642200
		loss: 1.641800
		loss: 1.641400
		loss: 1.641600
		loss: 1.641500
		loss: 1.641200
		loss: 1.641200
		loss: 1.641300
		loss: 1.641100
		loss: 1.641000
		loss: 1.641000
		loss: 1.640800
		loss: 1.640700
		loss: 1.640800
		loss: 1.640700
		loss: 1.640500
		loss: 1.640500
		loss: 1.640400
		loss: 1.640300
		loss: 1.640400
		loss: 1.640300
		loss: 1.640200
		loss: 1.640200
		loss: 1.640100
		loss: 1.640100
		loss: 1.640100
		loss: 1.640000
		loss: 1.639900
		loss: 1.639900
		loss: 1.639900
		loss: 1.639800
		loss: 1.639800
		loss: 1.639700
		loss: 1.639700
		loss: 1.639600
		loss: 1.639600
		loss: 1.639500
		loss: 1.639500
		loss: 1.639500
		loss: 1.639400
		loss: 1.639400
		loss: 1.639300
		loss: 1.639300
		loss: 1.639300
		loss: 1.639200
		loss: 1.639200
		loss: 1.639100
		loss: 1.639100
		loss: 1.639100
		loss: 1.639000
		loss: 1.639000
		loss: 1.638900
		loss: 1.638900
		loss: 1.638900
		loss: 1.638800
		loss: 1.638800
		loss: 1.638700
		loss: 1.638700
		loss: 1.638700
		loss: 1.638600
		loss: 1.638600
		loss: 1.638500
		loss: 1.638500
		loss: 1.638500
		loss: 1.638400
		loss: 1.638400
		loss: 1.638400
		loss: 1.638300
	Overall the loss development was 1.683300 -> 1.638300
problem epoch data for epoch 4, problem epoch 2
	sampling search time: 1.9189653396606445s
	during this search the following actions were chosen:
		close boot was chosen with probability 0.000000
	training time: 10.127475500106812s
	during the training the following losses were computed:
		loss: 1.638300
		loss: 1.638200
		loss: 1.638200
		loss: 1.638200
		loss: 1.638100
		loss: 1.638100
		loss: 1.638000
		loss: 1.638000
		loss: 1.638000
		loss: 1.637900
		loss: 1.637900
		loss: 1.637900
		loss: 1.637800
		loss: 1.637800
		loss: 1.637700
		loss: 1.637700
		loss: 1.637700
		loss: 1.637600
		loss: 1.637600
		loss: 1.637600
		loss: 1.637500
		loss: 1.637500
		loss: 1.637400
		loss: 1.637400
		loss: 1.637400
		loss: 1.637300
		loss: 1.637300
		loss: 1.637300
		loss: 1.637200
		loss: 1.637200
		loss: 1.637100
		loss: 1.637100
		loss: 1.637100
		loss: 1.637000
		loss: 1.637000
		loss: 1.637000
		loss: 1.636900
		loss: 1.636900
		loss: 1.636900
		loss: 1.636800
		loss: 1.636800
		loss: 1.636700
		loss: 1.636700
		loss: 1.636700
		loss: 1.636600
		loss: 1.636600
		loss: 1.636600
		loss: 1.636500
		loss: 1.636500
		loss: 1.636500
		loss: 1.636400
		loss: 1.636400
		loss: 1.636300
		loss: 1.636300
		loss: 1.636300
		loss: 1.636200
		loss: 1.636200
		loss: 1.636200
		loss: 1.636100
		loss: 1.636100
		loss: 1.636100
		loss: 1.636000
		loss: 1.636000
		loss: 1.636000
		loss: 1.635900
		loss: 1.635900
		loss: 1.635900
		loss: 1.635800
		loss: 1.635800
		loss: 1.635800
		loss: 1.635700
		loss: 1.635700
		loss: 1.635600
		loss: 1.635600
		loss: 1.635600
		loss: 1.635500
		loss: 1.635500
		loss: 1.635500
		loss: 1.635400
		loss: 1.635400
		loss: 1.635400
		loss: 1.635300
		loss: 1.635300
		loss: 1.635300
		loss: 1.635200
		loss: 1.635200
		loss: 1.635200
		loss: 1.635100
		loss: 1.635100
		loss: 1.635100
		loss: 1.635000
		loss: 1.635000
		loss: 1.635000
		loss: 1.634900
		loss: 1.634900
		loss: 1.634900
		loss: 1.634800
		loss: 1.634800
		loss: 1.634800
		loss: 1.634700
	Overall the loss development was 1.638300 -> 1.634700
problem epoch data for epoch 4, problem epoch 3
	sampling search time: 1.8924918174743652s
	during this search the following actions were chosen:
		close boot was chosen with probability 0.000000
	training time: 10.128064632415771s
	during the training the following losses were computed:
		loss: 1.634700
		loss: 1.634700
		loss: 1.634600
		loss: 1.634600
		loss: 1.634600
		loss: 1.634500
		loss: 1.634500
		loss: 1.634500
		loss: 1.634400
		loss: 1.634400
		loss: 1.634400
		loss: 1.634400
		loss: 1.634300
		loss: 1.634300
		loss: 1.634300
		loss: 1.634200
		loss: 1.634200
		loss: 1.634200
		loss: 1.634100
		loss: 1.634100
		loss: 1.634100
		loss: 1.634000
		loss: 1.634000
		loss: 1.634000
		loss: 1.633900
		loss: 1.633900
		loss: 1.633900
		loss: 1.633800
		loss: 1.633800
		loss: 1.633800
		loss: 1.633700
		loss: 1.633700
		loss: 1.633700
		loss: 1.633700
		loss: 1.633600
		loss: 1.633600
		loss: 1.633600
		loss: 1.633500
		loss: 1.633500
		loss: 1.633500
		loss: 1.633400
		loss: 1.633400
		loss: 1.633400
		loss: 1.633300
		loss: 1.633300
		loss: 1.633300
		loss: 1.633300
		loss: 1.633200
		loss: 1.633200
		loss: 1.633200
		loss: 1.633100
		loss: 1.633100
		loss: 1.633100
		loss: 1.633000
		loss: 1.633000
		loss: 1.633000
		loss: 1.632900
		loss: 1.632900
		loss: 1.632900
		loss: 1.632900
		loss: 1.632800
		loss: 1.632800
		loss: 1.632800
		loss: 1.632700
		loss: 1.632700
		loss: 1.632700
		loss: 1.632600
		loss: 1.632600
		loss: 1.632600
		loss: 1.632600
		loss: 1.632500
		loss: 1.632500
		loss: 1.632500
		loss: 1.632400
		loss: 1.632400
		loss: 1.632400
		loss: 1.632400
		loss: 1.632300
		loss: 1.632300
		loss: 1.632300
		loss: 1.632200
		loss: 1.632200
		loss: 1.632200
		loss: 1.632100
		loss: 1.632100
		loss: 1.632100
		loss: 1.632100
		loss: 1.632000
		loss: 1.632000
		loss: 1.632000
		loss: 1.631900
		loss: 1.631900
		loss: 1.631900
		loss: 1.631900
		loss: 1.631800
		loss: 1.631800
		loss: 1.631800
		loss: 1.631700
		loss: 1.631700
		loss: 1.631700
	Overall the loss development was 1.634700 -> 1.631700
In the epoch 4 for problem d-01.pddl 0 explorations in the sampling searches reached a goal
Training data for problem d-02.pddl in epoch 4:
model creation time: 15.389333724975586s
problem epoch data for epoch 4, problem epoch 1
	sampling search time: 33.21847081184387s
	during this search the following actions were chosen:
		close boot was chosen with probability 0.000000
	training time: 62.12442946434021s
	during the training the following losses were computed:
		loss: 2.605800
		loss: 2.562300
		loss: 2.562400
		loss: 2.544600
		loss: 2.543100
		loss: 2.532600
		loss: 2.533500
		loss: 2.527800
		loss: 2.522900
		loss: 2.525300
		loss: 2.521800
		loss: 2.517700
		loss: 2.516400
		loss: 2.512600
		loss: 2.510900
		loss: 2.512300
		loss: 2.510500
		loss: 2.507700
		loss: 2.506600
		loss: 2.504400
		loss: 2.502800
		loss: 2.502900
		loss: 2.501800
		loss: 2.500800
		loss: 2.500900
		loss: 2.500300
		loss: 2.499400
		loss: 2.499300
		loss: 2.498700
		loss: 2.498300
		loss: 2.498400
		loss: 2.497900
		loss: 2.497200
		loss: 2.497100
		loss: 2.496700
		loss: 2.496500
		loss: 2.496400
		loss: 2.495800
		loss: 2.495500
		loss: 2.495300
		loss: 2.494900
		loss: 2.494800
		loss: 2.494600
		loss: 2.494400
		loss: 2.494300
		loss: 2.494000
		loss: 2.493800
		loss: 2.493700
		loss: 2.493400
		loss: 2.493300
		loss: 2.493200
		loss: 2.493000
		loss: 2.492900
		loss: 2.492800
		loss: 2.492700
		loss: 2.492500
		loss: 2.492400
		loss: 2.492400
		loss: 2.492300
		loss: 2.492200
		loss: 2.492100
		loss: 2.492000
		loss: 2.491900
		loss: 2.491800
		loss: 2.491700
		loss: 2.491700
		loss: 2.491600
		loss: 2.491500
		loss: 2.491500
		loss: 2.491400
		loss: 2.491400
		loss: 2.491300
		loss: 2.491300
		loss: 2.491200
		loss: 2.491200
		loss: 2.491100
		loss: 2.491100
		loss: 2.491000
		loss: 2.491000
		loss: 2.490900
		loss: 2.490900
		loss: 2.490800
		loss: 2.490800
		loss: 2.490800
		loss: 2.490700
		loss: 2.490700
		loss: 2.490700
		loss: 2.490600
		loss: 2.490600
		loss: 2.490500
		loss: 2.490500
		loss: 2.490500
		loss: 2.490400
		loss: 2.490400
		loss: 2.490400
		loss: 2.490300
		loss: 2.490300
		loss: 2.490300
		loss: 2.490300
		loss: 2.490200
	Overall the loss development was 2.605800 -> 2.490200
problem epoch data for epoch 4, problem epoch 2
	sampling search time: 33.3874192237854s
	during this search the following actions were chosen:
		close boot was chosen with probability 0.000000
	training time: 10.137813568115234s
	during the training the following losses were computed:
		loss: 2.490200
		loss: 2.490200
		loss: 2.490100
		loss: 2.490100
		loss: 2.490100
		loss: 2.490000
		loss: 2.490000
		loss: 2.490000
		loss: 2.490000
		loss: 2.489900
		loss: 2.489900
		loss: 2.489900
		loss: 2.489800
		loss: 2.489800
		loss: 2.489800
		loss: 2.489800
		loss: 2.489700
		loss: 2.489700
		loss: 2.489700
		loss: 2.489600
		loss: 2.489600
		loss: 2.489600
		loss: 2.489600
		loss: 2.489500
		loss: 2.489500
		loss: 2.489500
		loss: 2.489500
		loss: 2.489400
		loss: 2.489400
		loss: 2.489400
		loss: 2.489400
		loss: 2.489300
		loss: 2.489300
		loss: 2.489300
		loss: 2.489300
		loss: 2.489200
		loss: 2.489200
		loss: 2.489200
		loss: 2.489100
		loss: 2.489100
		loss: 2.489100
		loss: 2.489100
		loss: 2.489000
		loss: 2.489000
		loss: 2.489000
		loss: 2.489000
		loss: 2.488900
		loss: 2.488900
		loss: 2.488900
		loss: 2.488900
		loss: 2.488800
		loss: 2.488800
		loss: 2.488800
		loss: 2.488800
		loss: 2.488700
		loss: 2.488700
		loss: 2.488700
		loss: 2.488700
		loss: 2.488700
		loss: 2.488600
		loss: 2.488600
		loss: 2.488600
		loss: 2.488600
		loss: 2.488500
		loss: 2.488500
		loss: 2.488500
		loss: 2.488500
		loss: 2.488400
		loss: 2.488400
		loss: 2.488400
		loss: 2.488400
		loss: 2.488300
		loss: 2.488300
		loss: 2.488300
		loss: 2.488300
		loss: 2.488200
		loss: 2.488200
		loss: 2.488200
		loss: 2.488200
		loss: 2.488100
		loss: 2.488100
		loss: 2.488100
		loss: 2.488100
		loss: 2.488000
		loss: 2.488000
		loss: 2.488000
		loss: 2.488000
		loss: 2.488000
		loss: 2.487900
		loss: 2.487900
		loss: 2.487900
		loss: 2.487900
		loss: 2.487800
		loss: 2.487800
		loss: 2.487800
		loss: 2.487800
		loss: 2.487700
		loss: 2.487700
		loss: 2.487700
		loss: 2.487700
	Overall the loss development was 2.490200 -> 2.487700
problem epoch data for epoch 4, problem epoch 3
	sampling search time: 212.55327439308167s
	during this search the following actions were chosen:
		open boot was chosen with probability 1.000000
		fetch wrench boot was chosen with probability 0.411735
		fetch jack boot was chosen with probability 0.813232
		fetch r1 boot was chosen with probability 0.354670
		fetch r2 boot was chosen with probability 0.597590
		fetch pump boot was chosen with probability 0.526005
		loosen nuts1 the-hub1 was chosen with probability 0.534045
		loosen nuts2 the-hub2 was chosen with probability 0.999724
		jack-up the-hub1 was chosen with probability 0.575347
		undo nuts1 the-hub1 was chosen with probability 0.999999
		remove-wheel w1 the-hub1 was chosen with probability 0.998838
		put-on-wheel r1 the-hub1 was chosen with probability 0.729421
		put-away w1 boot was chosen with probability 0.571526
		remove-wheel r1 the-hub1 was chosen with probability 0.495442
		put-on-wheel r2 the-hub1 was chosen with probability 0.745285
		remove-wheel r2 the-hub1 was chosen with probability 0.577210
	training time: 10.911039352416992s
	during the training the following losses were computed:
		loss: 2.610000
		loss: 2.566500
		loss: 2.533800
		loss: 2.491500
		loss: 2.467600
		loss: 2.441800
		loss: 2.445100
		loss: 2.451300
		loss: 2.455100
		loss: 2.458500
		loss: 2.455700
		loss: 2.456100
		loss: 2.449100
		loss: 2.444400
		loss: 2.443100
		loss: 2.440700
		loss: 2.439900
		loss: 2.436000
		loss: 2.432800
		loss: 2.431300
		loss: 2.427400
		loss: 2.425000
		loss: 2.424200
		loss: 2.424000
		loss: 2.425600
		loss: 2.425600
		loss: 2.425400
		loss: 2.425700
		loss: 2.424600
		loss: 2.423400
		loss: 2.421900
		loss: 2.420700
		loss: 2.420400
		loss: 2.419800
		loss: 2.419300
		loss: 2.419300
		loss: 2.419000
		loss: 2.418900
		loss: 2.418600
		loss: 2.418400
		loss: 2.418400
		loss: 2.418200
		loss: 2.418000
		loss: 2.417900
		loss: 2.417600
		loss: 2.417300
		loss: 2.416900
		loss: 2.416700
		loss: 2.416600
		loss: 2.416500
		loss: 2.416500
		loss: 2.416500
		loss: 2.416500
		loss: 2.416400
		loss: 2.416200
		loss: 2.416100
		loss: 2.416000
		loss: 2.415900
		loss: 2.415800
		loss: 2.415700
		loss: 2.415700
		loss: 2.415600
		loss: 2.415600
		loss: 2.415500
		loss: 2.415500
		loss: 2.415400
		loss: 2.415400
		loss: 2.415300
		loss: 2.415300
		loss: 2.415200
		loss: 2.415200
		loss: 2.415100
		loss: 2.415100
		loss: 2.415000
		loss: 2.415000
		loss: 2.415000
		loss: 2.415000
		loss: 2.414900
		loss: 2.414900
		loss: 2.414900
		loss: 2.414800
		loss: 2.414800
		loss: 2.414800
		loss: 2.414700
		loss: 2.414700
		loss: 2.414700
		loss: 2.414700
		loss: 2.414600
		loss: 2.414600
		loss: 2.414600
		loss: 2.414600
		loss: 2.414500
		loss: 2.414500
		loss: 2.414500
		loss: 2.414500
		loss: 2.414400
		loss: 2.414400
		loss: 2.414400
		loss: 2.414400
		loss: 2.414300
	Overall the loss development was 2.610000 -> 2.414300
In the epoch 4 for problem d-02.pddl 0 explorations in the sampling searches reached a goal
Success rate: 0

Epoch 5:
Training data for problem d-01.pddl in epoch 5:
model creation time: 7.92079496383667s
problem epoch data for epoch 5, problem epoch 1
	sampling search time: 2.073716878890991s
	during this search the following actions were chosen:
		close boot was chosen with probability 0.000000
	training time: 37.2152578830719s
	during the training the following losses were computed:
		loss: 1.697100
		loss: 1.734300
		loss: 1.663400
		loss: 1.673400
		loss: 1.687400
		loss: 1.663600
		loss: 1.644600
		loss: 1.649800
		loss: 1.658500
		loss: 1.653900
		loss: 1.644600
		loss: 1.642400
		loss: 1.646000
		loss: 1.646000
		loss: 1.640500
		loss: 1.636000
		loss: 1.637200
		loss: 1.640800
		loss: 1.641300
		loss: 1.638200
		loss: 1.635000
		loss: 1.634900
		loss: 1.636700
		loss: 1.637100
		loss: 1.635700
		loss: 1.634500
		loss: 1.634800
		loss: 1.635300
		loss: 1.634800
		loss: 1.633700
		loss: 1.633400
		loss: 1.634100
		loss: 1.634500
		loss: 1.633700
		loss: 1.632700
		loss: 1.632500
		loss: 1.633000
		loss: 1.633200
		loss: 1.632800
		loss: 1.632400
		loss: 1.632400
		loss: 1.632500
		loss: 1.632300
		loss: 1.632000
		loss: 1.632000
		loss: 1.632200
		loss: 1.632100
		loss: 1.631800
		loss: 1.631700
		loss: 1.631800
		loss: 1.631900
		loss: 1.631800
		loss: 1.631600
		loss: 1.631600
		loss: 1.631600
		loss: 1.631600
		loss: 1.631500
		loss: 1.631500
		loss: 1.631500
		loss: 1.631400
		loss: 1.631300
		loss: 1.631300
		loss: 1.631300
		loss: 1.631300
		loss: 1.631200
		loss: 1.631200
		loss: 1.631200
		loss: 1.631200
		loss: 1.631100
		loss: 1.631100
		loss: 1.631100
		loss: 1.631100
		loss: 1.631000
		loss: 1.631000
		loss: 1.631000
		loss: 1.631000
		loss: 1.630900
		loss: 1.630900
		loss: 1.630900
		loss: 1.630900
		loss: 1.630900
		loss: 1.630800
		loss: 1.630800
		loss: 1.630800
		loss: 1.630800
		loss: 1.630800
		loss: 1.630700
		loss: 1.630700
		loss: 1.630700
		loss: 1.630700
		loss: 1.630700
		loss: 1.630600
		loss: 1.630600
		loss: 1.630600
		loss: 1.630600
		loss: 1.630600
		loss: 1.630500
		loss: 1.630500
		loss: 1.630500
		loss: 1.630500
	Overall the loss development was 1.697100 -> 1.630500
problem epoch data for epoch 5, problem epoch 2
	sampling search time: 1.9159038066864014s
	during this search the following actions were chosen:
		close boot was chosen with probability 0.000000
	training time: 10.127008199691772s
	during the training the following losses were computed:
		loss: 1.630500
		loss: 1.630400
		loss: 1.630400
		loss: 1.630400
		loss: 1.630400
		loss: 1.630400
		loss: 1.630300
		loss: 1.630300
		loss: 1.630300
		loss: 1.630300
		loss: 1.630300
		loss: 1.630200
		loss: 1.630200
		loss: 1.630200
		loss: 1.630200
		loss: 1.630200
		loss: 1.630100
		loss: 1.630100
		loss: 1.630100
		loss: 1.630100
		loss: 1.630100
		loss: 1.630100
		loss: 1.630000
		loss: 1.630000
		loss: 1.630000
		loss: 1.630000
		loss: 1.630000
		loss: 1.629900
		loss: 1.629900
		loss: 1.629900
		loss: 1.629900
		loss: 1.629900
		loss: 1.629900
		loss: 1.629800
		loss: 1.629800
		loss: 1.629800
		loss: 1.629800
		loss: 1.629800
		loss: 1.629700
		loss: 1.629700
		loss: 1.629700
		loss: 1.629700
		loss: 1.629700
		loss: 1.629700
		loss: 1.629600
		loss: 1.629600
		loss: 1.629600
		loss: 1.629600
		loss: 1.629600
		loss: 1.629500
		loss: 1.629500
		loss: 1.629500
		loss: 1.629500
		loss: 1.629500
		loss: 1.629500
		loss: 1.629400
		loss: 1.629400
		loss: 1.629400
		loss: 1.629400
		loss: 1.629400
		loss: 1.629400
		loss: 1.629300
		loss: 1.629300
		loss: 1.629300
		loss: 1.629300
		loss: 1.629300
		loss: 1.629200
		loss: 1.629200
		loss: 1.629200
		loss: 1.629200
		loss: 1.629200
		loss: 1.629200
		loss: 1.629100
		loss: 1.629100
		loss: 1.629100
		loss: 1.629100
		loss: 1.629100
		loss: 1.629100
		loss: 1.629000
		loss: 1.629000
		loss: 1.629000
		loss: 1.629000
		loss: 1.629000
		loss: 1.629000
		loss: 1.628900
		loss: 1.628900
		loss: 1.628900
		loss: 1.628900
		loss: 1.628900
		loss: 1.628900
		loss: 1.628800
		loss: 1.628800
		loss: 1.628800
		loss: 1.628800
		loss: 1.628800
		loss: 1.628800
		loss: 1.628700
		loss: 1.628700
		loss: 1.628700
		loss: 1.628700
	Overall the loss development was 1.630500 -> 1.628700
problem epoch data for epoch 5, problem epoch 3
	sampling search time: 1.936305046081543s
	during this search the following actions were chosen:
		close boot was chosen with probability 0.000000
	training time: 10.127262353897095s
	during the training the following losses were computed:
		loss: 1.628700
		loss: 1.628700
		loss: 1.628600
		loss: 1.628600
		loss: 1.628600
		loss: 1.628600
		loss: 1.628600
		loss: 1.628600
		loss: 1.628500
		loss: 1.628500
		loss: 1.628500
		loss: 1.628500
		loss: 1.628500
		loss: 1.628500
		loss: 1.628500
		loss: 1.628400
		loss: 1.628400
		loss: 1.628400
		loss: 1.628400
		loss: 1.628400
		loss: 1.628400
		loss: 1.628300
		loss: 1.628300
		loss: 1.628300
		loss: 1.628300
		loss: 1.628300
		loss: 1.628300
		loss: 1.628200
		loss: 1.628200
		loss: 1.628200
		loss: 1.628200
		loss: 1.628200
		loss: 1.628200
		loss: 1.628200
		loss: 1.628100
		loss: 1.628100
		loss: 1.628100
		loss: 1.628100
		loss: 1.628100
		loss: 1.628100
		loss: 1.628000
		loss: 1.628000
		loss: 1.628000
		loss: 1.628000
		loss: 1.628000
		loss: 1.628000
		loss: 1.628000
		loss: 1.627900
		loss: 1.627900
		loss: 1.627900
		loss: 1.627900
		loss: 1.627900
		loss: 1.627900
		loss: 1.627800
		loss: 1.627800
		loss: 1.627800
		loss: 1.627800
		loss: 1.627800
		loss: 1.627800
		loss: 1.627800
		loss: 1.627700
		loss: 1.627700
		loss: 1.627700
		loss: 1.627700
		loss: 1.627700
		loss: 1.627700
		loss: 1.627700
		loss: 1.627600
		loss: 1.627600
		loss: 1.627600
		loss: 1.627600
		loss: 1.627600
		loss: 1.627600
		loss: 1.627600
		loss: 1.627500
		loss: 1.627500
		loss: 1.627500
		loss: 1.627500
		loss: 1.627500
		loss: 1.627500
		loss: 1.627500
		loss: 1.627400
		loss: 1.627400
		loss: 1.627400
		loss: 1.627400
		loss: 1.627400
		loss: 1.627400
		loss: 1.627400
		loss: 1.627300
		loss: 1.627300
		loss: 1.627300
		loss: 1.627300
		loss: 1.627300
		loss: 1.627300
		loss: 1.627300
		loss: 1.627200
		loss: 1.627200
		loss: 1.627200
		loss: 1.627200
		loss: 1.627200
	Overall the loss development was 1.628700 -> 1.627200
In the epoch 5 for problem d-01.pddl 0 explorations in the sampling searches reached a goal
Training data for problem d-02.pddl in epoch 5:
model creation time: 15.339562177658081s
problem epoch data for epoch 5, problem epoch 1
	sampling search time: 33.062700271606445s
	during this search the following actions were chosen:
		close boot was chosen with probability 0.000000
	training time: 61.847418546676636s
	during the training the following losses were computed:
		loss: 2.559100
		loss: 2.530300
		loss: 2.524900
		loss: 2.516200
		loss: 2.508300
		loss: 2.504800
		loss: 2.504400
		loss: 2.502900
		loss: 2.499600
		loss: 2.497200
		loss: 2.497400
		loss: 2.498200
		loss: 2.497300
		loss: 2.495100
		loss: 2.493400
		loss: 2.492900
		loss: 2.492700
		loss: 2.491900
		loss: 2.490800
		loss: 2.489800
		loss: 2.489500
		loss: 2.489800
		loss: 2.490100
		loss: 2.489800
		loss: 2.489300
		loss: 2.489000
		loss: 2.489000
		loss: 2.488900
		loss: 2.488600
		loss: 2.488300
		loss: 2.488000
		loss: 2.487900
		loss: 2.487600
		loss: 2.487200
		loss: 2.487000
		loss: 2.486800
		loss: 2.486800
		loss: 2.486800
		loss: 2.486600
		loss: 2.486400
		loss: 2.486300
		loss: 2.486200
		loss: 2.486100
		loss: 2.486000
		loss: 2.485900
		loss: 2.485800
		loss: 2.485700
		loss: 2.485600
		loss: 2.485500
		loss: 2.485500
		loss: 2.485400
		loss: 2.485400
		loss: 2.485300
		loss: 2.485300
		loss: 2.485200
		loss: 2.485100
		loss: 2.485100
		loss: 2.485000
		loss: 2.485000
		loss: 2.484900
		loss: 2.484900
		loss: 2.484800
		loss: 2.484800
		loss: 2.484800
		loss: 2.484700
		loss: 2.484700
		loss: 2.484600
		loss: 2.484600
		loss: 2.484600
		loss: 2.484500
		loss: 2.484500
		loss: 2.484500
		loss: 2.484400
		loss: 2.484400
		loss: 2.484400
		loss: 2.484300
		loss: 2.484300
		loss: 2.484300
		loss: 2.484200
		loss: 2.484200
		loss: 2.484200
		loss: 2.484200
		loss: 2.484200
		loss: 2.484200
		loss: 2.484300
		loss: 2.484700
		loss: 2.485200
		loss: 2.485500
		loss: 2.484700
		loss: 2.483900
		loss: 2.484400
		loss: 2.484800
		loss: 2.484100
		loss: 2.483900
		loss: 2.484400
		loss: 2.484100
		loss: 2.483800
		loss: 2.484100
		loss: 2.484100
		loss: 2.483700
	Overall the loss development was 2.559100 -> 2.483700
problem epoch data for epoch 5, problem epoch 2
	sampling search time: 33.21010112762451s
	during this search the following actions were chosen:
		close boot was chosen with probability 0.000000
	training time: 10.137587785720825s
	during the training the following losses were computed:
		loss: 2.483900
		loss: 2.484000
		loss: 2.483700
		loss: 2.483700
		loss: 2.483800
		loss: 2.483600
		loss: 2.483600
		loss: 2.483700
		loss: 2.483600
		loss: 2.483500
		loss: 2.483600
		loss: 2.483600
		loss: 2.483500
		loss: 2.483500
		loss: 2.483500
		loss: 2.483400
		loss: 2.483400
		loss: 2.483400
		loss: 2.483400
		loss: 2.483300
		loss: 2.483300
		loss: 2.483300
		loss: 2.483300
		loss: 2.483300
		loss: 2.483300
		loss: 2.483200
		loss: 2.483200
		loss: 2.483200
		loss: 2.483200
		loss: 2.483200
		loss: 2.483100
		loss: 2.483100
		loss: 2.483100
		loss: 2.483100
		loss: 2.483100
		loss: 2.483000
		loss: 2.483000
		loss: 2.483000
		loss: 2.483000
		loss: 2.483000
		loss: 2.483000
		loss: 2.482900
		loss: 2.482900
		loss: 2.482900
		loss: 2.482900
		loss: 2.482900
		loss: 2.482800
		loss: 2.482800
		loss: 2.482800
		loss: 2.482800
		loss: 2.482800
		loss: 2.482800
		loss: 2.482700
		loss: 2.482700
		loss: 2.482700
		loss: 2.482700
		loss: 2.482700
		loss: 2.482700
		loss: 2.482600
		loss: 2.482600
		loss: 2.482600
		loss: 2.482600
		loss: 2.482600
		loss: 2.482500
		loss: 2.482500
		loss: 2.482500
		loss: 2.482500
		loss: 2.482500
		loss: 2.482500
		loss: 2.482400
		loss: 2.482400
		loss: 2.482400
		loss: 2.482400
		loss: 2.482400
		loss: 2.482400
		loss: 2.482300
		loss: 2.482300
		loss: 2.482300
		loss: 2.482300
		loss: 2.482300
		loss: 2.482300
		loss: 2.482300
		loss: 2.482200
		loss: 2.482200
		loss: 2.482300
		loss: 2.482300
		loss: 2.482400
		loss: 2.482700
		loss: 2.483100
		loss: 2.483500
		loss: 2.483700
		loss: 2.483200
		loss: 2.482300
		loss: 2.482100
		loss: 2.482500
		loss: 2.482800
		loss: 2.482500
		loss: 2.482000
		loss: 2.482100
		loss: 2.482400
	Overall the loss development was 2.483900 -> 2.482400
problem epoch data for epoch 5, problem epoch 3
	sampling search time: 33.13513684272766s
	during this search the following actions were chosen:
		close boot was chosen with probability 0.000000
	training time: 10.137589693069458s
	during the training the following losses were computed:
		loss: 2.482300
		loss: 2.482000
		loss: 2.482000
		loss: 2.482200
		loss: 2.482200
		loss: 2.481900
		loss: 2.481900
		loss: 2.482000
		loss: 2.482000
		loss: 2.481900
		loss: 2.481800
		loss: 2.481900
		loss: 2.481900
		loss: 2.481800
		loss: 2.481800
		loss: 2.481800
		loss: 2.481800
		loss: 2.481700
		loss: 2.481700
		loss: 2.481700
		loss: 2.481700
		loss: 2.481700
		loss: 2.481600
		loss: 2.481600
		loss: 2.481600
		loss: 2.481600
		loss: 2.481600
		loss: 2.481600
		loss: 2.481600
		loss: 2.481600
		loss: 2.481500
		loss: 2.481500
		loss: 2.481500
		loss: 2.481500
		loss: 2.481500
		loss: 2.481500
		loss: 2.481400
		loss: 2.481400
		loss: 2.481400
		loss: 2.481400
		loss: 2.481400
		loss: 2.481400
		loss: 2.481400
		loss: 2.481300
		loss: 2.481300
		loss: 2.481300
		loss: 2.481300
		loss: 2.481300
		loss: 2.481300
		loss: 2.481300
		loss: 2.481300
		loss: 2.481200
		loss: 2.481200
		loss: 2.481200
		loss: 2.481200
		loss: 2.481200
		loss: 2.481200
		loss: 2.481200
		loss: 2.481100
		loss: 2.481100
		loss: 2.481100
		loss: 2.481100
		loss: 2.481100
		loss: 2.481100
		loss: 2.481100
		loss: 2.481100
		loss: 2.481000
		loss: 2.481000
		loss: 2.481000
		loss: 2.481000
		loss: 2.481000
		loss: 2.481000
		loss: 2.481000
		loss: 2.480900
		loss: 2.480900
		loss: 2.480900
		loss: 2.480900
		loss: 2.480900
		loss: 2.480900
		loss: 2.480900
		loss: 2.480900
		loss: 2.480800
		loss: 2.480800
		loss: 2.480800
		loss: 2.480800
		loss: 2.480800
		loss: 2.480800
		loss: 2.480800
		loss: 2.480800
		loss: 2.480800
		loss: 2.480900
		loss: 2.481100
		loss: 2.481400
		loss: 2.481900
		loss: 2.482600
		loss: 2.482900
		loss: 2.482500
		loss: 2.481300
		loss: 2.480600
		loss: 2.481100
	Overall the loss development was 2.482300 -> 2.481100
In the epoch 5 for problem d-02.pddl 0 explorations in the sampling searches reached a goal
Success rate: 0

Epoch 6:
Training data for problem d-01.pddl in epoch 6:
model creation time: 8.00388789176941s
problem epoch data for epoch 6, problem epoch 1
	sampling search time: 2.0280368328094482s
	during this search the following actions were chosen:
		close boot was chosen with probability 0.000000
	training time: 37.81995749473572s
	during the training the following losses were computed:
		loss: 1.682100
		loss: 1.713200
		loss: 1.650600
		loss: 1.663900
		loss: 1.670500
		loss: 1.645500
		loss: 1.633200
		loss: 1.642500
		loss: 1.647900
		loss: 1.640500
		loss: 1.632900
		loss: 1.634400
		loss: 1.639100
		loss: 1.637800
		loss: 1.631700
		loss: 1.628400
		loss: 1.630500
		loss: 1.633500
		loss: 1.632900
		loss: 1.630000
		loss: 1.628400
		loss: 1.629200
		loss: 1.629900
		loss: 1.628800
		loss: 1.627300
		loss: 1.627400
		loss: 1.628600
		loss: 1.628900
		loss: 1.627800
		loss: 1.626600
		loss: 1.626800
		loss: 1.627500
		loss: 1.627600
		loss: 1.626700
		loss: 1.626100
		loss: 1.626300
		loss: 1.626500
		loss: 1.626300
		loss: 1.625800
		loss: 1.625900
		loss: 1.626200
		loss: 1.626200
		loss: 1.625900
		loss: 1.625700
		loss: 1.625800
		loss: 1.625900
		loss: 1.625800
		loss: 1.625600
		loss: 1.625600
		loss: 1.625700
		loss: 1.625600
		loss: 1.625500
		loss: 1.625400
		loss: 1.625500
		loss: 1.625500
		loss: 1.625400
		loss: 1.625300
		loss: 1.625400
		loss: 1.625400
		loss: 1.625300
		loss: 1.625300
		loss: 1.625300
		loss: 1.625300
		loss: 1.625200
		loss: 1.625200
		loss: 1.625200
		loss: 1.625200
		loss: 1.625200
		loss: 1.625200
		loss: 1.625200
		loss: 1.625100
		loss: 1.625100
		loss: 1.625100
		loss: 1.625100
		loss: 1.625100
		loss: 1.625100
		loss: 1.625000
		loss: 1.625000
		loss: 1.625000
		loss: 1.625000
		loss: 1.625000
		loss: 1.625000
		loss: 1.625000
		loss: 1.625000
		loss: 1.624900
		loss: 1.624900
		loss: 1.624900
		loss: 1.624900
		loss: 1.624900
		loss: 1.624900
		loss: 1.624900
		loss: 1.624900
		loss: 1.624900
		loss: 1.624800
		loss: 1.624800
		loss: 1.624800
		loss: 1.624800
		loss: 1.624800
		loss: 1.624800
		loss: 1.624800
	Overall the loss development was 1.682100 -> 1.624800
problem epoch data for epoch 6, problem epoch 2
	sampling search time: 1.8902480602264404s
	during this search the following actions were chosen:
		close boot was chosen with probability 0.000000
	training time: 10.128559112548828s
	during the training the following losses were computed:
		loss: 1.624800
		loss: 1.624700
		loss: 1.624700
		loss: 1.624700
		loss: 1.624700
		loss: 1.624700
		loss: 1.624700
		loss: 1.624700
		loss: 1.624700
		loss: 1.624700
		loss: 1.624600
		loss: 1.624600
		loss: 1.624600
		loss: 1.624600
		loss: 1.624600
		loss: 1.624600
		loss: 1.624600
		loss: 1.624600
		loss: 1.624500
		loss: 1.624500
		loss: 1.624500
		loss: 1.624500
		loss: 1.624500
		loss: 1.624500
		loss: 1.624500
		loss: 1.624500
		loss: 1.624500
		loss: 1.624400
		loss: 1.624400
		loss: 1.624400
		loss: 1.624400
		loss: 1.624400
		loss: 1.624400
		loss: 1.624400
		loss: 1.624400
		loss: 1.624400
		loss: 1.624300
		loss: 1.624300
		loss: 1.624300
		loss: 1.624300
		loss: 1.624300
		loss: 1.624300
		loss: 1.624300
		loss: 1.624300
		loss: 1.624300
		loss: 1.624300
		loss: 1.624200
		loss: 1.624200
		loss: 1.624200
		loss: 1.624200
		loss: 1.624200
		loss: 1.624200
		loss: 1.624200
		loss: 1.624200
		loss: 1.624200
		loss: 1.624100
		loss: 1.624100
		loss: 1.624100
		loss: 1.624100
		loss: 1.624100
		loss: 1.624100
		loss: 1.624100
		loss: 1.624100
		loss: 1.624100
		loss: 1.624000
		loss: 1.624000
		loss: 1.624000
		loss: 1.624000
		loss: 1.624000
		loss: 1.624000
		loss: 1.624000
		loss: 1.624000
		loss: 1.624000
		loss: 1.624000
		loss: 1.623900
		loss: 1.623900
		loss: 1.623900
		loss: 1.623900
		loss: 1.623900
		loss: 1.623900
		loss: 1.623900
		loss: 1.623900
		loss: 1.623900
		loss: 1.623800
		loss: 1.623800
		loss: 1.623800
		loss: 1.623800
		loss: 1.623800
		loss: 1.623800
		loss: 1.623800
		loss: 1.623800
		loss: 1.623800
		loss: 1.623800
		loss: 1.623700
		loss: 1.623700
		loss: 1.623700
		loss: 1.623700
		loss: 1.623700
		loss: 1.623700
		loss: 1.623700
	Overall the loss development was 1.624800 -> 1.623700
problem epoch data for epoch 6, problem epoch 3
	sampling search time: 1.8934590816497803s
	during this search the following actions were chosen:
		close boot was chosen with probability 0.000000
	training time: 10.128215312957764s
	during the training the following losses were computed:
		loss: 1.623700
		loss: 1.623700
		loss: 1.623700
		loss: 1.623600
		loss: 1.623600
		loss: 1.623600
		loss: 1.623600
		loss: 1.623600
		loss: 1.623600
		loss: 1.623600
		loss: 1.623600
		loss: 1.623600
		loss: 1.623600
		loss: 1.623500
		loss: 1.623500
		loss: 1.623500
		loss: 1.623500
		loss: 1.623500
		loss: 1.623500
		loss: 1.623500
		loss: 1.623500
		loss: 1.623500
		loss: 1.623500
		loss: 1.623400
		loss: 1.623400
		loss: 1.623400
		loss: 1.623400
		loss: 1.623400
		loss: 1.623400
		loss: 1.623400
		loss: 1.623400
		loss: 1.623400
		loss: 1.623400
		loss: 1.623300
		loss: 1.623300
		loss: 1.623300
		loss: 1.623300
		loss: 1.623300
		loss: 1.623300
		loss: 1.623300
		loss: 1.623300
		loss: 1.623300
		loss: 1.623300
		loss: 1.623200
		loss: 1.623200
		loss: 1.623200
		loss: 1.623200
		loss: 1.623200
		loss: 1.623200
		loss: 1.623200
		loss: 1.623200
		loss: 1.623200
		loss: 1.623200
		loss: 1.623100
		loss: 1.623100
		loss: 1.623100
		loss: 1.623100
		loss: 1.623100
		loss: 1.623100
		loss: 1.623100
		loss: 1.623100
		loss: 1.623100
		loss: 1.623100
		loss: 1.623100
		loss: 1.623000
		loss: 1.623000
		loss: 1.623000
		loss: 1.623000
		loss: 1.623000
		loss: 1.623000
		loss: 1.623000
		loss: 1.623000
		loss: 1.623000
		loss: 1.623000
		loss: 1.623000
		loss: 1.622900
		loss: 1.622900
		loss: 1.622900
		loss: 1.622900
		loss: 1.622900
		loss: 1.622900
		loss: 1.622900
		loss: 1.622900
		loss: 1.622900
		loss: 1.622900
		loss: 1.622800
		loss: 1.622800
		loss: 1.622800
		loss: 1.622800
		loss: 1.622800
		loss: 1.622800
		loss: 1.622800
		loss: 1.622800
		loss: 1.622800
		loss: 1.622800
		loss: 1.622800
		loss: 1.622700
		loss: 1.622700
		loss: 1.622700
		loss: 1.622700
	Overall the loss development was 1.623700 -> 1.622700
In the epoch 6 for problem d-01.pddl 0 explorations in the sampling searches reached a goal
Training data for problem d-02.pddl in epoch 6:
model creation time: 15.552963256835938s
problem epoch data for epoch 6, problem epoch 1
	sampling search time: 33.29695677757263s
	during this search the following actions were chosen:
		close boot was chosen with probability 0.000000
	training time: 62.822158098220825s
	during the training the following losses were computed:
		loss: 2.542200
		loss: 2.520900
		loss: 2.509300
		loss: 2.505100
		loss: 2.503400
		loss: 2.498700
		loss: 2.493600
		loss: 2.493200
		loss: 2.492900
		loss: 2.493300
		loss: 2.491900
		loss: 2.490700
		loss: 2.489000
		loss: 2.488500
		loss: 2.488200
		loss: 2.488200
		loss: 2.487100
		loss: 2.486100
		loss: 2.485200
		loss: 2.485100
		loss: 2.484800
		loss: 2.484900
		loss: 2.484700
		loss: 2.484700
		loss: 2.484300
		loss: 2.484100
		loss: 2.483900
		loss: 2.483900
		loss: 2.483700
		loss: 2.483600
		loss: 2.483200
		loss: 2.482900
		loss: 2.482600
		loss: 2.482500
		loss: 2.482300
		loss: 2.482100
		loss: 2.481900
		loss: 2.481900
		loss: 2.481900
		loss: 2.481800
		loss: 2.481700
		loss: 2.481600
		loss: 2.481500
		loss: 2.481400
		loss: 2.481400
		loss: 2.481300
		loss: 2.481200
		loss: 2.481100
		loss: 2.481000
		loss: 2.480900
		loss: 2.480900
		loss: 2.480800
		loss: 2.480800
		loss: 2.480700
		loss: 2.480700
		loss: 2.480600
		loss: 2.480600
		loss: 2.480500
		loss: 2.480500
		loss: 2.480500
		loss: 2.480400
		loss: 2.480400
		loss: 2.480300
		loss: 2.480300
		loss: 2.480300
		loss: 2.480300
		loss: 2.480200
		loss: 2.480200
		loss: 2.480200
		loss: 2.480100
		loss: 2.480100
		loss: 2.480100
		loss: 2.480100
		loss: 2.480000
		loss: 2.480000
		loss: 2.480000
		loss: 2.480000
		loss: 2.480000
		loss: 2.479900
		loss: 2.479900
		loss: 2.479900
		loss: 2.479900
		loss: 2.479900
		loss: 2.479800
		loss: 2.479800
		loss: 2.479800
		loss: 2.479800
		loss: 2.479800
		loss: 2.479700
		loss: 2.479700
		loss: 2.479700
		loss: 2.479700
		loss: 2.479700
		loss: 2.479700
		loss: 2.479600
		loss: 2.479600
		loss: 2.479600
		loss: 2.479600
		loss: 2.479600
		loss: 2.479600
	Overall the loss development was 2.542200 -> 2.479600
problem epoch data for epoch 6, problem epoch 2
	sampling search time: 33.398897647857666s
	during this search the following actions were chosen:
		close boot was chosen with probability 0.000000
	training time: 10.138838768005371s
	during the training the following losses were computed:
		loss: 2.479600
		loss: 2.479500
		loss: 2.479500
		loss: 2.479500
		loss: 2.479500
		loss: 2.479500
		loss: 2.479500
		loss: 2.479500
		loss: 2.479400
		loss: 2.479400
		loss: 2.479400
		loss: 2.479500
		loss: 2.479500
		loss: 2.479700
		loss: 2.480000
		loss: 2.480500
		loss: 2.480700
		loss: 2.480200
		loss: 2.479400
		loss: 2.479500
		loss: 2.480000
		loss: 2.479900
		loss: 2.479300
		loss: 2.479400
		loss: 2.479800
		loss: 2.479500
		loss: 2.479200
		loss: 2.479500
		loss: 2.479500
		loss: 2.479200
		loss: 2.479200
		loss: 2.479400
		loss: 2.479300
		loss: 2.479100
		loss: 2.479200
		loss: 2.479300
		loss: 2.479100
		loss: 2.479100
		loss: 2.479200
		loss: 2.479100
		loss: 2.479100
		loss: 2.479100
		loss: 2.479100
		loss: 2.479000
		loss: 2.479000
		loss: 2.479100
		loss: 2.479000
		loss: 2.479000
		loss: 2.479000
		loss: 2.479000
		loss: 2.479000
		loss: 2.478900
		loss: 2.478900
		loss: 2.478900
		loss: 2.478900
		loss: 2.478900
		loss: 2.478900
		loss: 2.478900
		loss: 2.478900
		loss: 2.478900
		loss: 2.478900
		loss: 2.478800
		loss: 2.478800
		loss: 2.478800
		loss: 2.478800
		loss: 2.478800
		loss: 2.478800
		loss: 2.478800
		loss: 2.478800
		loss: 2.478800
		loss: 2.478700
		loss: 2.478700
		loss: 2.478700
		loss: 2.478700
		loss: 2.478700
		loss: 2.478700
		loss: 2.478700
		loss: 2.478700
		loss: 2.478700
		loss: 2.478700
		loss: 2.478600
		loss: 2.478600
		loss: 2.478600
		loss: 2.478600
		loss: 2.478600
		loss: 2.478600
		loss: 2.478600
		loss: 2.478600
		loss: 2.478600
		loss: 2.478600
		loss: 2.478500
		loss: 2.478500
		loss: 2.478500
		loss: 2.478500
		loss: 2.478500
		loss: 2.478500
		loss: 2.478500
		loss: 2.478500
		loss: 2.478500
		loss: 2.478500
	Overall the loss development was 2.479600 -> 2.478500
problem epoch data for epoch 6, problem epoch 3
	sampling search time: 33.11705684661865s
	during this search the following actions were chosen:
		close boot was chosen with probability 0.000000
	training time: 10.139065742492676s
	during the training the following losses were computed:
		loss: 2.478500
		loss: 2.478400
		loss: 2.478400
		loss: 2.478400
		loss: 2.478400
		loss: 2.478400
		loss: 2.478400
		loss: 2.478400
		loss: 2.478400
		loss: 2.478400
		loss: 2.478400
		loss: 2.478300
		loss: 2.478300
		loss: 2.478300
		loss: 2.478300
		loss: 2.478300
		loss: 2.478300
		loss: 2.478300
		loss: 2.478400
		loss: 2.478400
		loss: 2.478600
		loss: 2.478800
		loss: 2.479300
		loss: 2.480000
		loss: 2.480200
		loss: 2.479500
		loss: 2.478500
		loss: 2.478300
		loss: 2.479000
		loss: 2.479200
		loss: 2.478500
		loss: 2.478200
		loss: 2.478600
		loss: 2.478800
		loss: 2.478400
		loss: 2.478200
		loss: 2.478500
		loss: 2.478500
		loss: 2.478200
		loss: 2.478200
		loss: 2.478400
		loss: 2.478300
		loss: 2.478100
		loss: 2.478200
		loss: 2.478300
		loss: 2.478200
		loss: 2.478100
		loss: 2.478100
		loss: 2.478200
		loss: 2.478100
		loss: 2.478000
		loss: 2.478100
		loss: 2.478100
		loss: 2.478000
		loss: 2.478000
		loss: 2.478000
		loss: 2.478000
		loss: 2.478000
		loss: 2.478000
		loss: 2.478000
		loss: 2.478000
		loss: 2.477900
		loss: 2.477900
		loss: 2.478000
		loss: 2.477900
		loss: 2.477900
		loss: 2.477900
		loss: 2.477900
		loss: 2.477900
		loss: 2.477900
		loss: 2.477900
		loss: 2.477900
		loss: 2.477900
		loss: 2.477900
		loss: 2.477800
		loss: 2.477800
		loss: 2.477800
		loss: 2.477800
		loss: 2.477800
		loss: 2.477800
		loss: 2.477800
		loss: 2.477800
		loss: 2.477800
		loss: 2.477800
		loss: 2.477800
		loss: 2.477800
		loss: 2.477800
		loss: 2.477700
		loss: 2.477700
		loss: 2.477700
		loss: 2.477700
		loss: 2.477700
		loss: 2.477700
		loss: 2.477700
		loss: 2.477700
		loss: 2.477700
		loss: 2.477700
		loss: 2.477700
		loss: 2.477700
		loss: 2.477700
	Overall the loss development was 2.478500 -> 2.477700
In the epoch 6 for problem d-02.pddl 0 explorations in the sampling searches reached a goal
Success rate: 0

Epoch 7:
Training data for problem d-01.pddl in epoch 7:
model creation time: 8.044175148010254s
problem epoch data for epoch 7, problem epoch 1
	sampling search time: 1.9312288761138916s
	during this search the following actions were chosen:
		close boot was chosen with probability 0.000000
	training time: 37.52174496650696s
	during the training the following losses were computed:
		loss: 1.688000
		loss: 1.664900
		loss: 1.654800
		loss: 1.644300
		loss: 1.638700
		loss: 1.634100
		loss: 1.631600
		loss: 1.631300
		loss: 1.629700
		loss: 1.629800
		loss: 1.629900
		loss: 1.628700
		loss: 1.627900
		loss: 1.627100
		loss: 1.626500
		loss: 1.627300
		loss: 1.627600
		loss: 1.627100
		loss: 1.626600
		loss: 1.625500
		loss: 1.624800
		loss: 1.624800
		loss: 1.624800
		loss: 1.624700
		loss: 1.624700
		loss: 1.624500
		loss: 1.624300
		loss: 1.624200
		loss: 1.623900
		loss: 1.623700
		loss: 1.623600
		loss: 1.623400
		loss: 1.623300
		loss: 1.623200
		loss: 1.623000
		loss: 1.623100
		loss: 1.623100
		loss: 1.623000
		loss: 1.623000
		loss: 1.622900
		loss: 1.622800
		loss: 1.622900
		loss: 1.622800
		loss: 1.622800
		loss: 1.622700
		loss: 1.622700
		loss: 1.622600
		loss: 1.622600
		loss: 1.622600
		loss: 1.622500
		loss: 1.622500
		loss: 1.622500
		loss: 1.622400
		loss: 1.622400
		loss: 1.622400
		loss: 1.622400
		loss: 1.622400
		loss: 1.622300
		loss: 1.622300
		loss: 1.622300
		loss: 1.622300
		loss: 1.622300
		loss: 1.622300
		loss: 1.622200
		loss: 1.622200
		loss: 1.622200
		loss: 1.622200
		loss: 1.622200
		loss: 1.622200
		loss: 1.622100
		loss: 1.622100
		loss: 1.622100
		loss: 1.622100
		loss: 1.622100
		loss: 1.622100
		loss: 1.622100
		loss: 1.622000
		loss: 1.622000
		loss: 1.622000
		loss: 1.622000
		loss: 1.622000
		loss: 1.622000
		loss: 1.622000
		loss: 1.621900
		loss: 1.621900
		loss: 1.621900
		loss: 1.621900
		loss: 1.621900
		loss: 1.621900
		loss: 1.621900
		loss: 1.621900
		loss: 1.621800
		loss: 1.621800
		loss: 1.621800
		loss: 1.621800
		loss: 1.621800
		loss: 1.621800
		loss: 1.621800
		loss: 1.621800
		loss: 1.621700
	Overall the loss development was 1.688000 -> 1.621700
problem epoch data for epoch 7, problem epoch 2
	sampling search time: 1.914571762084961s
	during this search the following actions were chosen:
		close boot was chosen with probability 0.000000
	training time: 10.12795090675354s
	during the training the following losses were computed:
		loss: 1.621700
		loss: 1.621700
		loss: 1.621700
		loss: 1.621700
		loss: 1.621700
		loss: 1.621700
		loss: 1.621700
		loss: 1.621600
		loss: 1.621600
		loss: 1.621600
		loss: 1.621600
		loss: 1.621600
		loss: 1.621600
		loss: 1.621600
		loss: 1.621600
		loss: 1.621500
		loss: 1.621500
		loss: 1.621500
		loss: 1.621500
		loss: 1.621500
		loss: 1.621500
		loss: 1.621500
		loss: 1.621500
		loss: 1.621500
		loss: 1.621400
		loss: 1.621400
		loss: 1.621400
		loss: 1.621400
		loss: 1.621400
		loss: 1.621400
		loss: 1.621400
		loss: 1.621400
		loss: 1.621300
		loss: 1.621300
		loss: 1.621300
		loss: 1.621300
		loss: 1.621300
		loss: 1.621300
		loss: 1.621300
		loss: 1.621300
		loss: 1.621300
		loss: 1.621200
		loss: 1.621200
		loss: 1.621200
		loss: 1.621200
		loss: 1.621200
		loss: 1.621200
		loss: 1.621200
		loss: 1.621200
		loss: 1.621200
		loss: 1.621100
		loss: 1.621100
		loss: 1.621100
		loss: 1.621100
		loss: 1.621100
		loss: 1.621100
		loss: 1.621100
		loss: 1.621100
		loss: 1.621100
		loss: 1.621000
		loss: 1.621000
		loss: 1.621000
		loss: 1.621000
		loss: 1.621000
		loss: 1.621000
		loss: 1.621000
		loss: 1.621000
		loss: 1.621000
		loss: 1.620900
		loss: 1.620900
		loss: 1.620900
		loss: 1.620900
		loss: 1.620900
		loss: 1.620900
		loss: 1.620900
		loss: 1.620900
		loss: 1.620900
		loss: 1.620800
		loss: 1.620800
		loss: 1.620800
		loss: 1.620800
		loss: 1.620800
		loss: 1.620800
		loss: 1.620800
		loss: 1.620800
		loss: 1.620800
		loss: 1.620800
		loss: 1.620700
		loss: 1.620700
		loss: 1.620700
		loss: 1.620700
		loss: 1.620700
		loss: 1.620700
		loss: 1.620700
		loss: 1.620700
		loss: 1.620700
		loss: 1.620700
		loss: 1.620600
		loss: 1.620600
		loss: 1.620600
	Overall the loss development was 1.621700 -> 1.620600
problem epoch data for epoch 7, problem epoch 3
	sampling search time: 1.9318828582763672s
	during this search the following actions were chosen:
		close boot was chosen with probability 0.000000
	training time: 10.12769341468811s
	during the training the following losses were computed:
		loss: 1.620600
		loss: 1.620600
		loss: 1.620600
		loss: 1.620600
		loss: 1.620600
		loss: 1.620600
		loss: 1.620500
		loss: 1.620500
		loss: 1.620500
		loss: 1.620500
		loss: 1.620500
		loss: 1.620500
		loss: 1.620500
		loss: 1.620500
		loss: 1.620500
		loss: 1.620500
		loss: 1.620400
		loss: 1.620400
		loss: 1.620400
		loss: 1.620400
		loss: 1.620400
		loss: 1.620400
		loss: 1.620400
		loss: 1.620400
		loss: 1.620400
		loss: 1.620400
		loss: 1.620300
		loss: 1.620300
		loss: 1.620300
		loss: 1.620300
		loss: 1.620300
		loss: 1.620300
		loss: 1.620300
		loss: 1.620300
		loss: 1.620300
		loss: 1.620300
		loss: 1.620200
		loss: 1.620200
		loss: 1.620200
		loss: 1.620200
		loss: 1.620200
		loss: 1.620200
		loss: 1.620200
		loss: 1.620200
		loss: 1.620200
		loss: 1.620200
		loss: 1.620200
		loss: 1.620100
		loss: 1.620100
		loss: 1.620100
		loss: 1.620100
		loss: 1.620100
		loss: 1.620100
		loss: 1.620100
		loss: 1.620100
		loss: 1.620100
		loss: 1.620100
		loss: 1.620000
		loss: 1.620000
		loss: 1.620000
		loss: 1.620000
		loss: 1.620000
		loss: 1.620000
		loss: 1.620000
		loss: 1.620000
		loss: 1.620000
		loss: 1.620000
		loss: 1.620000
		loss: 1.619900
		loss: 1.619900
		loss: 1.619900
		loss: 1.619900
		loss: 1.619900
		loss: 1.619900
		loss: 1.619900
		loss: 1.619900
		loss: 1.619900
		loss: 1.619900
		loss: 1.619900
		loss: 1.619800
		loss: 1.619800
		loss: 1.619800
		loss: 1.619800
		loss: 1.619800
		loss: 1.619800
		loss: 1.619800
		loss: 1.619800
		loss: 1.619800
		loss: 1.619800
		loss: 1.619700
		loss: 1.619700
		loss: 1.619700
		loss: 1.619700
		loss: 1.619700
		loss: 1.619700
		loss: 1.619700
		loss: 1.619700
		loss: 1.619700
		loss: 1.619700
		loss: 1.619700
	Overall the loss development was 1.620600 -> 1.619700
In the epoch 7 for problem d-01.pddl 0 explorations in the sampling searches reached a goal
Training data for problem d-02.pddl in epoch 7:
model creation time: 15.695319652557373s
problem epoch data for epoch 7, problem epoch 1
	sampling search time: 33.13823103904724s
	during this search the following actions were chosen:
		close boot was chosen with probability 0.000000
	training time: 61.956392765045166s
	during the training the following losses were computed:
		loss: 2.588500
		loss: 2.544800
		loss: 2.533300
		loss: 2.529200
		loss: 2.520900
		loss: 2.518900
		loss: 2.511400
		loss: 2.503600
		loss: 2.501100
		loss: 2.499200
		loss: 2.498100
		loss: 2.498800
		loss: 2.497500
		loss: 2.493900
		loss: 2.491900
		loss: 2.491000
		loss: 2.489400
		loss: 2.488500
		loss: 2.488700
		loss: 2.488000
		loss: 2.486700
		loss: 2.485900
		loss: 2.485000
		loss: 2.484200
		loss: 2.484300
		loss: 2.484600
		loss: 2.484100
		loss: 2.483600
		loss: 2.483300
		loss: 2.482800
		loss: 2.482500
		loss: 2.482700
		loss: 2.482600
		loss: 2.482400
		loss: 2.482300
		loss: 2.481800
		loss: 2.481500
		loss: 2.481400
		loss: 2.481300
		loss: 2.481100
		loss: 2.481000
		loss: 2.480800
		loss: 2.480500
		loss: 2.480300
		loss: 2.480200
		loss: 2.480100
		loss: 2.480100
		loss: 2.479900
		loss: 2.479800
		loss: 2.479700
		loss: 2.479500
		loss: 2.479500
		loss: 2.479400
		loss: 2.479400
		loss: 2.479300
		loss: 2.479200
		loss: 2.479100
		loss: 2.479000
		loss: 2.479000
		loss: 2.478900
		loss: 2.478800
		loss: 2.478700
		loss: 2.478700
		loss: 2.478600
		loss: 2.478600
		loss: 2.478500
		loss: 2.478500
		loss: 2.478400
		loss: 2.478400
		loss: 2.478300
		loss: 2.478300
		loss: 2.478200
		loss: 2.478200
		loss: 2.478200
		loss: 2.478100
		loss: 2.478100
		loss: 2.478100
		loss: 2.478000
		loss: 2.478000
		loss: 2.478000
		loss: 2.477900
		loss: 2.477900
		loss: 2.477900
		loss: 2.477800
		loss: 2.477800
		loss: 2.477800
		loss: 2.477800
		loss: 2.477800
		loss: 2.477700
		loss: 2.477700
		loss: 2.477700
		loss: 2.477700
		loss: 2.477600
		loss: 2.477600
		loss: 2.477600
		loss: 2.477600
		loss: 2.477600
		loss: 2.477600
		loss: 2.477500
		loss: 2.477500
	Overall the loss development was 2.588500 -> 2.477500
problem epoch data for epoch 7, problem epoch 2
	sampling search time: 208.13110733032227s
	during this search the following actions were chosen:
		open boot was chosen with probability 1.000000
		fetch wrench boot was chosen with probability 0.384761
		fetch jack boot was chosen with probability 0.705733
		fetch r1 boot was chosen with probability 0.336142
		fetch r2 boot was chosen with probability 0.541484
		fetch pump boot was chosen with probability 0.495165
		loosen nuts1 the-hub1 was chosen with probability 0.500524
		loosen nuts2 the-hub2 was chosen with probability 0.999082
		jack-up the-hub1 was chosen with probability 0.973623
		undo nuts1 the-hub1 was chosen with probability 0.999999
		remove-wheel w1 the-hub1 was chosen with probability 0.999630
		put-on-wheel r1 the-hub1 was chosen with probability 0.796250
		remove-wheel r1 the-hub1 was chosen with probability 0.340857
	training time: 10.474345207214355s
	during the training the following losses were computed:
		loss: 2.735100
		loss: 2.688300
		loss: 2.657500
		loss: 2.624100
		loss: 2.584200
		loss: 2.555200
		loss: 2.529500
		loss: 2.501700
		loss: 2.488400
		loss: 2.488300
		loss: 2.485900
		loss: 2.482700
		loss: 2.482500
		loss: 2.480500
		loss: 2.478000
		loss: 2.478400
		loss: 2.477900
		loss: 2.474500
		loss: 2.472200
		loss: 2.472000
		loss: 2.471400
		loss: 2.470600
		loss: 2.470100
		loss: 2.468400
		loss: 2.466000
		loss: 2.464400
		loss: 2.462900
		loss: 2.460700
		loss: 2.458700
		loss: 2.457300
		loss: 2.455900
		loss: 2.454900
		loss: 2.454400
		loss: 2.453900
		loss: 2.453200
		loss: 2.452800
		loss: 2.452500
		loss: 2.452100
		loss: 2.451700
		loss: 2.451400
		loss: 2.450900
		loss: 2.450500
		loss: 2.450100
		loss: 2.449700
		loss: 2.449300
		loss: 2.448900
		loss: 2.448500
		loss: 2.448100
		loss: 2.447800
		loss: 2.447500
		loss: 2.447200
		loss: 2.447100
		loss: 2.446900
		loss: 2.446800
		loss: 2.446600
		loss: 2.446500
		loss: 2.446300
		loss: 2.446100
		loss: 2.446000
		loss: 2.445800
		loss: 2.445700
		loss: 2.445600
		loss: 2.445400
		loss: 2.445300
		loss: 2.445200
		loss: 2.445100
		loss: 2.445000
		loss: 2.444900
		loss: 2.444800
		loss: 2.444800
		loss: 2.444700
		loss: 2.444700
		loss: 2.444600
		loss: 2.444600
		loss: 2.444500
		loss: 2.444400
		loss: 2.444400
		loss: 2.444300
		loss: 2.444300
		loss: 2.444200
		loss: 2.444200
		loss: 2.444100
		loss: 2.444100
		loss: 2.444100
		loss: 2.444000
		loss: 2.444000
		loss: 2.444000
		loss: 2.443900
		loss: 2.443900
		loss: 2.443900
		loss: 2.443800
		loss: 2.443800
		loss: 2.443800
		loss: 2.443700
		loss: 2.443700
		loss: 2.443700
		loss: 2.443600
		loss: 2.443600
		loss: 2.443600
		loss: 2.443600
	Overall the loss development was 2.735100 -> 2.443600
problem epoch data for epoch 7, problem epoch 3
	sampling search time: 33.381580114364624s
	during this search the following actions were chosen:
		close boot was chosen with probability 0.000000
	training time: 10.485366582870483s
	during the training the following losses were computed:
		loss: 2.443500
		loss: 2.443500
		loss: 2.443500
		loss: 2.443500
		loss: 2.443400
		loss: 2.443400
		loss: 2.443400
		loss: 2.443400
		loss: 2.443400
		loss: 2.443300
		loss: 2.443300
		loss: 2.443300
		loss: 2.443300
		loss: 2.443300
		loss: 2.443200
		loss: 2.443200
		loss: 2.443200
		loss: 2.443200
		loss: 2.443200
		loss: 2.443100
		loss: 2.443100
		loss: 2.443100
		loss: 2.443100
		loss: 2.443100
		loss: 2.443100
		loss: 2.443000
		loss: 2.443000
		loss: 2.443000
		loss: 2.443000
		loss: 2.443000
		loss: 2.443000
		loss: 2.442900
		loss: 2.442900
		loss: 2.442900
		loss: 2.442900
		loss: 2.442900
		loss: 2.442900
		loss: 2.442900
		loss: 2.442800
		loss: 2.442800
		loss: 2.442800
		loss: 2.442800
		loss: 2.442800
		loss: 2.442800
		loss: 2.442800
		loss: 2.442800
		loss: 2.442700
		loss: 2.442700
		loss: 2.442700
		loss: 2.442700
		loss: 2.442700
		loss: 2.442700
		loss: 2.442700
		loss: 2.442600
		loss: 2.442600
		loss: 2.442600
		loss: 2.442600
		loss: 2.442600
		loss: 2.442600
		loss: 2.442600
		loss: 2.442600
		loss: 2.442600
		loss: 2.442500
		loss: 2.442500
		loss: 2.442500
		loss: 2.442500
		loss: 2.442500
		loss: 2.442500
		loss: 2.442500
		loss: 2.442500
		loss: 2.442500
		loss: 2.442400
		loss: 2.442400
		loss: 2.442400
		loss: 2.442400
		loss: 2.442400
		loss: 2.442400
		loss: 2.442400
		loss: 2.442400
		loss: 2.442400
		loss: 2.442300
		loss: 2.442300
		loss: 2.442300
		loss: 2.442300
		loss: 2.442300
		loss: 2.442300
		loss: 2.442300
		loss: 2.442300
		loss: 2.442300
		loss: 2.442300
		loss: 2.442300
		loss: 2.442200
		loss: 2.442200
		loss: 2.442200
		loss: 2.442200
		loss: 2.442200
		loss: 2.442200
		loss: 2.442200
		loss: 2.442200
		loss: 2.442200
	Overall the loss development was 2.443500 -> 2.442200
In the epoch 7 for problem d-02.pddl 0 explorations in the sampling searches reached a goal
Success rate: 0

Epoch 8:
Training data for problem d-01.pddl in epoch 8:
model creation time: 7.960818529129028s
problem epoch data for epoch 8, problem epoch 1
	sampling search time: 2.0807313919067383s
	during this search the following actions were chosen:
		close boot was chosen with probability 0.000000
	training time: 37.39948081970215s
	during the training the following losses were computed:
		loss: 1.698600
		loss: 1.663500
		loss: 1.650700
		loss: 1.651700
		loss: 1.648900
		loss: 1.641200
		loss: 1.638200
		loss: 1.637800
		loss: 1.636400
		loss: 1.634700
		loss: 1.632000
		loss: 1.629000
		loss: 1.628000
		loss: 1.628900
		loss: 1.629300
		loss: 1.628900
		loss: 1.627800
		loss: 1.626300
		loss: 1.625500
		loss: 1.625900
		loss: 1.626700
		loss: 1.626700
		loss: 1.626100
		loss: 1.625400
		loss: 1.624600
		loss: 1.624400
		loss: 1.624700
		loss: 1.624900
		loss: 1.624700
		loss: 1.624400
		loss: 1.624100
		loss: 1.623800
		loss: 1.623800
		loss: 1.623800
		loss: 1.623700
		loss: 1.623600
		loss: 1.623600
		loss: 1.623500
		loss: 1.623400
		loss: 1.623300
		loss: 1.623100
		loss: 1.623000
		loss: 1.622900
		loss: 1.622900
		loss: 1.622900
		loss: 1.622900
		loss: 1.622800
		loss: 1.622700
		loss: 1.622600
		loss: 1.622600
		loss: 1.622600
		loss: 1.622600
		loss: 1.622600
		loss: 1.622500
		loss: 1.622500
		loss: 1.622500
		loss: 1.622400
		loss: 1.622400
		loss: 1.622400
		loss: 1.622300
		loss: 1.622300
		loss: 1.622300
		loss: 1.622300
		loss: 1.622200
		loss: 1.622200
		loss: 1.622200
		loss: 1.622200
		loss: 1.622100
		loss: 1.622100
		loss: 1.622100
		loss: 1.622100
		loss: 1.622100
		loss: 1.622000
		loss: 1.622000
		loss: 1.622000
		loss: 1.622000
		loss: 1.622000
		loss: 1.621900
		loss: 1.621900
		loss: 1.621900
		loss: 1.621900
		loss: 1.621900
		loss: 1.621900
		loss: 1.621800
		loss: 1.621800
		loss: 1.621800
		loss: 1.621800
		loss: 1.621800
		loss: 1.621800
		loss: 1.621700
		loss: 1.621700
		loss: 1.621700
		loss: 1.621700
		loss: 1.621700
		loss: 1.621700
		loss: 1.621600
		loss: 1.621600
		loss: 1.621600
		loss: 1.621600
		loss: 1.621600
	Overall the loss development was 1.698600 -> 1.621600
problem epoch data for epoch 8, problem epoch 2
	sampling search time: 1.8814635276794434s
	during this search the following actions were chosen:
		close boot was chosen with probability 0.000000
	training time: 10.127113819122314s
	during the training the following losses were computed:
		loss: 1.621600
		loss: 1.621600
		loss: 1.621500
		loss: 1.621500
		loss: 1.621500
		loss: 1.621500
		loss: 1.621500
		loss: 1.621500
		loss: 1.621400
		loss: 1.621400
		loss: 1.621400
		loss: 1.621400
		loss: 1.621400
		loss: 1.621400
		loss: 1.621400
		loss: 1.621300
		loss: 1.621300
		loss: 1.621300
		loss: 1.621300
		loss: 1.621300
		loss: 1.621300
		loss: 1.621300
		loss: 1.621200
		loss: 1.621200
		loss: 1.621200
		loss: 1.621200
		loss: 1.621200
		loss: 1.621200
		loss: 1.621200
		loss: 1.621100
		loss: 1.621100
		loss: 1.621100
		loss: 1.621100
		loss: 1.621100
		loss: 1.621100
		loss: 1.621100
		loss: 1.621100
		loss: 1.621000
		loss: 1.621000
		loss: 1.621000
		loss: 1.621000
		loss: 1.621000
		loss: 1.621000
		loss: 1.621000
		loss: 1.620900
		loss: 1.620900
		loss: 1.620900
		loss: 1.620900
		loss: 1.620900
		loss: 1.620900
		loss: 1.620900
		loss: 1.620900
		loss: 1.620800
		loss: 1.620800
		loss: 1.620800
		loss: 1.620800
		loss: 1.620800
		loss: 1.620800
		loss: 1.620800
		loss: 1.620800
		loss: 1.620700
		loss: 1.620700
		loss: 1.620700
		loss: 1.620700
		loss: 1.620700
		loss: 1.620700
		loss: 1.620700
		loss: 1.620700
		loss: 1.620600
		loss: 1.620600
		loss: 1.620600
		loss: 1.620600
		loss: 1.620600
		loss: 1.620600
		loss: 1.620600
		loss: 1.620600
		loss: 1.620600
		loss: 1.620500
		loss: 1.620500
		loss: 1.620500
		loss: 1.620500
		loss: 1.620500
		loss: 1.620500
		loss: 1.620500
		loss: 1.620500
		loss: 1.620500
		loss: 1.620400
		loss: 1.620400
		loss: 1.620400
		loss: 1.620400
		loss: 1.620400
		loss: 1.620400
		loss: 1.620400
		loss: 1.620400
		loss: 1.620400
		loss: 1.620300
		loss: 1.620300
		loss: 1.620300
		loss: 1.620300
		loss: 1.620300
	Overall the loss development was 1.621600 -> 1.620300
problem epoch data for epoch 8, problem epoch 3
	sampling search time: 1.893146276473999s
	during this search the following actions were chosen:
		close boot was chosen with probability 0.000000
	training time: 10.128127336502075s
	during the training the following losses were computed:
		loss: 1.620300
		loss: 1.620300
		loss: 1.620300
		loss: 1.620300
		loss: 1.620200
		loss: 1.620200
		loss: 1.620200
		loss: 1.620200
		loss: 1.620200
		loss: 1.620200
		loss: 1.620200
		loss: 1.620200
		loss: 1.620200
		loss: 1.620100
		loss: 1.620100
		loss: 1.620100
		loss: 1.620100
		loss: 1.620100
		loss: 1.620100
		loss: 1.620100
		loss: 1.620100
		loss: 1.620100
		loss: 1.620100
		loss: 1.620000
		loss: 1.620000
		loss: 1.620000
		loss: 1.620000
		loss: 1.620000
		loss: 1.620000
		loss: 1.620000
		loss: 1.620000
		loss: 1.620000
		loss: 1.620000
		loss: 1.619900
		loss: 1.619900
		loss: 1.619900
		loss: 1.619900
		loss: 1.619900
		loss: 1.619900
		loss: 1.619900
		loss: 1.619900
		loss: 1.619900
		loss: 1.619900
		loss: 1.619800
		loss: 1.619800
		loss: 1.619800
		loss: 1.619800
		loss: 1.619800
		loss: 1.619800
		loss: 1.619800
		loss: 1.619800
		loss: 1.619800
		loss: 1.619800
		loss: 1.619800
		loss: 1.619700
		loss: 1.619700
		loss: 1.619700
		loss: 1.619700
		loss: 1.619700
		loss: 1.619700
		loss: 1.619700
		loss: 1.619700
		loss: 1.619700
		loss: 1.619700
		loss: 1.619700
		loss: 1.619600
		loss: 1.619600
		loss: 1.619600
		loss: 1.619600
		loss: 1.619600
		loss: 1.619600
		loss: 1.619600
		loss: 1.619600
		loss: 1.619600
		loss: 1.619600
		loss: 1.619600
		loss: 1.619500
		loss: 1.619500
		loss: 1.619500
		loss: 1.619500
		loss: 1.619500
		loss: 1.619500
		loss: 1.619500
		loss: 1.619500
		loss: 1.619500
		loss: 1.619500
		loss: 1.619500
		loss: 1.619400
		loss: 1.619400
		loss: 1.619400
		loss: 1.619400
		loss: 1.619400
		loss: 1.619400
		loss: 1.619400
		loss: 1.619400
		loss: 1.619400
		loss: 1.619400
		loss: 1.619400
		loss: 1.619400
		loss: 1.619300
	Overall the loss development was 1.620300 -> 1.619300
In the epoch 8 for problem d-01.pddl 0 explorations in the sampling searches reached a goal
Training data for problem d-02.pddl in epoch 8:
model creation time: 15.458320379257202s
problem epoch data for epoch 8, problem epoch 1
	sampling search time: 212.86793518066406s
	during this search the following actions were chosen:
		open boot was chosen with probability 1.000000
		fetch wrench boot was chosen with probability 0.465206
		fetch jack boot was chosen with probability 0.657218
		fetch r1 boot was chosen with probability 0.224935
		fetch r2 boot was chosen with probability 0.292749
		loosen nuts2 the-hub2 was chosen with probability 0.378176
		loosen nuts1 the-hub1 was chosen with probability 0.794888
		fetch pump boot was chosen with probability 0.949116
		jack-up the-hub2 was chosen with probability 0.803413
		undo nuts2 the-hub2 was chosen with probability 0.999987
		remove-wheel w2 the-hub2 was chosen with probability 0.998492
		put-on-wheel r2 the-hub2 was chosen with probability 0.863626
		inflate r1 was chosen with probability 0.493242
		inflate r2 was chosen with probability 0.978654
		put-away w2 boot was chosen with probability 0.702597
		remove-wheel r2 the-hub2 was chosen with probability 1.000000
		put-on-wheel r1 the-hub2 was chosen with probability 0.972919
		remove-wheel r1 the-hub2 was chosen with probability 1.000000
	training time: 70.2116322517395s
	during the training the following losses were computed:
		loss: 1.312500
		loss: 2.383700
		loss: 2.267500
		loss: 2.308300
		loss: 2.268500
		loss: 2.280100
		loss: 2.253300
		loss: 2.251700
		loss: 1.888700
		loss: 2.227700
		loss: 2.124000
		loss: 2.209000
		loss: 2.304500
		loss: 2.197500
		loss: 2.215500
		loss: 2.184500
		loss: 2.064000
		loss: 2.176400
		loss: 2.101100
		loss: 2.171800
		loss: 2.183200
		loss: 2.169300
		loss: 2.083500
		loss: 2.166800
		loss: 1.911000
		loss: 2.166100
		loss: 2.159100
		loss: 2.164200
		loss: 2.260600
		loss: 2.162500
		loss: 2.126400
		loss: 2.162100
		loss: 2.374700
		loss: 2.160800
		loss: 1.875900
		loss: 2.159400
		loss: 1.934300
		loss: 2.157900
		loss: 1.949100
		loss: 2.156600
		loss: 2.379700
		loss: 2.155000
		loss: 1.732900
		loss: 2.153800
		loss: 2.472700
		loss: 2.152700
		loss: 2.005200
		loss: 2.152000
		loss: 2.032400
		loss: 2.151400
		loss: 2.209600
		loss: 2.150600
		loss: 2.304500
		loss: 2.150100
		loss: 2.267300
		loss: 2.149300
		loss: 1.749500
		loss: 2.149100
		loss: 2.113100
		loss: 2.148300
		loss: 1.971200
		loss: 2.147900
		loss: 1.941400
		loss: 2.147300
		loss: 2.077600
		loss: 2.146800
		loss: 2.158400
		loss: 2.146400
		loss: 1.921400
		loss: 2.145900
		loss: 2.190100
		loss: 2.145600
		loss: 1.840800
		loss: 2.145500
		loss: 2.173500
		loss: 2.145400
		loss: 2.461600
		loss: 2.144700
		loss: 2.388600
		loss: 2.144600
		loss: 2.155800
		loss: 2.144400
		loss: 2.181100
		loss: 2.144100
		loss: 1.987800
		loss: 2.143800
		loss: 2.370400
		loss: 2.143600
		loss: 2.130100
		loss: 2.143500
		loss: 2.075900
		loss: 2.143300
		loss: 2.356300
		loss: 2.143100
		loss: 2.019500
		loss: 2.142700
		loss: 1.701800
		loss: 2.142900
		loss: 1.960800
		loss: 2.142500
		loss: 2.096200
		loss: 2.142400
		loss: 2.016700
		loss: 2.142300
		loss: 2.286300
		loss: 2.142200
		loss: 2.245300
		loss: 2.141900
		loss: 2.219100
		loss: 2.141800
		loss: 2.243100
		loss: 2.141700
		loss: 2.017300
		loss: 2.141400
		loss: 2.154200
		loss: 2.141500
		loss: 2.149400
		loss: 2.141400
		loss: 2.131400
		loss: 2.141300
		loss: 2.253300
		loss: 2.141100
		loss: 2.262100
		loss: 2.141000
		loss: 2.178900
		loss: 2.140900
		loss: 2.289000
		loss: 2.140900
		loss: 2.529300
		loss: 2.140900
		loss: 1.957400
		loss: 2.140900
		loss: 2.128100
		loss: 2.140500
		loss: 1.761300
		loss: 2.140400
		loss: 1.904200
		loss: 2.140700
		loss: 1.953900
		loss: 2.140600
		loss: 2.207300
		loss: 2.140500
		loss: 2.239400
		loss: 2.140500
		loss: 2.070500
		loss: 2.140600
		loss: 2.366600
		loss: 2.140500
		loss: 2.085000
		loss: 2.140200
		loss: 1.928800
		loss: 2.139900
		loss: 1.839100
		loss: 2.140000
		loss: 2.253800
		loss: 2.139800
		loss: 2.103900
		loss: 2.139700
		loss: 2.340500
		loss: 2.139700
		loss: 2.081600
		loss: 2.139600
		loss: 2.237000
		loss: 2.139700
		loss: 2.085700
		loss: 2.139500
		loss: 2.070900
		loss: 2.139400
		loss: 1.986000
		loss: 2.139200
		loss: 2.192900
		loss: 2.139300
		loss: 1.941500
		loss: 2.139300
		loss: 2.019600
		loss: 2.139200
		loss: 1.942100
		loss: 2.139100
		loss: 2.254900
		loss: 2.139200
		loss: 1.861000
		loss: 2.139000
		loss: 2.005300
		loss: 2.139000
		loss: 2.172900
		loss: 2.138900
		loss: 2.233600
		loss: 2.139100
		loss: 2.285600
		loss: 2.138800
		loss: 2.164300
		loss: 2.138900
		loss: 1.820300
		loss: 2.138800
		loss: 2.258600
		loss: 2.138900
		loss: 2.101600
		loss: 2.138700
		loss: 1.928200
		loss: 2.138900
	Overall the loss development was 1.312500 -> 2.138900
problem epoch data for epoch 8, problem epoch 2
	sampling search time: 33.35979700088501s
	during this search the following actions were chosen:
		close boot was chosen with probability 0.000000
	training time: 18.10979413986206s
	during the training the following losses were computed:
		loss: 3.165100
		loss: 2.138700
		loss: 2.229600
		loss: 2.138700
		loss: 2.142400
		loss: 2.138800
		loss: 2.229300
		loss: 2.138400
		loss: 2.125600
		loss: 2.138600
		loss: 2.170600
		loss: 2.138600
		loss: 2.189600
		loss: 2.138500
		loss: 2.234900
		loss: 2.138500
		loss: 2.001400
		loss: 2.138400
		loss: 1.877000
		loss: 2.138400
		loss: 2.248500
		loss: 2.138400
		loss: 2.303500
		loss: 2.138300
		loss: 2.249200
		loss: 2.138300
		loss: 2.112700
		loss: 2.138400
		loss: 2.169100
		loss: 2.138500
		loss: 1.952800
		loss: 2.138500
		loss: 2.257200
		loss: 2.138700
		loss: 2.192300
		loss: 2.138700
		loss: 2.224600
		loss: 2.138700
		loss: 2.246600
		loss: 2.138500
		loss: 1.826300
		loss: 2.138700
		loss: 2.146300
		loss: 2.138500
		loss: 1.820600
		loss: 2.138600
		loss: 1.951300
		loss: 2.138400
		loss: 2.240300
		loss: 2.138000
		loss: 2.333600
		loss: 2.138300
		loss: 1.911400
		loss: 2.138400
		loss: 1.961500
		loss: 2.138300
		loss: 2.008300
		loss: 2.138900
		loss: 1.980600
		loss: 2.138500
		loss: 2.204300
		loss: 2.138500
		loss: 2.417800
		loss: 2.138500
		loss: 2.403400
		loss: 2.138500
		loss: 2.178100
		loss: 2.138500
		loss: 2.043200
		loss: 2.138300
		loss: 2.050500
		loss: 2.138300
		loss: 2.285000
		loss: 2.138500
		loss: 2.182900
		loss: 2.138200
		loss: 2.206200
		loss: 2.137900
		loss: 2.244300
		loss: 2.137900
		loss: 2.255100
		loss: 2.137700
		loss: 1.767000
		loss: 2.137800
		loss: 2.343000
		loss: 2.137600
		loss: 2.144200
		loss: 2.137500
		loss: 2.281200
		loss: 2.137400
		loss: 2.328900
		loss: 2.137400
		loss: 2.426300
		loss: 2.137300
		loss: 2.317900
		loss: 2.137500
		loss: 2.288900
		loss: 2.137200
		loss: 2.329900
		loss: 2.137300
		loss: 2.103200
		loss: 2.137300
		loss: 2.025800
		loss: 2.137300
		loss: 2.005700
		loss: 2.137200
		loss: 2.008500
		loss: 2.137200
		loss: 2.242100
		loss: 2.137200
		loss: 2.064600
		loss: 2.137100
		loss: 1.874900
		loss: 2.137200
		loss: 2.184200
		loss: 2.137100
		loss: 2.012600
		loss: 2.137200
		loss: 2.185700
		loss: 2.137100
		loss: 1.840800
		loss: 2.137000
		loss: 2.093100
		loss: 2.137000
		loss: 2.178900
		loss: 2.137000
		loss: 2.328400
		loss: 2.136900
		loss: 2.220200
		loss: 2.136900
		loss: 2.130000
		loss: 2.137100
		loss: 2.240900
		loss: 2.137100
		loss: 2.474400
		loss: 2.137000
		loss: 1.970500
		loss: 2.136900
		loss: 1.934300
		loss: 2.136800
		loss: 2.360800
		loss: 2.136800
		loss: 2.065100
		loss: 2.136900
		loss: 2.242000
		loss: 2.137000
		loss: 1.925500
		loss: 2.137000
		loss: 2.094100
		loss: 2.137100
		loss: 2.028200
		loss: 2.137300
		loss: 2.128600
		loss: 2.137100
		loss: 2.111900
		loss: 2.137100
		loss: 2.260900
		loss: 2.136800
		loss: 2.379200
		loss: 2.136800
		loss: 2.137600
		loss: 2.136700
		loss: 2.148300
		loss: 2.136700
		loss: 2.385700
		loss: 2.136700
		loss: 2.331500
		loss: 2.136700
		loss: 2.492000
		loss: 2.136600
		loss: 2.156500
		loss: 2.136600
		loss: 1.997100
		loss: 2.136600
		loss: 2.219600
		loss: 2.136500
		loss: 1.836300
		loss: 2.136500
		loss: 1.920700
		loss: 2.136500
		loss: 2.273600
		loss: 2.136500
		loss: 2.091100
		loss: 2.136500
		loss: 2.204900
		loss: 2.136500
		loss: 1.894900
		loss: 2.136500
		loss: 1.805200
		loss: 2.136500
		loss: 2.036400
		loss: 2.136500
		loss: 2.334300
		loss: 2.136600
		loss: 2.124200
		loss: 2.136400
		loss: 1.827800
		loss: 2.136500
		loss: 2.285300
		loss: 2.136400
	Overall the loss development was 3.165100 -> 2.136400
problem epoch data for epoch 8, problem epoch 3
	sampling search time: 33.10665535926819s
	during this search the following actions were chosen:
		close boot was chosen with probability 0.000000
	training time: 18.104841947555542s
	during the training the following losses were computed:
		loss: 3.162400
		loss: 2.136500
		loss: 1.962000
		loss: 2.136500
		loss: 1.931300
		loss: 2.136400
		loss: 2.239900
		loss: 2.136500
		loss: 1.949000
		loss: 2.136600
		loss: 1.894100
		loss: 2.136400
		loss: 2.091000
		loss: 2.136300
		loss: 1.935000
		loss: 2.136300
		loss: 2.294600
		loss: 2.136300
		loss: 2.554300
		loss: 2.136200
		loss: 2.346400
		loss: 2.136300
		loss: 1.835500
		loss: 2.136300
		loss: 1.548100
		loss: 2.136400
		loss: 1.994000
		loss: 2.136800
		loss: 2.021500
		loss: 2.137000
		loss: 2.194900
		loss: 2.136900
		loss: 2.347900
		loss: 2.136700
		loss: 2.328700
		loss: 2.136300
		loss: 2.246700
		loss: 2.136400
		loss: 2.386000
		loss: 2.136500
		loss: 2.358100
		loss: 2.136600
		loss: 2.419900
		loss: 2.136600
		loss: 1.993900
		loss: 2.136600
		loss: 2.126100
		loss: 2.136600
		loss: 2.132300
		loss: 2.136800
		loss: 1.558900
		loss: 2.136700
		loss: 1.930100
		loss: 2.136500
		loss: 2.279800
		loss: 2.136500
		loss: 2.079000
		loss: 2.136300
		loss: 2.062000
		loss: 2.136300
		loss: 2.178900
		loss: 2.136400
		loss: 1.975900
		loss: 2.136100
		loss: 2.418000
		loss: 2.136200
		loss: 2.079300
		loss: 2.136200
		loss: 2.250400
		loss: 2.136200
		loss: 2.112800
		loss: 2.136200
		loss: 2.461700
		loss: 2.135900
		loss: 2.198000
		loss: 2.136000
		loss: 2.125400
		loss: 2.135900
		loss: 2.263900
		loss: 2.136000
		loss: 1.961300
		loss: 2.136100
		loss: 2.119500
		loss: 2.136100
		loss: 2.194500
		loss: 2.136300
		loss: 2.264600
		loss: 2.136000
		loss: 2.268400
		loss: 2.136300
		loss: 1.894000
		loss: 2.136100
		loss: 1.907800
		loss: 2.136400
		loss: 2.220000
		loss: 2.136400
		loss: 1.961900
		loss: 2.136800
		loss: 1.894700
		loss: 2.136900
		loss: 1.924300
		loss: 2.136900
		loss: 2.076100
		loss: 2.136900
		loss: 1.936500
		loss: 2.136900
		loss: 2.117100
		loss: 2.137100
		loss: 2.127800
		loss: 2.137400
		loss: 2.313000
		loss: 2.137400
		loss: 2.202000
		loss: 2.136200
		loss: 2.316800
		loss: 2.137000
		loss: 2.125700
		loss: 2.136600
		loss: 2.164900
		loss: 2.136100
		loss: 2.079200
		loss: 2.136100
		loss: 2.348100
		loss: 2.136000
		loss: 2.192800
		loss: 2.135800
		loss: 2.192900
		loss: 2.135800
		loss: 1.946000
		loss: 2.135800
		loss: 2.423300
		loss: 2.135800
		loss: 2.162800
		loss: 2.135700
		loss: 2.566800
		loss: 2.135700
		loss: 1.993800
		loss: 2.135700
		loss: 1.909300
		loss: 2.135600
		loss: 2.244800
		loss: 2.135600
		loss: 2.323000
		loss: 2.135700
		loss: 2.180100
		loss: 2.135700
		loss: 2.428700
		loss: 2.135800
		loss: 1.948100
		loss: 2.135700
		loss: 2.165800
		loss: 2.135900
		loss: 2.125400
		loss: 2.136000
		loss: 1.854900
		loss: 2.135900
		loss: 1.816000
		loss: 2.136000
		loss: 1.952900
		loss: 2.136000
		loss: 2.171000
		loss: 2.136200
		loss: 2.246700
		loss: 2.136200
		loss: 2.052800
		loss: 2.136000
		loss: 1.924600
		loss: 2.136000
		loss: 2.314700
		loss: 2.135700
		loss: 2.163000
		loss: 2.135700
		loss: 2.247500
		loss: 2.135900
		loss: 1.996500
		loss: 2.135600
		loss: 2.400100
		loss: 2.135600
		loss: 1.967300
		loss: 2.135500
		loss: 2.027400
		loss: 2.135500
		loss: 1.887500
		loss: 2.135600
		loss: 2.076200
		loss: 2.135400
		loss: 2.132200
		loss: 2.135600
		loss: 2.011000
		loss: 2.135600
		loss: 2.258000
		loss: 2.135600
		loss: 2.329300
		loss: 2.135600
		loss: 1.908000
		loss: 2.135500
		loss: 2.385600
		loss: 2.135400
		loss: 2.100600
		loss: 2.135400
	Overall the loss development was 3.162400 -> 2.135400
In the epoch 8 for problem d-02.pddl 0 explorations in the sampling searches reached a goal
Success rate: 0

Epoch 9:
Training data for problem d-01.pddl in epoch 9:
model creation time: 7.983187437057495s
problem epoch data for epoch 9, problem epoch 1
	sampling search time: 2.1540660858154297s
	during this search the following actions were chosen:
		close boot was chosen with probability 0.000000
	training time: 37.77844429016113s
	during the training the following losses were computed:
		loss: 1.674800
		loss: 1.675900
		loss: 1.646200
		loss: 1.655000
		loss: 1.643500
		loss: 1.633200
		loss: 1.636600
		loss: 1.637100
		loss: 1.632300
		loss: 1.631000
		loss: 1.632100
		loss: 1.630000
		loss: 1.627000
		loss: 1.626400
		loss: 1.626900
		loss: 1.626400
		loss: 1.625900
		loss: 1.626500
		loss: 1.626700
		loss: 1.625300
		loss: 1.624000
		loss: 1.624200
		loss: 1.625100
		loss: 1.625100
		loss: 1.624500
		loss: 1.624300
		loss: 1.624400
		loss: 1.624100
		loss: 1.623700
		loss: 1.623600
		loss: 1.623500
		loss: 1.623100
		loss: 1.622900
		loss: 1.623000
		loss: 1.623000
		loss: 1.622800
		loss: 1.622700
		loss: 1.622700
		loss: 1.622600
		loss: 1.622300
		loss: 1.622200
		loss: 1.622300
		loss: 1.622300
		loss: 1.622200
		loss: 1.622200
		loss: 1.622200
		loss: 1.622100
		loss: 1.622100
		loss: 1.622100
		loss: 1.622000
		loss: 1.622000
		loss: 1.622000
		loss: 1.621900
		loss: 1.621900
		loss: 1.621800
		loss: 1.621800
		loss: 1.621800
		loss: 1.621700
		loss: 1.621700
		loss: 1.621700
		loss: 1.621700
		loss: 1.621600
		loss: 1.621600
		loss: 1.621600
		loss: 1.621600
		loss: 1.621500
		loss: 1.621500
		loss: 1.621500
		loss: 1.621500
		loss: 1.621500
		loss: 1.621400
		loss: 1.621400
		loss: 1.621400
		loss: 1.621400
		loss: 1.621400
		loss: 1.621300
		loss: 1.621300
		loss: 1.621300
		loss: 1.621300
		loss: 1.621300
		loss: 1.621200
		loss: 1.621200
		loss: 1.621200
		loss: 1.621200
		loss: 1.621200
		loss: 1.621100
		loss: 1.621100
		loss: 1.621100
		loss: 1.621100
		loss: 1.621100
		loss: 1.621100
		loss: 1.621000
		loss: 1.621000
		loss: 1.621000
		loss: 1.621000
		loss: 1.621000
		loss: 1.620900
		loss: 1.620900
		loss: 1.620900
		loss: 1.620900
	Overall the loss development was 1.674800 -> 1.620900
problem epoch data for epoch 9, problem epoch 2
	sampling search time: 1.8842709064483643s
	during this search the following actions were chosen:
		close boot was chosen with probability 0.000000
	training time: 10.127333402633667s
	during the training the following losses were computed:
		loss: 1.620900
		loss: 1.620900
		loss: 1.620800
		loss: 1.620800
		loss: 1.620800
		loss: 1.620800
		loss: 1.620800
		loss: 1.620800
		loss: 1.620700
		loss: 1.620700
		loss: 1.620700
		loss: 1.620700
		loss: 1.620700
		loss: 1.620700
		loss: 1.620700
		loss: 1.620600
		loss: 1.620600
		loss: 1.620600
		loss: 1.620600
		loss: 1.620600
		loss: 1.620600
		loss: 1.620500
		loss: 1.620500
		loss: 1.620500
		loss: 1.620500
		loss: 1.620500
		loss: 1.620500
		loss: 1.620500
		loss: 1.620400
		loss: 1.620400
		loss: 1.620400
		loss: 1.620400
		loss: 1.620400
		loss: 1.620400
		loss: 1.620400
		loss: 1.620300
		loss: 1.620300
		loss: 1.620300
		loss: 1.620300
		loss: 1.620300
		loss: 1.620300
		loss: 1.620300
		loss: 1.620200
		loss: 1.620200
		loss: 1.620200
		loss: 1.620200
		loss: 1.620200
		loss: 1.620200
		loss: 1.620200
		loss: 1.620100
		loss: 1.620100
		loss: 1.620100
		loss: 1.620100
		loss: 1.620100
		loss: 1.620100
		loss: 1.620100
		loss: 1.620100
		loss: 1.620000
		loss: 1.620000
		loss: 1.620000
		loss: 1.620000
		loss: 1.620000
		loss: 1.620000
		loss: 1.620000
		loss: 1.619900
		loss: 1.619900
		loss: 1.619900
		loss: 1.619900
		loss: 1.619900
		loss: 1.619900
		loss: 1.619900
		loss: 1.619900
		loss: 1.619800
		loss: 1.619800
		loss: 1.619800
		loss: 1.619800
		loss: 1.619800
		loss: 1.619800
		loss: 1.619800
		loss: 1.619800
		loss: 1.619800
		loss: 1.619700
		loss: 1.619700
		loss: 1.619700
		loss: 1.619700
		loss: 1.619700
		loss: 1.619700
		loss: 1.619700
		loss: 1.619700
		loss: 1.619600
		loss: 1.619600
		loss: 1.619600
		loss: 1.619600
		loss: 1.619600
		loss: 1.619600
		loss: 1.619600
		loss: 1.619600
		loss: 1.619600
		loss: 1.619500
		loss: 1.619500
	Overall the loss development was 1.620900 -> 1.619500
problem epoch data for epoch 9, problem epoch 3
	sampling search time: 1.9422833919525146s
	during this search the following actions were chosen:
		close boot was chosen with probability 0.000000
	training time: 10.127291202545166s
	during the training the following losses were computed:
		loss: 1.619500
		loss: 1.619500
		loss: 1.619500
		loss: 1.619500
		loss: 1.619500
		loss: 1.619500
		loss: 1.619500
		loss: 1.619500
		loss: 1.619400
		loss: 1.619400
		loss: 1.619400
		loss: 1.619400
		loss: 1.619400
		loss: 1.619400
		loss: 1.619400
		loss: 1.619400
		loss: 1.619400
		loss: 1.619300
		loss: 1.619300
		loss: 1.619300
		loss: 1.619300
		loss: 1.619300
		loss: 1.619300
		loss: 1.619300
		loss: 1.619300
		loss: 1.619300
		loss: 1.619300
		loss: 1.619200
		loss: 1.619200
		loss: 1.619200
		loss: 1.619200
		loss: 1.619200
		loss: 1.619200
		loss: 1.619200
		loss: 1.619200
		loss: 1.619200
		loss: 1.619200
		loss: 1.619200
		loss: 1.619100
		loss: 1.619100
		loss: 1.619100
		loss: 1.619100
		loss: 1.619100
		loss: 1.619100
		loss: 1.619100
		loss: 1.619100
		loss: 1.619100
		loss: 1.619100
		loss: 1.619000
		loss: 1.619000
		loss: 1.619000
		loss: 1.619000
		loss: 1.619000
		loss: 1.619000
		loss: 1.619000
		loss: 1.619000
		loss: 1.619000
		loss: 1.619000
		loss: 1.619000
		loss: 1.618900
		loss: 1.618900
		loss: 1.618900
		loss: 1.618900
		loss: 1.618900
		loss: 1.618900
		loss: 1.618900
		loss: 1.618900
		loss: 1.618900
		loss: 1.618900
		loss: 1.618900
		loss: 1.618800
		loss: 1.618800
		loss: 1.618800
		loss: 1.618800
		loss: 1.618800
		loss: 1.618800
		loss: 1.618800
		loss: 1.618800
		loss: 1.618800
		loss: 1.618800
		loss: 1.618800
		loss: 1.618800
		loss: 1.618700
		loss: 1.618700
		loss: 1.618700
		loss: 1.618700
		loss: 1.618700
		loss: 1.618700
		loss: 1.618700
		loss: 1.618700
		loss: 1.618700
		loss: 1.618700
		loss: 1.618700
		loss: 1.618700
		loss: 1.618600
		loss: 1.618600
		loss: 1.618600
		loss: 1.618600
		loss: 1.618600
		loss: 1.618600
	Overall the loss development was 1.619500 -> 1.618600
In the epoch 9 for problem d-01.pddl 0 explorations in the sampling searches reached a goal
Training data for problem d-02.pddl in epoch 9:
model creation time: 15.456002950668335s
problem epoch data for epoch 9, problem epoch 1
	sampling search time: 207.6540470123291s
	during this search the following actions were chosen:
		open boot was chosen with probability 1.000000
		fetch wrench boot was chosen with probability 0.498088
		fetch jack boot was chosen with probability 0.622636
		loosen nuts2 the-hub2 was chosen with probability 0.248806
		loosen nuts1 the-hub1 was chosen with probability 0.576348
		fetch pump boot was chosen with probability 0.341797
		jack-up the-hub2 was chosen with probability 0.526667
		undo nuts2 the-hub2 was chosen with probability 0.935500
		fetch r2 boot was chosen with probability 0.416986
		remove-wheel w2 the-hub2 was chosen with probability 0.771832
		fetch r1 boot was chosen with probability 0.970342
		put-on-wheel r2 the-hub2 was chosen with probability 0.821567
		remove-wheel r2 the-hub2 was chosen with probability 0.694854
	training time: 71.35609030723572s
	during the training the following losses were computed:
		loss: 1.681700
		loss: 2.831400
		loss: 3.008600
		loss: 2.760400
		loss: 2.806600
		loss: 2.723900
		loss: 2.929000
		loss: 2.702100
		loss: 2.501500
		loss: 2.675500
		loss: 2.719900
		loss: 2.661500
		loss: 2.028800
		loss: 2.648900
		loss: 2.924100
		loss: 2.644100
		loss: 2.570900
		loss: 2.639200
		loss: 2.824800
		loss: 2.636500
		loss: 2.688900
		loss: 2.636800
		loss: 2.875600
		loss: 2.635300
		loss: 2.944700
		loss: 2.634400
		loss: 2.299600
		loss: 2.632900
		loss: 2.175100
		loss: 2.631300
		loss: 2.475000
		loss: 2.628600
		loss: 2.991200
		loss: 2.627300
		loss: 2.552800
		loss: 2.625500
		loss: 2.540100
		loss: 2.624400
		loss: 2.365300
		loss: 2.623700
		loss: 2.872200
		loss: 2.622300
		loss: 2.276300
		loss: 2.622000
		loss: 2.540600
		loss: 2.621100
		loss: 2.435800
		loss: 2.620400
		loss: 2.799300
		loss: 2.620100
		loss: 2.891600
		loss: 2.619500
		loss: 3.187000
		loss: 2.618700
		loss: 2.287000
		loss: 2.618200
		loss: 2.587600
		loss: 2.617600
		loss: 2.424400
		loss: 2.617200
		loss: 2.521000
		loss: 2.616500
		loss: 2.818900
		loss: 2.616300
		loss: 2.778500
		loss: 2.615700
		loss: 2.808900
		loss: 2.615600
		loss: 2.288800
		loss: 2.615000
		loss: 2.677900
		loss: 2.614700
		loss: 2.386200
		loss: 2.614900
		loss: 2.361900
		loss: 2.614000
		loss: 2.686600
		loss: 2.614000
		loss: 2.575500
		loss: 2.613900
		loss: 2.952000
		loss: 2.613500
		loss: 3.046400
		loss: 2.613300
		loss: 2.519000
		loss: 2.613100
		loss: 2.084500
		loss: 2.612700
		loss: 2.535700
		loss: 2.612500
		loss: 2.696400
		loss: 2.612300
		loss: 2.229100
		loss: 2.612100
		loss: 2.635400
		loss: 2.611800
		loss: 2.258000
		loss: 2.611800
		loss: 2.232800
		loss: 2.611600
		loss: 2.710600
		loss: 2.611400
		loss: 2.604500
		loss: 2.611100
		loss: 2.715600
		loss: 2.611100
		loss: 2.672800
		loss: 2.610700
		loss: 2.622200
		loss: 2.610600
		loss: 2.641000
		loss: 2.610400
		loss: 2.840100
		loss: 2.610100
		loss: 2.902400
		loss: 2.610000
		loss: 2.483500
		loss: 2.609900
		loss: 2.760400
		loss: 2.609700
		loss: 2.914200
		loss: 2.609600
		loss: 2.449800
		loss: 2.609600
		loss: 2.447800
		loss: 2.609300
		loss: 2.695800
		loss: 2.609200
		loss: 2.387400
		loss: 2.609200
		loss: 2.800600
		loss: 2.609100
		loss: 2.786800
		loss: 2.608900
		loss: 2.343100
		loss: 2.608800
		loss: 2.700000
		loss: 2.608700
		loss: 2.327700
		loss: 2.608600
		loss: 2.557000
		loss: 2.608500
		loss: 2.388400
		loss: 2.608400
		loss: 2.414800
		loss: 2.608200
		loss: 2.531700
		loss: 2.608300
		loss: 2.906700
		loss: 2.608300
		loss: 2.511700
		loss: 2.608100
		loss: 2.437600
		loss: 2.608300
		loss: 2.653700
		loss: 2.608100
		loss: 2.445600
		loss: 2.607800
		loss: 2.439600
		loss: 2.608200
		loss: 3.037000
		loss: 2.607800
		loss: 2.771500
		loss: 2.608000
		loss: 2.456600
		loss: 2.607900
		loss: 2.627600
		loss: 2.607600
		loss: 2.672200
		loss: 2.607700
		loss: 2.520000
		loss: 2.607200
		loss: 2.449800
		loss: 2.607400
		loss: 2.427400
		loss: 2.607300
		loss: 2.301600
		loss: 2.607200
		loss: 2.565800
		loss: 2.607000
		loss: 2.449600
		loss: 2.606900
		loss: 2.581400
		loss: 2.607000
		loss: 2.919900
		loss: 2.606800
		loss: 2.674200
		loss: 2.606800
		loss: 2.819500
		loss: 2.606700
		loss: 2.547200
		loss: 2.606600
		loss: 2.673200
		loss: 2.606500
		loss: 2.186300
		loss: 2.606500
		loss: 2.406200
		loss: 2.606500
		loss: 2.785100
		loss: 2.606400
	Overall the loss development was 1.681700 -> 2.606400
problem epoch data for epoch 9, problem epoch 2
	sampling search time: 209.05859065055847s
	during this search the following actions were chosen:
		open boot was chosen with probability 1.000000
		fetch wrench boot was chosen with probability 0.371877
		fetch jack boot was chosen with probability 0.325837
		loosen nuts1 the-hub1 was chosen with probability 0.489294
		loosen nuts2 the-hub2 was chosen with probability 0.882879
		jack-up the-hub1 was chosen with probability 0.845475
		undo nuts1 the-hub1 was chosen with probability 0.992454
		remove-wheel w1 the-hub1 was chosen with probability 0.880745
		fetch r1 boot was chosen with probability 0.551215
		fetch r2 boot was chosen with probability 0.752597
		fetch pump boot was chosen with probability 0.945893
		inflate r1 was chosen with probability 0.469098
		inflate r2 was chosen with probability 0.911197
		put-on-wheel r1 the-hub1 was chosen with probability 0.773661
		remove-wheel r1 the-hub1 was chosen with probability 0.999974
	training time: 19.415995836257935s
	during the training the following losses were computed:
		loss: 3.530600
		loss: 2.787000
		loss: 3.010900
		loss: 2.786700
		loss: 3.214100
		loss: 2.785900
		loss: 2.742100
		loss: 2.785200
		loss: 2.689300
		loss: 2.784500
		loss: 3.108800
		loss: 2.784200
		loss: 2.578500
		loss: 2.783700
		loss: 2.933000
		loss: 2.783200
		loss: 2.688800
		loss: 2.782400
		loss: 2.779700
		loss: 2.782100
		loss: 3.061100
		loss: 2.781800
		loss: 3.236300
		loss: 2.781500
		loss: 2.879400
		loss: 2.781100
		loss: 2.577600
		loss: 2.781000
		loss: 2.609300
		loss: 2.780600
		loss: 2.944200
		loss: 2.780500
		loss: 2.516200
		loss: 2.780300
		loss: 2.815200
		loss: 2.780400
		loss: 2.910400
		loss: 2.780200
		loss: 2.932200
		loss: 2.779900
		loss: 2.951600
		loss: 2.779600
		loss: 2.843500
		loss: 2.779500
		loss: 2.818100
		loss: 2.779400
		loss: 2.793200
		loss: 2.779300
		loss: 2.926200
		loss: 2.779000
		loss: 2.731400
		loss: 2.778900
		loss: 3.121700
		loss: 2.778800
		loss: 2.607000
		loss: 2.778700
		loss: 2.704000
		loss: 2.778700
		loss: 2.633400
		loss: 2.778700
		loss: 2.576300
		loss: 2.778400
		loss: 2.504800
		loss: 2.778400
		loss: 2.533100
		loss: 2.778500
		loss: 2.710600
		loss: 2.778100
		loss: 2.790900
		loss: 2.778100
		loss: 2.971500
		loss: 2.778200
		loss: 2.637600
		loss: 2.778000
		loss: 2.555800
		loss: 2.777900
		loss: 2.846400
		loss: 2.778100
		loss: 2.665600
		loss: 2.778000
		loss: 2.638200
		loss: 2.778000
		loss: 2.882900
		loss: 2.777800
		loss: 2.941800
		loss: 2.777700
		loss: 2.920900
		loss: 2.777600
		loss: 2.978100
		loss: 2.777700
		loss: 2.704700
		loss: 2.777500
		loss: 2.773400
		loss: 2.777400
		loss: 2.599600
		loss: 2.777400
		loss: 2.539900
		loss: 2.777300
		loss: 2.838200
		loss: 2.777300
		loss: 3.045000
		loss: 2.777200
		loss: 2.644100
		loss: 2.777000
		loss: 3.061300
		loss: 2.777000
		loss: 2.672200
		loss: 2.777000
		loss: 2.919800
		loss: 2.776900
		loss: 2.710900
		loss: 2.777000
		loss: 2.908300
		loss: 2.776900
		loss: 2.921400
		loss: 2.776700
		loss: 2.624400
		loss: 2.776700
		loss: 2.814000
		loss: 2.776700
		loss: 2.720100
		loss: 2.776800
		loss: 2.991800
		loss: 2.776700
		loss: 2.776600
		loss: 2.776600
		loss: 2.672200
		loss: 2.776500
		loss: 3.006300
		loss: 2.776600
		loss: 2.668500
		loss: 2.776500
		loss: 2.879800
		loss: 2.776500
		loss: 2.770400
		loss: 2.776400
		loss: 2.885600
		loss: 2.776500
		loss: 2.187400
		loss: 2.776300
		loss: 2.697700
		loss: 2.776300
		loss: 2.687100
		loss: 2.776200
		loss: 3.021600
		loss: 2.776200
		loss: 2.760500
		loss: 2.776100
		loss: 2.547600
		loss: 2.776200
		loss: 2.984900
		loss: 2.776100
		loss: 2.147600
		loss: 2.776100
		loss: 2.834100
		loss: 2.776100
		loss: 2.727100
		loss: 2.776200
		loss: 3.017900
		loss: 2.776300
		loss: 3.081400
		loss: 2.776300
		loss: 2.652800
		loss: 2.776400
		loss: 3.022000
		loss: 2.776400
		loss: 2.380500
		loss: 2.776300
		loss: 2.679000
		loss: 2.776100
		loss: 2.409200
		loss: 2.776100
		loss: 2.813100
		loss: 2.776100
		loss: 2.806400
		loss: 2.775900
		loss: 2.861300
		loss: 2.775800
		loss: 3.225300
		loss: 2.775800
		loss: 2.996600
		loss: 2.776000
		loss: 3.166500
		loss: 2.775900
		loss: 2.741200
		loss: 2.775600
		loss: 2.797400
		loss: 2.775600
		loss: 3.090700
		loss: 2.775700
		loss: 2.845200
		loss: 2.775900
		loss: 2.607900
		loss: 2.775700
		loss: 2.548600
		loss: 2.775700
		loss: 2.915700
		loss: 2.775600
		loss: 2.937600
		loss: 2.775600
	Overall the loss development was 3.530600 -> 2.775600
problem epoch data for epoch 9, problem epoch 3
	sampling search time: 33.43772578239441s
	during this search the following actions were chosen:
		close boot was chosen with probability 0.000000
	training time: 19.51828145980835s
	during the training the following losses were computed:
		loss: 2.023700
		loss: 2.775700
		loss: 2.970500
		loss: 2.775700
		loss: 2.850600
		loss: 2.775700
		loss: 2.860500
		loss: 2.776300
		loss: 2.961400
		loss: 2.775800
		loss: 2.532500
		loss: 2.776100
		loss: 3.022900
		loss: 2.775900
		loss: 2.815400
		loss: 2.775800
		loss: 3.354900
		loss: 2.776000
		loss: 2.962400
		loss: 2.776100
		loss: 2.835200
		loss: 2.775900
		loss: 1.976200
		loss: 2.776100
		loss: 2.918800
		loss: 2.775800
		loss: 2.653600
		loss: 2.775700
		loss: 2.898200
		loss: 2.775800
		loss: 2.520100
		loss: 2.776400
		loss: 3.004600
		loss: 2.777400
		loss: 2.896200
		loss: 2.777900
		loss: 2.863900
		loss: 2.778200
		loss: 3.106500
		loss: 2.776900
		loss: 2.687000
		loss: 2.777300
		loss: 2.512400
		loss: 2.777900
		loss: 2.418700
		loss: 2.777500
		loss: 2.508600
		loss: 2.777000
		loss: 3.117700
		loss: 2.776800
		loss: 3.122900
		loss: 2.776600
		loss: 2.881400
		loss: 2.776400
		loss: 2.735800
		loss: 2.776100
		loss: 3.079000
		loss: 2.776000
		loss: 3.066700
		loss: 2.775600
		loss: 3.114900
		loss: 2.775500
		loss: 2.366600
		loss: 2.775800
		loss: 3.037300
		loss: 2.775500
		loss: 3.011300
		loss: 2.775700
		loss: 3.091600
		loss: 2.775800
		loss: 2.893600
		loss: 2.775900
		loss: 2.874100
		loss: 2.775600
		loss: 2.675600
		loss: 2.775600
		loss: 2.484800
		loss: 2.775600
		loss: 2.559700
		loss: 2.775700
		loss: 2.752200
		loss: 2.775700
		loss: 2.849600
		loss: 2.775600
		loss: 2.931200
		loss: 2.775300
		loss: 2.843700
		loss: 2.775600
		loss: 2.989200
		loss: 2.775400
		loss: 2.568200
		loss: 2.775600
		loss: 3.212100
		loss: 2.775600
		loss: 2.794300
		loss: 2.775800
		loss: 2.736400
		loss: 2.775900
		loss: 2.410500
		loss: 2.775600
		loss: 3.025200
		loss: 2.775600
		loss: 3.213500
		loss: 2.775500
		loss: 2.742500
		loss: 2.775500
		loss: 2.967700
		loss: 2.775600
		loss: 2.714000
		loss: 2.775500
		loss: 2.791400
		loss: 2.775300
		loss: 2.753800
		loss: 2.775500
		loss: 3.029200
		loss: 2.775500
		loss: 2.850300
		loss: 2.775500
		loss: 2.565900
		loss: 2.775400
		loss: 3.040500
		loss: 2.775600
		loss: 2.505100
		loss: 2.775700
		loss: 2.813700
		loss: 2.775700
		loss: 2.914300
		loss: 2.775500
		loss: 2.785500
		loss: 2.775800
		loss: 2.875000
		loss: 2.775700
		loss: 2.537300
		loss: 2.775400
		loss: 2.521600
		loss: 2.775500
		loss: 2.724400
		loss: 2.775700
		loss: 2.760000
		loss: 2.775600
		loss: 3.246900
		loss: 2.775400
		loss: 2.398100
		loss: 2.775200
		loss: 2.837900
		loss: 2.775200
		loss: 2.632700
		loss: 2.775500
		loss: 2.394700
		loss: 2.775800
		loss: 2.529200
		loss: 2.775500
		loss: 2.598600
		loss: 2.775600
		loss: 3.045600
		loss: 2.776500
		loss: 2.890400
		loss: 2.776000
		loss: 2.868100
		loss: 2.776100
		loss: 2.874900
		loss: 2.775800
		loss: 2.388800
		loss: 2.775900
		loss: 2.738200
		loss: 2.775600
		loss: 2.974100
		loss: 2.775700
		loss: 2.639100
		loss: 2.775300
		loss: 2.886700
		loss: 2.775100
		loss: 3.140800
		loss: 2.774800
		loss: 2.801900
		loss: 2.775000
		loss: 2.540300
		loss: 2.774700
		loss: 2.763300
		loss: 2.774800
		loss: 3.055800
		loss: 2.774600
		loss: 3.068900
		loss: 2.774600
		loss: 2.831100
		loss: 2.774500
		loss: 2.675900
		loss: 2.774600
		loss: 2.661400
		loss: 2.774500
		loss: 2.816500
		loss: 2.774600
		loss: 2.531100
		loss: 2.774500
		loss: 3.082200
		loss: 2.774500
		loss: 2.685100
		loss: 2.774500
		loss: 2.369400
		loss: 2.774500
	Overall the loss development was 2.023700 -> 2.774500
In the epoch 9 for problem d-02.pddl 0 explorations in the sampling searches reached a goal
Success rate: 0

Epoch 10:
Training data for problem d-01.pddl in epoch 10:
model creation time: 7.96140718460083s
problem epoch data for epoch 10, problem epoch 1
	sampling search time: 2.090611457824707s
	during this search the following actions were chosen:
		close boot was chosen with probability 0.000000
	training time: 37.45765781402588s
	during the training the following losses were computed:
		loss: 1.821300
		loss: 1.737000
		loss: 1.690800
		loss: 1.680400
		loss: 1.679900
		loss: 1.677400
		loss: 1.668400
		loss: 1.657300
		loss: 1.650400
		loss: 1.649000
		loss: 1.650400
		loss: 1.650300
		loss: 1.646800
		loss: 1.640900
		loss: 1.635200
		loss: 1.631700
		loss: 1.631100
		loss: 1.632400
		loss: 1.634200
		loss: 1.634800
		loss: 1.633600
		loss: 1.631200
		loss: 1.628700
		loss: 1.627500
		loss: 1.627700
		loss: 1.628800
		loss: 1.629600
		loss: 1.629500
		loss: 1.628600
		loss: 1.627300
		loss: 1.626300
		loss: 1.625800
		loss: 1.625900
		loss: 1.626100
		loss: 1.626100
		loss: 1.625800
		loss: 1.625400
		loss: 1.625000
		loss: 1.624800
		loss: 1.624800
		loss: 1.624700
		loss: 1.624600
		loss: 1.624400
		loss: 1.624300
		loss: 1.624300
		loss: 1.624300
		loss: 1.624400
		loss: 1.624300
		loss: 1.624200
		loss: 1.624000
		loss: 1.623900
		loss: 1.623900
		loss: 1.623900
		loss: 1.623900
		loss: 1.623800
		loss: 1.623700
		loss: 1.623600
		loss: 1.623600
		loss: 1.623500
		loss: 1.623500
		loss: 1.623500
		loss: 1.623400
		loss: 1.623400
		loss: 1.623300
		loss: 1.623300
		loss: 1.623300
		loss: 1.623200
		loss: 1.623200
		loss: 1.623200
		loss: 1.623100
		loss: 1.623100
		loss: 1.623100
		loss: 1.623100
		loss: 1.623000
		loss: 1.623000
		loss: 1.623000
		loss: 1.622900
		loss: 1.622900
		loss: 1.622900
		loss: 1.622900
		loss: 1.622900
		loss: 1.622800
		loss: 1.622800
		loss: 1.622800
		loss: 1.622800
		loss: 1.622700
		loss: 1.622700
		loss: 1.622700
		loss: 1.622700
		loss: 1.622700
		loss: 1.622600
		loss: 1.622600
		loss: 1.622600
		loss: 1.622600
		loss: 1.622600
		loss: 1.622500
		loss: 1.622500
		loss: 1.622500
		loss: 1.622500
		loss: 1.622500
	Overall the loss development was 1.821300 -> 1.622500
problem epoch data for epoch 10, problem epoch 2
	sampling search time: 1.9260411262512207s
	during this search the following actions were chosen:
		close boot was chosen with probability 0.000000
	training time: 10.127023696899414s
	during the training the following losses were computed:
		loss: 1.622400
		loss: 1.622400
		loss: 1.622400
		loss: 1.622400
		loss: 1.622400
		loss: 1.622400
		loss: 1.622300
		loss: 1.622300
		loss: 1.622300
		loss: 1.622300
		loss: 1.622300
		loss: 1.622200
		loss: 1.622200
		loss: 1.622200
		loss: 1.622200
		loss: 1.622200
		loss: 1.622200
		loss: 1.622100
		loss: 1.622100
		loss: 1.622100
		loss: 1.622100
		loss: 1.622100
		loss: 1.622100
		loss: 1.622100
		loss: 1.622000
		loss: 1.622000
		loss: 1.622000
		loss: 1.622000
		loss: 1.622000
		loss: 1.622000
		loss: 1.621900
		loss: 1.621900
		loss: 1.621900
		loss: 1.621900
		loss: 1.621900
		loss: 1.621900
		loss: 1.621800
		loss: 1.621800
		loss: 1.621800
		loss: 1.621800
		loss: 1.621800
		loss: 1.621800
		loss: 1.621800
		loss: 1.621700
		loss: 1.621700
		loss: 1.621700
		loss: 1.621700
		loss: 1.621700
		loss: 1.621700
		loss: 1.621700
		loss: 1.621600
		loss: 1.621600
		loss: 1.621600
		loss: 1.621600
		loss: 1.621600
		loss: 1.621600
		loss: 1.621600
		loss: 1.621500
		loss: 1.621500
		loss: 1.621500
		loss: 1.621500
		loss: 1.621500
		loss: 1.621500
		loss: 1.621500
		loss: 1.621500
		loss: 1.621400
		loss: 1.621400
		loss: 1.621400
		loss: 1.621400
		loss: 1.621400
		loss: 1.621400
		loss: 1.621400
		loss: 1.621300
		loss: 1.621300
		loss: 1.621300
		loss: 1.621300
		loss: 1.621300
		loss: 1.621300
		loss: 1.621300
		loss: 1.621300
		loss: 1.621200
		loss: 1.621200
		loss: 1.621200
		loss: 1.621200
		loss: 1.621200
		loss: 1.621200
		loss: 1.621200
		loss: 1.621200
		loss: 1.621100
		loss: 1.621100
		loss: 1.621100
		loss: 1.621100
		loss: 1.621100
		loss: 1.621100
		loss: 1.621100
		loss: 1.621100
		loss: 1.621000
		loss: 1.621000
		loss: 1.621000
		loss: 1.621000
	Overall the loss development was 1.622400 -> 1.621000
problem epoch data for epoch 10, problem epoch 3
	sampling search time: 1.942732810974121s
	during this search the following actions were chosen:
		close boot was chosen with probability 0.000000
	training time: 10.127292156219482s
	during the training the following losses were computed:
		loss: 1.621000
		loss: 1.621000
		loss: 1.621000
		loss: 1.621000
		loss: 1.621000
		loss: 1.620900
		loss: 1.620900
		loss: 1.620900
		loss: 1.620900
		loss: 1.620900
		loss: 1.620900
		loss: 1.620900
		loss: 1.620900
		loss: 1.620900
		loss: 1.620800
		loss: 1.620800
		loss: 1.620800
		loss: 1.620800
		loss: 1.620800
		loss: 1.620800
		loss: 1.620800
		loss: 1.620800
		loss: 1.620700
		loss: 1.620700
		loss: 1.620700
		loss: 1.620700
		loss: 1.620700
		loss: 1.620700
		loss: 1.620700
		loss: 1.620700
		loss: 1.620700
		loss: 1.620700
		loss: 1.620600
		loss: 1.620600
		loss: 1.620600
		loss: 1.620600
		loss: 1.620600
		loss: 1.620600
		loss: 1.620600
		loss: 1.620600
		loss: 1.620600
		loss: 1.620500
		loss: 1.620500
		loss: 1.620500
		loss: 1.620500
		loss: 1.620500
		loss: 1.620500
		loss: 1.620500
		loss: 1.620500
		loss: 1.620500
		loss: 1.620500
		loss: 1.620400
		loss: 1.620400
		loss: 1.620400
		loss: 1.620400
		loss: 1.620400
		loss: 1.620400
		loss: 1.620400
		loss: 1.620400
		loss: 1.620400
		loss: 1.620300
		loss: 1.620300
		loss: 1.620300
		loss: 1.620300
		loss: 1.620300
		loss: 1.620300
		loss: 1.620300
		loss: 1.620300
		loss: 1.620300
		loss: 1.620300
		loss: 1.620300
		loss: 1.620200
		loss: 1.620200
		loss: 1.620200
		loss: 1.620200
		loss: 1.620200
		loss: 1.620200
		loss: 1.620200
		loss: 1.620200
		loss: 1.620200
		loss: 1.620200
		loss: 1.620100
		loss: 1.620100
		loss: 1.620100
		loss: 1.620100
		loss: 1.620100
		loss: 1.620100
		loss: 1.620100
		loss: 1.620100
		loss: 1.620100
		loss: 1.620100
		loss: 1.620100
		loss: 1.620000
		loss: 1.620000
		loss: 1.620000
		loss: 1.620000
		loss: 1.620000
		loss: 1.620000
		loss: 1.620000
		loss: 1.620000
	Overall the loss development was 1.621000 -> 1.620000
In the epoch 10 for problem d-01.pddl 0 explorations in the sampling searches reached a goal
Training data for problem d-02.pddl in epoch 10:
model creation time: 15.435087442398071s
problem epoch data for epoch 10, problem epoch 1
	sampling search time: 33.160555839538574s
	during this search the following actions were chosen:
		close boot was chosen with probability 0.000000
	training time: 62.5604944229126s
	during the training the following losses were computed:
		loss: 2.625300
		loss: 2.542500
		loss: 2.530800
		loss: 2.542500
		loss: 2.535600
		loss: 2.518600
		loss: 2.506200
		loss: 2.502400
		loss: 2.502900
		loss: 2.502300
		loss: 2.498000
		loss: 2.491800
		loss: 2.487500
		loss: 2.486800
		loss: 2.488600
		loss: 2.489800
		loss: 2.488700
		loss: 2.485900
		loss: 2.483400
		loss: 2.482800
		loss: 2.483900
		loss: 2.485200
		loss: 2.485200
		loss: 2.483900
		loss: 2.482200
		loss: 2.481000
		loss: 2.480900
		loss: 2.481300
		loss: 2.481500
		loss: 2.481100
		loss: 2.480400
		loss: 2.479800
		loss: 2.479700
		loss: 2.479700
		loss: 2.479700
		loss: 2.479500
		loss: 2.479200
		loss: 2.478900
		loss: 2.478900
		loss: 2.478900
		loss: 2.478700
		loss: 2.478500
		loss: 2.478200
		loss: 2.478100
		loss: 2.478100
		loss: 2.478200
		loss: 2.478000
		loss: 2.477800
		loss: 2.477600
		loss: 2.477600
		loss: 2.477600
		loss: 2.477600
		loss: 2.477500
		loss: 2.477400
		loss: 2.477300
		loss: 2.477200
		loss: 2.477200
		loss: 2.477100
		loss: 2.477100
		loss: 2.477000
		loss: 2.476900
		loss: 2.476900
		loss: 2.476900
		loss: 2.476800
		loss: 2.476800
		loss: 2.476700
		loss: 2.476700
		loss: 2.476700
		loss: 2.476600
		loss: 2.476600
		loss: 2.476500
		loss: 2.476500
		loss: 2.476500
		loss: 2.476400
		loss: 2.476400
		loss: 2.476400
		loss: 2.476400
		loss: 2.476300
		loss: 2.476300
		loss: 2.476300
		loss: 2.476300
		loss: 2.476200
		loss: 2.476200
		loss: 2.476200
		loss: 2.476200
		loss: 2.476200
		loss: 2.476100
		loss: 2.476100
		loss: 2.476100
		loss: 2.476100
		loss: 2.476100
		loss: 2.476000
		loss: 2.476000
		loss: 2.476000
		loss: 2.476000
		loss: 2.476000
		loss: 2.476000
		loss: 2.475900
		loss: 2.475900
		loss: 2.475900
	Overall the loss development was 2.625300 -> 2.475900
problem epoch data for epoch 10, problem epoch 2
	sampling search time: 33.25811266899109s
	during this search the following actions were chosen:
		close boot was chosen with probability 0.000000
	training time: 10.13845157623291s
	during the training the following losses were computed:
		loss: 2.475900
		loss: 2.475900
		loss: 2.475900
		loss: 2.475900
		loss: 2.475800
		loss: 2.475800
		loss: 2.475800
		loss: 2.475800
		loss: 2.475800
		loss: 2.475800
		loss: 2.475800
		loss: 2.475800
		loss: 2.475700
		loss: 2.475700
		loss: 2.475700
		loss: 2.475700
		loss: 2.475700
		loss: 2.475700
		loss: 2.475700
		loss: 2.475700
		loss: 2.475600
		loss: 2.475600
		loss: 2.475600
		loss: 2.475600
		loss: 2.475600
		loss: 2.475600
		loss: 2.475600
		loss: 2.475600
		loss: 2.475600
		loss: 2.475500
		loss: 2.475500
		loss: 2.475500
		loss: 2.475500
		loss: 2.475500
		loss: 2.475500
		loss: 2.475500
		loss: 2.475500
		loss: 2.475500
		loss: 2.475500
		loss: 2.475400
		loss: 2.475400
		loss: 2.475400
		loss: 2.475400
		loss: 2.475400
		loss: 2.475400
		loss: 2.475400
		loss: 2.475400
		loss: 2.475400
		loss: 2.475400
		loss: 2.475400
		loss: 2.475300
		loss: 2.475300
		loss: 2.475300
		loss: 2.475300
		loss: 2.475300
		loss: 2.475300
		loss: 2.475300
		loss: 2.475300
		loss: 2.475300
		loss: 2.475300
		loss: 2.475300
		loss: 2.475200
		loss: 2.475200
		loss: 2.475200
		loss: 2.475200
		loss: 2.475200
		loss: 2.475200
		loss: 2.475200
		loss: 2.475200
		loss: 2.475200
		loss: 2.475200
		loss: 2.475200
		loss: 2.475100
		loss: 2.475100
		loss: 2.475100
		loss: 2.475100
		loss: 2.475100
		loss: 2.475100
		loss: 2.475100
		loss: 2.475100
		loss: 2.475100
		loss: 2.475100
		loss: 2.475100
		loss: 2.475100
		loss: 2.475000
		loss: 2.475000
		loss: 2.475000
		loss: 2.475000
		loss: 2.475000
		loss: 2.475000
		loss: 2.475000
		loss: 2.475000
		loss: 2.475000
		loss: 2.475000
		loss: 2.475000
		loss: 2.475000
		loss: 2.475000
		loss: 2.474900
		loss: 2.474900
		loss: 2.474900
	Overall the loss development was 2.475900 -> 2.474900
problem epoch data for epoch 10, problem epoch 3
	sampling search time: 33.14216160774231s
	during this search the following actions were chosen:
		close boot was chosen with probability 0.000000
	training time: 10.137483596801758s
	during the training the following losses were computed:
		loss: 2.474900
		loss: 2.474900
		loss: 2.474900
		loss: 2.474900
		loss: 2.474900
		loss: 2.474900
		loss: 2.474900
		loss: 2.474900
		loss: 2.474900
		loss: 2.474900
		loss: 2.474800
		loss: 2.474800
		loss: 2.474800
		loss: 2.474800
		loss: 2.474800
		loss: 2.474800
		loss: 2.474800
		loss: 2.474800
		loss: 2.474800
		loss: 2.474800
		loss: 2.474800
		loss: 2.474800
		loss: 2.474800
		loss: 2.474700
		loss: 2.474700
		loss: 2.474700
		loss: 2.474700
		loss: 2.474700
		loss: 2.474700
		loss: 2.474700
		loss: 2.474700
		loss: 2.474700
		loss: 2.474700
		loss: 2.474700
		loss: 2.474700
		loss: 2.474700
		loss: 2.474700
		loss: 2.474700
		loss: 2.474600
		loss: 2.474600
		loss: 2.474600
		loss: 2.474600
		loss: 2.474700
		loss: 2.474700
		loss: 2.474800
		loss: 2.475000
		loss: 2.475300
		loss: 2.475600
		loss: 2.475400
		loss: 2.474900
		loss: 2.474600
		loss: 2.474800
		loss: 2.475100
		loss: 2.474900
		loss: 2.474600
		loss: 2.474600
		loss: 2.474800
		loss: 2.474800
		loss: 2.474600
		loss: 2.474500
		loss: 2.474700
		loss: 2.474700
		loss: 2.474500
		loss: 2.474500
		loss: 2.474600
		loss: 2.474600
		loss: 2.474500
		loss: 2.474500
		loss: 2.474500
		loss: 2.474500
		loss: 2.474500
		loss: 2.474500
		loss: 2.474500
		loss: 2.474500
		loss: 2.474400
		loss: 2.474400
		loss: 2.474400
		loss: 2.474500
		loss: 2.474400
		loss: 2.474400
		loss: 2.474400
		loss: 2.474400
		loss: 2.474400
		loss: 2.474400
		loss: 2.474400
		loss: 2.474400
		loss: 2.474400
		loss: 2.474400
		loss: 2.474300
		loss: 2.474300
		loss: 2.474300
		loss: 2.474300
		loss: 2.474300
		loss: 2.474300
		loss: 2.474300
		loss: 2.474300
		loss: 2.474300
		loss: 2.474300
		loss: 2.474300
		loss: 2.474300
	Overall the loss development was 2.474900 -> 2.474300
In the epoch 10 for problem d-02.pddl 0 explorations in the sampling searches reached a goal
Success rate: 0

