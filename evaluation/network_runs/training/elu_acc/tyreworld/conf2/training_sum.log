Training log data for domain tyreworld:
printing the data chronological
Epoch 1:
Training data for problem d-01.pddl in epoch 1:
model creation time: 12.010603189468384s
problem epoch data for epoch 1, problem epoch 1
	sampling search time: 2.4137580394744873s
	during this search the following actions were chosen:
	training time: 45.56154680252075s
	during the training the following losses were computed:
		loss: 5.133800
		loss: 4.791800
		loss: 4.554400
		loss: 4.405600
		loss: 4.323000
		loss: 4.282300
		loss: 4.262000
		loss: 4.247000
		loss: 4.229600
		loss: 4.207700
		loss: 4.181100
		loss: 4.151300
		loss: 4.119400
		loss: 4.086600
		loss: 4.053800
		loss: 4.022500
		loss: 3.993700
		loss: 3.968100
		loss: 3.946400
		loss: 3.928000
		loss: 3.911700
		loss: 3.896600
		loss: 3.881300
		loss: 3.865000
		loss: 3.847200
		loss: 3.827900
		loss: 3.807000
		loss: 3.785600
		loss: 3.764400
		loss: 3.743800
		loss: 3.723900
		loss: 3.705000
		loss: 3.686200
		loss: 3.667600
		loss: 3.649000
		loss: 3.630300
		loss: 3.611800
		loss: 3.593500
		loss: 3.575200
		loss: 3.557100
		loss: 3.538900
		loss: 3.520700
		loss: 3.502300
		loss: 3.483700
		loss: 3.465000
		loss: 3.446500
		loss: 3.428300
		loss: 3.410600
		loss: 3.392900
		loss: 3.375400
		loss: 3.357900
		loss: 3.340400
		loss: 3.322800
		loss: 3.305400
		loss: 3.288300
		loss: 3.271600
		loss: 3.255300
		loss: 3.239200
		loss: 3.223400
		loss: 3.207800
		loss: 3.192500
		loss: 3.177600
		loss: 3.163100
		loss: 3.148900
		loss: 3.135100
		loss: 3.121600
		loss: 3.108600
		loss: 3.096000
		loss: 3.083800
		loss: 3.071800
		loss: 3.060300
		loss: 3.049200
		loss: 3.038300
		loss: 3.027800
		loss: 3.017700
		loss: 3.007800
		loss: 2.998300
		loss: 2.989100
		loss: 2.980200
		loss: 2.971500
		loss: 2.963100
		loss: 2.955000
		loss: 2.947100
		loss: 2.939600
		loss: 2.932300
		loss: 2.925200
		loss: 2.918300
		loss: 2.911700
		loss: 2.905300
		loss: 2.899100
		loss: 2.893100
		loss: 2.887300
		loss: 2.881600
		loss: 2.876100
		loss: 2.870800
		loss: 2.865600
		loss: 2.860600
		loss: 2.855700
		loss: 2.850900
		loss: 2.846200
	Overall the loss development was 5.133800 -> 2.846200
problem epoch data for epoch 1, problem epoch 2
	sampling search time: 5.280609369277954s
	during this search the following actions were chosen:
	training time: 10.293687105178833s
	during the training the following losses were computed:
		loss: 3.913600
		loss: 3.769800
		loss: 3.604000
		loss: 3.465800
		loss: 3.366600
		loss: 3.297300
		loss: 3.249000
		loss: 3.218400
		loss: 3.204900
		loss: 3.207900
		loss: 3.220400
		loss: 3.231700
		loss: 3.231900
		loss: 3.217700
		loss: 3.195100
		loss: 3.172000
		loss: 3.151800
		loss: 3.133900
		loss: 3.116800
		loss: 3.099200
		loss: 3.081000
		loss: 3.064400
		loss: 3.051600
		loss: 3.044100
		loss: 3.041300
		loss: 3.040500
		loss: 3.038800
		loss: 3.034700
		loss: 3.028600
		loss: 3.021800
		loss: 3.015200
		loss: 3.009400
		loss: 3.004300
		loss: 2.999400
		loss: 2.994500
		loss: 2.989400
		loss: 2.984500
		loss: 2.980200
		loss: 2.976800
		loss: 2.974200
		loss: 2.971900
		loss: 2.969600
		loss: 2.966800
		loss: 2.963700
		loss: 2.960300
		loss: 2.957000
		loss: 2.953900
		loss: 2.951200
		loss: 2.948600
		loss: 2.946100
		loss: 2.943500
		loss: 2.940900
		loss: 2.938300
		loss: 2.935900
		loss: 2.933600
		loss: 2.931400
		loss: 2.929300
		loss: 2.927000
		loss: 2.924800
		loss: 2.922500
		loss: 2.920300
		loss: 2.918100
		loss: 2.916000
		loss: 2.913900
		loss: 2.911900
		loss: 2.909800
		loss: 2.907800
		loss: 2.905800
		loss: 2.903900
		loss: 2.902000
		loss: 2.900000
		loss: 2.898100
		loss: 2.896200
		loss: 2.894300
		loss: 2.892400
		loss: 2.890500
		loss: 2.888700
		loss: 2.886800
		loss: 2.885000
		loss: 2.883200
		loss: 2.881400
		loss: 2.879600
		loss: 2.877900
		loss: 2.876100
		loss: 2.874300
		loss: 2.872600
		loss: 2.870800
		loss: 2.869100
		loss: 2.867400
		loss: 2.865600
		loss: 2.863900
		loss: 2.862200
		loss: 2.860600
		loss: 2.858900
		loss: 2.857200
		loss: 2.855500
		loss: 2.853900
		loss: 2.852200
		loss: 2.850600
		loss: 2.848900
	Overall the loss development was 3.913600 -> 2.848900
problem epoch data for epoch 1, problem epoch 3
	sampling search time: 5.12566065788269s
	during this search the following actions were chosen:
	training time: 10.451602935791016s
	during the training the following losses were computed:
		loss: 2.658800
		loss: 2.655300
		loss: 2.652000
		loss: 2.649400
		loss: 2.647300
		loss: 2.645600
		loss: 2.643600
		loss: 2.641100
		loss: 2.638500
		loss: 2.636100
		loss: 2.634100
		loss: 2.632100
		loss: 2.630100
		loss: 2.628300
		loss: 2.626500
		loss: 2.624800
		loss: 2.623200
		loss: 2.621600
		loss: 2.619900
		loss: 2.618200
		loss: 2.616600
		loss: 2.615100
		loss: 2.613600
		loss: 2.612200
		loss: 2.610700
		loss: 2.609100
		loss: 2.607500
		loss: 2.606000
		loss: 2.604500
		loss: 2.603000
		loss: 2.601500
		loss: 2.600000
		loss: 2.598500
		loss: 2.597000
		loss: 2.595500
		loss: 2.594100
		loss: 2.592600
		loss: 2.591200
		loss: 2.589700
		loss: 2.588300
		loss: 2.586900
		loss: 2.585400
		loss: 2.584000
		loss: 2.582600
		loss: 2.581200
		loss: 2.579900
		loss: 2.578500
		loss: 2.577100
		loss: 2.575800
		loss: 2.574400
		loss: 2.573000
		loss: 2.571700
		loss: 2.570400
		loss: 2.569000
		loss: 2.567700
		loss: 2.566400
		loss: 2.565000
		loss: 2.563700
		loss: 2.562400
		loss: 2.561100
		loss: 2.559800
		loss: 2.558500
		loss: 2.557200
		loss: 2.555900
		loss: 2.554600
		loss: 2.553400
		loss: 2.552100
		loss: 2.550800
		loss: 2.549600
		loss: 2.548300
		loss: 2.547100
		loss: 2.545800
		loss: 2.544600
		loss: 2.543300
		loss: 2.542100
		loss: 2.540900
		loss: 2.539600
		loss: 2.538400
		loss: 2.537200
		loss: 2.536000
		loss: 2.534800
		loss: 2.533600
		loss: 2.532400
		loss: 2.531200
		loss: 2.530000
		loss: 2.528800
		loss: 2.527600
		loss: 2.526400
		loss: 2.525300
		loss: 2.524100
		loss: 2.522900
		loss: 2.521800
		loss: 2.520600
		loss: 2.519500
		loss: 2.518300
		loss: 2.517200
		loss: 2.516000
		loss: 2.514900
		loss: 2.513800
		loss: 2.512600
	Overall the loss development was 2.658800 -> 2.512600
In the epoch 1 for problem d-01.pddl 2 explorations in the sampling searches reached a goal
Training data for problem d-02.pddl in epoch 1:
model creation time: 30.46105122566223s
problem epoch data for epoch 1, problem epoch 1
	sampling search time: 28.35775089263916s
	during this search the following actions were chosen:
	training time: 105.79164528846741s
	during the training the following losses were computed:
		loss: 4.552300
		loss: 4.684000
		loss: 3.478500
		loss: 4.307500
		loss: 4.466800
		loss: 4.259200
		loss: 4.598700
		loss: 4.167600
		loss: 3.405100
		loss: 4.053200
		loss: 3.665500
		loss: 3.971700
		loss: 3.648800
		loss: 3.952600
		loss: 4.285300
		loss: 3.938400
		loss: 3.959800
		loss: 3.890500
		loss: 3.059700
		loss: 3.863000
		loss: 3.452600
		loss: 3.844200
		loss: 3.440600
		loss: 3.840800
		loss: 3.517200
		loss: 3.837200
		loss: 3.692200
		loss: 3.815300
		loss: 4.183500
		loss: 3.801200
		loss: 4.286400
		loss: 3.783600
		loss: 3.571100
		loss: 3.774700
		loss: 4.049400
		loss: 3.766800
		loss: 4.147500
		loss: 3.752100
		loss: 3.959800
		loss: 3.745900
		loss: 3.707700
		loss: 3.742100
		loss: 4.027500
		loss: 3.736000
		loss: 4.196700
		loss: 3.730700
		loss: 3.969400
		loss: 3.720700
		loss: 4.139900
		loss: 3.709200
		loss: 3.628800
		loss: 3.704000
		loss: 3.873700
		loss: 3.698900
		loss: 3.653600
		loss: 3.692900
		loss: 3.488100
		loss: 3.689300
		loss: 2.890500
		loss: 3.688200
		loss: 3.367200
		loss: 3.677800
		loss: 3.312200
		loss: 3.668200
		loss: 3.628100
		loss: 3.665200
		loss: 3.802300
		loss: 3.659100
		loss: 3.614000
		loss: 3.657300
		loss: 3.715800
		loss: 3.649300
		loss: 3.461400
		loss: 3.645000
		loss: 3.858900
		loss: 3.641300
		loss: 3.088700
		loss: 3.640800
		loss: 2.705500
		loss: 3.638100
		loss: 2.906900
		loss: 3.635800
		loss: 3.982700
		loss: 3.622000
		loss: 3.632600
		loss: 3.620000
		loss: 3.572600
		loss: 3.615700
		loss: 3.711400
		loss: 3.615600
		loss: 3.494000
		loss: 3.608700
		loss: 2.802000
		loss: 3.613400
		loss: 3.695800
		loss: 3.602800
		loss: 3.642900
		loss: 3.597700
		loss: 3.935600
		loss: 3.595600
		loss: 3.611900
		loss: 3.590600
		loss: 3.207700
		loss: 3.589500
		loss: 4.129800
		loss: 3.586900
		loss: 3.233800
		loss: 3.578600
		loss: 4.107100
		loss: 3.573400
		loss: 3.714100
		loss: 3.573000
		loss: 3.367300
		loss: 3.571300
		loss: 2.970300
		loss: 3.572600
		loss: 3.476800
		loss: 3.564500
		loss: 3.378800
		loss: 3.564200
		loss: 3.476500
		loss: 3.559300
		loss: 3.309400
		loss: 3.556000
		loss: 3.292100
		loss: 3.554400
		loss: 2.924200
		loss: 3.555000
		loss: 3.394900
		loss: 3.548500
		loss: 3.498700
		loss: 3.546200
		loss: 3.910900
		loss: 3.545600
		loss: 3.107200
		loss: 3.542600
		loss: 3.583000
		loss: 3.535500
		loss: 3.303300
		loss: 3.537800
		loss: 3.489200
		loss: 3.535400
		loss: 3.320400
		loss: 3.527100
		loss: 4.052800
		loss: 3.529500
		loss: 3.534800
		loss: 3.523300
		loss: 3.134700
		loss: 3.520300
		loss: 3.617400
		loss: 3.522800
		loss: 2.539500
		loss: 3.511500
		loss: 3.289800
		loss: 3.514800
		loss: 3.484100
		loss: 3.512100
		loss: 2.910300
		loss: 3.512700
		loss: 3.085100
		loss: 3.509700
		loss: 3.597600
		loss: 3.503400
		loss: 3.476700
		loss: 3.501400
		loss: 3.539500
		loss: 3.498600
		loss: 2.683900
		loss: 3.503100
		loss: 3.356900
		loss: 3.494200
		loss: 3.590600
		loss: 3.494300
		loss: 3.947900
		loss: 3.493100
		loss: 3.381700
		loss: 3.486900
		loss: 3.378000
		loss: 3.485900
		loss: 3.305700
		loss: 3.484200
		loss: 3.733900
		loss: 3.482300
		loss: 3.431600
		loss: 3.478500
		loss: 3.560600
		loss: 3.477100
		loss: 3.772200
		loss: 3.477300
		loss: 3.969900
		loss: 3.468600
		loss: 3.316800
		loss: 3.471700
		loss: 4.250900
		loss: 3.464400
		loss: 3.445100
		loss: 3.467300
		loss: 3.026900
		loss: 3.464000
	Overall the loss development was 4.552300 -> 3.464000
problem epoch data for epoch 1, problem epoch 2
	sampling search time: 33.50044226646423s
	during this search the following actions were chosen:
	training time: 23.627288818359375s
	during the training the following losses were computed:
		loss: 3.687000
		loss: 3.553300
		loss: 3.443700
		loss: 3.550100
		loss: 3.920600
		loss: 3.548900
		loss: 3.261800
		loss: 3.545300
		loss: 3.671700
		loss: 3.543100
		loss: 4.190100
		loss: 3.542500
		loss: 3.410300
		loss: 3.537900
		loss: 2.946900
		loss: 3.536000
		loss: 3.260300
		loss: 3.532100
		loss: 2.604200
		loss: 3.529600
		loss: 3.554500
		loss: 3.526800
		loss: 3.459500
		loss: 3.525600
		loss: 3.739500
		loss: 3.523300
		loss: 3.028400
		loss: 3.525200
		loss: 3.384500
		loss: 3.520000
		loss: 3.417900
		loss: 3.518000
		loss: 3.236400
		loss: 3.515900
		loss: 3.148400
		loss: 3.515200
		loss: 2.937200
		loss: 3.514300
		loss: 3.843100
		loss: 3.509700
		loss: 3.947700
		loss: 3.509100
		loss: 3.240600
		loss: 3.505900
		loss: 3.791500
		loss: 3.504500
		loss: 3.236700
		loss: 3.502500
		loss: 3.026800
		loss: 3.500400
		loss: 3.780300
		loss: 3.498000
		loss: 2.916600
		loss: 3.496900
		loss: 3.457500
		loss: 3.495600
		loss: 3.817200
		loss: 3.492700
		loss: 2.812200
		loss: 3.492100
		loss: 3.759400
		loss: 3.489100
		loss: 3.865800
		loss: 3.487900
		loss: 3.349000
		loss: 3.486000
		loss: 3.480800
		loss: 3.483100
		loss: 3.370100
		loss: 3.483000
		loss: 3.991000
		loss: 3.479700
		loss: 3.378800
		loss: 3.477600
		loss: 2.879100
		loss: 3.477600
		loss: 2.865700
		loss: 3.473800
		loss: 3.183400
		loss: 3.473400
		loss: 3.101300
		loss: 3.473200
		loss: 3.472700
		loss: 3.468000
		loss: 3.836700
		loss: 3.467500
		loss: 3.758100
		loss: 3.466700
		loss: 3.608500
		loss: 3.464000
		loss: 3.381800
		loss: 3.461200
		loss: 3.525900
		loss: 3.459400
		loss: 3.491000
		loss: 3.457500
		loss: 3.830700
		loss: 3.454500
		loss: 2.988700
		loss: 3.454500
		loss: 3.674000
		loss: 3.452100
		loss: 2.949400
		loss: 3.450000
		loss: 3.245200
		loss: 3.448800
		loss: 3.703400
		loss: 3.446300
		loss: 3.829100
		loss: 3.445400
		loss: 3.050200
		loss: 3.444000
		loss: 3.303500
		loss: 3.442600
		loss: 3.318700
		loss: 3.441600
		loss: 3.549500
		loss: 3.440700
		loss: 3.470300
		loss: 3.438600
		loss: 3.291100
		loss: 3.437400
		loss: 3.751000
		loss: 3.435600
		loss: 3.146500
		loss: 3.434700
		loss: 4.024600
		loss: 3.433300
		loss: 4.015500
		loss: 3.432800
		loss: 4.039100
		loss: 3.432100
		loss: 3.624900
		loss: 3.432300
		loss: 3.738400
		loss: 3.429500
		loss: 3.062400
		loss: 3.428500
		loss: 3.736800
		loss: 3.427900
		loss: 3.213200
		loss: 3.426400
		loss: 3.065800
		loss: 3.425600
		loss: 3.533100
		loss: 3.424400
		loss: 3.345200
		loss: 3.423100
		loss: 3.011300
		loss: 3.422500
		loss: 3.063600
		loss: 3.421400
		loss: 3.617300
		loss: 3.420400
		loss: 3.641100
		loss: 3.419100
		loss: 3.260700
		loss: 3.419300
		loss: 3.689400
		loss: 3.418800
		loss: 2.803300
		loss: 3.417800
		loss: 3.629200
		loss: 3.416300
		loss: 3.519500
		loss: 3.415700
		loss: 3.948900
		loss: 3.415800
		loss: 3.533600
		loss: 3.413600
		loss: 3.171000
		loss: 3.412500
		loss: 2.966900
		loss: 3.412400
		loss: 3.730800
		loss: 3.410500
		loss: 2.912500
		loss: 3.410000
		loss: 3.686600
		loss: 3.408900
		loss: 3.498600
		loss: 3.408200
		loss: 3.749900
		loss: 3.407200
		loss: 3.463500
		loss: 3.406300
		loss: 4.065100
		loss: 3.405500
		loss: 3.584200
		loss: 3.404700
		loss: 4.171100
		loss: 3.403800
		loss: 3.223500
		loss: 3.403200
		loss: 3.317600
		loss: 3.402700
		loss: 3.451900
		loss: 3.401800
		loss: 3.415300
		loss: 3.400900
	Overall the loss development was 3.687000 -> 3.400900
problem epoch data for epoch 1, problem epoch 3
	sampling search time: 27.651458740234375s
	during this search the following actions were chosen:
	training time: 18.758453845977783s
	during the training the following losses were computed:
		loss: 3.854100
		loss: 3.394800
		loss: 4.109400
		loss: 3.384600
		loss: 2.980700
		loss: 3.379600
		loss: 3.758700
		loss: 3.374500
		loss: 3.368800
		loss: 3.370200
		loss: 3.249100
		loss: 3.366200
		loss: 3.694300
		loss: 3.362500
		loss: 3.144900
		loss: 3.360800
		loss: 3.452600
		loss: 3.358500
		loss: 3.048700
		loss: 3.355500
		loss: 3.380400
		loss: 3.353600
		loss: 3.444600
		loss: 3.352100
		loss: 3.906800
		loss: 3.350500
		loss: 3.390100
		loss: 3.350100
		loss: 3.616500
		loss: 3.346100
		loss: 3.677300
		loss: 3.345500
		loss: 3.835500
		loss: 3.344100
		loss: 3.439300
		loss: 3.342500
		loss: 3.041400
		loss: 3.341600
		loss: 3.124700
		loss: 3.340100
		loss: 2.672200
		loss: 3.339500
		loss: 3.401000
		loss: 3.338500
		loss: 3.130100
		loss: 3.337400
		loss: 3.124000
		loss: 3.337000
		loss: 3.080600
		loss: 3.337300
		loss: 3.784700
		loss: 3.335700
		loss: 3.307200
		loss: 3.334300
		loss: 2.915400
		loss: 3.333400
		loss: 3.376900
		loss: 3.332000
		loss: 3.379600
		loss: 3.332100
		loss: 2.939200
		loss: 3.330500
		loss: 3.212100
		loss: 3.329500
		loss: 3.569600
		loss: 3.328800
		loss: 3.215400
		loss: 3.328100
		loss: 3.307500
		loss: 3.327300
		loss: 3.643100
		loss: 3.326600
		loss: 3.489200
		loss: 3.325700
		loss: 3.030800
		loss: 3.325600
		loss: 3.360000
		loss: 3.324600
		loss: 3.682600
		loss: 3.323700
		loss: 3.355800
		loss: 3.323300
		loss: 3.645700
		loss: 3.323100
		loss: 4.011500
		loss: 3.321900
		loss: 2.846000
		loss: 3.321700
		loss: 3.539700
		loss: 3.320800
		loss: 3.522800
		loss: 3.320200
		loss: 3.320500
		loss: 3.318900
		loss: 3.685900
		loss: 3.318500
		loss: 3.754800
		loss: 3.317800
		loss: 3.095600
		loss: 3.317500
		loss: 3.377600
		loss: 3.316900
		loss: 3.788200
		loss: 3.315700
		loss: 3.268000
		loss: 3.316400
		loss: 3.833100
		loss: 3.317400
		loss: 3.619600
		loss: 3.315700
		loss: 3.611900
		loss: 3.315100
		loss: 3.346400
		loss: 3.315700
		loss: 2.897300
		loss: 3.313700
		loss: 3.571800
		loss: 3.313300
		loss: 4.314100
		loss: 3.311300
		loss: 3.412000
		loss: 3.310800
		loss: 3.385300
		loss: 3.310300
		loss: 2.594100
		loss: 3.309200
		loss: 3.476300
		loss: 3.308500
		loss: 3.966000
		loss: 3.308000
		loss: 3.115200
		loss: 3.308100
		loss: 2.849100
		loss: 3.306600
		loss: 3.356700
		loss: 3.306300
		loss: 2.854900
		loss: 3.305900
		loss: 2.618000
		loss: 3.305400
		loss: 3.773200
		loss: 3.304500
		loss: 3.398300
		loss: 3.304000
		loss: 3.895400
		loss: 3.303600
		loss: 3.165300
		loss: 3.303100
		loss: 3.382700
		loss: 3.302300
		loss: 3.656100
		loss: 3.301900
		loss: 3.019300
		loss: 3.302000
		loss: 3.077400
		loss: 3.301000
		loss: 3.017200
		loss: 3.300600
		loss: 3.446500
		loss: 3.300200
		loss: 3.623900
		loss: 3.299200
		loss: 3.875800
		loss: 3.299000
		loss: 3.003900
		loss: 3.298500
		loss: 3.473800
		loss: 3.298100
		loss: 3.685700
		loss: 3.297200
		loss: 3.359900
		loss: 3.297200
		loss: 2.926700
		loss: 3.296300
		loss: 3.302100
		loss: 3.296500
		loss: 3.458700
		loss: 3.296300
		loss: 3.130000
		loss: 3.294900
		loss: 3.184700
		loss: 3.294600
		loss: 3.361700
		loss: 3.294700
		loss: 2.875400
		loss: 3.293900
		loss: 2.944000
		loss: 3.292900
		loss: 3.874600
		loss: 3.293900
		loss: 3.179500
		loss: 3.292800
		loss: 2.960700
		loss: 3.293000
		loss: 3.367100
		loss: 3.291600
		loss: 2.795700
		loss: 3.290700
		loss: 3.657200
		loss: 3.290100
	Overall the loss development was 3.854100 -> 3.290100
In the epoch 1 for problem d-02.pddl 3 explorations in the sampling searches reached a goal
Success rate: 83

Epoch 2:
Training data for problem d-01.pddl in epoch 2:
model creation time: 10.127720355987549s
problem epoch data for epoch 2, problem epoch 1
	sampling search time: 3.4727542400360107s
	during this search the following actions were chosen:
	training time: 43.20941424369812s
	during the training the following losses were computed:
		loss: 2.439700
		loss: 2.276500
		loss: 2.207400
		loss: 2.166500
		loss: 2.145600
		loss: 2.128000
		loss: 2.118100
		loss: 2.120200
		loss: 2.126100
		loss: 2.127300
		loss: 2.123100
		loss: 2.116200
		loss: 2.108800
		loss: 2.102000
		loss: 2.096100
		loss: 2.091000
		loss: 2.086300
		loss: 2.082600
		loss: 2.080800
		loss: 2.080800
		loss: 2.081300
		loss: 2.081300
		loss: 2.080600
		loss: 2.079700
		loss: 2.078900
		loss: 2.078100
		loss: 2.077200
		loss: 2.075800
		loss: 2.074000
		loss: 2.072000
		loss: 2.070500
		loss: 2.069600
		loss: 2.069200
		loss: 2.069000
		loss: 2.068800
		loss: 2.068500
		loss: 2.068200
		loss: 2.067800
		loss: 2.067400
		loss: 2.066700
		loss: 2.065900
		loss: 2.065000
		loss: 2.064200
		loss: 2.063500
		loss: 2.063000
		loss: 2.062500
		loss: 2.062000
		loss: 2.061600
		loss: 2.061200
		loss: 2.060700
		loss: 2.060300
		loss: 2.059900
		loss: 2.059400
		loss: 2.058900
		loss: 2.058400
		loss: 2.057900
		loss: 2.057400
		loss: 2.056900
		loss: 2.056400
		loss: 2.055900
		loss: 2.055500
		loss: 2.055000
		loss: 2.054600
		loss: 2.054200
		loss: 2.053700
		loss: 2.053300
		loss: 2.052900
		loss: 2.052400
		loss: 2.051900
		loss: 2.051500
		loss: 2.051000
		loss: 2.050600
		loss: 2.050200
		loss: 2.049700
		loss: 2.049300
		loss: 2.048900
		loss: 2.048400
		loss: 2.048000
		loss: 2.047600
		loss: 2.047100
		loss: 2.046700
		loss: 2.046300
		loss: 2.045900
		loss: 2.045400
		loss: 2.045000
		loss: 2.044600
		loss: 2.044200
		loss: 2.043700
		loss: 2.043300
		loss: 2.042900
		loss: 2.042500
		loss: 2.042100
		loss: 2.041600
		loss: 2.041200
		loss: 2.040800
		loss: 2.040400
		loss: 2.040000
		loss: 2.039600
		loss: 2.039200
		loss: 2.038700
	Overall the loss development was 2.439700 -> 2.038700
problem epoch data for epoch 2, problem epoch 2
	sampling search time: 3.7407679557800293s
	during this search the following actions were chosen:
	training time: 10.119864225387573s
	during the training the following losses were computed:
		loss: 2.012200
		loss: 2.001400
		loss: 1.995200
		loss: 1.996000
		loss: 1.996200
		loss: 1.994500
		loss: 1.992600
		loss: 1.989600
		loss: 1.986400
		loss: 1.984900
		loss: 1.984900
		loss: 1.984500
		loss: 1.982400
		loss: 1.979700
		loss: 1.978200
		loss: 1.978100
		loss: 1.978300
		loss: 1.977700
		loss: 1.976600
		loss: 1.975400
		loss: 1.974500
		loss: 1.974300
		loss: 1.974400
		loss: 1.974100
		loss: 1.973300
		loss: 1.972500
		loss: 1.972200
		loss: 1.972000
		loss: 1.971700
		loss: 1.971300
		loss: 1.970800
		loss: 1.970300
		loss: 1.969900
		loss: 1.969600
		loss: 1.969300
		loss: 1.968900
		loss: 1.968300
		loss: 1.967800
		loss: 1.967500
		loss: 1.967200
		loss: 1.966900
		loss: 1.966400
		loss: 1.965900
		loss: 1.965600
		loss: 1.965300
		loss: 1.964900
		loss: 1.964500
		loss: 1.964100
		loss: 1.963800
		loss: 1.963400
		loss: 1.963100
		loss: 1.962800
		loss: 1.962400
		loss: 1.962000
		loss: 1.961700
		loss: 1.961400
		loss: 1.961100
		loss: 1.960700
		loss: 1.960400
		loss: 1.960000
		loss: 1.959700
		loss: 1.959400
		loss: 1.959100
		loss: 1.958800
		loss: 1.958400
		loss: 1.958100
		loss: 1.957800
		loss: 1.957500
		loss: 1.957200
		loss: 1.956800
		loss: 1.956500
		loss: 1.956200
		loss: 1.955900
		loss: 1.955600
		loss: 1.955300
		loss: 1.955000
		loss: 1.954600
		loss: 1.954300
		loss: 1.954000
		loss: 1.953700
		loss: 1.953400
		loss: 1.953100
		loss: 1.952800
		loss: 1.952500
		loss: 1.952200
		loss: 1.951900
		loss: 1.951600
		loss: 1.951300
		loss: 1.951000
		loss: 1.950700
		loss: 1.950400
		loss: 1.950100
		loss: 1.949900
		loss: 1.949600
		loss: 1.949300
		loss: 1.949000
		loss: 1.948700
		loss: 1.948400
		loss: 1.948100
		loss: 1.947800
	Overall the loss development was 2.012200 -> 1.947800
problem epoch data for epoch 2, problem epoch 3
	sampling search time: 3.769653797149658s
	during this search the following actions were chosen:
	training time: 10.118191480636597s
	during the training the following losses were computed:
		loss: 1.934600
		loss: 1.934000
		loss: 1.933700
		loss: 1.933500
		loss: 1.933200
		loss: 1.932900
		loss: 1.932600
		loss: 1.932300
		loss: 1.932000
		loss: 1.931700
		loss: 1.931500
		loss: 1.931200
		loss: 1.930900
		loss: 1.930600
		loss: 1.930300
		loss: 1.930000
		loss: 1.929700
		loss: 1.929500
		loss: 1.929200
		loss: 1.928900
		loss: 1.928600
		loss: 1.928400
		loss: 1.928100
		loss: 1.927800
		loss: 1.927600
		loss: 1.927300
		loss: 1.927000
		loss: 1.926800
		loss: 1.926500
		loss: 1.926200
		loss: 1.926000
		loss: 1.925700
		loss: 1.925500
		loss: 1.925200
		loss: 1.925000
		loss: 1.924700
		loss: 1.924400
		loss: 1.924200
		loss: 1.923900
		loss: 1.923700
		loss: 1.923400
		loss: 1.923200
		loss: 1.922900
		loss: 1.922700
		loss: 1.922400
		loss: 1.922200
		loss: 1.922000
		loss: 1.921700
		loss: 1.921500
		loss: 1.921200
		loss: 1.921000
		loss: 1.920700
		loss: 1.920500
		loss: 1.920300
		loss: 1.920000
		loss: 1.919800
		loss: 1.919600
		loss: 1.919300
		loss: 1.919100
		loss: 1.918900
		loss: 1.918600
		loss: 1.918400
		loss: 1.918200
		loss: 1.917900
		loss: 1.917700
		loss: 1.917500
		loss: 1.917200
		loss: 1.917000
		loss: 1.916800
		loss: 1.916600
		loss: 1.916300
		loss: 1.916100
		loss: 1.915900
		loss: 1.915700
		loss: 1.915400
		loss: 1.915200
		loss: 1.915000
		loss: 1.914800
		loss: 1.914600
		loss: 1.914300
		loss: 1.914100
		loss: 1.913900
		loss: 1.913700
		loss: 1.913500
		loss: 1.913300
		loss: 1.913000
		loss: 1.912800
		loss: 1.912600
		loss: 1.912400
		loss: 1.912200
		loss: 1.912000
		loss: 1.911800
		loss: 1.911600
		loss: 1.911300
		loss: 1.911100
		loss: 1.910900
		loss: 1.910700
		loss: 1.910500
		loss: 1.910300
		loss: 1.910100
	Overall the loss development was 1.934600 -> 1.910100
In the epoch 2 for problem d-01.pddl 3 explorations in the sampling searches reached a goal
Training data for problem d-02.pddl in epoch 2:
model creation time: 21.403316259384155s
problem epoch data for epoch 2, problem epoch 1
	sampling search time: 22.62484097480774s
	during this search the following actions were chosen:
	training time: 81.80615282058716s
	during the training the following losses were computed:
		loss: 5.534600
		loss: 5.014300
		loss: 4.503700
		loss: 4.371700
		loss: 4.149900
		loss: 4.236700
		loss: 5.099600
		loss: 4.196300
		loss: 3.745700
		loss: 4.079200
		loss: 4.172300
		loss: 4.009900
		loss: 4.039900
		loss: 3.965300
		loss: 3.955000
		loss: 3.894000
		loss: 3.179400
		loss: 3.818400
		loss: 3.953200
		loss: 3.773800
		loss: 3.825700
		loss: 3.771700
		loss: 3.289900
		loss: 3.766700
		loss: 3.798000
		loss: 3.752600
		loss: 3.494300
		loss: 3.728200
		loss: 3.750400
		loss: 3.712400
		loss: 3.518900
		loss: 3.700600
		loss: 2.914100
		loss: 3.694300
		loss: 3.970700
		loss: 3.686000
		loss: 3.399000
		loss: 3.677900
		loss: 3.496300
		loss: 3.671800
		loss: 3.828300
		loss: 3.666000
		loss: 4.005100
		loss: 3.656800
		loss: 3.782200
		loss: 3.649500
		loss: 3.727600
		loss: 3.645200
		loss: 3.379800
		loss: 3.641300
		loss: 3.553900
		loss: 3.636000
		loss: 3.950200
		loss: 3.630800
		loss: 3.785300
		loss: 3.625400
		loss: 3.485100
		loss: 3.619900
		loss: 3.368400
		loss: 3.616000
		loss: 3.728400
		loss: 3.611600
		loss: 3.972600
		loss: 3.607000
		loss: 3.932500
		loss: 3.602200
		loss: 3.521200
		loss: 3.597300
		loss: 3.549600
		loss: 3.593000
		loss: 3.746500
		loss: 3.589100
		loss: 3.552700
		loss: 3.585600
		loss: 3.769500
		loss: 3.580900
		loss: 3.810300
		loss: 3.578100
		loss: 3.783900
		loss: 3.573600
		loss: 3.601200
		loss: 3.570000
		loss: 3.404700
		loss: 3.568700
		loss: 3.062300
		loss: 3.565300
		loss: 3.660100
		loss: 3.560900
		loss: 3.551200
		loss: 3.558000
		loss: 3.984200
		loss: 3.554600
		loss: 3.959000
		loss: 3.552600
		loss: 3.269000
		loss: 3.549300
		loss: 3.702600
		loss: 3.546800
		loss: 3.172300
		loss: 3.544600
		loss: 3.582500
		loss: 3.542100
		loss: 3.308100
		loss: 3.540000
		loss: 3.976400
		loss: 3.538300
		loss: 3.114000
		loss: 3.535900
		loss: 3.703900
		loss: 3.534000
		loss: 3.648900
		loss: 3.532800
		loss: 3.137100
		loss: 3.529900
		loss: 3.636000
		loss: 3.529300
		loss: 3.432800
		loss: 3.528000
		loss: 3.762600
		loss: 3.525600
		loss: 3.804600
		loss: 3.524500
		loss: 3.581200
		loss: 3.522600
		loss: 3.369700
		loss: 3.521500
		loss: 2.751100
		loss: 3.519600
		loss: 4.008000
		loss: 3.518900
		loss: 3.400100
		loss: 3.517500
		loss: 3.421600
		loss: 3.515700
		loss: 3.584800
		loss: 3.514700
		loss: 3.340700
		loss: 3.513700
		loss: 3.178900
		loss: 3.512700
		loss: 3.331700
		loss: 3.511600
		loss: 3.635800
		loss: 3.509900
		loss: 3.468300
		loss: 3.509800
		loss: 3.722300
		loss: 3.509300
		loss: 3.472600
		loss: 3.507900
		loss: 3.330200
		loss: 3.506700
		loss: 3.155200
		loss: 3.506200
		loss: 3.956200
		loss: 3.505200
		loss: 3.179900
		loss: 3.504100
		loss: 2.843700
		loss: 3.504100
		loss: 3.998000
		loss: 3.502800
		loss: 3.727800
		loss: 3.502500
		loss: 2.773900
		loss: 3.501200
		loss: 3.886900
		loss: 3.500700
		loss: 3.226500
		loss: 3.499800
		loss: 3.458300
		loss: 3.499500
		loss: 3.792200
		loss: 3.498600
		loss: 3.805100
		loss: 3.497600
		loss: 3.913900
		loss: 3.497000
		loss: 3.840400
		loss: 3.496700
		loss: 3.191400
		loss: 3.496300
		loss: 3.482900
		loss: 3.495100
		loss: 3.556500
		loss: 3.494900
		loss: 3.322600
		loss: 3.494300
		loss: 3.417100
		loss: 3.494000
		loss: 2.988100
		loss: 3.492800
		loss: 3.252600
		loss: 3.492300
		loss: 3.331700
		loss: 3.493100
		loss: 3.520800
		loss: 3.491200
		loss: 3.348000
		loss: 3.490700
	Overall the loss development was 5.534600 -> 3.490700
problem epoch data for epoch 2, problem epoch 2
	sampling search time: 23.66623616218567s
	during this search the following actions were chosen:
	training time: 21.292696237564087s
	during the training the following losses were computed:
		loss: 2.936500
		loss: 3.591800
		loss: 3.634800
		loss: 3.585100
		loss: 3.707800
		loss: 3.585000
		loss: 3.203800
		loss: 3.583800
		loss: 3.486500
		loss: 3.583200
		loss: 3.601800
		loss: 3.581500
		loss: 3.284500
		loss: 3.581800
		loss: 3.791400
		loss: 3.580300
		loss: 3.427800
		loss: 3.579600
		loss: 3.713200
		loss: 3.579200
		loss: 4.020900
		loss: 3.578700
		loss: 4.009300
		loss: 3.578600
		loss: 3.688100
		loss: 3.578000
		loss: 3.621500
		loss: 3.578000
		loss: 3.320800
		loss: 3.577600
		loss: 3.772200
		loss: 3.576900
		loss: 3.940700
		loss: 3.576600
		loss: 4.246800
		loss: 3.575800
		loss: 3.571600
		loss: 3.575700
		loss: 3.296000
		loss: 3.575300
		loss: 3.621400
		loss: 3.575300
		loss: 3.670600
		loss: 3.574900
		loss: 3.852500
		loss: 3.574400
		loss: 3.881800
		loss: 3.574500
		loss: 3.628400
		loss: 3.574500
		loss: 3.492000
		loss: 3.573700
		loss: 3.789700
		loss: 3.573700
		loss: 3.455200
		loss: 3.573300
		loss: 3.090100
		loss: 3.573200
		loss: 3.785000
		loss: 3.572300
		loss: 3.251300
		loss: 3.572700
		loss: 3.399600
		loss: 3.572000
		loss: 3.663700
		loss: 3.572000
		loss: 3.557200
		loss: 3.571500
		loss: 3.452400
		loss: 3.571500
		loss: 3.268700
		loss: 3.571600
		loss: 3.282900
		loss: 3.571200
		loss: 3.711700
		loss: 3.570700
		loss: 3.638600
		loss: 3.570200
		loss: 3.687900
		loss: 3.570100
		loss: 4.148200
		loss: 3.569400
		loss: 3.355300
		loss: 3.569600
		loss: 3.356300
		loss: 3.569200
		loss: 3.259100
		loss: 3.569200
		loss: 3.105700
		loss: 3.568800
		loss: 3.657100
		loss: 3.568500
		loss: 3.657700
		loss: 3.568100
		loss: 4.331100
		loss: 3.567800
		loss: 3.714800
		loss: 3.567600
		loss: 3.144200
		loss: 3.567400
		loss: 3.461000
		loss: 3.567500
		loss: 3.685800
		loss: 3.567000
		loss: 3.453700
		loss: 3.567000
		loss: 3.812600
		loss: 3.566600
		loss: 3.704300
		loss: 3.566500
		loss: 3.344300
		loss: 3.566300
		loss: 3.656400
		loss: 3.566000
		loss: 3.434100
		loss: 3.565800
		loss: 3.608300
		loss: 3.565600
		loss: 3.373200
		loss: 3.565400
		loss: 3.939800
		loss: 3.565100
		loss: 3.435800
		loss: 3.564700
		loss: 3.838600
		loss: 3.564800
		loss: 3.595500
		loss: 3.564300
		loss: 3.714100
		loss: 3.564400
		loss: 4.108300
		loss: 3.564000
		loss: 3.494500
		loss: 3.563900
		loss: 3.628400
		loss: 3.563900
		loss: 3.231300
		loss: 3.563600
		loss: 3.611000
		loss: 3.563300
		loss: 3.991100
		loss: 3.563100
		loss: 3.749900
		loss: 3.562700
		loss: 3.923500
		loss: 3.562500
		loss: 3.403900
		loss: 3.562500
		loss: 3.755000
		loss: 3.562100
		loss: 3.377200
		loss: 3.562100
		loss: 3.875800
		loss: 3.561700
		loss: 3.347700
		loss: 3.562000
		loss: 3.832300
		loss: 3.561500
		loss: 3.425700
		loss: 3.561900
		loss: 3.688200
		loss: 3.561000
		loss: 3.517300
		loss: 3.561100
		loss: 3.252400
		loss: 3.560900
		loss: 3.863500
		loss: 3.561200
		loss: 3.830900
		loss: 3.560700
		loss: 3.546200
		loss: 3.560100
		loss: 3.555400
		loss: 3.560500
		loss: 3.402300
		loss: 3.559500
		loss: 2.851600
		loss: 3.560000
		loss: 3.524600
		loss: 3.559400
		loss: 3.304500
		loss: 3.559500
		loss: 3.780100
		loss: 3.559100
		loss: 3.194300
		loss: 3.559000
		loss: 3.884100
		loss: 3.558700
		loss: 3.316300
		loss: 3.558900
		loss: 3.358200
		loss: 3.558500
		loss: 3.165400
		loss: 3.558400
		loss: 3.501800
		loss: 3.558200
		loss: 3.307000
		loss: 3.558000
		loss: 3.351900
		loss: 3.558000
	Overall the loss development was 2.936500 -> 3.558000
problem epoch data for epoch 2, problem epoch 3
	sampling search time: 26.880773067474365s
	during this search the following actions were chosen:
	training time: 22.455013513565063s
	during the training the following losses were computed:
		loss: 4.022200
		loss: 3.551100
		loss: 3.453700
		loss: 3.547800
		loss: 3.380600
		loss: 3.548100
		loss: 3.616200
		loss: 3.546200
		loss: 4.169100
		loss: 3.548000
		loss: 3.763200
		loss: 3.545500
		loss: 3.176500
		loss: 3.542900
		loss: 3.724000
		loss: 3.543000
		loss: 3.318200
		loss: 3.543600
		loss: 3.324000
		loss: 3.542700
		loss: 3.723200
		loss: 3.543000
		loss: 3.509400
		loss: 3.542200
		loss: 3.025800
		loss: 3.539800
		loss: 3.501000
		loss: 3.541300
		loss: 3.359600
		loss: 3.540400
		loss: 3.464500
		loss: 3.541000
		loss: 4.121200
		loss: 3.537400
		loss: 4.025600
		loss: 3.538100
		loss: 3.610300
		loss: 3.539100
		loss: 4.355800
		loss: 3.535900
		loss: 3.764300
		loss: 3.538800
		loss: 3.888000
		loss: 3.538000
		loss: 3.392400
		loss: 3.538100
		loss: 3.161400
		loss: 3.541300
		loss: 3.207600
		loss: 3.536600
		loss: 3.509500
		loss: 3.538100
		loss: 3.267600
		loss: 3.539100
		loss: 3.798200
		loss: 3.536900
		loss: 3.551300
		loss: 3.537200
		loss: 3.755800
		loss: 3.536300
		loss: 3.328000
		loss: 3.537700
		loss: 3.326300
		loss: 3.535700
		loss: 3.410600
		loss: 3.536000
		loss: 3.333600
		loss: 3.536900
		loss: 3.697200
		loss: 3.536200
		loss: 3.352700
		loss: 3.536200
		loss: 3.304700
		loss: 3.536500
		loss: 3.253900
		loss: 3.535900
		loss: 3.118500
		loss: 3.533300
		loss: 3.559900
		loss: 3.534600
		loss: 3.591900
		loss: 3.534200
		loss: 3.680800
		loss: 3.535000
		loss: 3.773800
		loss: 3.533700
		loss: 3.208300
		loss: 3.532900
		loss: 3.579000
		loss: 3.533700
		loss: 3.452600
		loss: 3.533700
		loss: 3.272500
		loss: 3.532200
		loss: 3.766600
		loss: 3.532200
		loss: 3.645700
		loss: 3.533200
		loss: 3.446000
		loss: 3.532800
		loss: 3.570900
		loss: 3.532200
		loss: 3.385900
		loss: 3.531600
		loss: 4.051600
		loss: 3.530100
		loss: 3.833200
		loss: 3.533200
		loss: 3.634000
		loss: 3.532200
		loss: 3.496300
		loss: 3.531800
		loss: 3.121300
		loss: 3.530400
		loss: 3.461800
		loss: 3.531400
		loss: 3.100800
		loss: 3.529500
		loss: 3.705800
		loss: 3.531700
		loss: 3.696700
		loss: 3.530200
		loss: 3.686500
		loss: 3.530200
		loss: 3.862200
		loss: 3.532000
		loss: 3.527600
		loss: 3.530600
		loss: 3.722300
		loss: 3.529300
		loss: 3.552900
		loss: 3.530400
		loss: 3.570500
		loss: 3.530100
		loss: 3.342400
		loss: 3.529000
		loss: 3.851000
		loss: 3.530900
		loss: 3.856500
		loss: 3.530800
		loss: 3.573100
		loss: 3.529400
		loss: 3.417700
		loss: 3.528700
		loss: 3.433800
		loss: 3.529600
		loss: 3.560000
		loss: 3.528800
		loss: 3.041100
		loss: 3.526800
		loss: 3.362000
		loss: 3.529200
		loss: 3.391100
		loss: 3.528000
		loss: 3.668600
		loss: 3.528800
		loss: 3.806400
		loss: 3.527200
		loss: 3.811000
		loss: 3.526900
		loss: 3.813600
		loss: 3.526900
		loss: 3.056700
		loss: 3.530100
		loss: 3.638400
		loss: 3.528300
		loss: 3.706300
		loss: 3.526900
		loss: 3.674500
		loss: 3.527000
		loss: 3.461500
		loss: 3.527500
		loss: 3.398600
		loss: 3.527500
		loss: 3.977700
		loss: 3.529100
		loss: 3.440100
		loss: 3.527400
		loss: 3.338100
		loss: 3.526400
		loss: 3.477100
		loss: 3.526900
		loss: 3.155500
		loss: 3.525200
		loss: 3.307600
		loss: 3.525400
		loss: 4.103000
		loss: 3.524100
		loss: 3.835600
		loss: 3.525100
		loss: 3.882800
		loss: 3.527600
		loss: 3.755700
		loss: 3.527000
		loss: 3.653700
		loss: 3.526500
		loss: 3.586900
		loss: 3.525600
		loss: 3.400000
		loss: 3.525200
	Overall the loss development was 4.022200 -> 3.525200
In the epoch 2 for problem d-02.pddl 2 explorations in the sampling searches reached a goal
Success rate: 83

Epoch 3:
Training data for problem d-01.pddl in epoch 3:
model creation time: 10.644229888916016s
problem epoch data for epoch 3, problem epoch 1
	sampling search time: 3.603574514389038s
	during this search the following actions were chosen:
	training time: 43.8002188205719s
	during the training the following losses were computed:
		loss: 2.144500
		loss: 1.998900
		loss: 1.913900
		loss: 1.874800
		loss: 1.859300
		loss: 1.838900
		loss: 1.819100
		loss: 1.810000
		loss: 1.807500
		loss: 1.805400
		loss: 1.802900
		loss: 1.801800
		loss: 1.800900
		loss: 1.798400
		loss: 1.794500
		loss: 1.791200
		loss: 1.789100
		loss: 1.787200
		loss: 1.784900
		loss: 1.782800
		loss: 1.781000
		loss: 1.778900
		loss: 1.776400
		loss: 1.774500
		loss: 1.773900
		loss: 1.774000
		loss: 1.773700
		loss: 1.773000
		loss: 1.772400
		loss: 1.772000
		loss: 1.771700
		loss: 1.771400
		loss: 1.771100
		loss: 1.770700
		loss: 1.770000
		loss: 1.769100
		loss: 1.768300
		loss: 1.767900
		loss: 1.767600
		loss: 1.767300
		loss: 1.767000
		loss: 1.766700
		loss: 1.766400
		loss: 1.766200
		loss: 1.766100
		loss: 1.765900
		loss: 1.765600
		loss: 1.765300
		loss: 1.764900
		loss: 1.764500
		loss: 1.764200
		loss: 1.763900
		loss: 1.763700
		loss: 1.763500
		loss: 1.763300
		loss: 1.763100
		loss: 1.762900
		loss: 1.762700
		loss: 1.762500
		loss: 1.762300
		loss: 1.762100
		loss: 1.761900
		loss: 1.761600
		loss: 1.761400
		loss: 1.761200
		loss: 1.761000
		loss: 1.760800
		loss: 1.760600
		loss: 1.760300
		loss: 1.760100
		loss: 1.759900
		loss: 1.759800
		loss: 1.759600
		loss: 1.759400
		loss: 1.759200
		loss: 1.759000
		loss: 1.758800
		loss: 1.758600
		loss: 1.758400
		loss: 1.758200
		loss: 1.758000
		loss: 1.757800
		loss: 1.757700
		loss: 1.757500
		loss: 1.757300
		loss: 1.757100
		loss: 1.756900
		loss: 1.756700
		loss: 1.756600
		loss: 1.756400
		loss: 1.756200
		loss: 1.756000
		loss: 1.755800
		loss: 1.755600
		loss: 1.755400
		loss: 1.755300
		loss: 1.755100
		loss: 1.754900
		loss: 1.754700
		loss: 1.754600
	Overall the loss development was 2.144500 -> 1.754600
problem epoch data for epoch 3, problem epoch 2
	sampling search time: 3.4802727699279785s
	during this search the following actions were chosen:
	training time: 10.111384630203247s
	during the training the following losses were computed:
		loss: 1.754400
		loss: 1.754200
		loss: 1.754000
		loss: 1.753800
		loss: 1.753700
		loss: 1.753500
		loss: 1.753300
		loss: 1.753100
		loss: 1.753000
		loss: 1.752800
		loss: 1.752600
		loss: 1.752500
		loss: 1.752300
		loss: 1.752100
		loss: 1.751900
		loss: 1.751800
		loss: 1.751600
		loss: 1.751400
		loss: 1.751300
		loss: 1.751100
		loss: 1.750900
		loss: 1.750800
		loss: 1.750600
		loss: 1.750400
		loss: 1.750300
		loss: 1.750100
		loss: 1.749900
		loss: 1.749800
		loss: 1.749600
		loss: 1.749500
		loss: 1.749300
		loss: 1.749100
		loss: 1.749000
		loss: 1.748800
		loss: 1.748700
		loss: 1.748500
		loss: 1.748300
		loss: 1.748200
		loss: 1.748000
		loss: 1.747900
		loss: 1.747700
		loss: 1.747600
		loss: 1.747400
		loss: 1.747300
		loss: 1.747100
		loss: 1.747000
		loss: 1.746800
		loss: 1.746700
		loss: 1.746500
		loss: 1.746300
		loss: 1.746200
		loss: 1.746000
		loss: 1.745900
		loss: 1.745800
		loss: 1.745600
		loss: 1.745500
		loss: 1.745300
		loss: 1.745200
		loss: 1.745000
		loss: 1.744900
		loss: 1.744700
		loss: 1.744600
		loss: 1.744400
		loss: 1.744300
		loss: 1.744200
		loss: 1.744000
		loss: 1.743900
		loss: 1.743700
		loss: 1.743600
		loss: 1.743400
		loss: 1.743300
		loss: 1.743200
		loss: 1.743000
		loss: 1.742900
		loss: 1.742800
		loss: 1.742600
		loss: 1.742500
		loss: 1.742300
		loss: 1.742200
		loss: 1.742100
		loss: 1.741900
		loss: 1.741800
		loss: 1.741700
		loss: 1.741500
		loss: 1.741400
		loss: 1.741300
		loss: 1.741100
		loss: 1.741000
		loss: 1.740900
		loss: 1.740700
		loss: 1.740600
		loss: 1.740500
		loss: 1.740400
		loss: 1.740200
		loss: 1.740100
		loss: 1.740000
		loss: 1.739800
		loss: 1.739700
		loss: 1.739600
		loss: 1.739500
	Overall the loss development was 1.754400 -> 1.739500
problem epoch data for epoch 3, problem epoch 3
	sampling search time: 3.4509050846099854s
	during this search the following actions were chosen:
	training time: 10.124243259429932s
	during the training the following losses were computed:
		loss: 1.729900
		loss: 1.729700
		loss: 1.729500
		loss: 1.729400
		loss: 1.729300
		loss: 1.729200
		loss: 1.729000
		loss: 1.728900
		loss: 1.728800
		loss: 1.728600
		loss: 1.728500
		loss: 1.728400
		loss: 1.728200
		loss: 1.728100
		loss: 1.728000
		loss: 1.727900
		loss: 1.727700
		loss: 1.727600
		loss: 1.727500
		loss: 1.727400
		loss: 1.727300
		loss: 1.727100
		loss: 1.727000
		loss: 1.726900
		loss: 1.726800
		loss: 1.726700
		loss: 1.726500
		loss: 1.726400
		loss: 1.726300
		loss: 1.726200
		loss: 1.726100
		loss: 1.726000
		loss: 1.725900
		loss: 1.725700
		loss: 1.725600
		loss: 1.725500
		loss: 1.725400
		loss: 1.725300
		loss: 1.725200
		loss: 1.725100
		loss: 1.725000
		loss: 1.724800
		loss: 1.724700
		loss: 1.724600
		loss: 1.724500
		loss: 1.724400
		loss: 1.724300
		loss: 1.724200
		loss: 1.724100
		loss: 1.724000
		loss: 1.723900
		loss: 1.723800
		loss: 1.723700
		loss: 1.723600
		loss: 1.723400
		loss: 1.723300
		loss: 1.723200
		loss: 1.723100
		loss: 1.723000
		loss: 1.722900
		loss: 1.722800
		loss: 1.722700
		loss: 1.722600
		loss: 1.722500
		loss: 1.722400
		loss: 1.722300
		loss: 1.722200
		loss: 1.722100
		loss: 1.722000
		loss: 1.721900
		loss: 1.721800
		loss: 1.721700
		loss: 1.721600
		loss: 1.721500
		loss: 1.721400
		loss: 1.721300
		loss: 1.721200
		loss: 1.721100
		loss: 1.721000
		loss: 1.720900
		loss: 1.720800
		loss: 1.720700
		loss: 1.720600
		loss: 1.720500
		loss: 1.720400
		loss: 1.720300
		loss: 1.720200
		loss: 1.720100
		loss: 1.720000
		loss: 1.719900
		loss: 1.719900
		loss: 1.719800
		loss: 1.719700
		loss: 1.719600
		loss: 1.719500
		loss: 1.719400
		loss: 1.719300
		loss: 1.719200
		loss: 1.719100
		loss: 1.719000
	Overall the loss development was 1.729900 -> 1.719000
In the epoch 3 for problem d-01.pddl 3 explorations in the sampling searches reached a goal
Training data for problem d-02.pddl in epoch 3:
model creation time: 21.066847324371338s
problem epoch data for epoch 3, problem epoch 1
	sampling search time: 25.840564966201782s
	during this search the following actions were chosen:
	training time: 88.97546315193176s
	during the training the following losses were computed:
		loss: 3.445300
		loss: 4.216300
		loss: 3.770700
		loss: 3.806000
		loss: 4.221800
		loss: 3.694800
		loss: 3.799100
		loss: 3.550600
		loss: 3.339700
		loss: 3.446100
		loss: 3.090300
		loss: 3.408000
		loss: 4.121100
		loss: 3.377300
		loss: 3.724400
		loss: 3.307400
		loss: 3.516100
		loss: 3.254500
		loss: 3.480900
		loss: 3.242100
		loss: 3.624100
		loss: 3.243200
		loss: 4.046700
		loss: 3.243200
		loss: 3.142500
		loss: 3.232600
		loss: 2.786700
		loss: 3.215900
		loss: 3.089800
		loss: 3.198700
		loss: 3.383600
		loss: 3.188800
		loss: 3.018700
		loss: 3.182300
		loss: 3.127500
		loss: 3.180100
		loss: 2.868300
		loss: 3.174200
		loss: 2.970300
		loss: 3.166200
		loss: 3.739500
		loss: 3.159400
		loss: 3.629900
		loss: 3.155500
		loss: 3.194100
		loss: 3.153500
		loss: 3.634400
		loss: 3.149900
		loss: 3.045500
		loss: 3.145600
		loss: 2.622000
		loss: 3.141800
		loss: 2.930500
		loss: 3.138000
		loss: 2.920500
		loss: 3.133900
		loss: 3.446300
		loss: 3.131100
		loss: 2.724800
		loss: 3.128600
		loss: 3.869700
		loss: 3.125000
		loss: 2.984600
		loss: 3.123100
		loss: 3.020200
		loss: 3.119800
		loss: 3.406500
		loss: 3.118000
		loss: 2.717000
		loss: 3.115200
		loss: 2.882900
		loss: 3.113200
		loss: 3.181500
		loss: 3.110800
		loss: 3.024900
		loss: 3.109900
		loss: 3.599900
		loss: 3.107300
		loss: 3.256100
		loss: 3.106100
		loss: 3.296800
		loss: 3.104100
		loss: 3.194900
		loss: 3.102100
		loss: 2.724100
		loss: 3.101300
		loss: 3.051600
		loss: 3.099000
		loss: 2.834200
		loss: 3.097900
		loss: 3.266300
		loss: 3.095600
		loss: 2.543200
		loss: 3.095400
		loss: 3.389500
		loss: 3.092800
		loss: 2.865800
		loss: 3.091300
		loss: 2.713800
		loss: 3.090100
		loss: 3.601700
		loss: 3.089400
		loss: 2.897300
		loss: 3.088600
		loss: 2.915700
		loss: 3.086800
		loss: 3.628800
		loss: 3.085800
		loss: 2.777600
		loss: 3.085300
		loss: 3.389000
		loss: 3.084300
		loss: 2.633200
		loss: 3.083200
		loss: 3.430400
		loss: 3.081900
		loss: 3.368200
		loss: 3.081000
		loss: 3.123200
		loss: 3.080000
		loss: 2.914200
		loss: 3.079400
		loss: 3.363400
		loss: 3.078800
		loss: 2.968100
		loss: 3.077600
		loss: 3.257500
		loss: 3.077000
		loss: 2.734600
		loss: 3.076400
		loss: 3.312900
		loss: 3.076100
		loss: 3.703500
		loss: 3.075200
		loss: 3.108400
		loss: 3.074500
		loss: 2.616000
		loss: 3.073600
		loss: 3.240900
		loss: 3.072600
		loss: 2.703100
		loss: 3.072300
		loss: 3.506800
		loss: 3.073000
		loss: 2.684100
		loss: 3.072500
		loss: 2.782800
		loss: 3.070700
		loss: 3.003600
		loss: 3.070500
		loss: 3.316400
		loss: 3.069900
		loss: 2.889300
		loss: 3.069300
		loss: 2.437100
		loss: 3.068800
		loss: 2.952200
		loss: 3.068200
		loss: 2.585200
		loss: 3.068200
		loss: 2.808400
		loss: 3.067300
		loss: 3.404600
		loss: 3.066900
		loss: 3.195200
		loss: 3.066900
		loss: 3.173300
		loss: 3.066200
		loss: 3.329200
		loss: 3.066000
		loss: 3.098500
		loss: 3.065500
		loss: 3.109100
		loss: 3.065000
		loss: 3.496800
		loss: 3.064700
		loss: 2.708800
		loss: 3.064300
		loss: 3.561000
		loss: 3.064100
		loss: 3.022500
		loss: 3.063800
		loss: 3.274900
		loss: 3.063500
		loss: 3.562400
		loss: 3.063900
		loss: 2.757200
		loss: 3.062800
		loss: 3.186600
		loss: 3.062600
		loss: 3.139200
		loss: 3.062600
		loss: 2.570800
		loss: 3.062200
		loss: 3.389300
		loss: 3.062100
		loss: 3.474400
		loss: 3.061700
		loss: 2.696700
		loss: 3.061400
	Overall the loss development was 3.445300 -> 3.061400
problem epoch data for epoch 3, problem epoch 2
	sampling search time: 22.68480396270752s
	during this search the following actions were chosen:
	training time: 20.79418134689331s
	during the training the following losses were computed:
		loss: 3.618900
		loss: 3.372200
		loss: 3.589800
		loss: 3.369600
		loss: 3.925900
		loss: 3.372500
		loss: 3.456500
		loss: 3.367100
		loss: 3.559900
		loss: 3.368800
		loss: 3.168200
		loss: 3.367800
		loss: 3.643400
		loss: 3.367100
		loss: 3.592900
		loss: 3.366800
		loss: 2.960500
		loss: 3.365400
		loss: 3.310100
		loss: 3.366100
		loss: 3.100700
		loss: 3.364600
		loss: 3.680600
		loss: 3.364900
		loss: 2.627600
		loss: 3.363900
		loss: 3.809000
		loss: 3.363500
		loss: 3.551200
		loss: 3.363100
		loss: 3.393300
		loss: 3.362700
		loss: 3.033300
		loss: 3.362600
		loss: 3.353100
		loss: 3.362400
		loss: 3.080400
		loss: 3.362200
		loss: 3.301900
		loss: 3.362400
		loss: 3.579500
		loss: 3.361800
		loss: 3.243500
		loss: 3.362200
		loss: 2.986300
		loss: 3.361500
		loss: 3.694600
		loss: 3.361700
		loss: 3.512900
		loss: 3.361300
		loss: 3.711100
		loss: 3.361400
		loss: 3.708900
		loss: 3.361400
		loss: 3.315500
		loss: 3.361300
		loss: 3.083100
		loss: 3.360900
		loss: 3.473400
		loss: 3.360800
		loss: 3.676900
		loss: 3.360900
		loss: 3.456000
		loss: 3.360700
		loss: 3.222500
		loss: 3.360700
		loss: 3.610000
		loss: 3.360400
		loss: 3.246500
		loss: 3.360400
		loss: 3.818500
		loss: 3.360200
		loss: 3.141900
		loss: 3.360300
		loss: 3.547600
		loss: 3.360100
		loss: 3.448200
		loss: 3.360500
		loss: 3.590900
		loss: 3.360300
		loss: 3.563200
		loss: 3.360000
		loss: 3.158300
		loss: 3.359900
		loss: 3.342500
		loss: 3.359600
		loss: 3.665900
		loss: 3.359700
		loss: 3.114200
		loss: 3.359700
		loss: 3.028800
		loss: 3.359400
		loss: 3.517600
		loss: 3.359800
		loss: 3.359900
		loss: 3.359300
		loss: 3.272800
		loss: 3.359400
		loss: 3.276700
		loss: 3.360700
		loss: 3.029400
		loss: 3.360000
		loss: 2.854600
		loss: 3.359200
		loss: 2.981300
		loss: 3.359000
		loss: 3.317700
		loss: 3.359000
		loss: 3.207700
		loss: 3.359000
		loss: 3.216900
		loss: 3.359100
		loss: 3.217900
		loss: 3.358700
		loss: 3.438600
		loss: 3.358500
		loss: 3.722500
		loss: 3.358700
		loss: 3.067600
		loss: 3.358700
		loss: 2.906500
		loss: 3.359100
		loss: 2.722000
		loss: 3.359600
		loss: 3.906400
		loss: 3.359900
		loss: 3.658700
		loss: 3.359300
		loss: 3.202100
		loss: 3.358600
		loss: 3.588100
		loss: 3.358800
		loss: 3.530100
		loss: 3.358900
		loss: 2.935200
		loss: 3.359800
		loss: 3.182000
		loss: 3.359200
		loss: 3.288700
		loss: 3.359100
		loss: 3.330100
		loss: 3.357800
		loss: 3.330100
		loss: 3.358800
		loss: 3.444300
		loss: 3.358600
		loss: 3.389000
		loss: 3.358600
		loss: 3.252100
		loss: 3.357400
		loss: 3.179200
		loss: 3.357300
		loss: 3.739900
		loss: 3.357600
		loss: 3.473300
		loss: 3.357200
		loss: 3.132400
		loss: 3.357000
		loss: 3.464800
		loss: 3.356900
		loss: 3.599500
		loss: 3.356900
		loss: 2.826600
		loss: 3.357000
		loss: 3.400100
		loss: 3.356700
		loss: 3.103600
		loss: 3.357000
		loss: 3.370700
		loss: 3.356500
		loss: 3.684200
		loss: 3.356800
		loss: 3.756000
		loss: 3.356900
		loss: 3.476800
		loss: 3.356500
		loss: 3.495600
		loss: 3.356400
		loss: 3.629200
		loss: 3.356700
		loss: 3.545300
		loss: 3.356200
		loss: 3.142700
		loss: 3.356200
		loss: 2.798800
		loss: 3.356000
		loss: 2.941500
		loss: 3.355900
		loss: 3.157400
		loss: 3.356000
		loss: 3.376000
		loss: 3.356000
		loss: 2.841400
		loss: 3.355900
		loss: 2.928200
		loss: 3.355900
		loss: 3.784700
		loss: 3.355600
		loss: 2.415200
		loss: 3.355700
	Overall the loss development was 3.618900 -> 3.355700
problem epoch data for epoch 3, problem epoch 3
	sampling search time: 23.830676078796387s
	during this search the following actions were chosen:
	training time: 21.0970299243927s
	during the training the following losses were computed:
		loss: 3.082700
		loss: 3.375000
		loss: 3.263800
		loss: 3.374000
		loss: 3.232900
		loss: 3.372600
		loss: 3.734900
		loss: 3.371700
		loss: 2.882900
		loss: 3.374900
		loss: 3.600500
		loss: 3.373800
		loss: 3.382700
		loss: 3.372700
		loss: 3.631500
		loss: 3.371400
		loss: 2.956200
		loss: 3.374300
		loss: 3.479500
		loss: 3.372800
		loss: 3.578100
		loss: 3.371400
		loss: 3.874100
		loss: 3.374600
		loss: 3.284200
		loss: 3.371900
		loss: 2.932100
		loss: 3.370100
		loss: 3.643000
		loss: 3.370900
		loss: 3.677500
		loss: 3.370600
		loss: 3.630600
		loss: 3.373200
		loss: 3.384200
		loss: 3.371900
		loss: 2.671400
		loss: 3.368700
		loss: 3.590700
		loss: 3.370900
		loss: 3.156700
		loss: 3.372800
		loss: 3.529300
		loss: 3.371000
		loss: 3.039300
		loss: 3.370100
		loss: 3.312900
		loss: 3.371800
		loss: 3.470600
		loss: 3.371100
		loss: 3.568400
		loss: 3.372600
		loss: 3.608500
		loss: 3.372700
		loss: 3.826000
		loss: 3.373700
		loss: 3.431000
		loss: 3.371200
		loss: 3.651700
		loss: 3.370000
		loss: 3.368200
		loss: 3.371600
		loss: 3.100800
		loss: 3.372600
		loss: 2.819100
		loss: 3.373600
		loss: 3.925600
		loss: 3.368600
		loss: 3.034700
		loss: 3.372500
		loss: 3.016700
		loss: 3.369500
		loss: 3.319800
		loss: 3.370700
		loss: 3.322700
		loss: 3.371100
		loss: 2.835200
		loss: 3.373300
		loss: 3.097300
		loss: 3.369600
		loss: 3.309500
		loss: 3.370600
		loss: 2.921900
		loss: 3.368700
		loss: 3.408000
		loss: 3.370800
		loss: 3.650200
		loss: 3.369200
		loss: 3.179800
		loss: 3.369900
		loss: 3.669600
		loss: 3.371900
		loss: 3.550800
		loss: 3.371300
		loss: 3.112100
		loss: 3.369300
		loss: 3.408900
		loss: 3.370800
		loss: 3.471300
		loss: 3.370800
		loss: 3.926800
		loss: 3.373100
		loss: 3.433600
		loss: 3.370500
		loss: 2.947300
		loss: 3.372400
		loss: 3.376000
		loss: 3.370100
		loss: 3.443500
		loss: 3.370300
		loss: 3.425200
		loss: 3.369800
		loss: 3.000600
		loss: 3.371600
		loss: 3.385700
		loss: 3.370000
		loss: 3.292200
		loss: 3.370300
		loss: 3.288500
		loss: 3.369400
		loss: 3.367600
		loss: 3.369900
		loss: 3.236700
		loss: 3.370600
		loss: 3.504600
		loss: 3.369000
		loss: 3.058800
		loss: 3.371200
		loss: 3.440900
		loss: 3.369200
		loss: 3.861000
		loss: 3.371600
		loss: 3.164100
		loss: 3.370400
		loss: 3.353900
		loss: 3.370000
		loss: 3.531100
		loss: 3.370200
		loss: 3.335000
		loss: 3.370500
		loss: 3.686100
		loss: 3.371700
		loss: 3.595700
		loss: 3.368500
		loss: 3.507700
		loss: 3.370300
		loss: 3.609500
		loss: 3.368700
		loss: 3.389200
		loss: 3.369600
		loss: 3.392700
		loss: 3.370100
		loss: 3.851700
		loss: 3.367700
		loss: 3.178700
		loss: 3.370600
		loss: 3.772300
		loss: 3.370900
		loss: 3.403300
		loss: 3.369600
		loss: 3.540400
		loss: 3.370200
		loss: 3.570100
		loss: 3.369700
		loss: 2.775200
		loss: 3.366600
		loss: 3.465400
		loss: 3.368400
		loss: 3.244500
		loss: 3.368300
		loss: 3.186800
		loss: 3.368200
		loss: 3.512300
		loss: 3.368600
		loss: 3.449800
		loss: 3.368200
		loss: 3.029500
		loss: 3.370600
		loss: 3.045000
		loss: 3.370700
		loss: 3.285300
		loss: 3.369400
		loss: 3.183500
		loss: 3.370600
		loss: 3.568700
		loss: 3.370400
		loss: 3.123900
		loss: 3.370500
		loss: 3.688800
		loss: 3.367800
		loss: 3.435800
		loss: 3.368900
		loss: 2.692600
		loss: 3.371700
		loss: 3.427500
		loss: 3.368700
		loss: 3.117700
		loss: 3.368300
		loss: 3.670500
		loss: 3.367500
	Overall the loss development was 3.082700 -> 3.367500
In the epoch 3 for problem d-02.pddl 3 explorations in the sampling searches reached a goal
Success rate: 100

Epoch 4:
Training data for problem d-01.pddl in epoch 4:
model creation time: 10.353525400161743s
problem epoch data for epoch 4, problem epoch 1
	sampling search time: 3.4749929904937744s
	during this search the following actions were chosen:
	training time: 43.71116757392883s
	during the training the following losses were computed:
		loss: 2.114800
		loss: 1.985800
		loss: 1.887000
		loss: 1.842700
		loss: 1.830200
		loss: 1.815900
		loss: 1.796700
		loss: 1.783100
		loss: 1.777700
		loss: 1.777400
		loss: 1.779600
		loss: 1.781500
		loss: 1.780300
		loss: 1.775400
		loss: 1.768800
		loss: 1.763300
		loss: 1.759700
		loss: 1.757800
		loss: 1.757200
		loss: 1.757400
		loss: 1.757500
		loss: 1.756300
		loss: 1.754200
		loss: 1.752100
		loss: 1.750700
		loss: 1.749900
		loss: 1.749100
		loss: 1.748300
		loss: 1.747400
		loss: 1.746500
		loss: 1.745500
		loss: 1.744900
		loss: 1.744900
		loss: 1.745200
		loss: 1.745400
		loss: 1.745400
		loss: 1.745200
		loss: 1.744700
		loss: 1.744000
		loss: 1.743300
		loss: 1.742900
		loss: 1.742500
		loss: 1.742200
		loss: 1.741900
		loss: 1.741700
		loss: 1.741500
		loss: 1.741500
		loss: 1.741500
		loss: 1.741500
		loss: 1.741300
		loss: 1.741100
		loss: 1.740800
		loss: 1.740500
		loss: 1.740300
		loss: 1.740100
		loss: 1.739900
		loss: 1.739800
		loss: 1.739700
		loss: 1.739500
		loss: 1.739400
		loss: 1.739300
		loss: 1.739100
		loss: 1.739000
		loss: 1.738900
		loss: 1.738700
		loss: 1.738600
		loss: 1.738400
		loss: 1.738300
		loss: 1.738200
		loss: 1.738100
		loss: 1.737900
		loss: 1.737800
		loss: 1.737600
		loss: 1.737500
		loss: 1.737400
		loss: 1.737200
		loss: 1.737100
		loss: 1.737000
		loss: 1.736900
		loss: 1.736800
		loss: 1.736600
		loss: 1.736500
		loss: 1.736400
		loss: 1.736300
		loss: 1.736200
		loss: 1.736000
		loss: 1.735900
		loss: 1.735800
		loss: 1.735700
		loss: 1.735500
		loss: 1.735400
		loss: 1.735300
		loss: 1.735200
		loss: 1.735100
		loss: 1.735000
		loss: 1.734800
		loss: 1.734700
		loss: 1.734600
		loss: 1.734500
		loss: 1.734400
	Overall the loss development was 2.114800 -> 1.734400
problem epoch data for epoch 4, problem epoch 2
	sampling search time: 3.5671744346618652s
	during this search the following actions were chosen:
	training time: 10.115465879440308s
	during the training the following losses were computed:
		loss: 1.734300
		loss: 1.734100
		loss: 1.734000
		loss: 1.733900
		loss: 1.733800
		loss: 1.733700
		loss: 1.733600
		loss: 1.733500
		loss: 1.733400
		loss: 1.733200
		loss: 1.733100
		loss: 1.733000
		loss: 1.732900
		loss: 1.732800
		loss: 1.732700
		loss: 1.732600
		loss: 1.732500
		loss: 1.732400
		loss: 1.732300
		loss: 1.732200
		loss: 1.732000
		loss: 1.731900
		loss: 1.731800
		loss: 1.731700
		loss: 1.731600
		loss: 1.731500
		loss: 1.731400
		loss: 1.731300
		loss: 1.731200
		loss: 1.731100
		loss: 1.731000
		loss: 1.730900
		loss: 1.730800
		loss: 1.730700
		loss: 1.730600
		loss: 1.730500
		loss: 1.730400
		loss: 1.730300
		loss: 1.730200
		loss: 1.730100
		loss: 1.730000
		loss: 1.729900
		loss: 1.729800
		loss: 1.729700
		loss: 1.729600
		loss: 1.729500
		loss: 1.729400
		loss: 1.729300
		loss: 1.729200
		loss: 1.729100
		loss: 1.729000
		loss: 1.728900
		loss: 1.728800
		loss: 1.728700
		loss: 1.728600
		loss: 1.728500
		loss: 1.728400
		loss: 1.728300
		loss: 1.728200
		loss: 1.728100
		loss: 1.728000
		loss: 1.727900
		loss: 1.727800
		loss: 1.727700
		loss: 1.727600
		loss: 1.727600
		loss: 1.727500
		loss: 1.727400
		loss: 1.727300
		loss: 1.727200
		loss: 1.727100
		loss: 1.727000
		loss: 1.726900
		loss: 1.726800
		loss: 1.726700
		loss: 1.726600
		loss: 1.726600
		loss: 1.726500
		loss: 1.726400
		loss: 1.726300
		loss: 1.726200
		loss: 1.726100
		loss: 1.726000
		loss: 1.725900
		loss: 1.725800
		loss: 1.725800
		loss: 1.725700
		loss: 1.725600
		loss: 1.725500
		loss: 1.725400
		loss: 1.725300
		loss: 1.725200
		loss: 1.725200
		loss: 1.725100
		loss: 1.725000
		loss: 1.724900
		loss: 1.724800
		loss: 1.724700
		loss: 1.724600
		loss: 1.724600
	Overall the loss development was 1.734300 -> 1.724600
problem epoch data for epoch 4, problem epoch 3
	sampling search time: 3.491816997528076s
	during this search the following actions were chosen:
	training time: 10.114378690719604s
	during the training the following losses were computed:
		loss: 1.684200
		loss: 1.683600
		loss: 1.683300
		loss: 1.683300
		loss: 1.683300
		loss: 1.683100
		loss: 1.682900
		loss: 1.682700
		loss: 1.682500
		loss: 1.682500
		loss: 1.682400
		loss: 1.682200
		loss: 1.682000
		loss: 1.681900
		loss: 1.681800
		loss: 1.681700
		loss: 1.681600
		loss: 1.681400
		loss: 1.681300
		loss: 1.681200
		loss: 1.681100
		loss: 1.681000
		loss: 1.680900
		loss: 1.680800
		loss: 1.680700
		loss: 1.680600
		loss: 1.680500
		loss: 1.680400
		loss: 1.680300
		loss: 1.680200
		loss: 1.680200
		loss: 1.680100
		loss: 1.680000
		loss: 1.679900
		loss: 1.679800
		loss: 1.679700
		loss: 1.679700
		loss: 1.679600
		loss: 1.679500
		loss: 1.679400
		loss: 1.679300
		loss: 1.679300
		loss: 1.679200
		loss: 1.679100
		loss: 1.679000
		loss: 1.679000
		loss: 1.678900
		loss: 1.678800
		loss: 1.678700
		loss: 1.678600
		loss: 1.678600
		loss: 1.678500
		loss: 1.678400
		loss: 1.678400
		loss: 1.678300
		loss: 1.678200
		loss: 1.678100
		loss: 1.678100
		loss: 1.678000
		loss: 1.677900
		loss: 1.677800
		loss: 1.677800
		loss: 1.677700
		loss: 1.677600
		loss: 1.677600
		loss: 1.677500
		loss: 1.677400
		loss: 1.677400
		loss: 1.677300
		loss: 1.677200
		loss: 1.677100
		loss: 1.677100
		loss: 1.677000
		loss: 1.676900
		loss: 1.676900
		loss: 1.676800
		loss: 1.676700
		loss: 1.676700
		loss: 1.676600
		loss: 1.676500
		loss: 1.676500
		loss: 1.676400
		loss: 1.676300
		loss: 1.676300
		loss: 1.676200
		loss: 1.676100
		loss: 1.676100
		loss: 1.676000
		loss: 1.675900
		loss: 1.675900
		loss: 1.675800
		loss: 1.675700
		loss: 1.675700
		loss: 1.675600
		loss: 1.675500
		loss: 1.675500
		loss: 1.675400
		loss: 1.675400
		loss: 1.675300
		loss: 1.675200
	Overall the loss development was 1.684200 -> 1.675200
In the epoch 4 for problem d-01.pddl 3 explorations in the sampling searches reached a goal
Training data for problem d-02.pddl in epoch 4:
model creation time: 19.45047640800476s
problem epoch data for epoch 4, problem epoch 1
	sampling search time: 32.595579862594604s
	during this search the following actions were chosen:
	training time: 102.47969722747803s
	during the training the following losses were computed:
		loss: 4.953800
		loss: 4.532900
		loss: 3.942600
		loss: 4.062400
		loss: 3.956900
		loss: 3.965500
		loss: 4.057400
		loss: 3.846500
		loss: 4.231100
		loss: 3.770900
		loss: 3.673200
		loss: 3.754300
		loss: 3.963300
		loss: 3.709700
		loss: 4.193900
		loss: 3.646800
		loss: 3.758700
		loss: 3.600400
		loss: 3.641500
		loss: 3.578600
		loss: 3.250600
		loss: 3.568700
		loss: 3.656200
		loss: 3.563200
		loss: 3.602300
		loss: 3.557600
		loss: 3.150700
		loss: 3.548100
		loss: 3.024300
		loss: 3.536000
		loss: 3.408900
		loss: 3.519100
		loss: 3.849500
		loss: 3.515300
		loss: 3.293300
		loss: 3.507400
		loss: 3.325200
		loss: 3.504600
		loss: 3.223400
		loss: 3.498800
		loss: 3.160600
		loss: 3.488500
		loss: 3.597200
		loss: 3.486300
		loss: 3.366400
		loss: 3.481800
		loss: 3.162200
		loss: 3.476000
		loss: 3.410300
		loss: 3.474900
		loss: 3.808400
		loss: 3.473000
		loss: 3.504100
		loss: 3.466600
		loss: 3.754300
		loss: 3.465700
		loss: 3.231900
		loss: 3.462900
		loss: 3.724900
		loss: 3.460400
		loss: 3.363000
		loss: 3.456400
		loss: 3.715600
		loss: 3.451500
		loss: 3.599000
		loss: 3.450000
		loss: 3.560900
		loss: 3.449100
		loss: 2.959400
		loss: 3.448900
		loss: 3.773500
		loss: 3.442300
		loss: 3.080600
		loss: 3.444100
		loss: 3.361700
		loss: 3.440600
		loss: 3.499600
		loss: 3.438900
		loss: 3.270800
		loss: 3.437400
		loss: 3.251500
		loss: 3.435700
		loss: 3.304800
		loss: 3.434200
		loss: 3.237900
		loss: 3.432300
		loss: 3.033200
		loss: 3.427400
		loss: 2.932800
		loss: 3.425500
		loss: 3.407700
		loss: 3.426800
		loss: 3.101400
		loss: 3.423800
		loss: 3.638800
		loss: 3.425300
		loss: 3.500300
		loss: 3.423400
		loss: 3.466900
		loss: 3.421300
		loss: 3.271800
		loss: 3.421500
		loss: 3.712400
		loss: 3.421100
		loss: 2.816400
		loss: 3.421700
		loss: 3.333500
		loss: 3.416900
		loss: 3.689200
		loss: 3.414600
		loss: 3.193600
		loss: 3.414500
		loss: 3.578200
		loss: 3.413700
		loss: 4.275300
		loss: 3.418500
		loss: 3.410000
		loss: 3.412500
		loss: 3.866700
		loss: 3.414600
		loss: 3.142800
		loss: 3.412600
		loss: 3.183800
		loss: 3.409200
		loss: 3.724600
		loss: 3.408700
		loss: 3.422900
		loss: 3.409100
		loss: 3.380900
		loss: 3.408600
		loss: 3.526600
		loss: 3.407100
		loss: 3.773100
		loss: 3.404700
		loss: 3.263800
		loss: 3.405700
		loss: 3.220100
		loss: 3.407100
		loss: 3.871500
		loss: 3.408200
		loss: 3.070300
		loss: 3.402700
		loss: 3.212200
		loss: 3.403000
		loss: 2.922700
		loss: 3.401000
		loss: 3.840400
		loss: 3.405600
		loss: 3.390700
		loss: 3.402600
		loss: 3.277900
		loss: 3.401500
		loss: 3.244400
		loss: 3.401700
		loss: 3.316800
		loss: 3.401200
		loss: 3.871200
		loss: 3.398300
		loss: 3.206500
		loss: 3.402500
		loss: 3.070500
		loss: 3.402300
		loss: 2.774400
		loss: 3.403600
		loss: 2.880600
		loss: 3.403000
		loss: 3.609900
		loss: 3.397500
		loss: 3.680500
		loss: 3.400800
		loss: 3.236500
		loss: 3.399200
		loss: 3.946200
		loss: 3.401100
		loss: 3.820800
		loss: 3.399900
		loss: 3.257900
		loss: 3.398200
		loss: 3.556900
		loss: 3.396100
		loss: 2.878000
		loss: 3.393800
		loss: 3.703100
		loss: 3.394700
		loss: 2.916400
		loss: 3.398900
		loss: 3.103900
		loss: 3.394200
		loss: 3.156500
		loss: 3.397000
		loss: 3.723400
		loss: 3.397200
		loss: 3.333400
		loss: 3.395500
		loss: 3.410800
		loss: 3.394800
		loss: 2.751800
		loss: 3.398200
		loss: 3.941500
		loss: 3.398200
	Overall the loss development was 4.953800 -> 3.398200
problem epoch data for epoch 4, problem epoch 2
	sampling search time: 23.89562439918518s
	during this search the following actions were chosen:
	training time: 26.027577877044678s
	during the training the following losses were computed:
		loss: 3.283800
		loss: 3.615800
		loss: 3.768000
		loss: 3.614900
		loss: 3.403500
		loss: 3.614000
		loss: 3.987500
		loss: 3.614100
		loss: 3.619500
		loss: 3.613900
		loss: 3.964300
		loss: 3.613800
		loss: 3.551100
		loss: 3.613600
		loss: 3.462300
		loss: 3.613100
		loss: 3.580300
		loss: 3.613000
		loss: 3.591800
		loss: 3.612700
		loss: 3.721300
		loss: 3.612500
		loss: 3.413000
		loss: 3.612200
		loss: 3.378700
		loss: 3.612100
		loss: 3.709200
		loss: 3.612100
		loss: 4.585000
		loss: 3.611900
		loss: 3.826300
		loss: 3.611800
		loss: 3.614400
		loss: 3.611600
		loss: 3.725000
		loss: 3.611600
		loss: 3.553300
		loss: 3.611200
		loss: 3.213700
		loss: 3.611300
		loss: 3.390300
		loss: 3.611200
		loss: 3.265300
		loss: 3.611000
		loss: 3.714000
		loss: 3.610900
		loss: 4.335500
		loss: 3.610800
		loss: 3.392400
		loss: 3.610700
		loss: 3.523800
		loss: 3.610700
		loss: 3.462700
		loss: 3.610600
		loss: 3.719500
		loss: 3.610700
		loss: 3.623200
		loss: 3.610500
		loss: 3.599100
		loss: 3.610600
		loss: 3.596700
		loss: 3.610500
		loss: 3.832000
		loss: 3.610300
		loss: 3.577800
		loss: 3.610300
		loss: 3.710800
		loss: 3.610200
		loss: 3.701500
		loss: 3.610100
		loss: 4.110900
		loss: 3.609900
		loss: 3.784200
		loss: 3.610000
		loss: 3.536100
		loss: 3.609700
		loss: 3.564900
		loss: 3.609600
		loss: 3.438600
		loss: 3.609700
		loss: 3.722900
		loss: 3.609600
		loss: 3.621100
		loss: 3.609600
		loss: 3.554300
		loss: 3.609400
		loss: 3.430900
		loss: 3.609600
		loss: 4.042900
		loss: 3.609700
		loss: 3.663400
		loss: 3.609700
		loss: 3.817900
		loss: 3.609400
		loss: 3.363500
		loss: 3.609000
		loss: 3.476000
		loss: 3.609600
		loss: 3.060200
		loss: 3.609000
		loss: 3.500700
		loss: 3.609300
		loss: 3.875100
		loss: 3.609000
		loss: 3.865100
		loss: 3.608800
		loss: 3.758100
		loss: 3.608800
		loss: 2.980100
		loss: 3.608700
		loss: 3.841800
		loss: 3.608700
		loss: 3.518300
		loss: 3.608700
		loss: 3.073700
		loss: 3.609100
		loss: 3.246400
		loss: 3.608600
		loss: 3.660000
		loss: 3.608800
		loss: 3.230300
		loss: 3.608400
		loss: 4.316300
		loss: 3.608300
		loss: 3.015300
		loss: 3.608800
		loss: 4.079200
		loss: 3.608900
		loss: 3.660200
		loss: 3.610000
		loss: 3.513500
		loss: 3.610700
		loss: 3.970800
		loss: 3.609600
		loss: 3.513700
		loss: 3.609600
		loss: 3.987400
		loss: 3.610100
		loss: 3.936100
		loss: 3.610700
		loss: 3.268300
		loss: 3.609400
		loss: 3.363000
		loss: 3.610200
		loss: 3.632100
		loss: 3.610200
		loss: 3.447300
		loss: 3.608300
		loss: 3.774100
		loss: 3.609400
		loss: 3.856900
		loss: 3.609300
		loss: 3.894700
		loss: 3.608700
		loss: 3.479100
		loss: 3.608300
		loss: 3.989300
		loss: 3.607900
		loss: 3.447000
		loss: 3.607700
		loss: 3.549400
		loss: 3.608100
		loss: 3.608500
		loss: 3.607900
		loss: 3.479200
		loss: 3.607700
		loss: 3.875400
		loss: 3.607300
		loss: 3.594100
		loss: 3.607700
		loss: 3.412600
		loss: 3.607500
		loss: 3.403800
		loss: 3.607100
		loss: 3.536500
		loss: 3.607200
		loss: 3.937900
		loss: 3.606900
		loss: 3.815400
		loss: 3.606900
		loss: 3.299900
		loss: 3.606900
		loss: 3.668800
		loss: 3.606800
		loss: 3.261700
		loss: 3.606900
		loss: 4.008700
		loss: 3.606900
		loss: 4.432600
		loss: 3.606800
		loss: 3.322700
		loss: 3.606800
		loss: 3.572200
		loss: 3.607000
		loss: 3.482700
		loss: 3.607100
		loss: 4.013500
		loss: 3.606700
		loss: 3.716300
		loss: 3.607300
	Overall the loss development was 3.283800 -> 3.607300
problem epoch data for epoch 4, problem epoch 3
	sampling search time: 33.75442695617676s
	during this search the following actions were chosen:
	training time: 30.313859224319458s
	during the training the following losses were computed:
		loss: 3.459100
		loss: 3.728700
		loss: 3.685100
		loss: 3.711300
		loss: 3.873700
		loss: 3.707600
		loss: 3.313300
		loss: 3.700800
		loss: 3.787700
		loss: 3.699900
		loss: 3.751500
		loss: 3.697700
		loss: 3.677900
		loss: 3.691400
		loss: 3.457900
		loss: 3.691900
		loss: 3.610400
		loss: 3.689000
		loss: 3.554400
		loss: 3.687000
		loss: 3.475800
		loss: 3.688600
		loss: 3.627500
		loss: 3.686800
		loss: 3.617100
		loss: 3.683700
		loss: 3.377700
		loss: 3.687600
		loss: 3.749700
		loss: 3.684800
		loss: 3.822300
		loss: 3.684700
		loss: 3.489800
		loss: 3.683100
		loss: 3.575300
		loss: 3.682000
		loss: 3.504500
		loss: 3.683600
		loss: 3.725700
		loss: 3.682000
		loss: 3.826400
		loss: 3.680600
		loss: 3.849200
		loss: 3.682200
		loss: 3.735100
		loss: 3.680800
		loss: 3.546800
		loss: 3.681700
		loss: 4.047500
		loss: 3.682100
		loss: 3.607300
		loss: 3.680400
		loss: 3.720400
		loss: 3.680400
		loss: 4.200500
		loss: 3.682200
		loss: 4.082900
		loss: 3.678800
		loss: 3.920800
		loss: 3.680900
		loss: 3.813300
		loss: 3.680400
		loss: 3.717100
		loss: 3.679700
		loss: 3.416000
		loss: 3.680800
		loss: 3.553400
		loss: 3.679300
		loss: 3.440800
		loss: 3.678900
		loss: 3.677500
		loss: 3.679600
		loss: 3.936600
		loss: 3.680500
		loss: 3.642700
		loss: 3.679800
		loss: 3.752000
		loss: 3.678900
		loss: 3.546900
		loss: 3.678700
		loss: 3.938900
		loss: 3.678000
		loss: 3.489300
		loss: 3.679600
		loss: 3.832700
		loss: 3.679600
		loss: 3.656400
		loss: 3.678900
		loss: 4.026000
		loss: 3.677300
		loss: 3.634600
		loss: 3.678900
		loss: 3.904800
		loss: 3.679600
		loss: 3.648500
		loss: 3.678700
		loss: 3.775100
		loss: 3.678100
		loss: 3.302900
		loss: 3.677000
		loss: 3.470800
		loss: 3.679200
		loss: 3.520900
		loss: 3.677600
		loss: 3.305400
		loss: 3.676900
		loss: 4.067900
		loss: 3.679900
		loss: 3.725100
		loss: 3.678400
		loss: 3.730600
		loss: 3.678500
		loss: 4.174500
		loss: 3.676100
		loss: 3.364800
		loss: 3.679300
		loss: 3.641000
		loss: 3.678000
		loss: 3.946100
		loss: 3.679000
		loss: 3.559100
		loss: 3.678400
		loss: 3.856100
		loss: 3.677200
		loss: 3.389000
		loss: 3.676700
		loss: 3.678100
		loss: 3.677600
		loss: 3.647700
		loss: 3.677800
		loss: 3.819300
		loss: 3.678200
		loss: 4.254400
		loss: 3.675500
		loss: 3.509500
		loss: 3.678200
		loss: 3.697900
		loss: 3.677700
		loss: 3.812700
		loss: 3.678400
		loss: 3.729500
		loss: 3.678300
		loss: 3.640000
		loss: 3.677300
		loss: 4.041100
		loss: 3.676100
		loss: 3.606500
		loss: 3.677300
		loss: 3.655100
		loss: 3.677200
		loss: 4.247000
		loss: 3.679800
		loss: 3.700400
		loss: 3.677300
		loss: 3.057200
		loss: 3.680000
		loss: 3.198700
		loss: 3.679700
		loss: 3.806700
		loss: 3.677900
		loss: 3.730000
		loss: 3.677300
		loss: 3.816100
		loss: 3.676900
		loss: 3.622800
		loss: 3.677700
		loss: 3.963000
		loss: 3.678500
		loss: 3.755200
		loss: 3.677600
		loss: 3.263100
		loss: 3.675800
		loss: 3.563200
		loss: 3.677500
		loss: 3.633500
		loss: 3.676900
		loss: 3.670000
		loss: 3.676700
		loss: 4.021000
		loss: 3.675100
		loss: 3.802000
		loss: 3.677500
		loss: 3.697400
		loss: 3.676800
		loss: 3.269900
		loss: 3.678200
		loss: 3.627700
		loss: 3.676700
		loss: 4.525000
		loss: 3.672900
		loss: 3.926700
		loss: 3.677500
		loss: 3.458800
		loss: 3.677200
		loss: 3.981800
		loss: 3.677600
		loss: 3.463900
		loss: 3.675500
		loss: 3.639000
		loss: 3.676000
	Overall the loss development was 3.459100 -> 3.676000
In the epoch 4 for problem d-02.pddl 3 explorations in the sampling searches reached a goal
Success rate: 100

Epoch 5:
Training data for problem d-01.pddl in epoch 5:
model creation time: 15.983997106552124s
problem epoch data for epoch 5, problem epoch 1
	sampling search time: 5.218027353286743s
	during this search the following actions were chosen:
	training time: 51.307411909103394s
	during the training the following losses were computed:
		loss: 2.171600
		loss: 2.008100
		loss: 1.932300
		loss: 1.872800
		loss: 1.846200
		loss: 1.829700
		loss: 1.811700
		loss: 1.798800
		loss: 1.794200
		loss: 1.793900
		loss: 1.791300
		loss: 1.785300
		loss: 1.778200
		loss: 1.772200
		loss: 1.767500
		loss: 1.763500
		loss: 1.760200
		loss: 1.757600
		loss: 1.755400
		loss: 1.753400
		loss: 1.751900
		loss: 1.751200
		loss: 1.750900
		loss: 1.750400
		loss: 1.749200
		loss: 1.747500
		loss: 1.745800
		loss: 1.744400
		loss: 1.743100
		loss: 1.742100
		loss: 1.741500
		loss: 1.741500
		loss: 1.741800
		loss: 1.742300
		loss: 1.742400
		loss: 1.742100
		loss: 1.741400
		loss: 1.740700
		loss: 1.740200
		loss: 1.739800
		loss: 1.739500
		loss: 1.739200
		loss: 1.738800
		loss: 1.738500
		loss: 1.738300
		loss: 1.738200
		loss: 1.738200
		loss: 1.738300
		loss: 1.738200
		loss: 1.738000
		loss: 1.737700
		loss: 1.737500
		loss: 1.737200
		loss: 1.737000
		loss: 1.736800
		loss: 1.736700
		loss: 1.736600
		loss: 1.736400
		loss: 1.736300
		loss: 1.736200
		loss: 1.736100
		loss: 1.736000
		loss: 1.735800
		loss: 1.735700
		loss: 1.735600
		loss: 1.735500
		loss: 1.735300
		loss: 1.735200
		loss: 1.735100
		loss: 1.735000
		loss: 1.734900
		loss: 1.734800
		loss: 1.734700
		loss: 1.734600
		loss: 1.734500
		loss: 1.734400
		loss: 1.734300
		loss: 1.734100
		loss: 1.734000
		loss: 1.733900
		loss: 1.733800
		loss: 1.733700
		loss: 1.733600
		loss: 1.733500
		loss: 1.733400
		loss: 1.733300
		loss: 1.733200
		loss: 1.733100
		loss: 1.733000
		loss: 1.732900
		loss: 1.732800
		loss: 1.732700
		loss: 1.732600
		loss: 1.732500
		loss: 1.732400
		loss: 1.732300
		loss: 1.732300
		loss: 1.732200
		loss: 1.732100
		loss: 1.732000
	Overall the loss development was 2.171600 -> 1.732000
problem epoch data for epoch 5, problem epoch 2
	sampling search time: 3.66080641746521s
	during this search the following actions were chosen:
	training time: 10.120396614074707s
	during the training the following losses were computed:
		loss: 1.727300
		loss: 1.727200
		loss: 1.727100
		loss: 1.727100
		loss: 1.727000
		loss: 1.726900
		loss: 1.726800
		loss: 1.726700
		loss: 1.726600
		loss: 1.726500
		loss: 1.726400
		loss: 1.726300
		loss: 1.726200
		loss: 1.726100
		loss: 1.726100
		loss: 1.726000
		loss: 1.725900
		loss: 1.725800
		loss: 1.725700
		loss: 1.725600
		loss: 1.725500
		loss: 1.725400
		loss: 1.725400
		loss: 1.725300
		loss: 1.725200
		loss: 1.725100
		loss: 1.725000
		loss: 1.724900
		loss: 1.724800
		loss: 1.724800
		loss: 1.724700
		loss: 1.724600
		loss: 1.724500
		loss: 1.724400
		loss: 1.724300
		loss: 1.724300
		loss: 1.724200
		loss: 1.724100
		loss: 1.724000
		loss: 1.723900
		loss: 1.723800
		loss: 1.723800
		loss: 1.723700
		loss: 1.723600
		loss: 1.723500
		loss: 1.723400
		loss: 1.723400
		loss: 1.723300
		loss: 1.723200
		loss: 1.723100
		loss: 1.723000
		loss: 1.723000
		loss: 1.722900
		loss: 1.722800
		loss: 1.722700
		loss: 1.722600
		loss: 1.722600
		loss: 1.722500
		loss: 1.722400
		loss: 1.722300
		loss: 1.722300
		loss: 1.722200
		loss: 1.722100
		loss: 1.722000
		loss: 1.722000
		loss: 1.721900
		loss: 1.721800
		loss: 1.721700
		loss: 1.721700
		loss: 1.721600
		loss: 1.721500
		loss: 1.721400
		loss: 1.721400
		loss: 1.721300
		loss: 1.721200
		loss: 1.721100
		loss: 1.721100
		loss: 1.721000
		loss: 1.720900
		loss: 1.720900
		loss: 1.720800
		loss: 1.720700
		loss: 1.720600
		loss: 1.720600
		loss: 1.720500
		loss: 1.720400
		loss: 1.720400
		loss: 1.720300
		loss: 1.720200
		loss: 1.720100
		loss: 1.720100
		loss: 1.720000
		loss: 1.719900
		loss: 1.719900
		loss: 1.719800
		loss: 1.719700
		loss: 1.719700
		loss: 1.719600
		loss: 1.719500
		loss: 1.719500
	Overall the loss development was 1.727300 -> 1.719500
problem epoch data for epoch 5, problem epoch 3
	sampling search time: 3.6837456226348877s
	during this search the following actions were chosen:
	training time: 10.113860845565796s
	during the training the following losses were computed:
		loss: 1.719400
		loss: 1.719300
		loss: 1.719300
		loss: 1.719200
		loss: 1.719100
		loss: 1.719100
		loss: 1.719000
		loss: 1.718900
		loss: 1.718900
		loss: 1.718800
		loss: 1.718700
		loss: 1.718700
		loss: 1.718600
		loss: 1.718500
		loss: 1.718500
		loss: 1.718400
		loss: 1.718300
		loss: 1.718300
		loss: 1.718200
		loss: 1.718100
		loss: 1.718100
		loss: 1.718000
		loss: 1.718000
		loss: 1.717900
		loss: 1.717800
		loss: 1.717800
		loss: 1.717700
		loss: 1.717600
		loss: 1.717600
		loss: 1.717500
		loss: 1.717500
		loss: 1.717400
		loss: 1.717300
		loss: 1.717300
		loss: 1.717200
		loss: 1.717100
		loss: 1.717100
		loss: 1.717000
		loss: 1.717000
		loss: 1.716900
		loss: 1.716800
		loss: 1.716800
		loss: 1.716700
		loss: 1.716700
		loss: 1.716600
		loss: 1.716500
		loss: 1.716500
		loss: 1.716400
		loss: 1.716400
		loss: 1.716300
		loss: 1.716200
		loss: 1.716200
		loss: 1.716100
		loss: 1.716100
		loss: 1.716000
		loss: 1.716000
		loss: 1.715900
		loss: 1.715800
		loss: 1.715800
		loss: 1.715700
		loss: 1.715700
		loss: 1.715600
		loss: 1.715600
		loss: 1.715500
		loss: 1.715400
		loss: 1.715400
		loss: 1.715300
		loss: 1.715300
		loss: 1.715200
		loss: 1.715200
		loss: 1.715100
		loss: 1.715100
		loss: 1.715000
		loss: 1.714900
		loss: 1.714900
		loss: 1.714800
		loss: 1.714800
		loss: 1.714700
		loss: 1.714700
		loss: 1.714600
		loss: 1.714600
		loss: 1.714500
		loss: 1.714500
		loss: 1.714400
		loss: 1.714300
		loss: 1.714300
		loss: 1.714200
		loss: 1.714200
		loss: 1.714100
		loss: 1.714100
		loss: 1.714000
		loss: 1.714000
		loss: 1.713900
		loss: 1.713900
		loss: 1.713800
		loss: 1.713800
		loss: 1.713700
		loss: 1.713700
		loss: 1.713600
		loss: 1.713600
	Overall the loss development was 1.719400 -> 1.713600
In the epoch 5 for problem d-01.pddl 3 explorations in the sampling searches reached a goal
Training data for problem d-02.pddl in epoch 5:
model creation time: 20.068697214126587s
problem epoch data for epoch 5, problem epoch 1
	sampling search time: 22.501497507095337s
	during this search the following actions were chosen:
	training time: 83.42641925811768s
	during the training the following losses were computed:
		loss: 4.430800
		loss: 4.490400
		loss: 4.065900
		loss: 4.050900
		loss: 4.330300
		loss: 3.917700
		loss: 3.262400
		loss: 3.792800
		loss: 3.695000
		loss: 3.687300
		loss: 3.342700
		loss: 3.629200
		loss: 4.040900
		loss: 3.594900
		loss: 4.013500
		loss: 3.540700
		loss: 3.550900
		loss: 3.501200
		loss: 3.295900
		loss: 3.485500
		loss: 4.002100
		loss: 3.480900
		loss: 3.489200
		loss: 3.488300
		loss: 3.299400
		loss: 3.477900
		loss: 3.502500
		loss: 3.457300
		loss: 3.603900
		loss: 3.442700
		loss: 3.565600
		loss: 3.439100
		loss: 3.296600
		loss: 3.432900
		loss: 3.807600
		loss: 3.429100
		loss: 3.860500
		loss: 3.423400
		loss: 3.371200
		loss: 3.417000
		loss: 3.346500
		loss: 3.410100
		loss: 3.928400
		loss: 3.408300
		loss: 3.440900
		loss: 3.406500
		loss: 3.184800
		loss: 3.403400
		loss: 2.889400
		loss: 3.400100
		loss: 2.926300
		loss: 3.396700
		loss: 4.148200
		loss: 3.393600
		loss: 3.481700
		loss: 3.391300
		loss: 3.161900
		loss: 3.389200
		loss: 3.984700
		loss: 3.387600
		loss: 2.753900
		loss: 3.386100
		loss: 2.976800
		loss: 3.383400
		loss: 3.798100
		loss: 3.381700
		loss: 3.194400
		loss: 3.380100
		loss: 3.916100
		loss: 3.378200
		loss: 3.451100
		loss: 3.376300
		loss: 3.563500
		loss: 3.374700
		loss: 3.143300
		loss: 3.373000
		loss: 3.450400
		loss: 3.371400
		loss: 3.110400
		loss: 3.369800
		loss: 3.478000
		loss: 3.368500
		loss: 3.067300
		loss: 3.367400
		loss: 3.486700
		loss: 3.365800
		loss: 3.283600
		loss: 3.364600
		loss: 3.295700
		loss: 3.362900
		loss: 3.664800
		loss: 3.362600
		loss: 3.525800
		loss: 3.360900
		loss: 3.161900
		loss: 3.359500
		loss: 3.017700
		loss: 3.358200
		loss: 3.369100
		loss: 3.357600
		loss: 3.415100
		loss: 3.356700
		loss: 3.174200
		loss: 3.355200
		loss: 3.824700
		loss: 3.354200
		loss: 3.422400
		loss: 3.353400
		loss: 3.335000
		loss: 3.352100
		loss: 3.234000
		loss: 3.351400
		loss: 3.192200
		loss: 3.350500
		loss: 3.284800
		loss: 3.350000
		loss: 2.999800
		loss: 3.349000
		loss: 3.617700
		loss: 3.348400
		loss: 3.617400
		loss: 3.347500
		loss: 3.732900
		loss: 3.346500
		loss: 3.528000
		loss: 3.345800
		loss: 3.455000
		loss: 3.345400
		loss: 3.115800
		loss: 3.345100
		loss: 3.059900
		loss: 3.344100
		loss: 3.051100
		loss: 3.343900
		loss: 2.950400
		loss: 3.342900
		loss: 2.730700
		loss: 3.342500
		loss: 3.510500
		loss: 3.341800
		loss: 3.425200
		loss: 3.341300
		loss: 3.444900
		loss: 3.340900
		loss: 3.694000
		loss: 3.340200
		loss: 3.594200
		loss: 3.339700
		loss: 2.629200
		loss: 3.339400
		loss: 3.993500
		loss: 3.338900
		loss: 3.037100
		loss: 3.338500
		loss: 3.000000
		loss: 3.338700
		loss: 3.413500
		loss: 3.338100
		loss: 3.174900
		loss: 3.338000
		loss: 3.857000
		loss: 3.337200
		loss: 2.884400
		loss: 3.337200
		loss: 2.834900
		loss: 3.337200
		loss: 3.406600
		loss: 3.336100
		loss: 2.992800
		loss: 3.336100
		loss: 3.248100
		loss: 3.336200
		loss: 3.895300
		loss: 3.335700
		loss: 2.839500
		loss: 3.335400
		loss: 3.053800
		loss: 3.335300
		loss: 3.424300
		loss: 3.335400
		loss: 3.380200
		loss: 3.334900
		loss: 3.799800
		loss: 3.334400
		loss: 3.757400
		loss: 3.334500
		loss: 3.328200
		loss: 3.334400
		loss: 3.636100
		loss: 3.334000
		loss: 3.445900
		loss: 3.333700
		loss: 3.591800
		loss: 3.333800
		loss: 3.193400
		loss: 3.333700
		loss: 3.347000
		loss: 3.333900
		loss: 3.909700
		loss: 3.333200
	Overall the loss development was 4.430800 -> 3.333200
problem epoch data for epoch 5, problem epoch 2
	sampling search time: 23.842586278915405s
	during this search the following actions were chosen:
	training time: 20.589457035064697s
	during the training the following losses were computed:
		loss: 2.858200
		loss: 3.320000
		loss: 3.591100
		loss: 3.318900
		loss: 3.642000
		loss: 3.318000
		loss: 3.465700
		loss: 3.317200
		loss: 3.023800
		loss: 3.317600
		loss: 3.329700
		loss: 3.316100
		loss: 3.641900
		loss: 3.317000
		loss: 3.528600
		loss: 3.315400
		loss: 3.291000
		loss: 3.315800
		loss: 3.153500
		loss: 3.314800
		loss: 3.096100
		loss: 3.314300
		loss: 3.433200
		loss: 3.316100
		loss: 3.036100
		loss: 3.314000
		loss: 3.078800
		loss: 3.316100
		loss: 3.267200
		loss: 3.315100
		loss: 3.111700
		loss: 3.314400
		loss: 2.986500
		loss: 3.316500
		loss: 3.533000
		loss: 3.314100
		loss: 3.787700
		loss: 3.312900
		loss: 3.389700
		loss: 3.314800
		loss: 2.670500
		loss: 3.317900
		loss: 3.184800
		loss: 3.315700
		loss: 3.263700
		loss: 3.315300
		loss: 3.407200
		loss: 3.314700
		loss: 3.264800
		loss: 3.314600
		loss: 3.665500
		loss: 3.313300
		loss: 3.301200
		loss: 3.314800
		loss: 3.229900
		loss: 3.314100
		loss: 3.385000
		loss: 3.314300
		loss: 3.752800
		loss: 3.312500
		loss: 3.534600
		loss: 3.313500
		loss: 3.270600
		loss: 3.313900
		loss: 3.492400
		loss: 3.315000
		loss: 3.554600
		loss: 3.315500
		loss: 3.135600
		loss: 3.315300
		loss: 3.278300
		loss: 3.314100
		loss: 3.543500
		loss: 3.315100
		loss: 3.580800
		loss: 3.315500
		loss: 3.264400
		loss: 3.314700
		loss: 3.153200
		loss: 3.315600
		loss: 3.053300
		loss: 3.313300
		loss: 3.333200
		loss: 3.313900
		loss: 3.407600
		loss: 3.315400
		loss: 3.111500
		loss: 3.315300
		loss: 3.513800
		loss: 3.312600
		loss: 3.599000
		loss: 3.312200
		loss: 3.268000
		loss: 3.313700
		loss: 3.565300
		loss: 3.315200
		loss: 3.342500
		loss: 3.314400
		loss: 3.255500
		loss: 3.313400
		loss: 3.415100
		loss: 3.312800
		loss: 2.965100
		loss: 3.315100
		loss: 3.330200
		loss: 3.313500
		loss: 3.445800
		loss: 3.312400
		loss: 3.645200
		loss: 3.314200
		loss: 3.349900
		loss: 3.312800
		loss: 3.159600
		loss: 3.313400
		loss: 3.278900
		loss: 3.312600
		loss: 3.170100
		loss: 3.311900
		loss: 3.327800
		loss: 3.312500
		loss: 3.919000
		loss: 3.315300
		loss: 3.539400
		loss: 3.313800
		loss: 3.327200
		loss: 3.312900
		loss: 3.517400
		loss: 3.312000
		loss: 3.394100
		loss: 3.312100
		loss: 3.001500
		loss: 3.314200
		loss: 3.056200
		loss: 3.312100
		loss: 3.100600
		loss: 3.312000
		loss: 3.042100
		loss: 3.311900
		loss: 3.708100
		loss: 3.310900
		loss: 3.441000
		loss: 3.313300
		loss: 2.816700
		loss: 3.310200
		loss: 3.813600
		loss: 3.310000
		loss: 3.205800
		loss: 3.311600
		loss: 3.816700
		loss: 3.314300
		loss: 2.725700
		loss: 3.314600
		loss: 3.452100
		loss: 3.312700
		loss: 2.815300
		loss: 3.314300
		loss: 3.335700
		loss: 3.311700
		loss: 3.302100
		loss: 3.311900
		loss: 3.030300
		loss: 3.313200
		loss: 3.215100
		loss: 3.312300
		loss: 3.319000
		loss: 3.311800
		loss: 3.152400
		loss: 3.312500
		loss: 3.156800
		loss: 3.311000
		loss: 3.566400
		loss: 3.312900
		loss: 3.219300
		loss: 3.312200
		loss: 3.292200
		loss: 3.311500
		loss: 3.217800
		loss: 3.312000
		loss: 3.263900
		loss: 3.311300
		loss: 3.426600
		loss: 3.310900
		loss: 3.178800
		loss: 3.312100
		loss: 3.402200
		loss: 3.311000
		loss: 3.087100
		loss: 3.312400
		loss: 3.219200
		loss: 3.311200
		loss: 3.044400
		loss: 3.312700
		loss: 3.336000
		loss: 3.311400
		loss: 3.104000
		loss: 3.312400
		loss: 3.336700
		loss: 3.312200
		loss: 3.123600
		loss: 3.313100
	Overall the loss development was 2.858200 -> 3.313100
problem epoch data for epoch 5, problem epoch 3
	sampling search time: 29.44860577583313s
	during this search the following actions were chosen:
	training time: 22.31396222114563s
	during the training the following losses were computed:
		loss: 4.042900
		loss: 3.430600
		loss: 3.111200
		loss: 3.430100
		loss: 3.415300
		loss: 3.430200
		loss: 3.113900
		loss: 3.430200
		loss: 3.563700
		loss: 3.428400
		loss: 3.092400
		loss: 3.428700
		loss: 3.567700
		loss: 3.428400
		loss: 3.231300
		loss: 3.427500
		loss: 3.469300
		loss: 3.427900
		loss: 3.607200
		loss: 3.427600
		loss: 3.532100
		loss: 3.427500
		loss: 3.392700
		loss: 3.427500
		loss: 3.120000
		loss: 3.427200
		loss: 3.430300
		loss: 3.426500
		loss: 3.601900
		loss: 3.426600
		loss: 3.664200
		loss: 3.426800
		loss: 3.362700
		loss: 3.426300
		loss: 3.239500
		loss: 3.426100
		loss: 3.060300
		loss: 3.426700
		loss: 2.816300
		loss: 3.426500
		loss: 3.710900
		loss: 3.426000
		loss: 3.465800
		loss: 3.426100
		loss: 3.253300
		loss: 3.425400
		loss: 3.421800
		loss: 3.425500
		loss: 3.536900
		loss: 3.425500
		loss: 3.396800
		loss: 3.425200
		loss: 3.565100
		loss: 3.425300
		loss: 3.893400
		loss: 3.425300
		loss: 3.306800
		loss: 3.424900
		loss: 3.455800
		loss: 3.425100
		loss: 3.371600
		loss: 3.425100
		loss: 3.664300
		loss: 3.425200
		loss: 3.360000
		loss: 3.425000
		loss: 3.528100
		loss: 3.425200
		loss: 3.612800
		loss: 3.424900
		loss: 2.872800
		loss: 3.425000
		loss: 3.573900
		loss: 3.424600
		loss: 3.074200
		loss: 3.425000
		loss: 3.685100
		loss: 3.424400
		loss: 3.446900
		loss: 3.424800
		loss: 3.255700
		loss: 3.424500
		loss: 3.113300
		loss: 3.424700
		loss: 3.344400
		loss: 3.424400
		loss: 3.398600
		loss: 3.424600
		loss: 3.558700
		loss: 3.424600
		loss: 3.136700
		loss: 3.424400
		loss: 3.471900
		loss: 3.424300
		loss: 3.356300
		loss: 3.424500
		loss: 3.524000
		loss: 3.424500
		loss: 3.181400
		loss: 3.424500
		loss: 3.999600
		loss: 3.424300
		loss: 3.446700
		loss: 3.424900
		loss: 3.186100
		loss: 3.424100
		loss: 3.704000
		loss: 3.424700
		loss: 3.636200
		loss: 3.424000
		loss: 3.487100
		loss: 3.423500
		loss: 3.550600
		loss: 3.423900
		loss: 3.898100
		loss: 3.424000
		loss: 3.257800
		loss: 3.423800
		loss: 2.932500
		loss: 3.423700
		loss: 3.516300
		loss: 3.423600
		loss: 3.304600
		loss: 3.423500
		loss: 3.503100
		loss: 3.423400
		loss: 3.414700
		loss: 3.423400
		loss: 3.088000
		loss: 3.423700
		loss: 3.684800
		loss: 3.423400
		loss: 3.178800
		loss: 3.423600
		loss: 3.318400
		loss: 3.423900
		loss: 3.415900
		loss: 3.424100
		loss: 3.543300
		loss: 3.423900
		loss: 3.453200
		loss: 3.423300
		loss: 3.356900
		loss: 3.423100
		loss: 3.578700
		loss: 3.422800
		loss: 3.408900
		loss: 3.423400
		loss: 3.319400
		loss: 3.423200
		loss: 3.709300
		loss: 3.423400
		loss: 3.205900
		loss: 3.422900
		loss: 3.348000
		loss: 3.423400
		loss: 3.378700
		loss: 3.423200
		loss: 3.769000
		loss: 3.422900
		loss: 3.594200
		loss: 3.422800
		loss: 3.489000
		loss: 3.423300
		loss: 3.519900
		loss: 3.422400
		loss: 3.413900
		loss: 3.422800
		loss: 3.078500
		loss: 3.422400
		loss: 3.632400
		loss: 3.422400
		loss: 3.299000
		loss: 3.422500
		loss: 3.307400
		loss: 3.422900
		loss: 3.595100
		loss: 3.422600
		loss: 3.161400
		loss: 3.422500
		loss: 3.073200
		loss: 3.422700
		loss: 3.592200
		loss: 3.422800
		loss: 3.480600
		loss: 3.422500
		loss: 3.804500
		loss: 3.422900
		loss: 3.117500
		loss: 3.422500
		loss: 4.018200
		loss: 3.422800
		loss: 3.614700
		loss: 3.423500
		loss: 3.775800
		loss: 3.422900
		loss: 3.414700
		loss: 3.423700
		loss: 3.314900
		loss: 3.423700
	Overall the loss development was 4.042900 -> 3.423700
In the epoch 5 for problem d-02.pddl 3 explorations in the sampling searches reached a goal
Success rate: 100

Epoch 6:
Training data for problem d-01.pddl in epoch 6:
model creation time: 10.997264385223389s
problem epoch data for epoch 6, problem epoch 1
	sampling search time: 5.363224506378174s
	during this search the following actions were chosen:
	training time: 47.8421847820282s
	during the training the following losses were computed:
		loss: 2.089600
		loss: 1.941800
		loss: 1.852300
		loss: 1.815800
		loss: 1.808000
		loss: 1.798600
		loss: 1.789300
		loss: 1.784200
		loss: 1.780400
		loss: 1.775400
		loss: 1.770900
		loss: 1.767100
		loss: 1.762600
		loss: 1.757600
		loss: 1.753600
		loss: 1.750800
		loss: 1.748300
		loss: 1.746100
		loss: 1.745600
		loss: 1.747000
		loss: 1.748400
		loss: 1.748100
		loss: 1.746300
		loss: 1.744300
		loss: 1.742600
		loss: 1.740900
		loss: 1.739200
		loss: 1.738000
		loss: 1.737100
		loss: 1.736600
		loss: 1.736500
		loss: 1.736900
		loss: 1.737400
		loss: 1.737400
		loss: 1.736900
		loss: 1.736500
		loss: 1.736100
		loss: 1.735800
		loss: 1.735300
		loss: 1.734900
		loss: 1.734500
		loss: 1.734300
		loss: 1.734100
		loss: 1.734000
		loss: 1.733800
		loss: 1.733700
		loss: 1.733600
		loss: 1.733500
		loss: 1.733400
		loss: 1.733200
		loss: 1.732900
		loss: 1.732700
		loss: 1.732500
		loss: 1.732400
		loss: 1.732300
		loss: 1.732200
		loss: 1.732100
		loss: 1.732000
		loss: 1.731900
		loss: 1.731800
		loss: 1.731600
		loss: 1.731500
		loss: 1.731400
		loss: 1.731300
		loss: 1.731200
		loss: 1.731000
		loss: 1.730900
		loss: 1.730800
		loss: 1.730700
		loss: 1.730700
		loss: 1.730500
		loss: 1.730400
		loss: 1.730300
		loss: 1.730200
		loss: 1.730100
		loss: 1.730000
		loss: 1.729900
		loss: 1.729800
		loss: 1.729700
		loss: 1.729600
		loss: 1.729500
		loss: 1.729400
		loss: 1.729300
		loss: 1.729200
		loss: 1.729100
		loss: 1.729000
		loss: 1.728900
		loss: 1.728800
		loss: 1.728700
		loss: 1.728600
		loss: 1.728600
		loss: 1.728500
		loss: 1.728400
		loss: 1.728300
		loss: 1.728200
		loss: 1.728100
		loss: 1.728000
		loss: 1.727900
		loss: 1.727800
		loss: 1.727700
	Overall the loss development was 2.089600 -> 1.727700
problem epoch data for epoch 6, problem epoch 2
	sampling search time: 3.341817855834961s
	during this search the following actions were chosen:
	training time: 10.112509489059448s
	during the training the following losses were computed:
		loss: 1.686600
		loss: 1.685800
		loss: 1.685400
		loss: 1.685400
		loss: 1.685500
		loss: 1.685300
		loss: 1.685000
		loss: 1.684700
		loss: 1.684600
		loss: 1.684500
		loss: 1.684400
		loss: 1.684200
		loss: 1.684000
		loss: 1.683900
		loss: 1.683700
		loss: 1.683700
		loss: 1.683500
		loss: 1.683300
		loss: 1.683200
		loss: 1.683100
		loss: 1.683000
		loss: 1.682900
		loss: 1.682800
		loss: 1.682600
		loss: 1.682500
		loss: 1.682400
		loss: 1.682300
		loss: 1.682300
		loss: 1.682200
		loss: 1.682100
		loss: 1.682000
		loss: 1.681900
		loss: 1.681800
		loss: 1.681700
		loss: 1.681600
		loss: 1.681500
		loss: 1.681400
		loss: 1.681400
		loss: 1.681300
		loss: 1.681200
		loss: 1.681100
		loss: 1.681000
		loss: 1.680900
		loss: 1.680900
		loss: 1.680800
		loss: 1.680700
		loss: 1.680600
		loss: 1.680500
		loss: 1.680500
		loss: 1.680400
		loss: 1.680300
		loss: 1.680200
		loss: 1.680200
		loss: 1.680100
		loss: 1.680000
		loss: 1.679900
		loss: 1.679900
		loss: 1.679800
		loss: 1.679700
		loss: 1.679700
		loss: 1.679600
		loss: 1.679500
		loss: 1.679400
		loss: 1.679400
		loss: 1.679300
		loss: 1.679200
		loss: 1.679100
		loss: 1.679100
		loss: 1.679000
		loss: 1.678900
		loss: 1.678900
		loss: 1.678800
		loss: 1.678700
		loss: 1.678700
		loss: 1.678600
		loss: 1.678500
		loss: 1.678400
		loss: 1.678400
		loss: 1.678300
		loss: 1.678200
		loss: 1.678200
		loss: 1.678100
		loss: 1.678000
		loss: 1.678000
		loss: 1.677900
		loss: 1.677800
		loss: 1.677800
		loss: 1.677700
		loss: 1.677600
		loss: 1.677600
		loss: 1.677500
		loss: 1.677400
		loss: 1.677400
		loss: 1.677300
		loss: 1.677300
		loss: 1.677200
		loss: 1.677100
		loss: 1.677100
		loss: 1.677000
		loss: 1.676900
	Overall the loss development was 1.686600 -> 1.676900
problem epoch data for epoch 6, problem epoch 3
	sampling search time: 3.430314064025879s
	during this search the following actions were chosen:
	training time: 10.110705614089966s
	during the training the following losses were computed:
		loss: 1.673600
		loss: 1.673500
		loss: 1.673500
		loss: 1.673400
		loss: 1.673300
		loss: 1.673300
		loss: 1.673200
		loss: 1.673100
		loss: 1.673100
		loss: 1.673000
		loss: 1.673000
		loss: 1.672900
		loss: 1.672800
		loss: 1.672800
		loss: 1.672700
		loss: 1.672700
		loss: 1.672600
		loss: 1.672500
		loss: 1.672500
		loss: 1.672400
		loss: 1.672400
		loss: 1.672300
		loss: 1.672200
		loss: 1.672200
		loss: 1.672100
		loss: 1.672100
		loss: 1.672000
		loss: 1.671900
		loss: 1.671900
		loss: 1.671800
		loss: 1.671800
		loss: 1.671700
		loss: 1.671700
		loss: 1.671600
		loss: 1.671500
		loss: 1.671500
		loss: 1.671400
		loss: 1.671400
		loss: 1.671300
		loss: 1.671300
		loss: 1.671200
		loss: 1.671100
		loss: 1.671100
		loss: 1.671000
		loss: 1.671000
		loss: 1.670900
		loss: 1.670900
		loss: 1.670800
		loss: 1.670800
		loss: 1.670700
		loss: 1.670600
		loss: 1.670600
		loss: 1.670500
		loss: 1.670500
		loss: 1.670400
		loss: 1.670400
		loss: 1.670300
		loss: 1.670300
		loss: 1.670200
		loss: 1.670200
		loss: 1.670100
		loss: 1.670100
		loss: 1.670000
		loss: 1.669900
		loss: 1.669900
		loss: 1.669800
		loss: 1.669800
		loss: 1.669700
		loss: 1.669700
		loss: 1.669600
		loss: 1.669600
		loss: 1.669500
		loss: 1.669500
		loss: 1.669400
		loss: 1.669400
		loss: 1.669300
		loss: 1.669300
		loss: 1.669200
		loss: 1.669200
		loss: 1.669100
		loss: 1.669100
		loss: 1.669000
		loss: 1.669000
		loss: 1.668900
		loss: 1.668900
		loss: 1.668800
		loss: 1.668800
		loss: 1.668700
		loss: 1.668700
		loss: 1.668600
		loss: 1.668600
		loss: 1.668500
		loss: 1.668500
		loss: 1.668400
		loss: 1.668400
		loss: 1.668300
		loss: 1.668300
		loss: 1.668200
		loss: 1.668200
		loss: 1.668100
	Overall the loss development was 1.673600 -> 1.668100
In the epoch 6 for problem d-01.pddl 3 explorations in the sampling searches reached a goal
Training data for problem d-02.pddl in epoch 6:
model creation time: 20.88202977180481s
problem epoch data for epoch 6, problem epoch 1
	sampling search time: 22.730576515197754s
	during this search the following actions were chosen:
	training time: 81.65343618392944s
	during the training the following losses were computed:
		loss: 4.791300
		loss: 4.476900
		loss: 3.684800
		loss: 4.095400
		loss: 3.698300
		loss: 4.024700
		loss: 4.301200
		loss: 3.893000
		loss: 3.963600
		loss: 3.839400
		loss: 3.446000
		loss: 3.821600
		loss: 3.364500
		loss: 3.751400
		loss: 4.057700
		loss: 3.704200
		loss: 3.281300
		loss: 3.696300
		loss: 3.746100
		loss: 3.672300
		loss: 3.834300
		loss: 3.663300
		loss: 3.380000
		loss: 3.659500
		loss: 3.446400
		loss: 3.643500
		loss: 3.315400
		loss: 3.629000
		loss: 3.449900
		loss: 3.620700
		loss: 3.183600
		loss: 3.615800
		loss: 3.885400
		loss: 3.608800
		loss: 4.153100
		loss: 3.607200
		loss: 4.000700
		loss: 3.601700
		loss: 3.231100
		loss: 3.588200
		loss: 3.908700
		loss: 3.588800
		loss: 3.454000
		loss: 3.586500
		loss: 3.463100
		loss: 3.582600
		loss: 3.870400
		loss: 3.577800
		loss: 3.930900
		loss: 3.578600
		loss: 3.340100
		loss: 3.574100
		loss: 3.448200
		loss: 3.569300
		loss: 3.685800
		loss: 3.567100
		loss: 3.384300
		loss: 3.564100
		loss: 3.950700
		loss: 3.565000
		loss: 3.706500
		loss: 3.559700
		loss: 3.190000
		loss: 3.560600
		loss: 2.842600
		loss: 3.552300
		loss: 4.114800
		loss: 3.551400
		loss: 3.733100
		loss: 3.553700
		loss: 3.586300
		loss: 3.550500
		loss: 3.177000
		loss: 3.547300
		loss: 3.327500
		loss: 3.549200
		loss: 3.725300
		loss: 3.545100
		loss: 3.567000
		loss: 3.544900
		loss: 2.841600
		loss: 3.547500
		loss: 3.365100
		loss: 3.540400
		loss: 3.105500
		loss: 3.542900
		loss: 3.338600
		loss: 3.540200
		loss: 4.235300
		loss: 3.541600
		loss: 4.042500
		loss: 3.533800
		loss: 3.171200
		loss: 3.533400
		loss: 3.682100
		loss: 3.535200
		loss: 3.682400
		loss: 3.532300
		loss: 3.123000
		loss: 3.529700
		loss: 3.530700
		loss: 3.531300
		loss: 3.971600
		loss: 3.527400
		loss: 3.937000
		loss: 3.531800
		loss: 3.718900
		loss: 3.527300
		loss: 3.792200
		loss: 3.528700
		loss: 3.037100
		loss: 3.524200
		loss: 3.696600
		loss: 3.524800
		loss: 3.376500
		loss: 3.525500
		loss: 3.805700
		loss: 3.522500
		loss: 3.525400
		loss: 3.523400
		loss: 3.709400
		loss: 3.521400
		loss: 3.498000
		loss: 3.522300
		loss: 3.279700
		loss: 3.522800
		loss: 3.720100
		loss: 3.519500
		loss: 3.008800
		loss: 3.522800
		loss: 3.668100
		loss: 3.518900
		loss: 4.019300
		loss: 3.521700
		loss: 3.575500
		loss: 3.518000
		loss: 3.547400
		loss: 3.517900
		loss: 3.591500
		loss: 3.517800
		loss: 3.768500
		loss: 3.518300
		loss: 3.915700
		loss: 3.518400
		loss: 3.198600
		loss: 3.513800
		loss: 3.801600
		loss: 3.516900
		loss: 2.953300
		loss: 3.518000
		loss: 4.330800
		loss: 3.519200
		loss: 3.019500
		loss: 3.511000
		loss: 3.068400
		loss: 3.511100
		loss: 3.260900
		loss: 3.511800
		loss: 3.727800
		loss: 3.511600
		loss: 3.579400
		loss: 3.512900
		loss: 3.571300
		loss: 3.512000
		loss: 3.649700
		loss: 3.511400
		loss: 3.483900
		loss: 3.511800
		loss: 3.708300
		loss: 3.510200
		loss: 3.714300
		loss: 3.509800
		loss: 3.696200
		loss: 3.509600
		loss: 3.756400
		loss: 3.511800
		loss: 3.226000
		loss: 3.508600
		loss: 3.653600
		loss: 3.509100
		loss: 3.206000
		loss: 3.507900
		loss: 3.842800
		loss: 3.511400
		loss: 3.473900
		loss: 3.509400
		loss: 3.671700
		loss: 3.508200
		loss: 3.667300
		loss: 3.509800
		loss: 3.278700
		loss: 3.510300
		loss: 3.122000
		loss: 3.510800
		loss: 3.568800
		loss: 3.508900
		loss: 3.649900
		loss: 3.509100
		loss: 2.809100
		loss: 3.504100
	Overall the loss development was 4.791300 -> 3.504100
problem epoch data for epoch 6, problem epoch 2
	sampling search time: 23.748239517211914s
	during this search the following actions were chosen:
	training time: 20.484463930130005s
	during the training the following losses were computed:
		loss: 3.778800
		loss: 3.475100
		loss: 3.182600
		loss: 3.474200
		loss: 3.489500
		loss: 3.473600
		loss: 3.491900
		loss: 3.473800
		loss: 3.427400
		loss: 3.472900
		loss: 3.220100
		loss: 3.472700
		loss: 3.082600
		loss: 3.472900
		loss: 3.585600
		loss: 3.472200
		loss: 3.362900
		loss: 3.471100
		loss: 3.710300
		loss: 3.471300
		loss: 3.366300
		loss: 3.471300
		loss: 3.515200
		loss: 3.471100
		loss: 2.684300
		loss: 3.470400
		loss: 2.821700
		loss: 3.470300
		loss: 3.559800
		loss: 3.470000
		loss: 3.673400
		loss: 3.469900
		loss: 3.271600
		loss: 3.469600
		loss: 3.117800
		loss: 3.469600
		loss: 3.523700
		loss: 3.469600
		loss: 3.015400
		loss: 3.469100
		loss: 3.821700
		loss: 3.469400
		loss: 3.504100
		loss: 3.469300
		loss: 3.678600
		loss: 3.468800
		loss: 3.427900
		loss: 3.469100
		loss: 3.166500
		loss: 3.469100
		loss: 3.622600
		loss: 3.468900
		loss: 3.365600
		loss: 3.468900
		loss: 3.513300
		loss: 3.468500
		loss: 3.185800
		loss: 3.468300
		loss: 3.362400
		loss: 3.468600
		loss: 3.360000
		loss: 3.468100
		loss: 3.310300
		loss: 3.467800
		loss: 3.424200
		loss: 3.467900
		loss: 3.174100
		loss: 3.468400
		loss: 3.489500
		loss: 3.468100
		loss: 3.993700
		loss: 3.467500
		loss: 3.414700
		loss: 3.467700
		loss: 3.339500
		loss: 3.468200
		loss: 3.104300
		loss: 3.468400
		loss: 3.484300
		loss: 3.467500
		loss: 3.116600
		loss: 3.467400
		loss: 3.386800
		loss: 3.467300
		loss: 3.283800
		loss: 3.468000
		loss: 3.414200
		loss: 3.467900
		loss: 3.115300
		loss: 3.467500
		loss: 3.347100
		loss: 3.468000
		loss: 3.502600
		loss: 3.467000
		loss: 3.116500
		loss: 3.466700
		loss: 3.317800
		loss: 3.467200
		loss: 3.966200
		loss: 3.466700
		loss: 4.028900
		loss: 3.466600
		loss: 3.387700
		loss: 3.466400
		loss: 3.284900
		loss: 3.466300
		loss: 3.653100
		loss: 3.466800
		loss: 3.800700
		loss: 3.466400
		loss: 3.637100
		loss: 3.466500
		loss: 2.802100
		loss: 3.466200
		loss: 3.021600
		loss: 3.466100
		loss: 3.764500
		loss: 3.466200
		loss: 3.317900
		loss: 3.466100
		loss: 3.636100
		loss: 3.465900
		loss: 3.055400
		loss: 3.465900
		loss: 3.390700
		loss: 3.465800
		loss: 3.502400
		loss: 3.465700
		loss: 3.526500
		loss: 3.465900
		loss: 3.260700
		loss: 3.466000
		loss: 4.062900
		loss: 3.466000
		loss: 3.297800
		loss: 3.466100
		loss: 3.454600
		loss: 3.466100
		loss: 3.480900
		loss: 3.466000
		loss: 2.814100
		loss: 3.465900
		loss: 3.925100
		loss: 3.465400
		loss: 4.092000
		loss: 3.466300
		loss: 3.918100
		loss: 3.466000
		loss: 3.948000
		loss: 3.466400
		loss: 3.183900
		loss: 3.466400
		loss: 3.600900
		loss: 3.467700
		loss: 3.246900
		loss: 3.467900
		loss: 3.844000
		loss: 3.466100
		loss: 3.401700
		loss: 3.465900
		loss: 3.626900
		loss: 3.465500
		loss: 3.890600
		loss: 3.466200
		loss: 3.511000
		loss: 3.465800
		loss: 3.038300
		loss: 3.465700
		loss: 3.400700
		loss: 3.465900
		loss: 3.393700
		loss: 3.465200
		loss: 3.259000
		loss: 3.464700
		loss: 3.857300
		loss: 3.465100
		loss: 3.428100
		loss: 3.465100
		loss: 3.957500
		loss: 3.465200
		loss: 3.742000
		loss: 3.465300
		loss: 3.991600
		loss: 3.464800
		loss: 3.514400
		loss: 3.464900
		loss: 2.868200
		loss: 3.465200
		loss: 3.046000
		loss: 3.464600
		loss: 3.595600
		loss: 3.464700
		loss: 3.373700
		loss: 3.464400
		loss: 3.668600
		loss: 3.464500
		loss: 3.082400
		loss: 3.464500
		loss: 3.260200
		loss: 3.464300
	Overall the loss development was 3.778800 -> 3.464300
problem epoch data for epoch 6, problem epoch 3
	sampling search time: 25.907776594161987s
	during this search the following actions were chosen:
	training time: 22.962015628814697s
	during the training the following losses were computed:
		loss: 4.084700
		loss: 3.669800
		loss: 3.729100
		loss: 3.666400
		loss: 3.937700
		loss: 3.665500
		loss: 3.419200
		loss: 3.666400
		loss: 3.893000
		loss: 3.663400
		loss: 3.479900
		loss: 3.666200
		loss: 3.103900
		loss: 3.660900
		loss: 3.988800
		loss: 3.662600
		loss: 3.829400
		loss: 3.663800
		loss: 3.754700
		loss: 3.662200
		loss: 3.792500
		loss: 3.661500
		loss: 3.134200
		loss: 3.663900
		loss: 3.622200
		loss: 3.661200
		loss: 3.778300
		loss: 3.661700
		loss: 3.627100
		loss: 3.661000
		loss: 3.682700
		loss: 3.661000
		loss: 3.625300
		loss: 3.660800
		loss: 3.561700
		loss: 3.660800
		loss: 2.991700
		loss: 3.657600
		loss: 4.016000
		loss: 3.661600
		loss: 3.557100
		loss: 3.661000
		loss: 3.482400
		loss: 3.661400
		loss: 4.285200
		loss: 3.657700
		loss: 3.660000
		loss: 3.659600
		loss: 3.689500
		loss: 3.659500
		loss: 3.853400
		loss: 3.659000
		loss: 3.454500
		loss: 3.658800
		loss: 3.205900
		loss: 3.661500
		loss: 3.777100
		loss: 3.659000
		loss: 3.887200
		loss: 3.658400
		loss: 3.261500
		loss: 3.661000
		loss: 3.972000
		loss: 3.660400
		loss: 3.229500
		loss: 3.661100
		loss: 3.533700
		loss: 3.659500
		loss: 3.564200
		loss: 3.659500
		loss: 3.151700
		loss: 3.656700
		loss: 3.191400
		loss: 3.660900
		loss: 3.274600
		loss: 3.657200
		loss: 3.558500
		loss: 3.659500
		loss: 3.742700
		loss: 3.658400
		loss: 3.621900
		loss: 3.658900
		loss: 4.128900
		loss: 3.660900
		loss: 3.265300
		loss: 3.660600
		loss: 3.469600
		loss: 3.659800
		loss: 4.054200
		loss: 3.657000
		loss: 4.331100
		loss: 3.661400
		loss: 3.406300
		loss: 3.659400
		loss: 3.374000
		loss: 3.660000
		loss: 3.484500
		loss: 3.659100
		loss: 3.700800
		loss: 3.658100
		loss: 3.731700
		loss: 3.658000
		loss: 3.580300
		loss: 3.658700
		loss: 3.768700
		loss: 3.657900
		loss: 4.030000
		loss: 3.659700
		loss: 3.373300
		loss: 3.657100
		loss: 3.621000
		loss: 3.658500
		loss: 3.546200
		loss: 3.658100
		loss: 3.537100
		loss: 3.658500
		loss: 4.046600
		loss: 3.660500
		loss: 3.922800
		loss: 3.659400
		loss: 3.877100
		loss: 3.659100
		loss: 4.223700
		loss: 3.660900
		loss: 3.883200
		loss: 3.657400
		loss: 3.370700
		loss: 3.659700
		loss: 3.488100
		loss: 3.659200
		loss: 3.918100
		loss: 3.657200
		loss: 3.533400
		loss: 3.657700
		loss: 3.800400
		loss: 3.659100
		loss: 3.809100
		loss: 3.659400
		loss: 3.306400
		loss: 3.659900
		loss: 3.759900
		loss: 3.658100
		loss: 3.236900
		loss: 3.659800
		loss: 3.497900
		loss: 3.659000
		loss: 3.570500
		loss: 3.657800
		loss: 3.686900
		loss: 3.658500
		loss: 4.068300
		loss: 3.660000
		loss: 3.305500
		loss: 3.660100
		loss: 3.569500
		loss: 3.659500
		loss: 3.329300
		loss: 3.657400
		loss: 3.758700
		loss: 3.658500
		loss: 3.925000
		loss: 3.659600
		loss: 3.342600
		loss: 3.659300
		loss: 3.626000
		loss: 3.657700
		loss: 3.949000
		loss: 3.656200
		loss: 3.364000
		loss: 3.658800
		loss: 3.802500
		loss: 3.657800
		loss: 4.019300
		loss: 3.656200
		loss: 4.306200
		loss: 3.655100
		loss: 3.709700
		loss: 3.657200
		loss: 3.429900
		loss: 3.658300
		loss: 3.954200
		loss: 3.658900
		loss: 3.739900
		loss: 3.658200
		loss: 3.633800
		loss: 3.657700
		loss: 3.274800
		loss: 3.659000
		loss: 3.471800
		loss: 3.656800
		loss: 3.647500
		loss: 3.657600
		loss: 3.825900
		loss: 3.656700
		loss: 3.600400
		loss: 3.657700
		loss: 3.336600
		loss: 3.658300
		loss: 3.502000
		loss: 3.658000
	Overall the loss development was 4.084700 -> 3.658000
In the epoch 6 for problem d-02.pddl 3 explorations in the sampling searches reached a goal
Success rate: 100

