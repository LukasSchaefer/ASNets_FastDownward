Training log data for domain tyreworld:
printing the data chronological
Epoch 1:
Training data for problem d-01.pddl in epoch 1:
model creation time: 13.019522428512573s
problem epoch data for epoch 1, problem epoch 1
	sampling search time: 3.1471736431121826s
	during this search the following actions were chosen:
	training time: 58.782602310180664s
	during the training the following losses were computed:
		loss: 3.711400
		loss: 3.516400
		loss: 3.360300
		loss: 3.238500
		loss: 3.146000
		loss: 3.079900
		loss: 3.028100
		loss: 2.988300
		loss: 2.955600
		loss: 2.926800
		loss: 2.899700
		loss: 2.873200
		loss: 2.847200
		loss: 2.821900
		loss: 2.797800
		loss: 2.774900
		loss: 2.753300
		loss: 2.732600
		loss: 2.711900
		loss: 2.690600
		loss: 2.668100
		loss: 2.644300
		loss: 2.619500
		loss: 2.594000
		loss: 2.568600
		loss: 2.543600
		loss: 2.519200
		loss: 2.495700
		loss: 2.472700
		loss: 2.450200
		loss: 2.427900
		loss: 2.405800
		loss: 2.383900
		loss: 2.362400
		loss: 2.341400
		loss: 2.320700
		loss: 2.300400
		loss: 2.280400
		loss: 2.260500
		loss: 2.240800
		loss: 2.221200
		loss: 2.201800
		loss: 2.182700
		loss: 2.163900
		loss: 2.145700
		loss: 2.127900
		loss: 2.110600
		loss: 2.093900
		loss: 2.077700
		loss: 2.062000
		loss: 2.047000
		loss: 2.032600
		loss: 2.018800
		loss: 2.005500
		loss: 1.992800
		loss: 1.980700
		loss: 1.969200
		loss: 1.958400
		loss: 1.948100
		loss: 1.938300
		loss: 1.929200
		loss: 1.920400
		loss: 1.912100
		loss: 1.904300
		loss: 1.896900
		loss: 1.889900
		loss: 1.883200
		loss: 1.876800
		loss: 1.870800
		loss: 1.865000
		loss: 1.859500
		loss: 1.854200
		loss: 1.849100
		loss: 1.844200
		loss: 1.839500
		loss: 1.835000
		loss: 1.830600
		loss: 1.826400
		loss: 1.822300
		loss: 1.818300
		loss: 1.814400
		loss: 1.810600
		loss: 1.806900
		loss: 1.803300
		loss: 1.799700
		loss: 1.796200
		loss: 1.792700
		loss: 1.789300
		loss: 1.786000
		loss: 1.782700
		loss: 1.779400
		loss: 1.776200
		loss: 1.773000
		loss: 1.769800
		loss: 1.766700
		loss: 1.763600
		loss: 1.760500
		loss: 1.757500
		loss: 1.754400
		loss: 1.751400
	Overall the loss development was 3.711400 -> 1.751400
problem epoch data for epoch 1, problem epoch 2
	sampling search time: 2.8710689544677734s
	during this search the following actions were chosen:
	training time: 10.107840061187744s
	during the training the following losses were computed:
		loss: 2.526800
		loss: 2.414100
		loss: 2.350700
		loss: 2.315500
		loss: 2.256600
		loss: 2.198900
		loss: 2.188400
		loss: 2.215500
		loss: 2.215900
		loss: 2.186900
		loss: 2.163600
		loss: 2.157800
		loss: 2.154800
		loss: 2.142500
		loss: 2.125000
		loss: 2.114300
		loss: 2.114100
		loss: 2.115000
		loss: 2.109000
		loss: 2.100600
		loss: 2.097600
		loss: 2.099500
		loss: 2.099700
		loss: 2.094800
		loss: 2.087300
		loss: 2.081700
		loss: 2.079200
		loss: 2.077100
		loss: 2.072900
		loss: 2.067600
		loss: 2.064000
		loss: 2.062500
		loss: 2.061400
		loss: 2.058900
		loss: 2.055300
		loss: 2.052000
		loss: 2.049600
		loss: 2.047500
		loss: 2.044700
		loss: 2.041400
		loss: 2.038600
		loss: 2.036600
		loss: 2.034800
		loss: 2.032500
		loss: 2.030000
		loss: 2.027600
		loss: 2.025700
		loss: 2.023700
		loss: 2.021300
		loss: 2.018800
		loss: 2.016600
		loss: 2.014700
		loss: 2.012800
		loss: 2.010700
		loss: 2.008500
		loss: 2.006500
		loss: 2.004600
		loss: 2.002700
		loss: 2.000600
		loss: 1.998500
		loss: 1.996600
		loss: 1.994700
		loss: 1.992800
		loss: 1.990800
		loss: 1.988800
		loss: 1.987000
		loss: 1.985100
		loss: 1.983200
		loss: 1.981200
		loss: 1.979400
		loss: 1.977600
		loss: 1.975700
		loss: 1.973900
		loss: 1.972000
		loss: 1.970200
		loss: 1.968400
		loss: 1.966600
		loss: 1.964700
		loss: 1.963000
		loss: 1.961200
		loss: 1.959400
		loss: 1.957600
		loss: 1.955900
		loss: 1.954100
		loss: 1.952400
		loss: 1.950600
		loss: 1.948900
		loss: 1.947200
		loss: 1.945400
		loss: 1.943700
		loss: 1.942000
		loss: 1.940300
		loss: 1.938600
		loss: 1.936900
		loss: 1.935300
		loss: 1.933600
		loss: 1.931900
		loss: 1.930300
		loss: 1.928600
		loss: 1.927000
	Overall the loss development was 2.526800 -> 1.927000
problem epoch data for epoch 1, problem epoch 3
	sampling search time: 3.2560997009277344s
	during this search the following actions were chosen:
	training time: 10.11786150932312s
	during the training the following losses were computed:
		loss: 2.434200
		loss: 2.396300
		loss: 2.368700
		loss: 2.358500
		loss: 2.343000
		loss: 2.320500
		loss: 2.301600
		loss: 2.286000
		loss: 2.272800
		loss: 2.265300
		loss: 2.260800
		loss: 2.253000
		loss: 2.243800
		loss: 2.240200
		loss: 2.241400
		loss: 2.241000
		loss: 2.237600
		loss: 2.234200
		loss: 2.231000
		loss: 2.227400
		loss: 2.224900
		loss: 2.223600
		loss: 2.221300
		loss: 2.217700
		loss: 2.214400
		loss: 2.212100
		loss: 2.209800
		loss: 2.207100
		loss: 2.204500
		loss: 2.202100
		loss: 2.199800
		loss: 2.197900
		loss: 2.196300
		loss: 2.194400
		loss: 2.192200
		loss: 2.190100
		loss: 2.188200
		loss: 2.186600
		loss: 2.185100
		loss: 2.183600
		loss: 2.181900
		loss: 2.180100
		loss: 2.178500
		loss: 2.176900
		loss: 2.175400
		loss: 2.173900
		loss: 2.172400
		loss: 2.170900
		loss: 2.169400
		loss: 2.168000
		loss: 2.166600
		loss: 2.165100
		loss: 2.163700
		loss: 2.162300
		loss: 2.160900
		loss: 2.159600
		loss: 2.158200
		loss: 2.156900
		loss: 2.155500
		loss: 2.154200
		loss: 2.152800
		loss: 2.151500
		loss: 2.150200
		loss: 2.148900
		loss: 2.147600
		loss: 2.146400
		loss: 2.145100
		loss: 2.143800
		loss: 2.142600
		loss: 2.141300
		loss: 2.140100
		loss: 2.138800
		loss: 2.137600
		loss: 2.136400
		loss: 2.135100
		loss: 2.133900
		loss: 2.132700
		loss: 2.131500
		loss: 2.130300
		loss: 2.129100
		loss: 2.128000
		loss: 2.126800
		loss: 2.125600
		loss: 2.124400
		loss: 2.123300
		loss: 2.122100
		loss: 2.121000
		loss: 2.119800
		loss: 2.118700
		loss: 2.117500
		loss: 2.116400
		loss: 2.115300
		loss: 2.114200
		loss: 2.113100
		loss: 2.111900
		loss: 2.110800
		loss: 2.109700
		loss: 2.108600
		loss: 2.107500
		loss: 2.106500
	Overall the loss development was 2.434200 -> 2.106500
In the epoch 1 for problem d-01.pddl 1 explorations in the sampling searches reached a goal
Training data for problem d-02.pddl in epoch 1:
model creation time: 26.592864513397217s
problem epoch data for epoch 1, problem epoch 1
	sampling search time: 16.811517238616943s
	during this search the following actions were chosen:
	training time: 111.0005431175232s
	during the training the following losses were computed:
		loss: 3.552300
		loss: 3.376800
		loss: 3.297100
		loss: 3.253300
		loss: 3.238000
		loss: 3.226900
		loss: 3.206300
		loss: 3.181000
		loss: 3.160100
		loss: 3.149400
		loss: 3.146700
		loss: 3.144300
		loss: 3.137900
		loss: 3.128800
		loss: 3.119300
		loss: 3.110000
		loss: 3.100900
		loss: 3.092500
		loss: 3.086000
		loss: 3.081500
		loss: 3.077900
		loss: 3.073500
		loss: 3.068100
		loss: 3.062600
		loss: 3.058000
		loss: 3.054200
		loss: 3.050500
		loss: 3.046300
		loss: 3.042300
		loss: 3.038800
		loss: 3.035600
		loss: 3.032200
		loss: 3.028700
		loss: 3.025100
		loss: 3.021900
		loss: 3.018900
		loss: 3.016000
		loss: 3.013300
		loss: 3.010800
		loss: 3.008400
		loss: 3.006100
		loss: 3.003700
		loss: 3.001200
		loss: 2.998900
		loss: 2.996900
		loss: 2.995000
		loss: 2.992800
		loss: 2.990600
		loss: 2.988600
		loss: 2.986700
		loss: 2.984900
		loss: 2.983100
		loss: 2.981300
		loss: 2.979600
		loss: 2.977800
		loss: 2.976000
		loss: 2.974300
		loss: 2.972700
		loss: 2.971200
		loss: 2.969600
		loss: 2.968100
		loss: 2.966600
		loss: 2.965100
		loss: 2.963700
		loss: 2.962300
		loss: 2.960800
		loss: 2.959400
		loss: 2.958000
		loss: 2.956700
		loss: 2.955400
		loss: 2.954100
		loss: 2.952800
		loss: 2.951500
		loss: 2.950200
		loss: 2.949000
		loss: 2.947800
		loss: 2.946600
		loss: 2.945300
		loss: 2.944100
		loss: 2.943000
		loss: 2.941800
		loss: 2.940600
		loss: 2.939500
		loss: 2.938400
		loss: 2.937200
		loss: 2.936100
		loss: 2.935000
		loss: 2.933900
		loss: 2.932800
		loss: 2.931800
		loss: 2.930700
		loss: 2.929700
		loss: 2.928600
		loss: 2.927600
		loss: 2.926600
		loss: 2.925500
		loss: 2.924500
		loss: 2.923500
		loss: 2.922500
		loss: 2.921500
	Overall the loss development was 3.552300 -> 2.921500
problem epoch data for epoch 1, problem epoch 2
	sampling search time: 16.710270166397095s
	during this search the following actions were chosen:
	training time: 18.039549827575684s
	during the training the following losses were computed:
		loss: 3.143500
		loss: 3.160800
		loss: 3.004200
		loss: 3.136000
		loss: 3.223200
		loss: 3.115400
		loss: 3.542400
		loss: 3.102300
		loss: 2.864200
		loss: 3.090300
		loss: 3.087300
		loss: 3.083000
		loss: 2.763700
		loss: 3.079700
		loss: 2.655700
		loss: 3.077000
		loss: 2.904300
		loss: 3.074700
		loss: 2.792800
		loss: 3.071900
		loss: 2.726100
		loss: 3.068900
		loss: 3.010600
		loss: 3.066300
		loss: 3.020500
		loss: 3.063400
		loss: 2.542600
		loss: 3.061000
		loss: 2.672200
		loss: 3.058600
		loss: 3.402100
		loss: 3.056000
		loss: 3.455100
		loss: 3.053600
		loss: 3.394700
		loss: 3.051800
		loss: 2.920300
		loss: 3.050400
		loss: 2.807200
		loss: 3.048000
		loss: 2.984100
		loss: 3.047200
		loss: 3.252900
		loss: 3.045700
		loss: 3.319300
		loss: 3.044100
		loss: 2.872700
		loss: 3.042000
		loss: 3.187100
		loss: 3.040400
		loss: 3.066400
		loss: 3.039300
		loss: 3.241400
		loss: 3.037900
		loss: 3.076200
		loss: 3.035600
		loss: 3.135900
		loss: 3.035300
		loss: 2.744800
		loss: 3.033600
		loss: 2.958700
		loss: 3.031800
		loss: 2.854200
		loss: 3.030700
		loss: 2.805800
		loss: 3.028900
		loss: 2.924000
		loss: 3.027700
		loss: 2.970000
		loss: 3.026600
		loss: 3.082900
		loss: 3.025100
		loss: 3.071300
		loss: 3.023600
		loss: 2.881700
		loss: 3.022600
		loss: 3.186100
		loss: 3.021300
		loss: 3.116000
		loss: 3.020000
		loss: 3.388200
		loss: 3.018800
		loss: 2.736800
		loss: 3.017500
		loss: 2.899300
		loss: 3.016600
		loss: 3.332800
		loss: 3.015100
		loss: 2.909200
		loss: 3.014000
		loss: 2.828900
		loss: 3.012900
		loss: 2.858600
		loss: 3.011800
		loss: 3.351300
		loss: 3.010700
		loss: 3.122400
		loss: 3.009600
		loss: 3.008900
		loss: 3.008400
		loss: 2.803500
		loss: 3.007500
		loss: 2.765700
		loss: 3.006400
		loss: 2.893700
		loss: 3.005200
		loss: 3.421600
		loss: 3.004300
		loss: 3.137400
		loss: 3.003100
		loss: 3.121600
		loss: 3.002000
		loss: 2.649700
		loss: 3.001000
		loss: 3.186500
		loss: 2.999900
		loss: 2.837600
		loss: 2.998900
		loss: 2.851100
		loss: 2.997900
		loss: 2.812900
		loss: 2.996900
		loss: 3.041800
		loss: 2.995800
		loss: 2.872300
		loss: 2.994800
		loss: 2.725500
		loss: 2.994000
		loss: 2.734200
		loss: 2.993400
		loss: 2.818000
		loss: 2.992200
		loss: 3.152100
		loss: 2.991200
		loss: 2.671600
		loss: 2.990700
		loss: 2.764100
		loss: 2.989500
		loss: 2.652100
		loss: 2.988100
		loss: 3.112700
		loss: 2.987300
		loss: 3.212400
		loss: 2.986500
		loss: 2.913000
		loss: 2.985600
		loss: 3.505900
		loss: 2.984400
		loss: 3.198800
		loss: 2.983500
		loss: 3.422100
		loss: 2.982500
		loss: 2.974200
		loss: 2.981800
		loss: 2.917100
		loss: 2.981300
		loss: 3.020700
		loss: 2.979800
		loss: 3.088000
		loss: 2.979000
		loss: 3.087500
		loss: 2.978100
		loss: 2.799700
		loss: 2.977000
		loss: 2.806000
		loss: 2.976500
		loss: 2.956300
		loss: 2.975800
		loss: 3.078900
		loss: 2.974800
		loss: 2.743200
		loss: 2.973800
		loss: 2.564300
		loss: 2.973200
		loss: 3.287900
		loss: 2.972100
		loss: 3.096500
		loss: 2.971500
		loss: 2.885900
		loss: 2.970600
		loss: 3.028300
		loss: 2.969900
		loss: 3.097700
		loss: 2.968900
		loss: 3.178900
		loss: 2.968100
		loss: 3.031100
		loss: 2.967300
		loss: 3.401800
		loss: 2.966300
		loss: 3.073800
		loss: 2.965600
		loss: 2.816300
		loss: 2.964800
		loss: 2.781800
		loss: 2.964100
		loss: 3.093100
		loss: 2.963100
		loss: 3.273400
		loss: 2.962500
	Overall the loss development was 3.143500 -> 2.962500
problem epoch data for epoch 1, problem epoch 3
	sampling search time: 16.120423316955566s
	during this search the following actions were chosen:
	training time: 19.265711545944214s
	during the training the following losses were computed:
		loss: 2.768400
		loss: 2.908000
		loss: 2.964200
		loss: 2.907700
		loss: 2.648800
		loss: 2.905500
		loss: 2.838100
		loss: 2.906700
		loss: 3.042100
		loss: 2.904200
		loss: 2.651500
		loss: 2.903200
		loss: 2.717200
		loss: 2.902500
		loss: 2.520600
		loss: 2.901300
		loss: 2.906600
		loss: 2.902300
		loss: 2.838900
		loss: 2.900800
		loss: 2.886700
		loss: 2.899800
		loss: 2.755700
		loss: 2.899800
		loss: 2.709900
		loss: 2.897000
		loss: 2.915900
		loss: 2.897200
		loss: 2.718400
		loss: 2.897700
		loss: 3.176300
		loss: 2.894200
		loss: 2.804200
		loss: 2.894500
		loss: 2.786100
		loss: 2.893700
		loss: 2.915000
		loss: 2.893600
		loss: 3.078700
		loss: 2.891800
		loss: 2.803300
		loss: 2.892800
		loss: 2.888500
		loss: 2.891400
		loss: 2.809000
		loss: 2.890500
		loss: 2.902800
		loss: 2.890300
		loss: 3.284000
		loss: 2.891900
		loss: 2.932700
		loss: 2.888500
		loss: 2.801900
		loss: 2.888600
		loss: 3.140100
		loss: 2.888900
		loss: 2.767800
		loss: 2.886200
		loss: 2.745000
		loss: 2.885500
		loss: 2.989900
		loss: 2.885000
		loss: 3.117100
		loss: 2.883700
		loss: 2.898700
		loss: 2.884400
		loss: 2.523200
		loss: 2.885900
		loss: 3.107200
		loss: 2.881900
		loss: 2.641700
		loss: 2.881200
		loss: 2.779700
		loss: 2.882500
		loss: 2.774700
		loss: 2.882100
		loss: 2.756500
		loss: 2.880000
		loss: 2.975100
		loss: 2.880700
		loss: 2.369400
		loss: 2.882500
		loss: 2.576000
		loss: 2.880700
		loss: 2.920200
		loss: 2.878600
		loss: 3.139300
		loss: 2.876400
		loss: 2.944000
		loss: 2.877100
		loss: 2.779500
		loss: 2.877500
		loss: 3.048700
		loss: 2.875500
		loss: 2.690000
		loss: 2.876900
		loss: 3.143400
		loss: 2.874000
		loss: 2.770700
		loss: 2.874600
		loss: 3.296400
		loss: 2.872300
		loss: 3.041200
		loss: 2.873300
		loss: 2.533300
		loss: 2.871800
		loss: 2.893300
		loss: 2.872900
		loss: 2.635900
		loss: 2.873400
		loss: 3.130500
		loss: 2.870000
		loss: 2.969200
		loss: 2.871600
		loss: 2.916700
		loss: 2.870800
		loss: 2.645800
		loss: 2.871500
		loss: 2.821500
		loss: 2.869600
		loss: 3.158400
		loss: 2.867600
		loss: 3.027900
		loss: 2.867500
		loss: 2.733400
		loss: 2.868900
		loss: 2.575100
		loss: 2.866100
		loss: 2.983500
		loss: 2.867600
		loss: 2.879600
		loss: 2.866500
		loss: 3.095600
		loss: 2.867100
		loss: 3.035400
		loss: 2.866200
		loss: 2.627800
		loss: 2.863600
		loss: 3.223500
		loss: 2.866400
		loss: 2.886700
		loss: 2.863800
		loss: 3.168400
		loss: 2.865100
		loss: 2.703600
		loss: 2.863700
		loss: 2.996800
		loss: 2.863200
		loss: 2.884800
		loss: 2.862200
		loss: 3.045300
		loss: 2.860600
		loss: 2.784200
		loss: 2.860800
		loss: 2.921600
		loss: 2.860400
		loss: 2.705800
		loss: 2.859300
		loss: 2.825800
		loss: 2.860000
		loss: 2.963400
		loss: 2.859000
		loss: 2.779100
		loss: 2.859600
		loss: 2.752000
		loss: 2.857900
		loss: 2.488000
		loss: 2.860000
		loss: 2.831800
		loss: 2.857600
		loss: 3.071000
		loss: 2.855900
		loss: 2.471900
		loss: 2.858800
		loss: 3.146900
		loss: 2.854200
		loss: 2.460200
		loss: 2.857800
		loss: 2.555500
		loss: 2.856800
		loss: 2.799800
		loss: 2.855000
		loss: 2.686500
		loss: 2.853300
		loss: 2.875700
		loss: 2.853800
		loss: 2.451700
		loss: 2.855900
		loss: 2.549200
		loss: 2.854800
		loss: 3.063400
		loss: 2.851400
		loss: 3.011300
		loss: 2.853200
		loss: 2.730800
		loss: 2.851200
		loss: 2.683800
		loss: 2.852500
		loss: 3.198200
		loss: 2.849100
	Overall the loss development was 2.768400 -> 2.849100
In the epoch 1 for problem d-02.pddl 3 explorations in the sampling searches reached a goal
Success rate: 66

Epoch 2:
Training data for problem d-01.pddl in epoch 2:
model creation time: 15.503982067108154s
problem epoch data for epoch 2, problem epoch 1
	sampling search time: 4.663725852966309s
	during this search the following actions were chosen:
	training time: 60.23709416389465s
	during the training the following losses were computed:
		loss: 1.523800
		loss: 1.481100
		loss: 1.469800
		loss: 1.440600
		loss: 1.429700
		loss: 1.431900
		loss: 1.430400
		loss: 1.424900
		loss: 1.421400
		loss: 1.421900
		loss: 1.423700
		loss: 1.422300
		loss: 1.417800
		loss: 1.414000
		loss: 1.413400
		loss: 1.414400
		loss: 1.413500
		loss: 1.410800
		loss: 1.409000
		loss: 1.409500
		loss: 1.410800
		loss: 1.410800
		loss: 1.409600
		loss: 1.408300
		loss: 1.407800
		loss: 1.407900
		loss: 1.407900
		loss: 1.407000
		loss: 1.405700
		loss: 1.404700
		loss: 1.404500
		loss: 1.404800
		loss: 1.404700
		loss: 1.404100
		loss: 1.403800
		loss: 1.403700
		loss: 1.403500
		loss: 1.403100
		loss: 1.402600
		loss: 1.402100
		loss: 1.401700
		loss: 1.401500
		loss: 1.401300
		loss: 1.401000
		loss: 1.400700
		loss: 1.400500
		loss: 1.400300
		loss: 1.400000
		loss: 1.399700
		loss: 1.399500
		loss: 1.399300
		loss: 1.399000
		loss: 1.398700
		loss: 1.398400
		loss: 1.398200
		loss: 1.398000
		loss: 1.397800
		loss: 1.397500
		loss: 1.397300
		loss: 1.397000
		loss: 1.396800
		loss: 1.396600
		loss: 1.396300
		loss: 1.396100
		loss: 1.395900
		loss: 1.395600
		loss: 1.395400
		loss: 1.395200
		loss: 1.394900
		loss: 1.394700
		loss: 1.394500
		loss: 1.394300
		loss: 1.394000
		loss: 1.393800
		loss: 1.393600
		loss: 1.393400
		loss: 1.393100
		loss: 1.392900
		loss: 1.392700
		loss: 1.392500
		loss: 1.392300
		loss: 1.392100
		loss: 1.391800
		loss: 1.391600
		loss: 1.391400
		loss: 1.391200
		loss: 1.391000
		loss: 1.390700
		loss: 1.390500
		loss: 1.390300
		loss: 1.390100
		loss: 1.389900
		loss: 1.389700
		loss: 1.389500
		loss: 1.389300
		loss: 1.389000
		loss: 1.388800
		loss: 1.388600
		loss: 1.388400
		loss: 1.388200
	Overall the loss development was 1.523800 -> 1.388200
problem epoch data for epoch 2, problem epoch 2
	sampling search time: 4.71060848236084s
	during this search the following actions were chosen:
	training time: 10.337331056594849s
	during the training the following losses were computed:
		loss: 1.559300
		loss: 1.559100
		loss: 1.558900
		loss: 1.558700
		loss: 1.558500
		loss: 1.558300
		loss: 1.558100
		loss: 1.557900
		loss: 1.557700
		loss: 1.557500
		loss: 1.557300
		loss: 1.557100
		loss: 1.556900
		loss: 1.556700
		loss: 1.556500
		loss: 1.556300
		loss: 1.556100
		loss: 1.555900
		loss: 1.555700
		loss: 1.555500
		loss: 1.555300
		loss: 1.555100
		loss: 1.554900
		loss: 1.554700
		loss: 1.554500
		loss: 1.554300
		loss: 1.554100
		loss: 1.553900
		loss: 1.553700
		loss: 1.553500
		loss: 1.553300
		loss: 1.553100
		loss: 1.552900
		loss: 1.552700
		loss: 1.552500
		loss: 1.552400
		loss: 1.552200
		loss: 1.552000
		loss: 1.551800
		loss: 1.551600
		loss: 1.551400
		loss: 1.551200
		loss: 1.551000
		loss: 1.550900
		loss: 1.550700
		loss: 1.550500
		loss: 1.550300
		loss: 1.550100
		loss: 1.549900
		loss: 1.549800
		loss: 1.549600
		loss: 1.549400
		loss: 1.549200
		loss: 1.549000
		loss: 1.548900
		loss: 1.548700
		loss: 1.548500
		loss: 1.548300
		loss: 1.548100
		loss: 1.548000
		loss: 1.547800
		loss: 1.547600
		loss: 1.547400
		loss: 1.547300
		loss: 1.547100
		loss: 1.546900
		loss: 1.546800
		loss: 1.546600
		loss: 1.546400
		loss: 1.546200
		loss: 1.546100
		loss: 1.545900
		loss: 1.545700
		loss: 1.545600
		loss: 1.545400
		loss: 1.545200
		loss: 1.545000
		loss: 1.544900
		loss: 1.544700
		loss: 1.544500
		loss: 1.544400
		loss: 1.544200
		loss: 1.544000
		loss: 1.543900
		loss: 1.543700
		loss: 1.543500
		loss: 1.543400
		loss: 1.543200
		loss: 1.543100
		loss: 1.542900
		loss: 1.542700
		loss: 1.542600
		loss: 1.542400
		loss: 1.542300
		loss: 1.542100
		loss: 1.541900
		loss: 1.541800
		loss: 1.541600
		loss: 1.541500
		loss: 1.541300
	Overall the loss development was 1.559300 -> 1.541300
problem epoch data for epoch 2, problem epoch 3
	sampling search time: 4.809175968170166s
	during this search the following actions were chosen:
	training time: 10.326159238815308s
	during the training the following losses were computed:
		loss: 1.599300
		loss: 1.599200
		loss: 1.599000
		loss: 1.598900
		loss: 1.598700
		loss: 1.598500
		loss: 1.598400
		loss: 1.598200
		loss: 1.598100
		loss: 1.597900
		loss: 1.597800
		loss: 1.597600
		loss: 1.597500
		loss: 1.597300
		loss: 1.597100
		loss: 1.597000
		loss: 1.596800
		loss: 1.596700
		loss: 1.596500
		loss: 1.596400
		loss: 1.596200
		loss: 1.596100
		loss: 1.595900
		loss: 1.595800
		loss: 1.595600
		loss: 1.595500
		loss: 1.595300
		loss: 1.595200
		loss: 1.595100
		loss: 1.594900
		loss: 1.594800
		loss: 1.594600
		loss: 1.594500
		loss: 1.594300
		loss: 1.594200
		loss: 1.594000
		loss: 1.593900
		loss: 1.593800
		loss: 1.593600
		loss: 1.593500
		loss: 1.593300
		loss: 1.593200
		loss: 1.593100
		loss: 1.592900
		loss: 1.592800
		loss: 1.592600
		loss: 1.592500
		loss: 1.592400
		loss: 1.592200
		loss: 1.592100
		loss: 1.592000
		loss: 1.591800
		loss: 1.591700
		loss: 1.591600
		loss: 1.591400
		loss: 1.591300
		loss: 1.591100
		loss: 1.591000
		loss: 1.590900
		loss: 1.590700
		loss: 1.590600
		loss: 1.590500
		loss: 1.590300
		loss: 1.590200
		loss: 1.590100
		loss: 1.590000
		loss: 1.589800
		loss: 1.589700
		loss: 1.589600
		loss: 1.589400
		loss: 1.589300
		loss: 1.589200
		loss: 1.589000
		loss: 1.588900
		loss: 1.588800
		loss: 1.588700
		loss: 1.588500
		loss: 1.588400
		loss: 1.588300
		loss: 1.588200
		loss: 1.588000
		loss: 1.587900
		loss: 1.587800
		loss: 1.587700
		loss: 1.587500
		loss: 1.587400
		loss: 1.587300
		loss: 1.587200
		loss: 1.587000
		loss: 1.586900
		loss: 1.586800
		loss: 1.586700
		loss: 1.586500
		loss: 1.586400
		loss: 1.586300
		loss: 1.586200
		loss: 1.586100
		loss: 1.585900
		loss: 1.585800
		loss: 1.585700
	Overall the loss development was 1.599300 -> 1.585700
In the epoch 2 for problem d-01.pddl 3 explorations in the sampling searches reached a goal
Training data for problem d-02.pddl in epoch 2:
model creation time: 29.998703718185425s
problem epoch data for epoch 2, problem epoch 1
	sampling search time: 11.805310010910034s
	during this search the following actions were chosen:
	training time: 75.9828188419342s
	during the training the following losses were computed:
		loss: 3.117400
		loss: 2.964100
		loss: 2.945800
		loss: 2.919900
		loss: 2.884700
		loss: 2.867600
		loss: 2.869500
		loss: 2.873300
		loss: 2.867400
		loss: 2.853700
		loss: 2.840900
		loss: 2.834900
		loss: 2.835200
		loss: 2.836700
		loss: 2.835000
		loss: 2.830500
		loss: 2.826300
		loss: 2.824500
		loss: 2.824300
		loss: 2.823100
		loss: 2.819800
		loss: 2.815700
		loss: 2.812800
		loss: 2.812400
		loss: 2.813300
		loss: 2.813600
		loss: 2.812500
		loss: 2.810600
		loss: 2.808900
		loss: 2.807600
		loss: 2.806500
		loss: 2.805000
		loss: 2.803200
		loss: 2.801700
		loss: 2.800900
		loss: 2.800700
		loss: 2.800500
		loss: 2.799900
		loss: 2.798900
		loss: 2.797800
		loss: 2.797000
		loss: 2.796500
		loss: 2.795900
		loss: 2.795100
		loss: 2.794400
		loss: 2.793800
		loss: 2.793300
		loss: 2.792700
		loss: 2.791900
		loss: 2.791100
		loss: 2.790600
		loss: 2.790100
		loss: 2.789600
		loss: 2.789100
		loss: 2.788500
		loss: 2.787900
		loss: 2.787400
		loss: 2.786800
		loss: 2.786300
		loss: 2.785800
		loss: 2.785300
		loss: 2.784900
		loss: 2.784500
		loss: 2.784000
		loss: 2.783600
		loss: 2.783100
		loss: 2.782700
		loss: 2.782300
		loss: 2.781900
		loss: 2.781500
		loss: 2.781200
		loss: 2.780800
		loss: 2.780400
		loss: 2.780100
		loss: 2.779800
		loss: 2.779500
		loss: 2.779100
		loss: 2.778800
		loss: 2.778600
		loss: 2.778300
		loss: 2.778000
		loss: 2.777800
		loss: 2.777500
		loss: 2.777300
		loss: 2.777000
		loss: 2.776800
		loss: 2.776600
		loss: 2.776400
		loss: 2.776200
		loss: 2.776000
		loss: 2.775800
		loss: 2.775700
		loss: 2.775500
		loss: 2.775300
		loss: 2.775200
		loss: 2.775000
		loss: 2.774900
		loss: 2.774800
		loss: 2.774600
		loss: 2.774500
	Overall the loss development was 3.117400 -> 2.774500
problem epoch data for epoch 2, problem epoch 2
	sampling search time: 12.204615116119385s
	during this search the following actions were chosen:
	training time: 20.285443544387817s
	during the training the following losses were computed:
		loss: 2.376200
		loss: 2.796800
		loss: 2.825400
		loss: 2.795100
		loss: 2.779500
		loss: 2.794400
		loss: 2.639600
		loss: 2.793400
		loss: 2.443400
		loss: 2.793200
		loss: 2.860700
		loss: 2.792600
		loss: 2.571000
		loss: 2.791600
		loss: 2.949500
		loss: 2.791300
		loss: 2.985600
		loss: 2.790600
		loss: 2.515800
		loss: 2.790300
		loss: 2.801700
		loss: 2.790000
		loss: 2.771300
		loss: 2.789400
		loss: 2.602900
		loss: 2.789300
		loss: 2.817300
		loss: 2.789200
		loss: 2.774600
		loss: 2.788700
		loss: 2.688000
		loss: 2.788700
		loss: 2.784000
		loss: 2.788400
		loss: 2.838000
		loss: 2.788100
		loss: 3.161600
		loss: 2.788000
		loss: 2.909600
		loss: 2.788000
		loss: 2.564500
		loss: 2.787700
		loss: 2.878900
		loss: 2.787200
		loss: 2.364800
		loss: 2.787200
		loss: 2.573400
		loss: 2.787100
		loss: 2.880700
		loss: 2.786700
		loss: 2.606200
		loss: 2.786600
		loss: 2.865300
		loss: 2.786500
		loss: 2.845100
		loss: 2.786200
		loss: 2.992500
		loss: 2.786300
		loss: 2.766400
		loss: 2.785900
		loss: 2.837000
		loss: 2.785700
		loss: 2.616200
		loss: 2.785500
		loss: 2.381500
		loss: 2.785300
		loss: 2.779300
		loss: 2.785100
		loss: 2.720300
		loss: 2.784900
		loss: 3.175500
		loss: 2.784700
		loss: 2.874200
		loss: 2.784800
		loss: 2.681000
		loss: 2.784500
		loss: 2.522800
		loss: 2.784500
		loss: 2.814700
		loss: 2.784400
		loss: 3.384900
		loss: 2.784300
		loss: 2.851100
		loss: 2.784000
		loss: 2.826100
		loss: 2.783900
		loss: 2.822800
		loss: 2.783800
		loss: 3.226100
		loss: 2.783600
		loss: 2.833500
		loss: 2.783400
		loss: 2.882200
		loss: 2.783200
		loss: 2.765600
		loss: 2.783100
		loss: 3.022400
		loss: 2.783100
		loss: 2.249900
		loss: 2.783000
		loss: 2.633600
		loss: 2.783200
		loss: 2.639900
		loss: 2.783000
		loss: 2.957400
		loss: 2.782600
		loss: 2.866300
		loss: 2.782700
		loss: 2.986200
		loss: 2.782900
		loss: 2.378700
		loss: 2.783000
		loss: 2.483400
		loss: 2.782900
		loss: 2.958000
		loss: 2.782400
		loss: 3.002400
		loss: 2.782400
		loss: 2.805800
		loss: 2.783400
		loss: 2.465300
		loss: 2.783000
		loss: 2.734400
		loss: 2.782300
		loss: 2.878500
		loss: 2.782000
		loss: 2.724900
		loss: 2.781600
		loss: 2.861300
		loss: 2.781600
		loss: 2.626700
		loss: 2.781600
		loss: 2.518600
		loss: 2.781500
		loss: 2.837600
		loss: 2.781300
		loss: 2.627000
		loss: 2.780700
		loss: 2.506200
		loss: 2.780800
		loss: 2.968900
		loss: 2.780600
		loss: 2.837300
		loss: 2.780600
		loss: 3.004600
		loss: 2.780200
		loss: 2.638400
		loss: 2.780100
		loss: 2.249600
		loss: 2.780000
		loss: 2.804600
		loss: 2.779900
		loss: 2.372900
		loss: 2.779700
		loss: 2.902900
		loss: 2.779700
		loss: 2.701100
		loss: 2.779700
		loss: 2.784900
		loss: 2.779900
		loss: 2.868800
		loss: 2.780000
		loss: 2.683200
		loss: 2.779600
		loss: 2.711000
		loss: 2.779200
		loss: 2.646600
		loss: 2.779700
		loss: 2.650000
		loss: 2.779800
		loss: 2.959900
		loss: 2.779800
		loss: 2.555600
		loss: 2.779200
		loss: 2.977600
		loss: 2.779100
		loss: 2.516400
		loss: 2.779100
		loss: 3.022600
		loss: 2.778800
		loss: 2.858000
		loss: 2.779000
		loss: 2.988700
		loss: 2.778400
		loss: 2.862800
		loss: 2.778400
		loss: 2.747800
		loss: 2.778500
		loss: 2.823300
		loss: 2.778300
		loss: 2.866000
		loss: 2.777800
		loss: 2.859500
		loss: 2.777800
		loss: 2.716900
		loss: 2.777700
		loss: 2.735400
		loss: 2.777700
		loss: 2.977800
		loss: 2.777600
	Overall the loss development was 2.376200 -> 2.777600
problem epoch data for epoch 2, problem epoch 3
	sampling search time: 11.655576467514038s
	during this search the following actions were chosen:
	training time: 19.8981294631958s
	during the training the following losses were computed:
		loss: 2.349600
		loss: 2.777500
		loss: 2.495000
		loss: 2.777400
		loss: 2.471900
		loss: 2.777100
		loss: 3.277500
		loss: 2.777100
		loss: 2.873000
		loss: 2.777000
		loss: 2.718300
		loss: 2.776900
		loss: 2.665600
		loss: 2.776800
		loss: 2.985000
		loss: 2.776700
		loss: 2.281700
		loss: 2.776500
		loss: 2.863900
		loss: 2.776500
		loss: 2.810600
		loss: 2.776400
		loss: 2.796200
		loss: 2.776200
		loss: 2.554600
		loss: 2.776100
		loss: 2.819000
		loss: 2.776000
		loss: 2.814700
		loss: 2.775900
		loss: 2.556300
		loss: 2.775900
		loss: 2.722000
		loss: 2.775700
		loss: 2.992100
		loss: 2.775700
		loss: 2.843100
		loss: 2.775600
		loss: 2.724700
		loss: 2.775500
		loss: 2.731400
		loss: 2.775500
		loss: 2.739400
		loss: 2.775400
		loss: 3.077000
		loss: 2.775200
		loss: 2.723000
		loss: 2.775200
		loss: 2.858800
		loss: 2.775100
		loss: 2.614400
		loss: 2.775000
		loss: 2.942200
		loss: 2.775100
		loss: 2.938000
		loss: 2.774900
		loss: 2.591100
		loss: 2.774700
		loss: 2.926900
		loss: 2.774600
		loss: 2.704600
		loss: 2.774600
		loss: 2.764700
		loss: 2.774600
		loss: 2.779200
		loss: 2.774500
		loss: 2.387500
		loss: 2.774400
		loss: 2.662200
		loss: 2.774300
		loss: 2.846600
		loss: 2.774200
		loss: 3.010300
		loss: 2.774300
		loss: 3.016600
		loss: 2.774200
		loss: 2.982900
		loss: 2.774300
		loss: 2.640400
		loss: 2.774600
		loss: 2.814300
		loss: 2.774600
		loss: 3.002500
		loss: 2.774200
		loss: 2.799400
		loss: 2.773800
		loss: 2.663800
		loss: 2.773700
		loss: 2.362900
		loss: 2.773400
		loss: 2.510100
		loss: 2.773400
		loss: 2.810600
		loss: 2.773300
		loss: 2.568100
		loss: 2.773300
		loss: 2.907300
		loss: 2.773200
		loss: 2.419200
		loss: 2.773000
		loss: 2.912200
		loss: 2.772800
		loss: 2.639400
		loss: 2.772800
		loss: 3.003200
		loss: 2.772800
		loss: 2.656900
		loss: 2.772700
		loss: 2.534600
		loss: 2.772800
		loss: 2.635200
		loss: 2.772900
		loss: 2.537500
		loss: 2.772900
		loss: 2.560500
		loss: 2.772800
		loss: 2.874600
		loss: 2.772500
		loss: 2.856700
		loss: 2.772400
		loss: 2.965900
		loss: 2.772500
		loss: 2.870200
		loss: 2.772100
		loss: 3.000000
		loss: 2.772200
		loss: 2.523500
		loss: 2.772100
		loss: 2.957700
		loss: 2.771900
		loss: 2.988400
		loss: 2.771900
		loss: 3.059600
		loss: 2.771700
		loss: 2.563600
		loss: 2.771500
		loss: 3.092500
		loss: 2.771400
		loss: 2.890900
		loss: 2.771300
		loss: 2.521400
		loss: 2.771200
		loss: 2.911800
		loss: 2.771200
		loss: 2.690400
		loss: 2.771000
		loss: 2.958000
		loss: 2.771000
		loss: 2.747300
		loss: 2.770900
		loss: 2.660400
		loss: 2.770900
		loss: 2.538200
		loss: 2.770900
		loss: 2.719700
		loss: 2.770800
		loss: 2.516400
		loss: 2.770800
		loss: 2.614300
		loss: 2.770700
		loss: 2.655300
		loss: 2.770600
		loss: 2.698600
		loss: 2.770600
		loss: 2.846900
		loss: 2.770400
		loss: 2.620300
		loss: 2.770400
		loss: 2.714500
		loss: 2.770300
		loss: 2.738800
		loss: 2.770200
		loss: 3.002200
		loss: 2.770200
		loss: 2.926700
		loss: 2.770100
		loss: 3.025700
		loss: 2.770100
		loss: 2.843100
		loss: 2.770200
		loss: 2.981200
		loss: 2.770400
		loss: 2.645100
		loss: 2.770500
		loss: 2.453000
		loss: 2.770000
		loss: 2.830500
		loss: 2.769900
		loss: 2.738300
		loss: 2.770200
		loss: 2.664300
		loss: 2.770000
		loss: 2.837000
		loss: 2.769500
		loss: 2.899700
		loss: 2.769400
		loss: 2.572900
		loss: 2.769300
		loss: 2.633900
		loss: 2.769100
	Overall the loss development was 2.349600 -> 2.769100
In the epoch 2 for problem d-02.pddl 3 explorations in the sampling searches reached a goal
Success rate: 100

Epoch 3:
Training data for problem d-01.pddl in epoch 3:
model creation time: 10.82997751235962s
problem epoch data for epoch 3, problem epoch 1
	sampling search time: 3.304248332977295s
	during this search the following actions were chosen:
	training time: 42.62588429450989s
	during the training the following losses were computed:
		loss: 1.573100
		loss: 1.626100
		loss: 1.554000
		loss: 1.580400
		loss: 1.583100
		loss: 1.556800
		loss: 1.546300
		loss: 1.558300
		loss: 1.565000
		loss: 1.555900
		loss: 1.545000
		loss: 1.544300
		loss: 1.550100
		loss: 1.551800
		loss: 1.546800
		loss: 1.541500
		loss: 1.541800
		loss: 1.545300
		loss: 1.546200
		loss: 1.543000
		loss: 1.539700
		loss: 1.539700
		loss: 1.541700
		loss: 1.542100
		loss: 1.540200
		loss: 1.538200
		loss: 1.538300
		loss: 1.539500
		loss: 1.539600
		loss: 1.538400
		loss: 1.537300
		loss: 1.537600
		loss: 1.538400
		loss: 1.538300
		loss: 1.537300
		loss: 1.536600
		loss: 1.536900
		loss: 1.537200
		loss: 1.537000
		loss: 1.536300
		loss: 1.536100
		loss: 1.536300
		loss: 1.536300
		loss: 1.536000
		loss: 1.535600
		loss: 1.535600
		loss: 1.535700
		loss: 1.535600
		loss: 1.535300
		loss: 1.535100
		loss: 1.535200
		loss: 1.535200
		loss: 1.535000
		loss: 1.534800
		loss: 1.534800
		loss: 1.534800
		loss: 1.534600
		loss: 1.534500
		loss: 1.534400
		loss: 1.534400
		loss: 1.534300
		loss: 1.534200
		loss: 1.534100
		loss: 1.534100
		loss: 1.534000
		loss: 1.533900
		loss: 1.533800
		loss: 1.533800
		loss: 1.533700
		loss: 1.533600
		loss: 1.533500
		loss: 1.533500
		loss: 1.533400
		loss: 1.533300
		loss: 1.533200
		loss: 1.533200
		loss: 1.533100
		loss: 1.533100
		loss: 1.533000
		loss: 1.532900
		loss: 1.532900
		loss: 1.532800
		loss: 1.532700
		loss: 1.532700
		loss: 1.532600
		loss: 1.532500
		loss: 1.532500
		loss: 1.532400
		loss: 1.532300
		loss: 1.532300
		loss: 1.532200
		loss: 1.532200
		loss: 1.532100
		loss: 1.532000
		loss: 1.532000
		loss: 1.531900
		loss: 1.531900
		loss: 1.531800
		loss: 1.531700
		loss: 1.531700
	Overall the loss development was 1.573100 -> 1.531700
problem epoch data for epoch 3, problem epoch 2
	sampling search time: 3.1860883235931396s
	during this search the following actions were chosen:
	training time: 10.11491084098816s
	during the training the following losses were computed:
		loss: 1.645800
		loss: 1.645800
		loss: 1.645700
		loss: 1.645600
		loss: 1.645600
		loss: 1.645500
		loss: 1.645500
		loss: 1.645400
		loss: 1.645300
		loss: 1.645300
		loss: 1.645200
		loss: 1.645200
		loss: 1.645100
		loss: 1.645000
		loss: 1.645000
		loss: 1.644900
		loss: 1.644800
		loss: 1.644800
		loss: 1.644700
		loss: 1.644700
		loss: 1.644600
		loss: 1.644600
		loss: 1.644500
		loss: 1.644500
		loss: 1.644400
		loss: 1.644300
		loss: 1.644300
		loss: 1.644200
		loss: 1.644200
		loss: 1.644100
		loss: 1.644100
		loss: 1.644000
		loss: 1.644000
		loss: 1.643900
		loss: 1.643900
		loss: 1.643800
		loss: 1.643700
		loss: 1.643700
		loss: 1.643600
		loss: 1.643600
		loss: 1.643500
		loss: 1.643500
		loss: 1.643400
		loss: 1.643400
		loss: 1.643300
		loss: 1.643300
		loss: 1.643200
		loss: 1.643200
		loss: 1.643100
		loss: 1.643100
		loss: 1.643000
		loss: 1.643000
		loss: 1.642900
		loss: 1.642900
		loss: 1.642800
		loss: 1.642800
		loss: 1.642700
		loss: 1.642700
		loss: 1.642600
		loss: 1.642600
		loss: 1.642500
		loss: 1.642500
		loss: 1.642400
		loss: 1.642400
		loss: 1.642300
		loss: 1.642300
		loss: 1.642200
		loss: 1.642200
		loss: 1.642100
		loss: 1.642100
		loss: 1.642000
		loss: 1.642000
		loss: 1.641900
		loss: 1.641900
		loss: 1.641800
		loss: 1.641800
		loss: 1.641800
		loss: 1.641700
		loss: 1.641700
		loss: 1.641600
		loss: 1.641600
		loss: 1.641500
		loss: 1.641500
		loss: 1.641400
		loss: 1.641400
		loss: 1.641300
		loss: 1.641300
		loss: 1.641200
		loss: 1.641200
		loss: 1.641100
		loss: 1.641100
		loss: 1.641000
		loss: 1.641000
		loss: 1.641000
		loss: 1.640900
		loss: 1.640900
		loss: 1.640800
		loss: 1.640800
		loss: 1.640700
		loss: 1.640700
	Overall the loss development was 1.645800 -> 1.640700
problem epoch data for epoch 3, problem epoch 3
	sampling search time: 3.0732526779174805s
	during this search the following actions were chosen:
	training time: 10.111715078353882s
	during the training the following losses were computed:
		loss: 1.716900
		loss: 1.716800
		loss: 1.716800
		loss: 1.716700
		loss: 1.716700
		loss: 1.716600
		loss: 1.716600
		loss: 1.716500
		loss: 1.716500
		loss: 1.716400
		loss: 1.716400
		loss: 1.716300
		loss: 1.716300
		loss: 1.716200
		loss: 1.716200
		loss: 1.716100
		loss: 1.716100
		loss: 1.716000
		loss: 1.716000
		loss: 1.715900
		loss: 1.715900
		loss: 1.715800
		loss: 1.715800
		loss: 1.715700
		loss: 1.715700
		loss: 1.715600
		loss: 1.715600
		loss: 1.715600
		loss: 1.715500
		loss: 1.715500
		loss: 1.715400
		loss: 1.715400
		loss: 1.715300
		loss: 1.715300
		loss: 1.715200
		loss: 1.715200
		loss: 1.715200
		loss: 1.715100
		loss: 1.715100
		loss: 1.715000
		loss: 1.715000
		loss: 1.714900
		loss: 1.714900
		loss: 1.714900
		loss: 1.714800
		loss: 1.714800
		loss: 1.714700
		loss: 1.714700
		loss: 1.714600
		loss: 1.714600
		loss: 1.714600
		loss: 1.714500
		loss: 1.714500
		loss: 1.714400
		loss: 1.714400
		loss: 1.714400
		loss: 1.714300
		loss: 1.714300
		loss: 1.714200
		loss: 1.714200
		loss: 1.714200
		loss: 1.714100
		loss: 1.714100
		loss: 1.714000
		loss: 1.714000
		loss: 1.713900
		loss: 1.713900
		loss: 1.713900
		loss: 1.713800
		loss: 1.713800
		loss: 1.713700
		loss: 1.713700
		loss: 1.713700
		loss: 1.713600
		loss: 1.713600
		loss: 1.713500
		loss: 1.713500
		loss: 1.713500
		loss: 1.713400
		loss: 1.713400
		loss: 1.713300
		loss: 1.713300
		loss: 1.713300
		loss: 1.713200
		loss: 1.713200
		loss: 1.713100
		loss: 1.713100
		loss: 1.713100
		loss: 1.713000
		loss: 1.713000
		loss: 1.712900
		loss: 1.712900
		loss: 1.712900
		loss: 1.712800
		loss: 1.712800
		loss: 1.712700
		loss: 1.712700
		loss: 1.712700
		loss: 1.712600
		loss: 1.712600
	Overall the loss development was 1.716900 -> 1.712600
In the epoch 3 for problem d-01.pddl 3 explorations in the sampling searches reached a goal
Training data for problem d-02.pddl in epoch 3:
model creation time: 19.893784999847412s
problem epoch data for epoch 3, problem epoch 1
	sampling search time: 11.670754194259644s
	during this search the following actions were chosen:
	training time: 84.56423592567444s
	during the training the following losses were computed:
		loss: 3.287200
		loss: 3.223000
		loss: 3.187100
		loss: 3.162900
		loss: 3.166500
		loss: 3.173600
		loss: 3.167800
		loss: 3.155900
		loss: 3.146900
		loss: 3.144000
		loss: 3.142900
		loss: 3.140000
		loss: 3.137300
		loss: 3.136800
		loss: 3.136500
		loss: 3.133700
		loss: 3.130100
		loss: 3.128900
		loss: 3.130200
		loss: 3.130600
		loss: 3.128800
		loss: 3.126700
		loss: 3.125400
		loss: 3.124500
		loss: 3.123300
		loss: 3.122200
		loss: 3.121500
		loss: 3.121100
		loss: 3.120200
		loss: 3.118700
		loss: 3.117200
		loss: 3.116600
		loss: 3.116400
		loss: 3.115900
		loss: 3.115200
		loss: 3.114500
		loss: 3.113900
		loss: 3.112900
		loss: 3.112000
		loss: 3.111600
		loss: 3.111400
		loss: 3.111100
		loss: 3.110600
		loss: 3.110100
		loss: 3.109600
		loss: 3.109100
		loss: 3.108700
		loss: 3.108400
		loss: 3.108100
		loss: 3.107800
		loss: 3.107300
		loss: 3.107000
		loss: 3.106700
		loss: 3.106400
		loss: 3.106100
		loss: 3.105900
		loss: 3.105600
		loss: 3.105300
		loss: 3.105100
		loss: 3.105000
		loss: 3.104800
		loss: 3.104600
		loss: 3.104400
		loss: 3.104200
		loss: 3.104000
		loss: 3.103900
		loss: 3.103800
		loss: 3.103600
		loss: 3.103500
		loss: 3.103400
		loss: 3.103200
		loss: 3.103100
		loss: 3.103000
		loss: 3.102900
		loss: 3.102800
		loss: 3.102700
		loss: 3.102600
		loss: 3.102500
		loss: 3.102400
		loss: 3.102300
		loss: 3.102300
		loss: 3.102200
		loss: 3.102100
		loss: 3.102000
		loss: 3.102000
		loss: 3.101900
		loss: 3.101800
		loss: 3.101800
		loss: 3.101700
		loss: 3.101600
		loss: 3.101600
		loss: 3.101500
		loss: 3.101500
		loss: 3.101400
		loss: 3.101400
		loss: 3.101300
		loss: 3.101200
		loss: 3.101200
		loss: 3.101100
		loss: 3.101100
	Overall the loss development was 3.287200 -> 3.101100
problem epoch data for epoch 3, problem epoch 2
	sampling search time: 11.608793258666992s
	during this search the following actions were chosen:
	training time: 19.55566167831421s
	during the training the following losses were computed:
		loss: 3.534200
		loss: 3.036700
		loss: 2.811200
		loss: 3.032800
		loss: 3.347800
		loss: 3.031900
		loss: 3.332200
		loss: 3.034600
		loss: 3.028900
		loss: 3.033400
		loss: 2.955100
		loss: 3.032900
		loss: 2.918200
		loss: 3.032500
		loss: 2.951900
		loss: 3.032700
		loss: 2.580700
		loss: 3.034600
		loss: 2.640300
		loss: 3.034400
		loss: 3.357400
		loss: 3.033700
		loss: 2.918700
		loss: 3.032500
		loss: 2.693400
		loss: 3.033900
		loss: 2.620000
		loss: 3.034100
		loss: 3.036200
		loss: 3.031700
		loss: 2.911100
		loss: 3.032000
		loss: 2.981900
		loss: 3.031600
		loss: 2.663700
		loss: 3.032900
		loss: 2.864700
		loss: 3.031600
		loss: 3.060800
		loss: 3.030600
		loss: 3.023000
		loss: 3.030600
		loss: 3.125100
		loss: 3.031000
		loss: 3.283100
		loss: 3.029300
		loss: 2.575200
		loss: 3.032700
		loss: 3.532900
		loss: 3.032700
		loss: 3.081900
		loss: 3.030600
		loss: 3.111600
		loss: 3.030800
		loss: 3.221100
		loss: 3.029400
		loss: 3.027100
		loss: 3.030500
		loss: 3.069200
		loss: 3.030300
		loss: 2.580500
		loss: 3.027800
		loss: 3.327500
		loss: 3.028600
		loss: 3.296200
		loss: 3.028400
		loss: 2.832000
		loss: 3.031100
		loss: 3.219700
		loss: 3.028900
		loss: 3.019900
		loss: 3.029600
		loss: 3.078800
		loss: 3.029700
		loss: 3.402500
		loss: 3.031900
		loss: 3.179800
		loss: 3.029500
		loss: 3.094400
		loss: 3.029900
		loss: 3.056400
		loss: 3.030500
		loss: 3.073600
		loss: 3.030100
		loss: 2.555400
		loss: 3.027900
		loss: 2.840500
		loss: 3.028700
		loss: 2.986700
		loss: 3.029600
		loss: 3.342300
		loss: 3.027600
		loss: 3.311700
		loss: 3.030500
		loss: 2.860500
		loss: 3.029900
		loss: 3.158000
		loss: 3.028200
		loss: 3.070000
		loss: 3.028600
		loss: 2.745000
		loss: 3.030400
		loss: 3.157100
		loss: 3.028100
		loss: 3.232300
		loss: 3.029900
		loss: 2.664900
		loss: 3.030800
		loss: 2.806800
		loss: 3.027900
		loss: 3.046400
		loss: 3.028700
		loss: 3.221500
		loss: 3.029500
		loss: 2.501300
		loss: 3.031100
		loss: 3.095800
		loss: 3.028100
		loss: 3.325300
		loss: 3.029700
		loss: 2.970200
		loss: 3.028600
		loss: 3.371500
		loss: 3.030000
		loss: 3.290200
		loss: 3.027000
		loss: 3.188400
		loss: 3.029000
		loss: 3.135400
		loss: 3.028700
		loss: 2.726200
		loss: 3.029500
		loss: 2.830700
		loss: 3.027000
		loss: 3.071200
		loss: 3.027800
		loss: 2.976800
		loss: 3.027800
		loss: 2.984100
		loss: 3.028200
		loss: 2.671500
		loss: 3.029700
		loss: 3.303800
		loss: 3.029100
		loss: 3.545800
		loss: 3.030300
		loss: 3.112400
		loss: 3.027400
		loss: 3.259500
		loss: 3.026600
		loss: 3.218300
		loss: 3.026900
		loss: 3.147800
		loss: 3.027100
		loss: 3.074000
		loss: 3.027300
		loss: 2.918900
		loss: 3.026900
		loss: 2.744600
		loss: 3.026000
		loss: 2.460900
		loss: 3.030200
		loss: 3.225700
		loss: 3.026400
		loss: 2.717000
		loss: 3.026300
		loss: 2.776500
		loss: 3.029200
		loss: 3.120200
		loss: 3.028600
		loss: 2.932500
		loss: 3.027800
		loss: 3.071300
		loss: 3.027800
		loss: 3.095700
		loss: 3.027600
		loss: 2.532400
		loss: 3.025400
		loss: 3.186000
		loss: 3.028500
		loss: 3.255600
		loss: 3.026300
		loss: 3.433400
		loss: 3.025200
		loss: 3.095500
		loss: 3.027300
		loss: 2.854700
		loss: 3.026200
		loss: 2.809500
		loss: 3.028000
		loss: 3.155200
		loss: 3.027900
		loss: 2.985600
		loss: 3.028400
		loss: 3.398400
		loss: 3.028900
		loss: 3.140700
		loss: 3.029600
		loss: 2.888200
		loss: 3.029200
	Overall the loss development was 3.534200 -> 3.029200
problem epoch data for epoch 3, problem epoch 3
	sampling search time: 11.10910415649414s
	during this search the following actions were chosen:
	training time: 20.161696195602417s
	during the training the following losses were computed:
		loss: 3.559100
		loss: 3.078200
		loss: 3.222300
		loss: 3.076900
		loss: 3.096300
		loss: 3.075600
		loss: 3.241200
		loss: 3.074700
		loss: 2.705700
		loss: 3.076800
		loss: 2.590100
		loss: 3.071900
		loss: 2.913200
		loss: 3.074800
		loss: 3.245700
		loss: 3.075100
		loss: 3.088100
		loss: 3.074200
		loss: 3.418400
		loss: 3.075400
		loss: 3.105100
		loss: 3.073900
		loss: 3.115500
		loss: 3.073400
		loss: 3.159400
		loss: 3.073900
		loss: 3.224400
		loss: 3.072900
		loss: 3.057400
		loss: 3.073700
		loss: 3.138500
		loss: 3.073800
		loss: 3.417300
		loss: 3.071500
		loss: 3.011100
		loss: 3.073100
		loss: 3.139500
		loss: 3.073400
		loss: 2.906500
		loss: 3.074200
		loss: 2.986400
		loss: 3.073600
		loss: 3.332000
		loss: 3.071600
		loss: 3.492800
		loss: 3.074900
		loss: 3.283700
		loss: 3.071900
		loss: 3.243500
		loss: 3.073600
		loss: 3.333900
		loss: 3.071400
		loss: 2.660800
		loss: 3.074700
		loss: 3.436400
		loss: 3.074300
		loss: 3.080400
		loss: 3.072500
		loss: 3.018200
		loss: 3.072200
		loss: 3.237800
		loss: 3.073600
		loss: 3.228600
		loss: 3.071900
		loss: 2.876600
		loss: 3.071500
		loss: 2.816500
		loss: 3.073800
		loss: 3.023300
		loss: 3.073100
		loss: 3.145200
		loss: 3.072800
		loss: 2.877900
		loss: 3.071400
		loss: 3.401700
		loss: 3.073800
		loss: 3.021600
		loss: 3.072400
		loss: 3.183400
		loss: 3.072700
		loss: 3.096300
		loss: 3.072200
		loss: 3.401100
		loss: 3.073700
		loss: 2.909200
		loss: 3.071200
		loss: 3.166900
		loss: 3.072400
		loss: 3.197000
		loss: 3.071300
		loss: 3.383200
		loss: 3.070400
		loss: 2.767900
		loss: 3.070400
		loss: 2.872100
		loss: 3.072800
		loss: 2.895500
		loss: 3.072800
		loss: 3.115800
		loss: 3.071900
		loss: 2.960100
		loss: 3.072700
		loss: 3.012800
		loss: 3.072200
		loss: 3.113600
		loss: 3.071700
		loss: 2.984100
		loss: 3.072200
		loss: 2.889000
		loss: 3.070800
		loss: 3.083500
		loss: 3.072000
		loss: 3.242200
		loss: 3.070900
		loss: 3.325200
		loss: 3.072800
		loss: 3.437200
		loss: 3.073400
		loss: 3.147200
		loss: 3.071200
		loss: 3.097700
		loss: 3.071500
		loss: 3.044100
		loss: 3.071300
		loss: 2.601200
		loss: 3.069100
		loss: 2.829300
		loss: 3.070200
		loss: 2.834600
		loss: 3.072400
		loss: 3.441400
		loss: 3.073100
		loss: 2.960800
		loss: 3.071900
		loss: 3.073000
		loss: 3.071400
		loss: 2.938400
		loss: 3.070700
		loss: 3.009300
		loss: 3.071000
		loss: 3.116200
		loss: 3.071000
		loss: 3.310400
		loss: 3.072300
		loss: 3.141800
		loss: 3.071400
		loss: 2.911200
		loss: 3.071800
		loss: 2.909400
		loss: 3.070300
		loss: 3.197600
		loss: 3.071600
		loss: 3.010600
		loss: 3.071200
		loss: 2.731300
		loss: 3.069200
		loss: 3.255800
		loss: 3.069900
		loss: 3.036800
		loss: 3.070600
		loss: 3.063900
		loss: 3.070800
		loss: 3.130100
		loss: 3.070400
		loss: 3.001000
		loss: 3.070400
		loss: 3.155700
		loss: 3.070300
		loss: 3.169400
		loss: 3.071100
		loss: 3.201000
		loss: 3.071300
		loss: 3.048100
		loss: 3.070500
		loss: 3.313400
		loss: 3.069500
		loss: 3.101200
		loss: 3.070400
		loss: 3.082900
		loss: 3.070500
		loss: 3.044100
		loss: 3.070500
		loss: 3.351200
		loss: 3.069300
		loss: 3.359400
		loss: 3.072000
		loss: 3.073300
		loss: 3.070500
		loss: 2.969200
		loss: 3.071400
		loss: 2.946000
		loss: 3.070200
		loss: 2.627800
		loss: 3.072700
		loss: 2.955900
		loss: 3.071200
		loss: 2.907700
		loss: 3.071300
		loss: 2.895000
		loss: 3.069400
	Overall the loss development was 3.559100 -> 3.069400
In the epoch 3 for problem d-02.pddl 3 explorations in the sampling searches reached a goal
Success rate: 100

Epoch 4:
Training data for problem d-01.pddl in epoch 4:
model creation time: 9.886576175689697s
problem epoch data for epoch 4, problem epoch 1
	sampling search time: 3.280006170272827s
	during this search the following actions were chosen:
	training time: 44.066582918167114s
	during the training the following losses were computed:
		loss: 1.484300
		loss: 1.482400
		loss: 1.479000
		loss: 1.473900
		loss: 1.468800
		loss: 1.464900
		loss: 1.468800
		loss: 1.465600
		loss: 1.463500
		loss: 1.464100
		loss: 1.463700
		loss: 1.463900
		loss: 1.462900
		loss: 1.461600
		loss: 1.462500
		loss: 1.462900
		loss: 1.461300
		loss: 1.460700
		loss: 1.461000
		loss: 1.460600
		loss: 1.460500
		loss: 1.460600
		loss: 1.460300
		loss: 1.460200
		loss: 1.459900
		loss: 1.459300
		loss: 1.459400
		loss: 1.459500
		loss: 1.459000
		loss: 1.458800
		loss: 1.458800
		loss: 1.458700
		loss: 1.458700
		loss: 1.458500
		loss: 1.458300
		loss: 1.458400
		loss: 1.458300
		loss: 1.458200
		loss: 1.458200
		loss: 1.458100
		loss: 1.457900
		loss: 1.457900
		loss: 1.457800
		loss: 1.457700
		loss: 1.457600
		loss: 1.457500
		loss: 1.457500
		loss: 1.457400
		loss: 1.457300
		loss: 1.457300
		loss: 1.457200
		loss: 1.457200
		loss: 1.457100
		loss: 1.457000
		loss: 1.457000
		loss: 1.456900
		loss: 1.456900
		loss: 1.456800
		loss: 1.456700
		loss: 1.456700
		loss: 1.456600
		loss: 1.456600
		loss: 1.456500
		loss: 1.456500
		loss: 1.456400
		loss: 1.456400
		loss: 1.456300
		loss: 1.456300
		loss: 1.456200
		loss: 1.456100
		loss: 1.456100
		loss: 1.456100
		loss: 1.456000
		loss: 1.456000
		loss: 1.455900
		loss: 1.455900
		loss: 1.455800
		loss: 1.455800
		loss: 1.455700
		loss: 1.455700
		loss: 1.455600
		loss: 1.455600
		loss: 1.455500
		loss: 1.455500
		loss: 1.455400
		loss: 1.455400
		loss: 1.455300
		loss: 1.455300
		loss: 1.455200
		loss: 1.455200
		loss: 1.455200
		loss: 1.455100
		loss: 1.455100
		loss: 1.455000
		loss: 1.455000
		loss: 1.454900
		loss: 1.454900
		loss: 1.454800
		loss: 1.454800
		loss: 1.454800
	Overall the loss development was 1.484300 -> 1.454800
problem epoch data for epoch 4, problem epoch 2
	sampling search time: 3.198779821395874s
	during this search the following actions were chosen:
	training time: 10.15383768081665s
	during the training the following losses were computed:
		loss: 1.652800
		loss: 1.652700
		loss: 1.652500
		loss: 1.652600
		loss: 1.652400
		loss: 1.652400
		loss: 1.652300
		loss: 1.652300
		loss: 1.652100
		loss: 1.652200
		loss: 1.652000
		loss: 1.652000
		loss: 1.651900
		loss: 1.651900
		loss: 1.651800
		loss: 1.651800
		loss: 1.651700
		loss: 1.651600
		loss: 1.651600
		loss: 1.651500
		loss: 1.651500
		loss: 1.651400
		loss: 1.651400
		loss: 1.651300
		loss: 1.651300
		loss: 1.651200
		loss: 1.651200
		loss: 1.651100
		loss: 1.651100
		loss: 1.651000
		loss: 1.651000
		loss: 1.651000
		loss: 1.650900
		loss: 1.650900
		loss: 1.650800
		loss: 1.650800
		loss: 1.650800
		loss: 1.650700
		loss: 1.650700
		loss: 1.650600
		loss: 1.650600
		loss: 1.650600
		loss: 1.650500
		loss: 1.650500
		loss: 1.650500
		loss: 1.650400
		loss: 1.650400
		loss: 1.650300
		loss: 1.650300
		loss: 1.650300
		loss: 1.650200
		loss: 1.650200
		loss: 1.650100
		loss: 1.650100
		loss: 1.650100
		loss: 1.650000
		loss: 1.650000
		loss: 1.650000
		loss: 1.649900
		loss: 1.649900
		loss: 1.649900
		loss: 1.649800
		loss: 1.649800
		loss: 1.649700
		loss: 1.649700
		loss: 1.649700
		loss: 1.649600
		loss: 1.649600
		loss: 1.649600
		loss: 1.649500
		loss: 1.649500
		loss: 1.649500
		loss: 1.649400
		loss: 1.649400
		loss: 1.649400
		loss: 1.649300
		loss: 1.649300
		loss: 1.649200
		loss: 1.649200
		loss: 1.649200
		loss: 1.649100
		loss: 1.649100
		loss: 1.649100
		loss: 1.649000
		loss: 1.649000
		loss: 1.649000
		loss: 1.648900
		loss: 1.648900
		loss: 1.648900
		loss: 1.648800
		loss: 1.648800
		loss: 1.648800
		loss: 1.648700
		loss: 1.648700
		loss: 1.648700
		loss: 1.648600
		loss: 1.648600
		loss: 1.648600
		loss: 1.648500
		loss: 1.648500
	Overall the loss development was 1.652800 -> 1.648500
problem epoch data for epoch 4, problem epoch 3
	sampling search time: 4.2160422801971436s
	during this search the following actions were chosen:
	training time: 10.127002954483032s
	during the training the following losses were computed:
		loss: 1.685100
		loss: 1.686200
		loss: 1.686200
		loss: 1.684300
		loss: 1.683500
		loss: 1.684200
		loss: 1.683400
		loss: 1.682200
		loss: 1.682500
		loss: 1.682500
		loss: 1.681600
		loss: 1.681700
		loss: 1.682000
		loss: 1.681500
		loss: 1.681500
		loss: 1.681800
		loss: 1.681500
		loss: 1.681500
		loss: 1.681700
		loss: 1.681400
		loss: 1.681400
		loss: 1.681500
		loss: 1.681300
		loss: 1.681200
		loss: 1.681200
		loss: 1.681000
		loss: 1.680900
		loss: 1.681000
		loss: 1.680800
		loss: 1.680700
		loss: 1.680800
		loss: 1.680700
		loss: 1.680600
		loss: 1.680600
		loss: 1.680600
		loss: 1.680500
		loss: 1.680500
		loss: 1.680500
		loss: 1.680400
		loss: 1.680400
		loss: 1.680400
		loss: 1.680400
		loss: 1.680300
		loss: 1.680300
		loss: 1.680300
		loss: 1.680200
		loss: 1.680200
		loss: 1.680200
		loss: 1.680100
		loss: 1.680100
		loss: 1.680100
		loss: 1.680000
		loss: 1.680000
		loss: 1.680000
		loss: 1.679900
		loss: 1.679900
		loss: 1.679900
		loss: 1.679900
		loss: 1.679800
		loss: 1.679800
		loss: 1.679800
		loss: 1.679700
		loss: 1.679700
		loss: 1.679700
		loss: 1.679700
		loss: 1.679600
		loss: 1.679600
		loss: 1.679600
		loss: 1.679500
		loss: 1.679500
		loss: 1.679500
		loss: 1.679500
		loss: 1.679400
		loss: 1.679400
		loss: 1.679400
		loss: 1.679400
		loss: 1.679300
		loss: 1.679300
		loss: 1.679300
		loss: 1.679200
		loss: 1.679200
		loss: 1.679200
		loss: 1.679200
		loss: 1.679100
		loss: 1.679100
		loss: 1.679100
		loss: 1.679100
		loss: 1.679000
		loss: 1.679000
		loss: 1.679000
		loss: 1.679000
		loss: 1.678900
		loss: 1.678900
		loss: 1.678900
		loss: 1.678900
		loss: 1.678800
		loss: 1.678800
		loss: 1.678800
		loss: 1.678800
		loss: 1.678700
	Overall the loss development was 1.685100 -> 1.678700
In the epoch 4 for problem d-01.pddl 3 explorations in the sampling searches reached a goal
Training data for problem d-02.pddl in epoch 4:
model creation time: 21.069521188735962s
problem epoch data for epoch 4, problem epoch 1
	sampling search time: 17.609835624694824s
	during this search the following actions were chosen:
	training time: 74.8020589351654s
	during the training the following losses were computed:
		loss: 3.170600
		loss: 3.069800
		loss: 3.037300
		loss: 2.978300
		loss: 2.951600
		loss: 2.954500
		loss: 2.953700
		loss: 2.941000
		loss: 2.931300
		loss: 2.930800
		loss: 2.932100
		loss: 2.928200
		loss: 2.921500
		loss: 2.918300
		loss: 2.919200
		loss: 2.919700
		loss: 2.917300
		loss: 2.914300
		loss: 2.913100
		loss: 2.913600
		loss: 2.913400
		loss: 2.911900
		loss: 2.910300
		loss: 2.909900
		loss: 2.909800
		loss: 2.908800
		loss: 2.907200
		loss: 2.905700
		loss: 2.905000
		loss: 2.904400
		loss: 2.903600
		loss: 2.902800
		loss: 2.902400
		loss: 2.902200
		loss: 2.901800
		loss: 2.901300
		loss: 2.900900
		loss: 2.900600
		loss: 2.900200
		loss: 2.899700
		loss: 2.899300
		loss: 2.898900
		loss: 2.898500
		loss: 2.898100
		loss: 2.897800
		loss: 2.897500
		loss: 2.897000
		loss: 2.896500
		loss: 2.896100
		loss: 2.895700
		loss: 2.895300
		loss: 2.894900
		loss: 2.894600
		loss: 2.894400
		loss: 2.894000
		loss: 2.893700
		loss: 2.893400
		loss: 2.893100
		loss: 2.892700
		loss: 2.892300
		loss: 2.892000
		loss: 2.891700
		loss: 2.891400
		loss: 2.891000
		loss: 2.890700
		loss: 2.890400
		loss: 2.890100
		loss: 2.889800
		loss: 2.889600
		loss: 2.889300
		loss: 2.889000
		loss: 2.888700
		loss: 2.888400
		loss: 2.888200
		loss: 2.887900
		loss: 2.887700
		loss: 2.887500
		loss: 2.887300
		loss: 2.887100
		loss: 2.886900
		loss: 2.886700
		loss: 2.886500
		loss: 2.886300
		loss: 2.886100
		loss: 2.886000
		loss: 2.885900
		loss: 2.885700
		loss: 2.885600
		loss: 2.885500
		loss: 2.885400
		loss: 2.885300
		loss: 2.885200
		loss: 2.885100
		loss: 2.885000
		loss: 2.884900
		loss: 2.884800
		loss: 2.884800
		loss: 2.884700
		loss: 2.884600
		loss: 2.884600
	Overall the loss development was 3.170600 -> 2.884600
problem epoch data for epoch 4, problem epoch 2
	sampling search time: 11.454612493515015s
	during this search the following actions were chosen:
	training time: 19.76732039451599s
	during the training the following losses were computed:
		loss: 3.189000
		loss: 2.858900
		loss: 2.996100
		loss: 2.857600
		loss: 2.718600
		loss: 2.855900
		loss: 2.654900
		loss: 2.857300
		loss: 2.648600
		loss: 2.854900
		loss: 2.883200
		loss: 2.855300
		loss: 2.874200
		loss: 2.855000
		loss: 2.966000
		loss: 2.855300
		loss: 2.701200
		loss: 2.855300
		loss: 2.961000
		loss: 2.853700
		loss: 3.023200
		loss: 2.854900
		loss: 3.018600
		loss: 2.854800
		loss: 2.541900
		loss: 2.852300
		loss: 2.888600
		loss: 2.853600
		loss: 2.732000
		loss: 2.853100
		loss: 2.790500
		loss: 2.853800
		loss: 2.863000
		loss: 2.853500
		loss: 2.769300
		loss: 2.853900
		loss: 3.312200
		loss: 2.851100
		loss: 2.388200
		loss: 2.851000
		loss: 2.829300
		loss: 2.853200
		loss: 2.791100
		loss: 2.853400
		loss: 2.679200
		loss: 2.854000
		loss: 2.792300
		loss: 2.853400
		loss: 2.612600
		loss: 2.851900
		loss: 2.938000
		loss: 2.852500
		loss: 2.651200
		loss: 2.851900
		loss: 2.486000
		loss: 2.851200
		loss: 2.968800
		loss: 2.852400
		loss: 2.679600
		loss: 2.853700
		loss: 2.756600
		loss: 2.852400
		loss: 2.918400
		loss: 2.853100
		loss: 2.635300
		loss: 2.851700
		loss: 3.056300
		loss: 2.851800
		loss: 2.761900
		loss: 2.853100
		loss: 2.821700
		loss: 2.852800
		loss: 2.936700
		loss: 2.853100
		loss: 2.706000
		loss: 2.851800
		loss: 2.768900
		loss: 2.852900
		loss: 2.517700
		loss: 2.851000
		loss: 3.091800
		loss: 2.853700
		loss: 2.932700
		loss: 2.852100
		loss: 3.210600
		loss: 2.850700
		loss: 2.789200
		loss: 2.852600
		loss: 3.018400
		loss: 2.851600
		loss: 2.745800
		loss: 2.851900
		loss: 2.760800
		loss: 2.851900
		loss: 2.745700
		loss: 2.852900
		loss: 2.823200
		loss: 2.852100
		loss: 3.041900
		loss: 2.853100
		loss: 3.075900
		loss: 2.853300
		loss: 2.719500
		loss: 2.851600
		loss: 3.078100
		loss: 2.853200
		loss: 2.755700
		loss: 2.851600
		loss: 2.898300
		loss: 2.852400
		loss: 2.957000
		loss: 2.852600
		loss: 2.842500
		loss: 2.852100
		loss: 2.852500
		loss: 2.852100
		loss: 3.055500
		loss: 2.853000
		loss: 2.734300
		loss: 2.852500
		loss: 2.701800
		loss: 2.851300
		loss: 2.863000
		loss: 2.851900
		loss: 2.896800
		loss: 2.852100
		loss: 2.738500
		loss: 2.851300
		loss: 3.134500
		loss: 2.853200
		loss: 2.833100
		loss: 2.851700
		loss: 2.695200
		loss: 2.851000
		loss: 2.660500
		loss: 2.850800
		loss: 2.809800
		loss: 2.851500
		loss: 2.688500
		loss: 2.850900
		loss: 2.680600
		loss: 2.850900
		loss: 2.735500
		loss: 2.852200
		loss: 3.072200
		loss: 2.852600
		loss: 2.829000
		loss: 2.851400
		loss: 2.729100
		loss: 2.851000
		loss: 2.805100
		loss: 2.851300
		loss: 2.865300
		loss: 2.851400
		loss: 2.864600
		loss: 2.851600
		loss: 2.887300
		loss: 2.851700
		loss: 2.873600
		loss: 2.851400
		loss: 2.778200
		loss: 2.851900
		loss: 3.000200
		loss: 2.850800
		loss: 2.581000
		loss: 2.852700
		loss: 2.764000
		loss: 2.851800
		loss: 2.318300
		loss: 2.853900
		loss: 2.909500
		loss: 2.851000
		loss: 2.808800
		loss: 2.851100
		loss: 2.898500
		loss: 2.851000
		loss: 2.869100
		loss: 2.851200
		loss: 2.792300
		loss: 2.850900
		loss: 2.896400
		loss: 2.851000
		loss: 2.692700
		loss: 2.850400
		loss: 2.762300
		loss: 2.850800
		loss: 2.960100
		loss: 2.850600
		loss: 2.395000
		loss: 2.848900
		loss: 2.785300
		loss: 2.850800
		loss: 3.012100
		loss: 2.851800
		loss: 2.673900
		loss: 2.851900
		loss: 2.902700
		loss: 2.850700
		loss: 3.053800
		loss: 2.851900
	Overall the loss development was 3.189000 -> 2.851900
problem epoch data for epoch 4, problem epoch 3
	sampling search time: 11.627619504928589s
	during this search the following actions were chosen:
	training time: 21.010148525238037s
	during the training the following losses were computed:
		loss: 2.708400
		loss: 2.872900
		loss: 2.903300
		loss: 2.872800
		loss: 2.739400
		loss: 2.872900
		loss: 2.761800
		loss: 2.872900
		loss: 2.947600
		loss: 2.872800
		loss: 2.844700
		loss: 2.872700
		loss: 3.029400
		loss: 2.872700
		loss: 2.947100
		loss: 2.872800
		loss: 3.066400
		loss: 2.872700
		loss: 2.978400
		loss: 2.872700
		loss: 2.957700
		loss: 2.872700
		loss: 2.803900
		loss: 2.872600
		loss: 3.044600
		loss: 2.872600
		loss: 2.855500
		loss: 2.872600
		loss: 2.924100
		loss: 2.872600
		loss: 3.025800
		loss: 2.872600
		loss: 2.862100
		loss: 2.872500
		loss: 2.728600
		loss: 2.872500
		loss: 2.649700
		loss: 2.872500
		loss: 2.909700
		loss: 2.872500
		loss: 3.114900
		loss: 2.872500
		loss: 2.720000
		loss: 2.872400
		loss: 2.804300
		loss: 2.872400
		loss: 2.926200
		loss: 2.872400
		loss: 2.819000
		loss: 2.872400
		loss: 2.718100
		loss: 2.872300
		loss: 2.867500
		loss: 2.872300
		loss: 2.554400
		loss: 2.872300
		loss: 2.827900
		loss: 2.872300
		loss: 2.927400
		loss: 2.872300
		loss: 2.659300
		loss: 2.872200
		loss: 2.866600
		loss: 2.872200
		loss: 2.888100
		loss: 2.872200
		loss: 3.068200
		loss: 2.872200
		loss: 2.745900
		loss: 2.872200
		loss: 2.859400
		loss: 2.872200
		loss: 3.174300
		loss: 2.872100
		loss: 3.029300
		loss: 2.872200
		loss: 2.933700
		loss: 2.872400
		loss: 3.158700
		loss: 2.872200
		loss: 2.534900
		loss: 2.872200
		loss: 2.961300
		loss: 2.872200
		loss: 3.180100
		loss: 2.872300
		loss: 2.732000
		loss: 2.872300
		loss: 2.698500
		loss: 2.872700
		loss: 2.940500
		loss: 2.872500
		loss: 2.854100
		loss: 2.872800
		loss: 2.682500
		loss: 2.872800
		loss: 2.763500
		loss: 2.873000
		loss: 3.071700
		loss: 2.873000
		loss: 3.212000
		loss: 2.872700
		loss: 2.915000
		loss: 2.872400
		loss: 2.772800
		loss: 2.872200
		loss: 2.851500
		loss: 2.872100
		loss: 2.928100
		loss: 2.872000
		loss: 3.106600
		loss: 2.871900
		loss: 2.725900
		loss: 2.871800
		loss: 3.121400
		loss: 2.871800
		loss: 2.905500
		loss: 2.871800
		loss: 2.830000
		loss: 2.871800
		loss: 2.819700
		loss: 2.871900
		loss: 3.091100
		loss: 2.871800
		loss: 2.918800
		loss: 2.871700
		loss: 3.291000
		loss: 2.871600
		loss: 2.958500
		loss: 2.871600
		loss: 3.159600
		loss: 2.871600
		loss: 2.851200
		loss: 2.871500
		loss: 3.036900
		loss: 2.871500
		loss: 3.115100
		loss: 2.871500
		loss: 2.863100
		loss: 2.871400
		loss: 2.746400
		loss: 2.871400
		loss: 3.019300
		loss: 2.871500
		loss: 3.037900
		loss: 2.871500
		loss: 2.479100
		loss: 2.871400
		loss: 2.850700
		loss: 2.871600
		loss: 2.656600
		loss: 2.871800
		loss: 2.813600
		loss: 2.871600
		loss: 2.915800
		loss: 2.871600
		loss: 3.336900
		loss: 2.871600
		loss: 3.173800
		loss: 2.871600
		loss: 2.825900
		loss: 2.871300
		loss: 2.651300
		loss: 2.871500
		loss: 2.908600
		loss: 2.871400
		loss: 2.949100
		loss: 2.871300
		loss: 2.766600
		loss: 2.871300
		loss: 2.750800
		loss: 2.871200
		loss: 2.889400
		loss: 2.871300
		loss: 2.927500
		loss: 2.871300
		loss: 2.779900
		loss: 2.871200
		loss: 2.739500
		loss: 2.871400
		loss: 3.032900
		loss: 2.871200
		loss: 2.883600
		loss: 2.871300
		loss: 3.037400
		loss: 2.871200
		loss: 2.912000
		loss: 2.871200
		loss: 3.019900
		loss: 2.871100
		loss: 2.833300
		loss: 2.871100
		loss: 3.134600
		loss: 2.871000
		loss: 2.821900
		loss: 2.871000
		loss: 2.710900
		loss: 2.871000
		loss: 2.614400
		loss: 2.870900
	Overall the loss development was 2.708400 -> 2.870900
In the epoch 4 for problem d-02.pddl 3 explorations in the sampling searches reached a goal
Success rate: 100

Epoch 5:
Training data for problem d-01.pddl in epoch 5:
model creation time: 9.828851222991943s
problem epoch data for epoch 5, problem epoch 1
	sampling search time: 3.0862948894500732s
	during this search the following actions were chosen:
	training time: 43.682286739349365s
	during the training the following losses were computed:
		loss: 1.490100
		loss: 1.476900
		loss: 1.485900
		loss: 1.473700
		loss: 1.471900
		loss: 1.460500
		loss: 1.463400
		loss: 1.461400
		loss: 1.456900
		loss: 1.457500
		loss: 1.456400
		loss: 1.454300
		loss: 1.455400
		loss: 1.455500
		loss: 1.453000
		loss: 1.452800
		loss: 1.454500
		loss: 1.453500
		loss: 1.451400
		loss: 1.451600
		loss: 1.452100
		loss: 1.451400
		loss: 1.451200
		loss: 1.451600
		loss: 1.451100
		loss: 1.450600
		loss: 1.450900
		loss: 1.450700
		loss: 1.450300
		loss: 1.450400
		loss: 1.450500
		loss: 1.450000
		loss: 1.449900
		loss: 1.450100
		loss: 1.449800
		loss: 1.449500
		loss: 1.449500
		loss: 1.449400
		loss: 1.449200
		loss: 1.449200
		loss: 1.449000
		loss: 1.448800
		loss: 1.448900
		loss: 1.448900
		loss: 1.448700
		loss: 1.448700
		loss: 1.448600
		loss: 1.448500
		loss: 1.448500
		loss: 1.448500
		loss: 1.448400
		loss: 1.448400
		loss: 1.448300
		loss: 1.448200
		loss: 1.448200
		loss: 1.448200
		loss: 1.448100
		loss: 1.448000
		loss: 1.448000
		loss: 1.447900
		loss: 1.447900
		loss: 1.447800
		loss: 1.447800
		loss: 1.447700
		loss: 1.447700
		loss: 1.447600
		loss: 1.447600
		loss: 1.447600
		loss: 1.447500
		loss: 1.447500
		loss: 1.447400
		loss: 1.447400
		loss: 1.447300
		loss: 1.447300
		loss: 1.447300
		loss: 1.447200
		loss: 1.447200
		loss: 1.447100
		loss: 1.447100
		loss: 1.447100
		loss: 1.447000
		loss: 1.447000
		loss: 1.446900
		loss: 1.446900
		loss: 1.446900
		loss: 1.446800
		loss: 1.446800
		loss: 1.446800
		loss: 1.446700
		loss: 1.446700
		loss: 1.446600
		loss: 1.446600
		loss: 1.446600
		loss: 1.446500
		loss: 1.446500
		loss: 1.446500
		loss: 1.446400
		loss: 1.446400
		loss: 1.446400
		loss: 1.446300
	Overall the loss development was 1.490100 -> 1.446300
problem epoch data for epoch 5, problem epoch 2
	sampling search time: 3.207761526107788s
	during this search the following actions were chosen:
	training time: 10.155043601989746s
	during the training the following losses were computed:
		loss: 1.494700
		loss: 1.484500
		loss: 1.482800
		loss: 1.480100
		loss: 1.478500
		loss: 1.481400
		loss: 1.481600
		loss: 1.480500
		loss: 1.478700
		loss: 1.478000
		loss: 1.476700
		loss: 1.475000
		loss: 1.476600
		loss: 1.477100
		loss: 1.475800
		loss: 1.475600
		loss: 1.474700
		loss: 1.473600
		loss: 1.473800
		loss: 1.474000
		loss: 1.473800
		loss: 1.473300
		loss: 1.473100
		loss: 1.473000
		loss: 1.472400
		loss: 1.472500
		loss: 1.472600
		loss: 1.472300
		loss: 1.472400
		loss: 1.472200
		loss: 1.471900
		loss: 1.471700
		loss: 1.471700
		loss: 1.471700
		loss: 1.471600
		loss: 1.471600
		loss: 1.471500
		loss: 1.471400
		loss: 1.471300
		loss: 1.471300
		loss: 1.471200
		loss: 1.471200
		loss: 1.471200
		loss: 1.471100
		loss: 1.471100
		loss: 1.471000
		loss: 1.471000
		loss: 1.471000
		loss: 1.470900
		loss: 1.470900
		loss: 1.470900
		loss: 1.470800
		loss: 1.470800
		loss: 1.470800
		loss: 1.470800
		loss: 1.470700
		loss: 1.470700
		loss: 1.470700
		loss: 1.470600
		loss: 1.470600
		loss: 1.470600
		loss: 1.470600
		loss: 1.470600
		loss: 1.470500
		loss: 1.470500
		loss: 1.470500
		loss: 1.470500
		loss: 1.470400
		loss: 1.470400
		loss: 1.470400
		loss: 1.470400
		loss: 1.470300
		loss: 1.470300
		loss: 1.470300
		loss: 1.470300
		loss: 1.470300
		loss: 1.470200
		loss: 1.470200
		loss: 1.470200
		loss: 1.470200
		loss: 1.470200
		loss: 1.470100
		loss: 1.470100
		loss: 1.470100
		loss: 1.470100
		loss: 1.470100
		loss: 1.470000
		loss: 1.470000
		loss: 1.470000
		loss: 1.470000
		loss: 1.470000
		loss: 1.469900
		loss: 1.469900
		loss: 1.469900
		loss: 1.469900
		loss: 1.469900
		loss: 1.469800
		loss: 1.469800
		loss: 1.469800
		loss: 1.469800
	Overall the loss development was 1.494700 -> 1.469800
problem epoch data for epoch 5, problem epoch 3
	sampling search time: 4.963623523712158s
	during this search the following actions were chosen:
	training time: 10.16293978691101s
	during the training the following losses were computed:
		loss: 1.669900
		loss: 1.669900
		loss: 1.669900
		loss: 1.669800
		loss: 1.669800
		loss: 1.669700
		loss: 1.669700
		loss: 1.669600
		loss: 1.669700
		loss: 1.669600
		loss: 1.669600
		loss: 1.669500
		loss: 1.669500
		loss: 1.669500
		loss: 1.669500
		loss: 1.669400
		loss: 1.669400
		loss: 1.669400
		loss: 1.669400
		loss: 1.669300
		loss: 1.669300
		loss: 1.669300
		loss: 1.669300
		loss: 1.669200
		loss: 1.669200
		loss: 1.669200
		loss: 1.669200
		loss: 1.669100
		loss: 1.669100
		loss: 1.669100
		loss: 1.669100
		loss: 1.669100
		loss: 1.669000
		loss: 1.669000
		loss: 1.669000
		loss: 1.669000
		loss: 1.669000
		loss: 1.668900
		loss: 1.668900
		loss: 1.668900
		loss: 1.668900
		loss: 1.668900
		loss: 1.668900
		loss: 1.668800
		loss: 1.668800
		loss: 1.668800
		loss: 1.668800
		loss: 1.668800
		loss: 1.668800
		loss: 1.668700
		loss: 1.668700
		loss: 1.668700
		loss: 1.668700
		loss: 1.668700
		loss: 1.668700
		loss: 1.668600
		loss: 1.668600
		loss: 1.668600
		loss: 1.668600
		loss: 1.668600
		loss: 1.668600
		loss: 1.668500
		loss: 1.668500
		loss: 1.668500
		loss: 1.668500
		loss: 1.668500
		loss: 1.668500
		loss: 1.668400
		loss: 1.668400
		loss: 1.668400
		loss: 1.668400
		loss: 1.668400
		loss: 1.668400
		loss: 1.668400
		loss: 1.668300
		loss: 1.668300
		loss: 1.668300
		loss: 1.668300
		loss: 1.668300
		loss: 1.668300
		loss: 1.668300
		loss: 1.668200
		loss: 1.668200
		loss: 1.668200
		loss: 1.668200
		loss: 1.668200
		loss: 1.668200
		loss: 1.668100
		loss: 1.668100
		loss: 1.668100
		loss: 1.668100
		loss: 1.668100
		loss: 1.668100
		loss: 1.668100
		loss: 1.668000
		loss: 1.668000
		loss: 1.668000
		loss: 1.668000
		loss: 1.668000
		loss: 1.668000
	Overall the loss development was 1.669900 -> 1.668000
In the epoch 5 for problem d-01.pddl 3 explorations in the sampling searches reached a goal
Training data for problem d-02.pddl in epoch 5:
model creation time: 29.8942551612854s
problem epoch data for epoch 5, problem epoch 1
	sampling search time: 17.100877046585083s
	during this search the following actions were chosen:
	training time: 102.50629019737244s
	during the training the following losses were computed:
		loss: 3.149700
		loss: 3.049900
		loss: 3.012200
		loss: 2.956700
		loss: 2.931800
		loss: 2.937700
		loss: 2.938500
		loss: 2.928300
		loss: 2.921200
		loss: 2.921900
		loss: 2.922300
		loss: 2.916500
		loss: 2.908300
		loss: 2.904300
		loss: 2.904600
		loss: 2.903800
		loss: 2.900100
		loss: 2.896900
		loss: 2.897300
		loss: 2.899300
		loss: 2.899400
		loss: 2.897600
		loss: 2.896200
		loss: 2.896100
		loss: 2.895700
		loss: 2.893800
		loss: 2.891500
		loss: 2.890600
		loss: 2.890700
		loss: 2.890400
		loss: 2.889400
		loss: 2.888700
		loss: 2.888600
		loss: 2.888500
		loss: 2.887600
		loss: 2.886800
		loss: 2.886400
		loss: 2.886400
		loss: 2.886000
		loss: 2.885400
		loss: 2.885100
		loss: 2.884900
		loss: 2.884600
		loss: 2.884100
		loss: 2.883700
		loss: 2.883500
		loss: 2.883300
		loss: 2.882900
		loss: 2.882600
		loss: 2.882400
		loss: 2.882200
		loss: 2.881800
		loss: 2.881600
		loss: 2.881400
		loss: 2.881200
		loss: 2.880900
		loss: 2.880700
		loss: 2.880500
		loss: 2.880300
		loss: 2.880000
		loss: 2.879800
		loss: 2.879600
		loss: 2.879400
		loss: 2.879200
		loss: 2.879000
		loss: 2.878800
		loss: 2.878600
		loss: 2.878500
		loss: 2.878300
		loss: 2.878100
		loss: 2.878000
		loss: 2.877800
		loss: 2.877700
		loss: 2.877500
		loss: 2.877300
		loss: 2.877200
		loss: 2.877000
		loss: 2.876900
		loss: 2.876700
		loss: 2.876600
		loss: 2.876500
		loss: 2.876300
		loss: 2.876200
		loss: 2.876100
		loss: 2.876000
		loss: 2.875900
		loss: 2.875700
		loss: 2.875600
		loss: 2.875500
		loss: 2.875400
		loss: 2.875300
		loss: 2.875200
		loss: 2.875100
		loss: 2.875000
		loss: 2.874900
		loss: 2.874800
		loss: 2.874700
		loss: 2.874600
		loss: 2.874500
		loss: 2.874400
	Overall the loss development was 3.149700 -> 2.874400
problem epoch data for epoch 5, problem epoch 2
	sampling search time: 11.68763542175293s
	during this search the following actions were chosen:
	training time: 23.159441709518433s
	during the training the following losses were computed:
		loss: 3.080900
		loss: 2.910700
		loss: 2.906000
		loss: 2.910300
		loss: 2.782900
		loss: 2.909800
		loss: 3.102000
		loss: 2.909400
		loss: 2.893000
		loss: 2.908800
		loss: 2.690200
		loss: 2.908300
		loss: 2.556400
		loss: 2.907900
		loss: 3.165000
		loss: 2.907400
		loss: 3.137700
		loss: 2.907100
		loss: 3.012800
		loss: 2.906800
		loss: 3.083200
		loss: 2.906600
		loss: 2.765700
		loss: 2.906400
		loss: 2.979700
		loss: 2.906200
		loss: 2.913400
		loss: 2.906000
		loss: 2.830200
		loss: 2.906000
		loss: 2.966000
		loss: 2.905700
		loss: 2.998200
		loss: 2.905600
		loss: 3.009600
		loss: 2.905500
		loss: 2.818900
		loss: 2.905500
		loss: 2.920500
		loss: 2.905200
		loss: 2.760400
		loss: 2.905300
		loss: 3.044000
		loss: 2.905100
		loss: 2.817400
		loss: 2.905000
		loss: 2.977900
		loss: 2.904900
		loss: 2.680200
		loss: 2.904800
		loss: 2.843500
		loss: 2.904800
		loss: 3.019000
		loss: 2.904800
		loss: 3.102500
		loss: 2.904900
		loss: 3.132600
		loss: 2.904900
		loss: 3.055600
		loss: 2.904600
		loss: 2.880400
		loss: 2.904600
		loss: 2.748500
		loss: 2.904400
		loss: 2.893500
		loss: 2.904400
		loss: 2.843000
		loss: 2.904300
		loss: 2.958200
		loss: 2.904200
		loss: 3.125700
		loss: 2.904300
		loss: 2.950300
		loss: 2.904000
		loss: 2.988000
		loss: 2.903900
		loss: 2.852400
		loss: 2.904100
		loss: 3.139000
		loss: 2.904100
		loss: 2.617900
		loss: 2.904400
		loss: 2.966000
		loss: 2.904500
		loss: 2.636500
		loss: 2.903900
		loss: 2.879100
		loss: 2.903800
		loss: 3.295100
		loss: 2.903900
		loss: 2.601800
		loss: 2.904000
		loss: 3.032200
		loss: 2.903900
		loss: 2.742200
		loss: 2.903800
		loss: 3.296700
		loss: 2.903600
		loss: 2.846300
		loss: 2.903500
		loss: 2.741300
		loss: 2.903400
		loss: 2.957300
		loss: 2.903300
		loss: 2.833000
		loss: 2.903300
		loss: 2.508800
		loss: 2.903200
		loss: 3.260800
		loss: 2.903100
		loss: 2.894800
		loss: 2.903100
		loss: 2.914300
		loss: 2.903100
		loss: 3.014200
		loss: 2.903000
		loss: 3.156600
		loss: 2.903100
		loss: 2.628200
		loss: 2.903000
		loss: 2.969100
		loss: 2.903000
		loss: 3.116200
		loss: 2.903000
		loss: 2.763300
		loss: 2.902900
		loss: 3.319900
		loss: 2.902800
		loss: 3.010800
		loss: 2.902800
		loss: 2.804300
		loss: 2.902700
		loss: 3.294300
		loss: 2.902700
		loss: 2.742900
		loss: 2.902600
		loss: 2.652100
		loss: 2.902600
		loss: 2.627300
		loss: 2.902500
		loss: 2.768000
		loss: 2.902500
		loss: 3.263500
		loss: 2.902500
		loss: 3.125200
		loss: 2.902400
		loss: 3.079900
		loss: 2.902500
		loss: 2.948600
		loss: 2.902400
		loss: 2.867200
		loss: 2.902400
		loss: 2.782600
		loss: 2.902400
		loss: 2.758100
		loss: 2.902300
		loss: 2.539600
		loss: 2.902300
		loss: 2.755100
		loss: 2.902300
		loss: 3.000200
		loss: 2.902300
		loss: 3.102000
		loss: 2.902200
		loss: 3.023200
		loss: 2.902300
		loss: 3.187500
		loss: 2.902200
		loss: 2.846700
		loss: 2.902200
		loss: 3.095500
		loss: 2.902200
		loss: 2.888300
		loss: 2.902200
		loss: 3.001400
		loss: 2.902200
		loss: 2.805700
		loss: 2.902100
		loss: 2.754700
		loss: 2.902100
		loss: 2.855600
		loss: 2.902100
		loss: 2.705900
		loss: 2.902000
		loss: 3.188400
		loss: 2.902000
		loss: 2.828600
		loss: 2.901900
		loss: 2.763600
		loss: 2.901900
		loss: 2.690500
		loss: 2.901900
		loss: 2.953400
		loss: 2.901900
		loss: 2.654700
		loss: 2.902000
		loss: 2.781300
		loss: 2.901900
		loss: 2.548200
		loss: 2.901900
	Overall the loss development was 3.080900 -> 2.901900
problem epoch data for epoch 5, problem epoch 3
	sampling search time: 16.963332891464233s
	during this search the following actions were chosen:
	training time: 30.353515148162842s
	during the training the following losses were computed:
		loss: 3.199600
		loss: 3.022200
		loss: 3.162000
		loss: 3.022200
		loss: 3.201000
		loss: 3.022100
		loss: 2.682800
		loss: 3.022100
		loss: 3.079000
		loss: 3.022200
		loss: 2.732600
		loss: 3.022100
		loss: 3.138400
		loss: 3.022100
		loss: 3.376400
		loss: 3.022000
		loss: 2.985700
		loss: 3.022000
		loss: 2.722700
		loss: 3.022000
		loss: 2.750000
		loss: 3.022000
		loss: 3.417700
		loss: 3.021900
		loss: 3.177700
		loss: 3.021900
		loss: 2.888700
		loss: 3.022100
		loss: 3.043800
		loss: 3.022300
		loss: 2.897900
		loss: 3.022300
		loss: 2.891300
		loss: 3.022400
		loss: 2.674300
		loss: 3.022600
		loss: 3.240800
		loss: 3.023500
		loss: 3.084400
		loss: 3.023700
		loss: 2.728500
		loss: 3.023100
		loss: 3.254300
		loss: 3.022900
		loss: 2.570200
		loss: 3.022600
		loss: 2.676600
		loss: 3.022700
		loss: 2.940300
		loss: 3.023400
		loss: 3.090100
		loss: 3.023500
		loss: 3.112300
		loss: 3.022800
		loss: 2.990500
		loss: 3.022700
		loss: 2.827000
		loss: 3.022800
		loss: 2.924800
		loss: 3.022900
		loss: 2.753800
		loss: 3.022900
		loss: 3.346200
		loss: 3.022500
		loss: 2.903400
		loss: 3.022400
		loss: 3.000900
		loss: 3.022100
		loss: 2.864500
		loss: 3.022100
		loss: 2.973800
		loss: 3.022000
		loss: 3.323200
		loss: 3.022100
		loss: 2.817900
		loss: 3.022000
		loss: 3.044000
		loss: 3.022000
		loss: 3.234000
		loss: 3.021900
		loss: 3.306100
		loss: 3.021600
		loss: 3.469000
		loss: 3.021700
		loss: 3.263400
		loss: 3.021700
		loss: 3.113200
		loss: 3.021700
		loss: 2.836100
		loss: 3.021800
		loss: 3.007900
		loss: 3.021600
		loss: 2.785500
		loss: 3.021600
		loss: 3.044600
		loss: 3.021500
		loss: 3.084700
		loss: 3.021400
		loss: 2.865400
		loss: 3.021400
		loss: 2.932000
		loss: 3.021400
		loss: 3.148900
		loss: 3.021400
		loss: 3.013300
		loss: 3.021400
		loss: 3.089800
		loss: 3.021400
		loss: 3.252400
		loss: 3.021400
		loss: 2.732700
		loss: 3.021400
		loss: 3.020100
		loss: 3.021400
		loss: 3.386300
		loss: 3.021300
		loss: 3.016800
		loss: 3.021300
		loss: 3.320700
		loss: 3.021300
		loss: 2.993700
		loss: 3.021400
		loss: 3.028800
		loss: 3.021300
		loss: 3.241000
		loss: 3.021200
		loss: 2.858000
		loss: 3.021300
		loss: 3.449400
		loss: 3.021200
		loss: 3.189900
		loss: 3.021300
		loss: 3.210100
		loss: 3.021200
		loss: 3.553300
		loss: 3.021200
		loss: 2.897400
		loss: 3.021200
		loss: 2.964300
		loss: 3.021500
		loss: 2.857800
		loss: 3.021700
		loss: 3.103600
		loss: 3.021800
		loss: 2.954700
		loss: 3.021800
		loss: 3.164600
		loss: 3.021600
		loss: 3.040400
		loss: 3.021500
		loss: 3.038900
		loss: 3.021500
		loss: 2.732900
		loss: 3.021500
		loss: 2.746000
		loss: 3.021400
		loss: 2.874200
		loss: 3.021500
		loss: 3.267300
		loss: 3.021500
		loss: 3.211800
		loss: 3.021300
		loss: 3.153500
		loss: 3.021400
		loss: 2.700300
		loss: 3.021200
		loss: 2.640800
		loss: 3.021200
		loss: 3.052800
		loss: 3.021300
		loss: 3.097600
		loss: 3.021200
		loss: 3.010300
		loss: 3.021000
		loss: 2.975000
		loss: 3.020900
		loss: 3.290000
		loss: 3.020900
		loss: 2.743900
		loss: 3.020900
		loss: 3.160300
		loss: 3.020900
		loss: 2.979600
		loss: 3.020900
		loss: 2.937000
		loss: 3.020900
		loss: 2.987300
		loss: 3.020900
		loss: 2.862900
		loss: 3.020900
		loss: 3.150100
		loss: 3.020900
		loss: 3.002000
		loss: 3.020900
		loss: 2.840600
		loss: 3.020900
		loss: 3.309600
		loss: 3.020900
		loss: 3.218800
		loss: 3.020900
	Overall the loss development was 3.199600 -> 3.020900
In the epoch 5 for problem d-02.pddl 3 explorations in the sampling searches reached a goal
Success rate: 100

