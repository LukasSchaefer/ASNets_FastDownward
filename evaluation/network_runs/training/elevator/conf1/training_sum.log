Training log data for domain elevator:
printing the data chronological
Epoch 1:
Training data for problem d-01.pddl in epoch 1:
model creation time: 109.71423840522766s
problem epoch data for epoch 1, problem epoch 1
	sampling search time: 979.8085172176361s
	during this search the following actions were chosen:
		move-down-slow slow0-0 n4 n1 was chosen with probability 0.109999
		move-down-slow slow0-0 n1 n0 was chosen with probability 0.109980
		move-down-fast fast1 n6 n0 was chosen with probability 0.064012
		move-up-slow slow1-0 n4 n8 was chosen with probability 0.059330
		move-down-slow slow1-0 n8 n7 was chosen with probability 0.096986
		move-down-slow slow1-0 n7 n4 was chosen with probability 0.098355
	training time: 893.9017524719238s
	during the training the following losses were computed:
		loss: 8.897800
		loss: 8.538700
		loss: 8.216300
		loss: 7.922000
		loss: 7.655300
		loss: 7.414600
		loss: 7.193900
		loss: 6.993800
		loss: 6.807900
		loss: 6.634500
		loss: 6.468700
		loss: 6.302700
		loss: 6.138000
		loss: 5.980700
		loss: 5.831200
		loss: 5.691900
		loss: 5.563800
		loss: 5.446600
		loss: 5.342300
		loss: 5.250500
		loss: 5.172100
		loss: 5.105600
		loss: 5.048800
		loss: 4.998300
		loss: 4.952200
		loss: 4.908800
		loss: 4.866200
		loss: 4.824900
		loss: 4.785100
		loss: 4.748800
		loss: 4.716000
		loss: 4.686700
		loss: 4.661200
		loss: 4.638800
		loss: 4.619800
		loss: 4.604000
		loss: 4.589800
		loss: 4.576500
		loss: 4.562900
		loss: 4.548400
		loss: 4.532800
		loss: 4.516600
		loss: 4.500000
		loss: 4.483000
		loss: 4.466200
		loss: 4.450600
		loss: 4.436600
		loss: 4.424300
		loss: 4.413800
		loss: 4.404500
		loss: 4.395900
		loss: 4.387400
		loss: 4.378500
		loss: 4.369100
		loss: 4.359600
		loss: 4.349800
		loss: 4.340000
		loss: 4.330400
		loss: 4.321200
		loss: 4.312400
		loss: 4.304300
		loss: 4.297000
		loss: 4.290200
		loss: 4.283500
		loss: 4.276700
		loss: 4.269600
		loss: 4.262500
		loss: 4.255200
		loss: 4.248000
		loss: 4.240900
		loss: 4.234000
		loss: 4.227200
		loss: 4.220600
		loss: 4.214200
		loss: 4.207900
		loss: 4.201800
		loss: 4.195600
		loss: 4.189200
		loss: 4.182800
		loss: 4.176200
		loss: 4.169700
		loss: 4.163000
		loss: 4.156300
		loss: 4.149600
		loss: 4.143000
		loss: 4.136200
		loss: 4.129300
		loss: 4.122300
		loss: 4.115200
		loss: 4.108000
		loss: 4.100800
		loss: 4.093500
		loss: 4.086200
		loss: 4.078700
		loss: 4.071300
		loss: 4.063900
		loss: 4.056200
		loss: 4.048500
		loss: 4.040700
		loss: 4.032800
		loss: 4.024900
		loss: 4.016900
		loss: 4.008800
		loss: 4.000600
		loss: 3.992400
		loss: 3.984200
		loss: 3.975700
		loss: 3.967300
		loss: 3.958800
		loss: 3.950200
		loss: 3.941500
		loss: 3.932900
		loss: 3.924000
		loss: 3.914900
		loss: 3.905400
		loss: 3.895700
		loss: 3.886000
		loss: 3.876000
		loss: 3.866300
		loss: 3.857000
		loss: 3.847400
		loss: 3.837800
		loss: 3.828300
		loss: 3.818600
		loss: 3.808600
		loss: 3.798700
		loss: 3.789000
		loss: 3.779500
		loss: 3.770300
		loss: 3.761000
		loss: 3.752000
		loss: 3.743000
		loss: 3.733800
		loss: 3.724800
		loss: 3.716000
		loss: 3.707200
		loss: 3.698500
		loss: 3.689800
		loss: 3.680900
		loss: 3.672200
		loss: 3.663700
		loss: 3.655200
		loss: 3.646600
		loss: 3.638200
		loss: 3.629700
		loss: 3.621300
		loss: 3.612900
		loss: 3.604600
		loss: 3.596500
		loss: 3.588400
		loss: 3.580400
		loss: 3.572500
		loss: 3.564700
		loss: 3.557200
		loss: 3.549600
		loss: 3.542000
		loss: 3.534600
		loss: 3.527400
		loss: 3.520200
		loss: 3.513100
		loss: 3.506300
		loss: 3.499400
		loss: 3.492800
		loss: 3.486500
		loss: 3.480100
		loss: 3.473700
		loss: 3.467500
		loss: 3.461300
		loss: 3.455200
		loss: 3.449300
		loss: 3.443600
		loss: 3.437800
		loss: 3.432200
		loss: 3.426800
		loss: 3.421600
		loss: 3.416400
		loss: 3.411300
		loss: 3.406400
		loss: 3.401500
		loss: 3.396700
		loss: 3.392100
		loss: 3.387500
		loss: 3.382900
		loss: 3.378600
		loss: 3.374300
		loss: 3.370000
		loss: 3.365800
		loss: 3.361800
		loss: 3.357900
		loss: 3.354000
		loss: 3.350300
		loss: 3.346600
		loss: 3.343000
		loss: 3.339500
		loss: 3.336100
		loss: 3.332600
		loss: 3.329300
		loss: 3.326000
		loss: 3.322900
		loss: 3.319800
		loss: 3.316700
		loss: 3.313700
		loss: 3.310800
		loss: 3.307900
		loss: 3.305100
		loss: 3.302500
		loss: 3.299800
		loss: 3.297100
		loss: 3.294600
		loss: 3.292100
		loss: 3.289700
		loss: 3.287300
		loss: 3.284900
		loss: 3.282700
		loss: 3.280400
		loss: 3.278300
		loss: 3.276300
		loss: 3.274200
		loss: 3.272200
		loss: 3.270200
		loss: 3.268300
		loss: 3.266500
		loss: 3.264600
		loss: 3.262700
		loss: 3.261000
		loss: 3.259300
		loss: 3.257500
		loss: 3.255900
		loss: 3.254300
		loss: 3.252600
		loss: 3.251000
		loss: 3.249600
		loss: 3.248000
		loss: 3.246400
		loss: 3.245000
		loss: 3.243500
		loss: 3.242000
		loss: 3.240600
		loss: 3.239300
		loss: 3.237900
		loss: 3.236600
		loss: 3.235300
		loss: 3.234000
		loss: 3.232700
		loss: 3.231400
		loss: 3.230200
		loss: 3.229000
		loss: 3.227700
		loss: 3.226500
		loss: 3.225300
		loss: 3.224200
		loss: 3.223000
		loss: 3.221800
		loss: 3.220700
		loss: 3.219600
		loss: 3.218400
	Overall the loss development was 8.897800 -> 3.218400
problem epoch data for epoch 1, problem epoch 2
	sampling search time: 450.5614523887634s
	during this search the following actions were chosen:
		move-down-slow slow0-0 n4 n1 was chosen with probability 0.476843
		board p1 slow0-0 n1 n0 n1 was chosen with probability 0.888757
		leave p1 slow0-0 n1 n1 n0 was chosen with probability 0.607446
	training time: 219.9593367576599s
	during the training the following losses were computed:
		loss: 2.417000
		loss: 2.415700
		loss: 2.413600
		loss: 2.411900
		loss: 2.410200
		loss: 2.408000
		loss: 2.406500
		loss: 2.404800
		loss: 2.402800
		loss: 2.401400
		loss: 2.399800
		loss: 2.398000
		loss: 2.396800
		loss: 2.395300
		loss: 2.393900
		loss: 2.392800
		loss: 2.391600
		loss: 2.390300
		loss: 2.389300
		loss: 2.388300
		loss: 2.387100
		loss: 2.386100
		loss: 2.385200
		loss: 2.384300
		loss: 2.383300
		loss: 2.382400
		loss: 2.381600
		loss: 2.380800
		loss: 2.379900
		loss: 2.379100
		loss: 2.378400
		loss: 2.377700
		loss: 2.376900
		loss: 2.376200
		loss: 2.375500
		loss: 2.374800
		loss: 2.374200
		loss: 2.373600
		loss: 2.373000
		loss: 2.372300
		loss: 2.371700
		loss: 2.371200
		loss: 2.370600
		loss: 2.370000
		loss: 2.369400
		loss: 2.368800
		loss: 2.368300
		loss: 2.367800
		loss: 2.367300
		loss: 2.366800
		loss: 2.366300
		loss: 2.365800
		loss: 2.365300
		loss: 2.364900
		loss: 2.364400
		loss: 2.363900
		loss: 2.363400
		loss: 2.362900
		loss: 2.362400
		loss: 2.361900
		loss: 2.361500
		loss: 2.361000
		loss: 2.360600
		loss: 2.360200
		loss: 2.359800
		loss: 2.359400
		loss: 2.359100
		loss: 2.359000
		loss: 2.359100
		loss: 2.359500
		loss: 2.359400
		loss: 2.358700
		loss: 2.357200
		loss: 2.356200
		loss: 2.356400
		loss: 2.356700
		loss: 2.355800
		loss: 2.354700
		loss: 2.354600
		loss: 2.354800
		loss: 2.354200
		loss: 2.353300
		loss: 2.353100
		loss: 2.353100
		loss: 2.352600
		loss: 2.351900
		loss: 2.351600
		loss: 2.351500
		loss: 2.351100
		loss: 2.350600
		loss: 2.350100
		loss: 2.350000
		loss: 2.349800
		loss: 2.349300
		loss: 2.348800
		loss: 2.348500
		loss: 2.348300
		loss: 2.348100
		loss: 2.347700
		loss: 2.347300
		loss: 2.346900
		loss: 2.346700
		loss: 2.346400
		loss: 2.346100
		loss: 2.345700
		loss: 2.345300
		loss: 2.345000
		loss: 2.344800
		loss: 2.344500
		loss: 2.344300
		loss: 2.343900
		loss: 2.343600
		loss: 2.343200
		loss: 2.342900
		loss: 2.342600
		loss: 2.342400
		loss: 2.342100
		loss: 2.341800
		loss: 2.341500
		loss: 2.341200
		loss: 2.340900
		loss: 2.340600
		loss: 2.340300
		loss: 2.340000
		loss: 2.339700
		loss: 2.339400
		loss: 2.339200
		loss: 2.338900
		loss: 2.338700
		loss: 2.338400
		loss: 2.338200
		loss: 2.338000
		loss: 2.337600
		loss: 2.337300
		loss: 2.337000
		loss: 2.336700
		loss: 2.336400
		loss: 2.336100
		loss: 2.335800
		loss: 2.335600
		loss: 2.335300
		loss: 2.335100
		loss: 2.334900
		loss: 2.334700
		loss: 2.334500
		loss: 2.334300
		loss: 2.334200
		loss: 2.333900
		loss: 2.333600
		loss: 2.333100
		loss: 2.332700
		loss: 2.332400
		loss: 2.332200
		loss: 2.332100
		loss: 2.331900
		loss: 2.331800
		loss: 2.331600
		loss: 2.331300
		loss: 2.331000
		loss: 2.330600
		loss: 2.330200
		loss: 2.329900
		loss: 2.329700
		loss: 2.329500
		loss: 2.329500
		loss: 2.329500
		loss: 2.329600
		loss: 2.329700
		loss: 2.329700
		loss: 2.329100
		loss: 2.328300
		loss: 2.327500
		loss: 2.327400
		loss: 2.327500
		loss: 2.327400
		loss: 2.326800
		loss: 2.326300
		loss: 2.326100
		loss: 2.326200
		loss: 2.326100
		loss: 2.325800
		loss: 2.325300
		loss: 2.324900
		loss: 2.324700
		loss: 2.324700
		loss: 2.324500
		loss: 2.324200
		loss: 2.323900
		loss: 2.323500
		loss: 2.323300
		loss: 2.323100
		loss: 2.323000
		loss: 2.322800
		loss: 2.322500
		loss: 2.322200
		loss: 2.321900
		loss: 2.321700
		loss: 2.321500
		loss: 2.321300
		loss: 2.321200
		loss: 2.321000
		loss: 2.320800
		loss: 2.320500
		loss: 2.320200
		loss: 2.320000
		loss: 2.319700
		loss: 2.319500
		loss: 2.319300
		loss: 2.319200
		loss: 2.319000
		loss: 2.318800
		loss: 2.318600
		loss: 2.318300
		loss: 2.318100
		loss: 2.317800
		loss: 2.317600
		loss: 2.317300
		loss: 2.317100
		loss: 2.316900
		loss: 2.316700
		loss: 2.316600
		loss: 2.316400
		loss: 2.316300
		loss: 2.316200
		loss: 2.316100
		loss: 2.315900
		loss: 2.315500
		loss: 2.315200
		loss: 2.314800
		loss: 2.314600
		loss: 2.314500
		loss: 2.314500
		loss: 2.314400
		loss: 2.314300
		loss: 2.314000
		loss: 2.313700
		loss: 2.313300
		loss: 2.313000
		loss: 2.312800
		loss: 2.312700
		loss: 2.312500
		loss: 2.312400
		loss: 2.312300
		loss: 2.312100
		loss: 2.311900
		loss: 2.311700
		loss: 2.311400
		loss: 2.311100
		loss: 2.310800
		loss: 2.310600
		loss: 2.310500
		loss: 2.310300
		loss: 2.310200
		loss: 2.310100
		loss: 2.310000
		loss: 2.309800
	Overall the loss development was 2.417000 -> 2.309800
problem epoch data for epoch 1, problem epoch 3
	sampling search time: 584.7403042316437s
	during this search the following actions were chosen:
		move-down-slow slow0-0 n4 n1 was chosen with probability 0.504352
		board p1 slow0-0 n1 n0 n1 was chosen with probability 0.987082
		move-down-slow slow0-0 n1 n0 was chosen with probability 0.501522
		leave p1 slow0-0 n0 n1 n0 was chosen with probability 0.501697
		board p1 slow0-0 n0 n0 n1 was chosen with probability 0.539240
	training time: 227.38496899604797s
	during the training the following losses were computed:
		loss: 2.280200
		loss: 2.279900
		loss: 2.279500
		loss: 2.279200
		loss: 2.279000
		loss: 2.278900
		loss: 2.278800
		loss: 2.278600
		loss: 2.278300
		loss: 2.278000
		loss: 2.277800
		loss: 2.277600
		loss: 2.277500
		loss: 2.277300
		loss: 2.277200
		loss: 2.276900
		loss: 2.276700
		loss: 2.276500
		loss: 2.276300
		loss: 2.276100
		loss: 2.275900
		loss: 2.275800
		loss: 2.275600
		loss: 2.275500
		loss: 2.275300
		loss: 2.275100
		loss: 2.274900
		loss: 2.274600
		loss: 2.274400
		loss: 2.274200
		loss: 2.274000
		loss: 2.273800
		loss: 2.273700
		loss: 2.273600
		loss: 2.273500
		loss: 2.273400
		loss: 2.273200
		loss: 2.273000
		loss: 2.272700
		loss: 2.272400
		loss: 2.272200
		loss: 2.272000
		loss: 2.271900
		loss: 2.271800
		loss: 2.271600
		loss: 2.271500
		loss: 2.271300
		loss: 2.271100
		loss: 2.270900
		loss: 2.270600
		loss: 2.270400
		loss: 2.270200
		loss: 2.270100
		loss: 2.269900
		loss: 2.269700
		loss: 2.269600
		loss: 2.269500
		loss: 2.269400
		loss: 2.269300
		loss: 2.269200
		loss: 2.269100
		loss: 2.268900
		loss: 2.268600
		loss: 2.268300
		loss: 2.268000
		loss: 2.267800
		loss: 2.267700
		loss: 2.267500
		loss: 2.267400
		loss: 2.267400
		loss: 2.267300
		loss: 2.267300
		loss: 2.267100
		loss: 2.266900
		loss: 2.266600
		loss: 2.266300
		loss: 2.266000
		loss: 2.265800
		loss: 2.265700
		loss: 2.265700
		loss: 2.265500
		loss: 2.265300
		loss: 2.265100
		loss: 2.264900
		loss: 2.264700
		loss: 2.264500
		loss: 2.264300
		loss: 2.264200
		loss: 2.264000
		loss: 2.263900
		loss: 2.263900
		loss: 2.263900
		loss: 2.264000
		loss: 2.264200
		loss: 2.264200
		loss: 2.263800
		loss: 2.263100
		loss: 2.262600
		loss: 2.262400
		loss: 2.262500
		loss: 2.262600
		loss: 2.262500
		loss: 2.262300
		loss: 2.261800
		loss: 2.261500
		loss: 2.261300
		loss: 2.261300
		loss: 2.261300
		loss: 2.261100
		loss: 2.260900
		loss: 2.260600
		loss: 2.260300
		loss: 2.260200
		loss: 2.260100
		loss: 2.260100
		loss: 2.260000
		loss: 2.259900
		loss: 2.259700
		loss: 2.259500
		loss: 2.259200
		loss: 2.259000
		loss: 2.258800
		loss: 2.258700
		loss: 2.258600
		loss: 2.258500
		loss: 2.258400
		loss: 2.258300
		loss: 2.258300
		loss: 2.258100
		loss: 2.258000
		loss: 2.257700
		loss: 2.257500
		loss: 2.257200
		loss: 2.257000
		loss: 2.256900
		loss: 2.256800
		loss: 2.256800
		loss: 2.256800
		loss: 2.256800
		loss: 2.256700
		loss: 2.256600
		loss: 2.256200
		loss: 2.255900
		loss: 2.255600
		loss: 2.255400
		loss: 2.255400
		loss: 2.255300
		loss: 2.255200
		loss: 2.255000
		loss: 2.254800
		loss: 2.254500
		loss: 2.254400
		loss: 2.254200
		loss: 2.254200
		loss: 2.254100
		loss: 2.254100
		loss: 2.254200
		loss: 2.254100
		loss: 2.254000
		loss: 2.253800
		loss: 2.253500
		loss: 2.253200
		loss: 2.252900
		loss: 2.252700
		loss: 2.252600
		loss: 2.252600
		loss: 2.252500
		loss: 2.252400
		loss: 2.252100
		loss: 2.251900
		loss: 2.251700
		loss: 2.251500
		loss: 2.251400
		loss: 2.251300
		loss: 2.251300
		loss: 2.251300
		loss: 2.251400
		loss: 2.251300
		loss: 2.251200
		loss: 2.250900
		loss: 2.250500
		loss: 2.250200
		loss: 2.250100
		loss: 2.250000
		loss: 2.250000
		loss: 2.249900
		loss: 2.249800
		loss: 2.249600
		loss: 2.249300
		loss: 2.249100
		loss: 2.248900
		loss: 2.248800
		loss: 2.248700
		loss: 2.248700
		loss: 2.248600
		loss: 2.248600
		loss: 2.248600
		loss: 2.248600
		loss: 2.248400
		loss: 2.248000
		loss: 2.247700
		loss: 2.247500
		loss: 2.247400
		loss: 2.247400
		loss: 2.247400
		loss: 2.247500
		loss: 2.247500
		loss: 2.247400
		loss: 2.247200
		loss: 2.246900
		loss: 2.246400
		loss: 2.246200
		loss: 2.246100
		loss: 2.246100
		loss: 2.246100
		loss: 2.245900
		loss: 2.245700
		loss: 2.245500
		loss: 2.245300
		loss: 2.245100
		loss: 2.245100
		loss: 2.245100
		loss: 2.245100
		loss: 2.245300
		loss: 2.245400
		loss: 2.245500
		loss: 2.245300
		loss: 2.244700
		loss: 2.244100
		loss: 2.243900
		loss: 2.244000
		loss: 2.244100
		loss: 2.244100
		loss: 2.243700
		loss: 2.243400
		loss: 2.243100
		loss: 2.243100
		loss: 2.243100
		loss: 2.243000
		loss: 2.242800
		loss: 2.242600
		loss: 2.242400
		loss: 2.242200
		loss: 2.242100
		loss: 2.242000
		loss: 2.242000
		loss: 2.241900
		loss: 2.241800
		loss: 2.241800
		loss: 2.241700
		loss: 2.241600
		loss: 2.241400
		loss: 2.241300
		loss: 2.241100
		loss: 2.240800
		loss: 2.240600
	Overall the loss development was 2.280200 -> 2.240600
problem epoch data for epoch 1, problem epoch 4
	sampling search time: 449.41386699676514s
	during this search the following actions were chosen:
		move-down-slow slow0-0 n4 n1 was chosen with probability 0.504830
		board p1 slow0-0 n1 n0 n1 was chosen with probability 0.988834
		leave p1 slow0-0 n1 n1 n0 was chosen with probability 0.502133
	training time: 220.2599494457245s
	during the training the following losses were computed:
		loss: 2.270300
		loss: 2.270200
		loss: 2.270200
		loss: 2.270400
		loss: 2.270600
		loss: 2.271200
		loss: 2.271500
		loss: 2.271400
		loss: 2.270500
		loss: 2.269400
		loss: 2.269200
		loss: 2.269600
		loss: 2.269900
		loss: 2.269400
		loss: 2.268800
		loss: 2.268600
		loss: 2.268800
		loss: 2.268800
		loss: 2.268500
		loss: 2.268100
		loss: 2.267900
		loss: 2.267800
		loss: 2.267800
		loss: 2.267900
		loss: 2.267900
		loss: 2.267900
		loss: 2.267900
		loss: 2.267700
		loss: 2.267500
		loss: 2.267100
		loss: 2.266800
		loss: 2.266600
		loss: 2.266700
		loss: 2.266700
		loss: 2.266600
		loss: 2.266400
		loss: 2.266100
		loss: 2.265900
		loss: 2.265900
		loss: 2.265900
		loss: 2.265800
		loss: 2.265700
		loss: 2.265600
		loss: 2.265400
		loss: 2.265200
		loss: 2.265100
		loss: 2.264900
		loss: 2.264800
		loss: 2.264700
		loss: 2.264600
		loss: 2.264600
		loss: 2.264500
		loss: 2.264400
		loss: 2.264300
		loss: 2.264100
		loss: 2.263900
		loss: 2.263800
		loss: 2.263600
		loss: 2.263500
		loss: 2.263400
		loss: 2.263400
		loss: 2.263300
		loss: 2.263300
		loss: 2.263300
		loss: 2.263300
		loss: 2.263200
		loss: 2.263100
		loss: 2.262900
		loss: 2.262600
		loss: 2.262300
		loss: 2.262200
		loss: 2.262200
		loss: 2.262200
		loss: 2.262300
		loss: 2.262200
		loss: 2.262100
		loss: 2.261800
		loss: 2.261500
		loss: 2.261300
		loss: 2.261300
		loss: 2.261300
		loss: 2.261300
		loss: 2.261100
		loss: 2.261000
		loss: 2.260800
		loss: 2.260600
		loss: 2.260500
		loss: 2.260400
		loss: 2.260200
		loss: 2.260100
		loss: 2.260100
		loss: 2.260000
		loss: 2.260000
		loss: 2.260100
		loss: 2.260300
		loss: 2.260700
		loss: 2.260900
		loss: 2.260800
		loss: 2.260200
		loss: 2.259500
		loss: 2.259000
		loss: 2.259100
		loss: 2.259400
		loss: 2.259400
		loss: 2.259000
		loss: 2.258600
		loss: 2.258400
		loss: 2.258500
		loss: 2.258600
		loss: 2.258700
		loss: 2.258500
		loss: 2.258300
		loss: 2.258000
		loss: 2.257600
		loss: 2.257600
		loss: 2.257600
		loss: 2.257600
		loss: 2.257400
		loss: 2.257200
		loss: 2.257000
		loss: 2.256900
		loss: 2.257000
		loss: 2.257000
		loss: 2.257100
		loss: 2.257000
		loss: 2.256900
		loss: 2.256600
		loss: 2.256300
		loss: 2.256100
		loss: 2.256000
		loss: 2.256100
		loss: 2.256100
		loss: 2.256100
		loss: 2.255900
		loss: 2.255800
		loss: 2.255600
		loss: 2.255400
		loss: 2.255200
		loss: 2.255100
		loss: 2.255000
		loss: 2.255000
		loss: 2.255000
		loss: 2.255000
		loss: 2.255000
		loss: 2.254900
		loss: 2.254800
		loss: 2.254500
		loss: 2.254300
		loss: 2.254100
		loss: 2.254000
		loss: 2.254100
		loss: 2.254000
		loss: 2.253900
		loss: 2.253800
		loss: 2.253600
		loss: 2.253400
		loss: 2.253300
		loss: 2.253200
		loss: 2.253100
		loss: 2.253000
		loss: 2.253000
		loss: 2.253000
		loss: 2.253100
		loss: 2.253200
		loss: 2.253200
		loss: 2.253200
		loss: 2.252900
		loss: 2.252600
		loss: 2.252200
		loss: 2.252000
		loss: 2.252000
		loss: 2.252000
		loss: 2.252200
		loss: 2.252200
		loss: 2.252200
		loss: 2.251900
		loss: 2.251600
		loss: 2.251300
		loss: 2.251200
		loss: 2.251200
		loss: 2.251300
		loss: 2.251200
		loss: 2.251000
		loss: 2.250800
		loss: 2.250600
		loss: 2.250500
		loss: 2.250400
		loss: 2.250400
		loss: 2.250500
		loss: 2.250600
		loss: 2.250900
		loss: 2.251000
		loss: 2.251200
		loss: 2.251000
		loss: 2.250400
		loss: 2.249700
		loss: 2.249500
		loss: 2.249600
		loss: 2.249800
		loss: 2.249700
		loss: 2.249400
		loss: 2.249000
		loss: 2.248900
		loss: 2.249000
		loss: 2.249000
		loss: 2.249000
		loss: 2.248900
		loss: 2.248700
		loss: 2.248500
		loss: 2.248300
		loss: 2.248200
		loss: 2.248100
		loss: 2.248100
		loss: 2.248000
		loss: 2.248000
		loss: 2.247800
		loss: 2.247700
		loss: 2.247500
		loss: 2.247400
		loss: 2.247300
		loss: 2.247300
		loss: 2.247300
		loss: 2.247300
		loss: 2.247300
		loss: 2.247500
		loss: 2.247500
		loss: 2.247400
		loss: 2.247100
		loss: 2.246700
		loss: 2.246400
		loss: 2.246400
		loss: 2.246400
		loss: 2.246500
		loss: 2.246600
		loss: 2.246500
		loss: 2.246400
		loss: 2.246100
		loss: 2.245800
		loss: 2.245600
		loss: 2.245600
		loss: 2.245600
		loss: 2.245500
		loss: 2.245400
		loss: 2.245200
		loss: 2.245100
		loss: 2.245000
		loss: 2.244900
		loss: 2.244900
		loss: 2.245000
		loss: 2.245100
		loss: 2.245300
		loss: 2.245500
		loss: 2.245500
		loss: 2.245200
		loss: 2.244700
		loss: 2.244200
	Overall the loss development was 2.270300 -> 2.244200
problem epoch data for epoch 1, problem epoch 5
	sampling search time: 553.1759068965912s
	during this search the following actions were chosen:
		move-down-slow slow0-0 n4 n1 was chosen with probability 0.502496
		board p1 slow0-0 n1 n0 n1 was chosen with probability 0.990927
		move-down-slow slow0-0 n1 n0 was chosen with probability 0.500006
		board p3 slow0-0 n0 n1 n2 was chosen with probability 0.504525
		leave p3 slow0-0 n0 n2 n1 was chosen with probability 0.334436
	training time: 220.05127239227295s
	during the training the following losses were computed:
		loss: 2.244100
		loss: 2.244200
		loss: 2.244500
		loss: 2.244400
		loss: 2.244100
		loss: 2.243700
		loss: 2.243500
		loss: 2.243600
		loss: 2.243700
		loss: 2.243800
		loss: 2.243700
		loss: 2.243600
		loss: 2.243300
		loss: 2.243000
		loss: 2.242800
		loss: 2.242800
		loss: 2.242900
		loss: 2.242800
		loss: 2.242600
		loss: 2.242400
		loss: 2.242300
		loss: 2.242200
		loss: 2.242200
		loss: 2.242300
		loss: 2.242400
		loss: 2.242700
		loss: 2.243100
		loss: 2.243500
		loss: 2.243300
		loss: 2.242600
		loss: 2.241700
		loss: 2.241400
		loss: 2.241700
		loss: 2.242000
		loss: 2.241900
		loss: 2.241400
		loss: 2.241000
		loss: 2.241100
		loss: 2.241300
		loss: 2.241200
		loss: 2.240800
		loss: 2.240600
		loss: 2.240600
		loss: 2.240800
		loss: 2.240800
		loss: 2.240600
		loss: 2.240400
		loss: 2.240100
		loss: 2.240000
		loss: 2.239900
		loss: 2.240000
		loss: 2.240000
		loss: 2.239900
		loss: 2.239800
		loss: 2.239600
		loss: 2.239400
		loss: 2.239300
		loss: 2.239300
		loss: 2.239300
		loss: 2.239300
		loss: 2.239200
		loss: 2.239100
		loss: 2.239000
		loss: 2.238900
		loss: 2.238800
		loss: 2.238700
		loss: 2.238500
		loss: 2.238400
		loss: 2.238300
		loss: 2.238300
		loss: 2.238200
		loss: 2.238200
		loss: 2.238100
		loss: 2.238200
		loss: 2.238200
		loss: 2.238300
		loss: 2.238200
		loss: 2.238100
		loss: 2.237800
		loss: 2.237500
		loss: 2.237400
		loss: 2.237400
		loss: 2.237400
		loss: 2.237400
		loss: 2.237400
		loss: 2.237300
		loss: 2.237100
		loss: 2.236900
		loss: 2.236800
		loss: 2.236700
		loss: 2.236700
		loss: 2.236700
		loss: 2.236700
		loss: 2.236700
		loss: 2.236600
		loss: 2.236400
		loss: 2.236200
		loss: 2.236000
		loss: 2.236000
		loss: 2.236000
		loss: 2.236100
		loss: 2.236200
		loss: 2.236500
		loss: 2.236500
		loss: 2.236500
		loss: 2.236100
		loss: 2.235600
		loss: 2.235300
		loss: 2.235300
		loss: 2.235500
		loss: 2.235500
		loss: 2.235200
		loss: 2.234900
		loss: 2.234800
		loss: 2.234900
		loss: 2.235000
		loss: 2.235200
		loss: 2.235300
		loss: 2.235400
		loss: 2.235300
		loss: 2.235200
		loss: 2.234700
		loss: 2.234300
		loss: 2.234100
		loss: 2.234100
		loss: 2.234300
		loss: 2.234300
		loss: 2.234100
		loss: 2.233800
		loss: 2.233600
		loss: 2.233600
		loss: 2.233700
		loss: 2.233800
		loss: 2.233700
		loss: 2.233600
		loss: 2.233400
		loss: 2.233100
		loss: 2.233000
		loss: 2.232900
		loss: 2.233000
		loss: 2.232900
		loss: 2.232900
		loss: 2.232800
		loss: 2.232700
		loss: 2.232500
		loss: 2.232400
		loss: 2.232300
		loss: 2.232200
		loss: 2.232200
		loss: 2.232100
		loss: 2.232000
		loss: 2.231900
		loss: 2.231900
		loss: 2.231900
		loss: 2.232000
		loss: 2.232200
		loss: 2.232700
		loss: 2.233000
		loss: 2.233200
		loss: 2.232900
		loss: 2.232200
		loss: 2.231400
		loss: 2.231200
		loss: 2.231500
		loss: 2.231800
		loss: 2.231900
		loss: 2.231400
		loss: 2.230900
		loss: 2.230800
		loss: 2.231000
		loss: 2.231100
		loss: 2.230900
		loss: 2.230600
		loss: 2.230400
		loss: 2.230400
		loss: 2.230500
		loss: 2.230500
		loss: 2.230400
		loss: 2.230200
		loss: 2.230000
		loss: 2.229900
		loss: 2.229800
		loss: 2.229800
		loss: 2.229800
		loss: 2.229700
		loss: 2.229700
		loss: 2.229600
		loss: 2.229500
		loss: 2.229400
		loss: 2.229300
		loss: 2.229200
		loss: 2.229100
		loss: 2.229000
		loss: 2.228900
		loss: 2.228800
		loss: 2.228800
		loss: 2.228700
		loss: 2.228700
		loss: 2.228700
		loss: 2.228700
		loss: 2.228800
		loss: 2.229100
		loss: 2.229300
		loss: 2.229600
		loss: 2.229600
		loss: 2.229200
		loss: 2.228500
		loss: 2.228100
		loss: 2.228000
		loss: 2.228200
		loss: 2.228200
		loss: 2.228000
		loss: 2.227700
		loss: 2.227600
		loss: 2.227700
		loss: 2.227900
		loss: 2.227900
		loss: 2.227900
		loss: 2.227700
		loss: 2.227500
		loss: 2.227200
		loss: 2.227000
		loss: 2.227000
		loss: 2.227000
		loss: 2.227100
		loss: 2.227000
		loss: 2.226800
		loss: 2.226600
		loss: 2.226500
		loss: 2.226500
		loss: 2.226500
		loss: 2.226600
		loss: 2.226700
		loss: 2.226900
		loss: 2.227000
		loss: 2.227100
		loss: 2.226800
		loss: 2.226400
		loss: 2.225900
		loss: 2.225800
		loss: 2.225900
		loss: 2.226000
		loss: 2.226000
		loss: 2.225700
		loss: 2.225500
		loss: 2.225400
		loss: 2.225400
		loss: 2.225600
		loss: 2.225600
		loss: 2.225700
		loss: 2.225600
		loss: 2.225500
		loss: 2.225300
		loss: 2.225000
		loss: 2.224800
		loss: 2.224700
	Overall the loss development was 2.244100 -> 2.224700
In the epoch 1 for problem d-01.pddl 0 explorations in the sampling searches reached a goal

Epoch 2:
Training data for problem d-01.pddl in epoch 2:
model creation time: 113.95283675193787s
problem epoch data for epoch 2, problem epoch 1
	sampling search time: 597.4574763774872s
	during this search the following actions were chosen:
		move-down-slow slow0-0 n4 n1 was chosen with probability 0.504070
		board p1 slow0-0 n1 n0 n1 was chosen with probability 0.992533
		move-down-slow slow0-0 n1 n0 was chosen with probability 0.499815
		board p3 slow0-0 n0 n1 n2 was chosen with probability 0.505416
		move-up-slow slow0-0 n0 n2 was chosen with probability 0.335306
		leave p1 slow0-0 n2 n2 n1 was chosen with probability 0.502931
		board p1 slow0-0 n2 n1 n2 was chosen with probability 0.523865
	training time: 604.0993685722351s
	during the training the following losses were computed:
		loss: 2.195100
		loss: 2.544300
		loss: 2.223500
		loss: 2.310800
		loss: 2.375000
		loss: 2.281800
		loss: 2.199400
		loss: 2.222600
		loss: 2.274000
		loss: 2.280400
		loss: 2.243400
		loss: 2.203600
		loss: 2.199900
		loss: 2.226500
		loss: 2.241400
		loss: 2.230200
		loss: 2.207900
		loss: 2.195600
		loss: 2.202300
		loss: 2.215000
		loss: 2.218100
		loss: 2.208900
		loss: 2.197000
		loss: 2.193900
		loss: 2.199400
		loss: 2.205600
		loss: 2.205500
		loss: 2.199600
		loss: 2.194000
		loss: 2.193300
		loss: 2.196600
		loss: 2.199500
		loss: 2.198800
		loss: 2.195300
		loss: 2.192400
		loss: 2.192400
		loss: 2.194400
		loss: 2.195600
		loss: 2.194400
		loss: 2.192200
		loss: 2.191100
		loss: 2.191700
		loss: 2.192800
		loss: 2.192800
		loss: 2.191500
		loss: 2.190400
		loss: 2.190300
		loss: 2.190900
		loss: 2.191200
		loss: 2.190600
		loss: 2.189700
		loss: 2.189400
		loss: 2.189700
		loss: 2.190000
		loss: 2.189600
		loss: 2.189000
		loss: 2.188800
		loss: 2.189000
		loss: 2.189000
		loss: 2.188800
		loss: 2.188400
		loss: 2.188200
		loss: 2.188300
		loss: 2.188300
		loss: 2.188000
		loss: 2.187800
		loss: 2.187700
		loss: 2.187700
		loss: 2.187600
		loss: 2.187400
		loss: 2.187200
		loss: 2.187200
		loss: 2.187100
		loss: 2.187000
		loss: 2.186800
		loss: 2.186700
		loss: 2.186700
		loss: 2.186600
		loss: 2.186400
		loss: 2.186300
		loss: 2.186300
		loss: 2.186200
		loss: 2.186100
		loss: 2.186000
		loss: 2.185900
		loss: 2.185800
		loss: 2.185700
		loss: 2.185600
		loss: 2.185500
		loss: 2.185400
		loss: 2.185300
		loss: 2.185200
		loss: 2.185200
		loss: 2.185100
		loss: 2.185000
		loss: 2.184900
		loss: 2.184800
		loss: 2.184700
		loss: 2.184600
		loss: 2.184600
		loss: 2.184500
		loss: 2.184400
		loss: 2.184300
		loss: 2.184200
		loss: 2.184200
		loss: 2.184100
		loss: 2.184000
		loss: 2.183900
		loss: 2.183800
		loss: 2.183800
		loss: 2.183700
		loss: 2.183600
		loss: 2.183500
		loss: 2.183500
		loss: 2.183400
		loss: 2.183300
		loss: 2.183200
		loss: 2.183200
		loss: 2.183100
		loss: 2.183000
		loss: 2.182900
		loss: 2.182900
		loss: 2.182800
		loss: 2.182700
		loss: 2.182700
		loss: 2.182600
		loss: 2.182500
		loss: 2.182500
		loss: 2.182400
		loss: 2.182300
		loss: 2.182300
		loss: 2.182200
		loss: 2.182100
		loss: 2.182100
		loss: 2.182000
		loss: 2.181900
		loss: 2.181900
		loss: 2.181800
		loss: 2.181700
		loss: 2.181700
		loss: 2.181600
		loss: 2.181500
		loss: 2.181500
		loss: 2.181400
		loss: 2.181300
		loss: 2.181300
		loss: 2.181200
		loss: 2.181200
		loss: 2.181100
		loss: 2.181000
		loss: 2.181000
		loss: 2.180900
		loss: 2.180900
		loss: 2.180800
		loss: 2.180700
		loss: 2.180700
		loss: 2.180600
		loss: 2.180600
		loss: 2.180500
		loss: 2.180500
		loss: 2.180400
		loss: 2.180300
		loss: 2.180300
		loss: 2.180200
		loss: 2.180200
		loss: 2.180100
		loss: 2.180100
		loss: 2.180000
		loss: 2.179900
		loss: 2.179900
		loss: 2.179800
		loss: 2.179800
		loss: 2.179700
		loss: 2.179700
		loss: 2.179600
		loss: 2.179600
		loss: 2.179500
		loss: 2.179500
		loss: 2.179400
		loss: 2.179400
		loss: 2.179300
		loss: 2.179300
		loss: 2.179200
		loss: 2.179100
		loss: 2.179100
		loss: 2.179000
		loss: 2.179000
		loss: 2.178900
		loss: 2.178900
		loss: 2.178800
		loss: 2.178800
		loss: 2.178700
		loss: 2.178700
		loss: 2.178600
		loss: 2.178600
		loss: 2.178500
		loss: 2.178500
		loss: 2.178400
		loss: 2.178400
		loss: 2.178300
		loss: 2.178300
		loss: 2.178200
		loss: 2.178200
		loss: 2.178200
		loss: 2.178100
		loss: 2.178100
		loss: 2.178000
		loss: 2.178000
		loss: 2.177900
		loss: 2.177900
		loss: 2.177800
		loss: 2.177800
		loss: 2.177700
		loss: 2.177700
		loss: 2.177600
		loss: 2.177600
		loss: 2.177500
		loss: 2.177500
		loss: 2.177500
		loss: 2.177400
		loss: 2.177400
		loss: 2.177300
		loss: 2.177300
		loss: 2.177200
		loss: 2.177200
		loss: 2.177100
		loss: 2.177100
		loss: 2.177100
		loss: 2.177000
		loss: 2.177000
		loss: 2.176900
		loss: 2.176900
		loss: 2.176800
		loss: 2.176800
		loss: 2.176700
		loss: 2.176700
		loss: 2.176700
		loss: 2.176600
		loss: 2.176600
		loss: 2.176500
		loss: 2.176500
		loss: 2.176500
		loss: 2.176400
		loss: 2.176400
		loss: 2.176300
		loss: 2.176300
		loss: 2.176200
		loss: 2.176200
		loss: 2.176200
		loss: 2.176100
		loss: 2.176100
		loss: 2.176000
		loss: 2.176000
		loss: 2.176000
		loss: 2.175900
		loss: 2.175900
	Overall the loss development was 2.195100 -> 2.175900
problem epoch data for epoch 2, problem epoch 2
	sampling search time: 448.80459809303284s
	during this search the following actions were chosen:
		move-down-slow slow0-0 n4 n1 was chosen with probability 0.506362
		board p1 slow0-0 n1 n0 n1 was chosen with probability 0.993555
		leave p1 slow0-0 n1 n1 n0 was chosen with probability 0.500932
	training time: 227.98338890075684s
	during the training the following losses were computed:
		loss: 2.205500
		loss: 2.205500
		loss: 2.205400
		loss: 2.205400
		loss: 2.205400
		loss: 2.205300
		loss: 2.205300
		loss: 2.205200
		loss: 2.205200
		loss: 2.205200
		loss: 2.205100
		loss: 2.205100
		loss: 2.205100
		loss: 2.205000
		loss: 2.205000
		loss: 2.204900
		loss: 2.204900
		loss: 2.204900
		loss: 2.204800
		loss: 2.204800
		loss: 2.204700
		loss: 2.204700
		loss: 2.204700
		loss: 2.204600
		loss: 2.204600
		loss: 2.204500
		loss: 2.204500
		loss: 2.204500
		loss: 2.204400
		loss: 2.204400
		loss: 2.204400
		loss: 2.204300
		loss: 2.204300
		loss: 2.204200
		loss: 2.204200
		loss: 2.204200
		loss: 2.204100
		loss: 2.204100
		loss: 2.204100
		loss: 2.204000
		loss: 2.204000
		loss: 2.203900
		loss: 2.203900
		loss: 2.203900
		loss: 2.203800
		loss: 2.203800
		loss: 2.203800
		loss: 2.203700
		loss: 2.203700
		loss: 2.203700
		loss: 2.203600
		loss: 2.203600
		loss: 2.203500
		loss: 2.203500
		loss: 2.203500
		loss: 2.203400
		loss: 2.203400
		loss: 2.203400
		loss: 2.203300
		loss: 2.203300
		loss: 2.203300
		loss: 2.203200
		loss: 2.203200
		loss: 2.203100
		loss: 2.203100
		loss: 2.203100
		loss: 2.203000
		loss: 2.203000
		loss: 2.203000
		loss: 2.202900
		loss: 2.202900
		loss: 2.202900
		loss: 2.202800
		loss: 2.202800
		loss: 2.202800
		loss: 2.202700
		loss: 2.202700
		loss: 2.202700
		loss: 2.202600
		loss: 2.202600
		loss: 2.202600
		loss: 2.202500
		loss: 2.202500
		loss: 2.202400
		loss: 2.202400
		loss: 2.202400
		loss: 2.202300
		loss: 2.202300
		loss: 2.202300
		loss: 2.202200
		loss: 2.202200
		loss: 2.202200
		loss: 2.202100
		loss: 2.202100
		loss: 2.202100
		loss: 2.202100
		loss: 2.202000
		loss: 2.202000
		loss: 2.201900
		loss: 2.201900
		loss: 2.201900
		loss: 2.201800
		loss: 2.201800
		loss: 2.201800
		loss: 2.201700
		loss: 2.201700
		loss: 2.201700
		loss: 2.201600
		loss: 2.201600
		loss: 2.201600
		loss: 2.201500
		loss: 2.201500
		loss: 2.201500
		loss: 2.201400
		loss: 2.201400
		loss: 2.201400
		loss: 2.201300
		loss: 2.201300
		loss: 2.201300
		loss: 2.201200
		loss: 2.201200
		loss: 2.201200
		loss: 2.201100
		loss: 2.201100
		loss: 2.201100
		loss: 2.201000
		loss: 2.201000
		loss: 2.201000
		loss: 2.200900
		loss: 2.200900
		loss: 2.200900
		loss: 2.200900
		loss: 2.200800
		loss: 2.200800
		loss: 2.200800
		loss: 2.200700
		loss: 2.200700
		loss: 2.200700
		loss: 2.200600
		loss: 2.200600
		loss: 2.200600
		loss: 2.200500
		loss: 2.200500
		loss: 2.200500
		loss: 2.200400
		loss: 2.200400
		loss: 2.200400
		loss: 2.200300
		loss: 2.200300
		loss: 2.200300
		loss: 2.200200
		loss: 2.200200
		loss: 2.200200
		loss: 2.200100
		loss: 2.200100
		loss: 2.200100
		loss: 2.200100
		loss: 2.200000
		loss: 2.200000
		loss: 2.200000
		loss: 2.199900
		loss: 2.199900
		loss: 2.199900
		loss: 2.199800
		loss: 2.199800
		loss: 2.199800
		loss: 2.199700
		loss: 2.199700
		loss: 2.199700
		loss: 2.199600
		loss: 2.199600
		loss: 2.199600
		loss: 2.199500
		loss: 2.199500
		loss: 2.199500
		loss: 2.199500
		loss: 2.199400
		loss: 2.199400
		loss: 2.199400
		loss: 2.199300
		loss: 2.199300
		loss: 2.199300
		loss: 2.199200
		loss: 2.199200
		loss: 2.199200
		loss: 2.199100
		loss: 2.199100
		loss: 2.199100
		loss: 2.199100
		loss: 2.199000
		loss: 2.199000
		loss: 2.199000
		loss: 2.198900
		loss: 2.198900
		loss: 2.198900
		loss: 2.198900
		loss: 2.198800
		loss: 2.198800
		loss: 2.198700
		loss: 2.198700
		loss: 2.198700
		loss: 2.198700
		loss: 2.198600
		loss: 2.198600
		loss: 2.198600
		loss: 2.198500
		loss: 2.198500
		loss: 2.198500
		loss: 2.198500
		loss: 2.198400
		loss: 2.198400
		loss: 2.198400
		loss: 2.198300
		loss: 2.198300
		loss: 2.198300
		loss: 2.198200
		loss: 2.198200
		loss: 2.198200
		loss: 2.198100
		loss: 2.198100
		loss: 2.198100
		loss: 2.198000
		loss: 2.198000
		loss: 2.198000
		loss: 2.198000
		loss: 2.197900
		loss: 2.197900
		loss: 2.197900
		loss: 2.197800
		loss: 2.197800
		loss: 2.197800
		loss: 2.197800
		loss: 2.197700
		loss: 2.197700
		loss: 2.197700
		loss: 2.197600
		loss: 2.197600
		loss: 2.197600
		loss: 2.197500
		loss: 2.197500
		loss: 2.197500
		loss: 2.197500
		loss: 2.197400
		loss: 2.197400
		loss: 2.197400
		loss: 2.197300
		loss: 2.197300
		loss: 2.197300
		loss: 2.197200
		loss: 2.197200
		loss: 2.197200
		loss: 2.197200
		loss: 2.197100
		loss: 2.197100
		loss: 2.197100
		loss: 2.197000
	Overall the loss development was 2.205500 -> 2.197000
problem epoch data for epoch 2, problem epoch 3
	sampling search time: 449.4085760116577s
	during this search the following actions were chosen:
		move-down-slow slow0-0 n4 n1 was chosen with probability 0.505038
		board p1 slow0-0 n1 n0 n1 was chosen with probability 0.994154
		leave p1 slow0-0 n1 n1 n0 was chosen with probability 0.500793
	training time: 227.47722172737122s
	during the training the following losses were computed:
		loss: 2.197000
		loss: 2.197000
		loss: 2.197000
		loss: 2.196900
		loss: 2.196900
		loss: 2.196900
		loss: 2.196800
		loss: 2.196800
		loss: 2.196800
		loss: 2.196700
		loss: 2.196700
		loss: 2.196700
		loss: 2.196700
		loss: 2.196600
		loss: 2.196600
		loss: 2.196600
		loss: 2.196500
		loss: 2.196500
		loss: 2.196500
		loss: 2.196500
		loss: 2.196400
		loss: 2.196400
		loss: 2.196400
		loss: 2.196300
		loss: 2.196300
		loss: 2.196300
		loss: 2.196200
		loss: 2.196200
		loss: 2.196200
		loss: 2.196200
		loss: 2.196100
		loss: 2.196100
		loss: 2.196100
		loss: 2.196100
		loss: 2.196000
		loss: 2.196000
		loss: 2.196000
		loss: 2.195900
		loss: 2.195900
		loss: 2.195900
		loss: 2.195800
		loss: 2.195800
		loss: 2.195800
		loss: 2.195800
		loss: 2.195700
		loss: 2.195700
		loss: 2.195700
		loss: 2.195600
		loss: 2.195600
		loss: 2.195600
		loss: 2.195600
		loss: 2.195600
		loss: 2.195500
		loss: 2.195500
		loss: 2.195500
		loss: 2.195400
		loss: 2.195400
		loss: 2.195400
		loss: 2.195300
		loss: 2.195300
		loss: 2.195300
		loss: 2.195300
		loss: 2.195200
		loss: 2.195200
		loss: 2.195200
		loss: 2.195100
		loss: 2.195100
		loss: 2.195100
		loss: 2.195000
		loss: 2.195000
		loss: 2.195000
		loss: 2.195000
		loss: 2.194900
		loss: 2.194900
		loss: 2.194900
		loss: 2.194800
		loss: 2.194800
		loss: 2.194800
		loss: 2.194800
		loss: 2.194700
		loss: 2.194700
		loss: 2.194700
		loss: 2.194600
		loss: 2.194600
		loss: 2.194600
		loss: 2.194600
		loss: 2.194500
		loss: 2.194500
		loss: 2.194500
		loss: 2.194400
		loss: 2.194400
		loss: 2.194400
		loss: 2.194400
		loss: 2.194300
		loss: 2.194300
		loss: 2.194300
		loss: 2.194200
		loss: 2.194200
		loss: 2.194200
		loss: 2.194200
		loss: 2.194100
		loss: 2.194100
		loss: 2.194100
		loss: 2.194100
		loss: 2.194000
		loss: 2.194000
		loss: 2.194000
		loss: 2.193900
		loss: 2.193900
		loss: 2.193900
		loss: 2.193900
		loss: 2.193800
		loss: 2.193800
		loss: 2.193800
		loss: 2.193700
		loss: 2.193700
		loss: 2.193700
		loss: 2.193700
		loss: 2.193700
		loss: 2.193700
		loss: 2.193700
		loss: 2.193600
		loss: 2.193500
		loss: 2.193500
		loss: 2.193500
		loss: 2.193500
		loss: 2.193500
		loss: 2.193400
		loss: 2.193300
		loss: 2.193300
		loss: 2.193300
		loss: 2.193300
		loss: 2.193300
		loss: 2.193200
		loss: 2.193200
		loss: 2.193100
		loss: 2.193100
		loss: 2.193100
		loss: 2.193100
		loss: 2.193100
		loss: 2.193000
		loss: 2.193000
		loss: 2.193000
		loss: 2.192900
		loss: 2.192900
		loss: 2.192900
		loss: 2.192800
		loss: 2.192800
		loss: 2.192800
		loss: 2.192800
		loss: 2.192700
		loss: 2.192700
		loss: 2.192700
		loss: 2.192600
		loss: 2.192600
		loss: 2.192600
		loss: 2.192600
		loss: 2.192500
		loss: 2.192500
		loss: 2.192500
		loss: 2.192500
		loss: 2.192400
		loss: 2.192400
		loss: 2.192400
		loss: 2.192300
		loss: 2.192300
		loss: 2.192300
		loss: 2.192300
		loss: 2.192200
		loss: 2.192200
		loss: 2.192200
		loss: 2.192100
		loss: 2.192100
		loss: 2.192100
		loss: 2.192100
		loss: 2.192000
		loss: 2.192000
		loss: 2.192000
		loss: 2.192000
		loss: 2.191900
		loss: 2.191900
		loss: 2.191900
		loss: 2.191900
		loss: 2.191800
		loss: 2.191800
		loss: 2.191700
		loss: 2.191700
		loss: 2.191700
		loss: 2.191700
		loss: 2.191700
		loss: 2.191600
		loss: 2.191600
		loss: 2.191600
		loss: 2.191600
		loss: 2.191500
		loss: 2.191500
		loss: 2.191500
		loss: 2.191400
		loss: 2.191400
		loss: 2.191400
		loss: 2.191300
		loss: 2.191300
		loss: 2.191300
		loss: 2.191300
		loss: 2.191200
		loss: 2.191200
		loss: 2.191200
		loss: 2.191200
		loss: 2.191100
		loss: 2.191100
		loss: 2.191100
		loss: 2.191000
		loss: 2.191000
		loss: 2.191000
		loss: 2.190900
		loss: 2.190900
		loss: 2.190900
		loss: 2.190900
		loss: 2.190800
		loss: 2.190800
		loss: 2.190800
		loss: 2.190800
		loss: 2.190800
		loss: 2.190800
		loss: 2.190800
		loss: 2.190700
		loss: 2.190700
		loss: 2.190600
		loss: 2.190600
		loss: 2.190500
		loss: 2.190500
		loss: 2.190500
		loss: 2.190500
		loss: 2.190500
		loss: 2.190500
		loss: 2.190500
		loss: 2.190400
		loss: 2.190400
		loss: 2.190300
		loss: 2.190300
		loss: 2.190200
		loss: 2.190200
		loss: 2.190200
		loss: 2.190300
		loss: 2.190200
		loss: 2.190200
		loss: 2.190100
		loss: 2.190100
		loss: 2.190000
		loss: 2.190000
		loss: 2.190000
		loss: 2.190000
		loss: 2.190000
		loss: 2.189900
		loss: 2.189900
		loss: 2.189800
	Overall the loss development was 2.197000 -> 2.189800
problem epoch data for epoch 2, problem epoch 4
	sampling search time: 448.99132204055786s
	during this search the following actions were chosen:
		move-down-slow slow0-0 n4 n1 was chosen with probability 0.506096
		board p1 slow0-0 n1 n0 n1 was chosen with probability 0.994845
		leave p1 slow0-0 n1 n1 n0 was chosen with probability 0.501261
	training time: 228.28290247917175s
	during the training the following losses were computed:
		loss: 2.189800
		loss: 2.189800
		loss: 2.189800
		loss: 2.189700
		loss: 2.189700
		loss: 2.189700
		loss: 2.189700
		loss: 2.189600
		loss: 2.189600
		loss: 2.189600
		loss: 2.189600
		loss: 2.189600
		loss: 2.189600
		loss: 2.189500
		loss: 2.189500
		loss: 2.189400
		loss: 2.189400
		loss: 2.189400
		loss: 2.189400
		loss: 2.189400
		loss: 2.189400
		loss: 2.189400
		loss: 2.189400
		loss: 2.189300
		loss: 2.189300
		loss: 2.189200
		loss: 2.189100
		loss: 2.189100
		loss: 2.189100
		loss: 2.189100
		loss: 2.189100
		loss: 2.189100
		loss: 2.189000
		loss: 2.189000
		loss: 2.188900
		loss: 2.188900
		loss: 2.188900
		loss: 2.188900
		loss: 2.188800
		loss: 2.188800
		loss: 2.188800
		loss: 2.188800
		loss: 2.188800
		loss: 2.188800
		loss: 2.188700
		loss: 2.188700
		loss: 2.188600
		loss: 2.188600
		loss: 2.188600
		loss: 2.188500
		loss: 2.188500
		loss: 2.188500
		loss: 2.188500
		loss: 2.188500
		loss: 2.188500
		loss: 2.188500
		loss: 2.188400
		loss: 2.188400
		loss: 2.188300
		loss: 2.188300
		loss: 2.188200
		loss: 2.188200
		loss: 2.188200
		loss: 2.188200
		loss: 2.188200
		loss: 2.188200
		loss: 2.188200
		loss: 2.188200
		loss: 2.188100
		loss: 2.188100
		loss: 2.188000
		loss: 2.188000
		loss: 2.188000
		loss: 2.188000
		loss: 2.188000
		loss: 2.188000
		loss: 2.188000
		loss: 2.187900
		loss: 2.187900
		loss: 2.187800
		loss: 2.187800
		loss: 2.187700
		loss: 2.187700
		loss: 2.187700
		loss: 2.187700
		loss: 2.187700
		loss: 2.187700
		loss: 2.187600
		loss: 2.187600
		loss: 2.187500
		loss: 2.187500
		loss: 2.187500
		loss: 2.187500
		loss: 2.187500
		loss: 2.187400
		loss: 2.187400
		loss: 2.187400
		loss: 2.187300
		loss: 2.187300
		loss: 2.187300
		loss: 2.187200
		loss: 2.187200
		loss: 2.187200
		loss: 2.187200
		loss: 2.187200
		loss: 2.187200
		loss: 2.187200
		loss: 2.187100
		loss: 2.187100
		loss: 2.187000
		loss: 2.187000
		loss: 2.187000
		loss: 2.187000
		loss: 2.187000
		loss: 2.187000
		loss: 2.187100
		loss: 2.187100
		loss: 2.187200
		loss: 2.187100
		loss: 2.187000
		loss: 2.186800
		loss: 2.186700
		loss: 2.186700
		loss: 2.186800
		loss: 2.186800
		loss: 2.186700
		loss: 2.186700
		loss: 2.186600
		loss: 2.186600
		loss: 2.186600
		loss: 2.186600
		loss: 2.186600
		loss: 2.186600
		loss: 2.186600
		loss: 2.186500
		loss: 2.186400
		loss: 2.186400
		loss: 2.186300
		loss: 2.186300
		loss: 2.186400
		loss: 2.186400
		loss: 2.186300
		loss: 2.186300
		loss: 2.186300
		loss: 2.186200
		loss: 2.186100
		loss: 2.186100
		loss: 2.186100
		loss: 2.186100
		loss: 2.186100
		loss: 2.186100
		loss: 2.186100
		loss: 2.186100
		loss: 2.186100
		loss: 2.186000
		loss: 2.185900
		loss: 2.185900
		loss: 2.185800
		loss: 2.185800
		loss: 2.185800
		loss: 2.185900
		loss: 2.185900
		loss: 2.185900
		loss: 2.185800
		loss: 2.185700
		loss: 2.185700
		loss: 2.185600
		loss: 2.185600
		loss: 2.185600
		loss: 2.185700
		loss: 2.185700
		loss: 2.185700
		loss: 2.185600
		loss: 2.185500
		loss: 2.185500
		loss: 2.185400
		loss: 2.185400
		loss: 2.185400
		loss: 2.185400
		loss: 2.185400
		loss: 2.185500
		loss: 2.185500
		loss: 2.185500
		loss: 2.185400
		loss: 2.185300
		loss: 2.185200
		loss: 2.185200
		loss: 2.185200
		loss: 2.185200
		loss: 2.185200
		loss: 2.185100
		loss: 2.185100
		loss: 2.185100
		loss: 2.185000
		loss: 2.185000
		loss: 2.185000
		loss: 2.184900
		loss: 2.184900
		loss: 2.184900
		loss: 2.184800
		loss: 2.184800
		loss: 2.184800
		loss: 2.184800
		loss: 2.184800
		loss: 2.184700
		loss: 2.184700
		loss: 2.184700
		loss: 2.184800
		loss: 2.184800
		loss: 2.184800
		loss: 2.184800
		loss: 2.184800
		loss: 2.184700
		loss: 2.184600
		loss: 2.184500
		loss: 2.184500
		loss: 2.184500
		loss: 2.184500
		loss: 2.184500
		loss: 2.184500
		loss: 2.184600
		loss: 2.184600
		loss: 2.184600
		loss: 2.184500
		loss: 2.184400
		loss: 2.184300
		loss: 2.184200
		loss: 2.184300
		loss: 2.184300
		loss: 2.184300
		loss: 2.184200
		loss: 2.184200
		loss: 2.184100
		loss: 2.184100
		loss: 2.184000
		loss: 2.184000
		loss: 2.184000
		loss: 2.184000
		loss: 2.184000
		loss: 2.184000
		loss: 2.184100
		loss: 2.184100
		loss: 2.184200
		loss: 2.184200
		loss: 2.184100
		loss: 2.184000
		loss: 2.183900
		loss: 2.183800
		loss: 2.183700
		loss: 2.183700
		loss: 2.183700
		loss: 2.183800
		loss: 2.183800
		loss: 2.183900
		loss: 2.183800
		loss: 2.183700
	Overall the loss development was 2.189800 -> 2.183700
problem epoch data for epoch 2, problem epoch 5
	sampling search time: 450.1422233581543s
	during this search the following actions were chosen:
		move-down-slow slow0-0 n4 n1 was chosen with probability 0.505822
		board p1 slow0-0 n1 n0 n1 was chosen with probability 0.995244
		leave p1 slow0-0 n1 n1 n0 was chosen with probability 0.503524
	training time: 227.4831738471985s
	during the training the following losses were computed:
		loss: 2.183600
		loss: 2.183500
		loss: 2.183500
		loss: 2.183600
		loss: 2.183600
		loss: 2.183600
		loss: 2.183600
		loss: 2.183600
		loss: 2.183500
		loss: 2.183400
		loss: 2.183300
		loss: 2.183300
		loss: 2.183300
		loss: 2.183300
		loss: 2.183300
		loss: 2.183300
		loss: 2.183300
		loss: 2.183300
		loss: 2.183200
		loss: 2.183200
		loss: 2.183200
		loss: 2.183100
		loss: 2.183100
		loss: 2.183000
		loss: 2.183000
		loss: 2.183000
		loss: 2.182900
		loss: 2.182900
		loss: 2.182900
		loss: 2.182900
		loss: 2.183000
		loss: 2.183000
		loss: 2.183200
		loss: 2.183300
		loss: 2.183300
		loss: 2.183200
		loss: 2.183000
		loss: 2.182800
		loss: 2.182700
		loss: 2.182700
		loss: 2.182800
		loss: 2.182900
		loss: 2.182900
		loss: 2.182800
		loss: 2.182700
		loss: 2.182600
		loss: 2.182500
		loss: 2.182500
		loss: 2.182500
		loss: 2.182500
		loss: 2.182600
		loss: 2.182600
		loss: 2.182600
		loss: 2.182500
		loss: 2.182400
		loss: 2.182300
		loss: 2.182300
		loss: 2.182300
		loss: 2.182300
		loss: 2.182400
		loss: 2.182500
		loss: 2.182600
		loss: 2.182600
		loss: 2.182500
		loss: 2.182300
		loss: 2.182100
		loss: 2.182100
		loss: 2.182100
		loss: 2.182200
		loss: 2.182200
		loss: 2.182200
		loss: 2.182100
		loss: 2.182000
		loss: 2.181900
		loss: 2.181900
		loss: 2.181900
		loss: 2.181800
		loss: 2.181800
		loss: 2.181800
		loss: 2.181900
		loss: 2.181900
		loss: 2.182100
		loss: 2.182200
		loss: 2.182500
		loss: 2.182600
		loss: 2.182700
		loss: 2.182600
		loss: 2.182300
		loss: 2.181900
		loss: 2.181600
		loss: 2.181600
		loss: 2.181700
		loss: 2.181900
		loss: 2.181900
		loss: 2.181800
		loss: 2.181600
		loss: 2.181400
		loss: 2.181400
		loss: 2.181500
		loss: 2.181600
		loss: 2.181500
		loss: 2.181400
		loss: 2.181300
		loss: 2.181300
		loss: 2.181200
		loss: 2.181300
		loss: 2.181300
		loss: 2.181300
		loss: 2.181400
		loss: 2.181500
		loss: 2.181500
		loss: 2.181500
		loss: 2.181400
		loss: 2.181300
		loss: 2.181100
		loss: 2.181000
		loss: 2.181000
		loss: 2.181000
		loss: 2.181000
		loss: 2.181100
		loss: 2.181200
		loss: 2.181400
		loss: 2.181500
		loss: 2.181600
		loss: 2.181400
		loss: 2.181200
		loss: 2.180900
		loss: 2.180800
		loss: 2.180900
		loss: 2.181000
		loss: 2.181100
		loss: 2.181000
		loss: 2.180800
		loss: 2.180600
		loss: 2.180700
		loss: 2.180800
		loss: 2.180900
		loss: 2.181100
		loss: 2.181000
		loss: 2.181000
		loss: 2.180700
		loss: 2.180500
		loss: 2.180500
		loss: 2.180500
		loss: 2.180600
		loss: 2.180600
		loss: 2.180500
		loss: 2.180400
		loss: 2.180300
		loss: 2.180300
		loss: 2.180300
		loss: 2.180300
		loss: 2.180300
		loss: 2.180400
		loss: 2.180500
		loss: 2.180700
		loss: 2.180900
		loss: 2.181000
		loss: 2.180900
		loss: 2.180600
		loss: 2.180300
		loss: 2.180100
		loss: 2.180100
		loss: 2.180300
		loss: 2.180400
		loss: 2.180300
		loss: 2.180100
		loss: 2.180000
		loss: 2.179900
		loss: 2.180000
		loss: 2.180100
		loss: 2.180200
		loss: 2.180100
		loss: 2.180000
		loss: 2.179900
		loss: 2.179800
		loss: 2.179800
		loss: 2.179800
		loss: 2.179800
		loss: 2.179800
		loss: 2.179800
		loss: 2.179800
		loss: 2.179800
		loss: 2.179700
		loss: 2.179700
		loss: 2.179700
		loss: 2.179600
		loss: 2.179500
		loss: 2.179500
		loss: 2.179500
		loss: 2.179500
		loss: 2.179400
		loss: 2.179400
		loss: 2.179500
		loss: 2.179500
		loss: 2.179700
		loss: 2.179800
		loss: 2.180000
		loss: 2.180100
		loss: 2.180100
		loss: 2.179900
		loss: 2.179600
		loss: 2.179300
		loss: 2.179200
		loss: 2.179300
		loss: 2.179400
		loss: 2.179700
		loss: 2.179800
		loss: 2.179900
		loss: 2.179700
		loss: 2.179400
		loss: 2.179100
		loss: 2.179100
		loss: 2.179200
		loss: 2.179400
		loss: 2.179300
		loss: 2.179100
		loss: 2.178900
		loss: 2.179000
		loss: 2.179000
		loss: 2.179100
		loss: 2.179100
		loss: 2.179100
		loss: 2.179000
		loss: 2.178900
		loss: 2.178900
		loss: 2.178800
		loss: 2.178800
		loss: 2.178700
		loss: 2.178700
		loss: 2.178700
		loss: 2.178700
		loss: 2.178700
		loss: 2.178700
		loss: 2.178700
		loss: 2.178700
		loss: 2.178700
		loss: 2.178700
		loss: 2.178700
		loss: 2.178800
		loss: 2.178900
		loss: 2.178900
		loss: 2.178800
		loss: 2.178600
		loss: 2.178400
		loss: 2.178400
		loss: 2.178400
		loss: 2.178500
		loss: 2.178500
		loss: 2.178500
		loss: 2.178500
		loss: 2.178500
		loss: 2.178400
		loss: 2.178400
		loss: 2.178300
		loss: 2.178200
	Overall the loss development was 2.183600 -> 2.178200
In the epoch 2 for problem d-01.pddl 0 explorations in the sampling searches reached a goal

Epoch 3:
Training data for problem d-01.pddl in epoch 3:
model creation time: 116.85602855682373s

