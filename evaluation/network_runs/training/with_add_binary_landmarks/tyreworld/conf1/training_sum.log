Training log data for domain tyreworld:
printing the data chronological
Epoch 1:
Training data for problem d-01.pddl in epoch 1:
model creation time: 6.695791482925415s
problem epoch data for epoch 1, problem epoch 1
	sampling search time: 1.9573924541473389s
	during this search the following actions were chosen:
		close boot was chosen with probability 0.000000
	training time: 36.657861948013306s
	during the training the following losses were computed:
		loss: 4.325700
		loss: 4.122700
		loss: 3.974100
		loss: 3.866100
		loss: 3.783400
		loss: 3.715100
		loss: 3.656000
		loss: 3.602900
		loss: 3.553600
		loss: 3.506500
		loss: 3.460800
		loss: 3.416500
		loss: 3.373800
		loss: 3.332600
		loss: 3.292400
		loss: 3.253200
		loss: 3.215200
		loss: 3.177700
		loss: 3.140700
		loss: 3.103400
		loss: 3.065700
		loss: 3.027900
		loss: 2.990500
		loss: 2.954000
		loss: 2.918200
		loss: 2.884100
		loss: 2.851400
		loss: 2.820000
		loss: 2.790300
		loss: 2.761900
		loss: 2.735000
		loss: 2.709300
		loss: 2.684800
		loss: 2.661900
		loss: 2.640600
		loss: 2.620800
		loss: 2.602300
		loss: 2.585100
		loss: 2.569100
		loss: 2.554000
		loss: 2.539800
		loss: 2.526400
		loss: 2.513700
		loss: 2.502000
		loss: 2.491100
		loss: 2.480700
		loss: 2.471100
		loss: 2.462100
		loss: 2.453900
		loss: 2.446300
		loss: 2.439300
		loss: 2.432700
		loss: 2.426500
		loss: 2.420500
		loss: 2.414800
		loss: 2.409300
		loss: 2.404100
		loss: 2.399000
		loss: 2.394200
		loss: 2.389500
		loss: 2.385100
		loss: 2.380800
		loss: 2.376600
		loss: 2.372600
		loss: 2.368700
		loss: 2.364900
		loss: 2.361200
		loss: 2.357600
		loss: 2.354000
		loss: 2.350400
		loss: 2.346900
		loss: 2.343500
		loss: 2.340100
		loss: 2.336700
		loss: 2.333400
		loss: 2.330200
		loss: 2.326900
		loss: 2.323700
		loss: 2.320500
		loss: 2.317300
		loss: 2.314200
		loss: 2.311000
		loss: 2.307900
		loss: 2.304800
		loss: 2.301800
		loss: 2.298700
		loss: 2.295700
		loss: 2.292600
		loss: 2.289600
		loss: 2.286700
		loss: 2.283700
		loss: 2.280700
		loss: 2.277800
		loss: 2.274800
		loss: 2.271900
		loss: 2.269000
		loss: 2.266100
		loss: 2.263200
		loss: 2.260300
		loss: 2.257500
	Overall the loss development was 4.325700 -> 2.257500
problem epoch data for epoch 1, problem epoch 2
	sampling search time: 1.8680872917175293s
	during this search the following actions were chosen:
		close boot was chosen with probability 0.000000
	training time: 10.128001689910889s
	during the training the following losses were computed:
		loss: 2.254600
		loss: 2.251800
		loss: 2.248900
		loss: 2.246100
		loss: 2.243300
		loss: 2.240500
		loss: 2.237800
		loss: 2.235000
		loss: 2.232200
		loss: 2.229500
		loss: 2.226800
		loss: 2.224000
		loss: 2.221300
		loss: 2.218600
		loss: 2.215900
		loss: 2.213300
		loss: 2.210600
		loss: 2.207900
		loss: 2.205300
		loss: 2.202700
		loss: 2.200000
		loss: 2.197400
		loss: 2.194800
		loss: 2.192200
		loss: 2.189600
		loss: 2.187100
		loss: 2.184500
		loss: 2.182000
		loss: 2.179400
		loss: 2.176900
		loss: 2.174400
		loss: 2.171900
		loss: 2.169400
		loss: 2.166900
		loss: 2.164400
		loss: 2.161900
		loss: 2.159500
		loss: 2.157000
		loss: 2.154600
		loss: 2.152200
		loss: 2.149800
		loss: 2.147400
		loss: 2.145000
		loss: 2.142600
		loss: 2.140200
		loss: 2.137800
		loss: 2.135500
		loss: 2.133100
		loss: 2.130800
		loss: 2.128500
		loss: 2.126200
		loss: 2.123900
		loss: 2.121600
		loss: 2.119300
		loss: 2.117000
		loss: 2.114800
		loss: 2.112500
		loss: 2.110300
		loss: 2.108000
		loss: 2.105800
		loss: 2.103600
		loss: 2.101400
		loss: 2.099200
		loss: 2.097000
		loss: 2.094900
		loss: 2.092700
		loss: 2.090500
		loss: 2.088400
		loss: 2.086300
		loss: 2.084100
		loss: 2.082000
		loss: 2.079900
		loss: 2.077800
		loss: 2.075700
		loss: 2.073600
		loss: 2.071600
		loss: 2.069500
		loss: 2.067500
		loss: 2.065400
		loss: 2.063400
		loss: 2.061400
		loss: 2.059400
		loss: 2.057300
		loss: 2.055400
		loss: 2.053400
		loss: 2.051400
		loss: 2.049400
		loss: 2.047500
		loss: 2.045500
		loss: 2.043600
		loss: 2.041600
		loss: 2.039700
		loss: 2.037800
		loss: 2.035900
		loss: 2.034000
		loss: 2.032100
		loss: 2.030200
		loss: 2.028400
		loss: 2.026500
		loss: 2.024700
	Overall the loss development was 2.254600 -> 2.024700
problem epoch data for epoch 1, problem epoch 3
	sampling search time: 3.4125144481658936s
	during this search the following actions were chosen:
		open boot was chosen with probability 1.000000
		fetch pump boot was chosen with probability 0.264048
		inflate r1 was chosen with probability 0.372511
		fetch r1 boot was chosen with probability 0.334521
		fetch wrench boot was chosen with probability 0.502901
		fetch jack boot was chosen with probability 0.552709
		loosen nuts1 the-hub1 was chosen with probability 0.964695
		jack-up the-hub1 was chosen with probability 0.983944
		undo nuts1 the-hub1 was chosen with probability 0.991450
		remove-wheel w1 the-hub1 was chosen with probability 0.989544
		put-on-wheel r1 the-hub1 was chosen with probability 0.600316
		put-away w1 boot was chosen with probability 0.901786
		do-up nuts1 the-hub1 was chosen with probability 0.535575
		undo nuts1 the-hub1 was chosen with probability 0.371539
	training time: 10.137613534927368s
	during the training the following losses were computed:
		loss: 2.367800
		loss: 2.285000
		loss: 2.211500
		loss: 2.186400
		loss: 2.171100
		loss: 2.148500
		loss: 2.129100
		loss: 2.113200
		loss: 2.105700
		loss: 2.108900
		loss: 2.112800
		loss: 2.111500
		loss: 2.108400
		loss: 2.104600
		loss: 2.099900
		loss: 2.093500
		loss: 2.083600
		loss: 2.072300
		loss: 2.065000
		loss: 2.063000
		loss: 2.062400
		loss: 2.061100
		loss: 2.059500
		loss: 2.057700
		loss: 2.055500
		loss: 2.053600
		loss: 2.051900
		loss: 2.049800
		loss: 2.046700
		loss: 2.043100
		loss: 2.039400
		loss: 2.036500
		loss: 2.034300
		loss: 2.032200
		loss: 2.030100
		loss: 2.028500
		loss: 2.027400
		loss: 2.026200
		loss: 2.024800
		loss: 2.023400
		loss: 2.021900
		loss: 2.020100
		loss: 2.018300
		loss: 2.016700
		loss: 2.015200
		loss: 2.013600
		loss: 2.011900
		loss: 2.010200
		loss: 2.008700
		loss: 2.007300
		loss: 2.006100
		loss: 2.004900
		loss: 2.003600
		loss: 2.002400
		loss: 2.001000
		loss: 1.999600
		loss: 1.998300
		loss: 1.996900
		loss: 1.995600
		loss: 1.994300
		loss: 1.993100
		loss: 1.991800
		loss: 1.990600
		loss: 1.989400
		loss: 1.988200
		loss: 1.987000
		loss: 1.985800
		loss: 1.984600
		loss: 1.983400
		loss: 1.982200
		loss: 1.981000
		loss: 1.979800
		loss: 1.978600
		loss: 1.977400
		loss: 1.976300
		loss: 1.975100
		loss: 1.974000
		loss: 1.972900
		loss: 1.971700
		loss: 1.970600
		loss: 1.969500
		loss: 1.968400
		loss: 1.967200
		loss: 1.966100
		loss: 1.965000
		loss: 1.963900
		loss: 1.962800
		loss: 1.961700
		loss: 1.960700
		loss: 1.959600
		loss: 1.958500
		loss: 1.957400
		loss: 1.956400
		loss: 1.955300
		loss: 1.954300
		loss: 1.953200
		loss: 1.952200
		loss: 1.951100
		loss: 1.950100
		loss: 1.949000
	Overall the loss development was 2.367800 -> 1.949000
In the epoch 1 for problem d-01.pddl 0 explorations in the sampling searches reached a goal
Training data for problem d-02.pddl in epoch 1:
model creation time: 16.866180896759033s
problem epoch data for epoch 1, problem epoch 1
	sampling search time: 33.27924466133118s
	during this search the following actions were chosen:
		close boot was chosen with probability 0.000000
	training time: 64.92352986335754s
	during the training the following losses were computed:
		loss: 3.161900
		loss: 2.996000
		loss: 2.985400
		loss: 2.963100
		loss: 2.924000
		loss: 2.903800
		loss: 2.904900
		loss: 2.907500
		loss: 2.898300
		loss: 2.881100
		loss: 2.867100
		loss: 2.861100
		loss: 2.859400
		loss: 2.856000
		loss: 2.849100
		loss: 2.841300
		loss: 2.835300
		loss: 2.830600
		loss: 2.825200
		loss: 2.818600
		loss: 2.812600
		loss: 2.808800
		loss: 2.806100
		loss: 2.802800
		loss: 2.798500
		loss: 2.794000
		loss: 2.790600
		loss: 2.787800
		loss: 2.784900
		loss: 2.781500
		loss: 2.778200
		loss: 2.775600
		loss: 2.773400
		loss: 2.770800
		loss: 2.767700
		loss: 2.764700
		loss: 2.762500
		loss: 2.760800
		loss: 2.759000
		loss: 2.756900
		loss: 2.754700
		loss: 2.752600
		loss: 2.750700
		loss: 2.748800
		loss: 2.746900
		loss: 2.745300
		loss: 2.743900
		loss: 2.742400
		loss: 2.740700
		loss: 2.739200
		loss: 2.737800
		loss: 2.736500
		loss: 2.735200
		loss: 2.733900
		loss: 2.732600
		loss: 2.731300
		loss: 2.730100
		loss: 2.728900
		loss: 2.727800
		loss: 2.726700
		loss: 2.725500
		loss: 2.724400
		loss: 2.723400
		loss: 2.722400
		loss: 2.721400
		loss: 2.720400
		loss: 2.719400
		loss: 2.718400
		loss: 2.717400
		loss: 2.716400
		loss: 2.715500
		loss: 2.714600
		loss: 2.713600
		loss: 2.712700
		loss: 2.711800
		loss: 2.710900
		loss: 2.710000
		loss: 2.709100
		loss: 2.708200
		loss: 2.707300
		loss: 2.706500
		loss: 2.705600
		loss: 2.704800
		loss: 2.703900
		loss: 2.703100
		loss: 2.702300
		loss: 2.701400
		loss: 2.700600
		loss: 2.699800
		loss: 2.699000
		loss: 2.698200
		loss: 2.697400
		loss: 2.696600
		loss: 2.695800
		loss: 2.695000
		loss: 2.694200
		loss: 2.693500
		loss: 2.692700
		loss: 2.691900
		loss: 2.691200
	Overall the loss development was 3.161900 -> 2.691200
problem epoch data for epoch 1, problem epoch 2
	sampling search time: 33.47255063056946s
	during this search the following actions were chosen:
		close boot was chosen with probability 0.000000
	training time: 10.139134883880615s
	during the training the following losses were computed:
		loss: 2.690400
		loss: 2.689600
		loss: 2.688900
		loss: 2.688100
		loss: 2.687400
		loss: 2.686600
		loss: 2.685900
		loss: 2.685200
		loss: 2.684400
		loss: 2.683700
		loss: 2.683000
		loss: 2.682300
		loss: 2.681500
		loss: 2.680800
		loss: 2.680100
		loss: 2.679400
		loss: 2.678700
		loss: 2.678000
		loss: 2.677300
		loss: 2.676600
		loss: 2.675900
		loss: 2.675200
		loss: 2.674500
		loss: 2.673900
		loss: 2.673200
		loss: 2.672500
		loss: 2.671800
		loss: 2.671200
		loss: 2.670500
		loss: 2.669800
		loss: 2.669200
		loss: 2.668500
		loss: 2.667800
		loss: 2.667200
		loss: 2.666500
		loss: 2.665900
		loss: 2.665200
		loss: 2.664600
		loss: 2.663900
		loss: 2.663300
		loss: 2.662700
		loss: 2.662000
		loss: 2.661400
		loss: 2.660800
		loss: 2.660100
		loss: 2.659500
		loss: 2.658900
		loss: 2.658300
		loss: 2.657700
		loss: 2.657100
		loss: 2.656400
		loss: 2.655800
		loss: 2.655200
		loss: 2.654600
		loss: 2.654000
		loss: 2.653400
		loss: 2.652800
		loss: 2.652200
		loss: 2.651700
		loss: 2.651100
		loss: 2.650500
		loss: 2.649900
		loss: 2.649300
		loss: 2.648700
		loss: 2.648200
		loss: 2.647600
		loss: 2.647000
		loss: 2.646500
		loss: 2.645900
		loss: 2.645300
		loss: 2.644800
		loss: 2.644200
		loss: 2.643600
		loss: 2.643100
		loss: 2.642500
		loss: 2.642000
		loss: 2.641400
		loss: 2.640900
		loss: 2.640300
		loss: 2.639800
		loss: 2.639300
		loss: 2.638700
		loss: 2.638200
		loss: 2.637700
		loss: 2.637100
		loss: 2.636600
		loss: 2.636100
		loss: 2.635500
		loss: 2.635000
		loss: 2.634500
		loss: 2.634000
		loss: 2.633500
		loss: 2.632900
		loss: 2.632400
		loss: 2.631900
		loss: 2.631400
		loss: 2.630900
		loss: 2.630400
		loss: 2.629900
		loss: 2.629400
	Overall the loss development was 2.690400 -> 2.629400
problem epoch data for epoch 1, problem epoch 3
	sampling search time: 178.05200576782227s
	during this search the following actions were chosen:
		open boot was chosen with probability 1.000000
		fetch pump boot was chosen with probability 0.210792
		fetch r2 boot was chosen with probability 0.194484
		fetch wrench boot was chosen with probability 0.248229
		fetch jack boot was chosen with probability 0.241077
		fetch r1 boot was chosen with probability 0.275977
		loosen nuts1 the-hub1 was chosen with probability 0.295510
		jack-up the-hub1 was chosen with probability 0.315103
		undo nuts1 the-hub1 was chosen with probability 0.457226
		remove-wheel w1 the-hub1 was chosen with probability 0.425893
		put-on-wheel r1 the-hub1 was chosen with probability 0.282776
		loosen nuts2 the-hub2 was chosen with probability 0.312717
		put-away w1 boot was chosen with probability 0.343641
		inflate r1 was chosen with probability 0.476727
		inflate r2 was chosen with probability 0.901534
		do-up nuts1 the-hub1 was chosen with probability 0.725961
		jack-down the-hub1 was chosen with probability 0.648721
		jack-up the-hub2 was chosen with probability 0.835261
		undo nuts2 the-hub2 was chosen with probability 0.912412
		remove-wheel w2 the-hub2 was chosen with probability 0.874703
		put-on-wheel r2 the-hub2 was chosen with probability 0.517822
		put-away w2 boot was chosen with probability 0.772005
		tighten nuts1 the-hub1 was chosen with probability 0.799742
		do-up nuts2 the-hub2 was chosen with probability 0.522701
		jack-down the-hub2 was chosen with probability 0.544854
		tighten nuts2 the-hub2 was chosen with probability 0.843545
		put-away pump boot was chosen with probability 0.262221
		put-away jack boot was chosen with probability 0.288622
		loosen nuts2 the-hub2 was chosen with probability 0.270069
		tighten nuts2 the-hub2 was chosen with probability 0.909240
	training time: 17.797558546066284s
	during the training the following losses were computed:
		loss: 3.914400
		loss: 3.255900
		loss: 3.124100
		loss: 3.194900
		loss: 3.019100
		loss: 3.167900
		loss: 3.126700
		loss: 3.144900
		loss: 3.350300
		loss: 3.162100
		loss: 3.122100
		loss: 3.137200
		loss: 3.088100
		loss: 3.142100
		loss: 3.172800
		loss: 3.123300
		loss: 3.015900
		loss: 3.121300
		loss: 2.883200
		loss: 3.115600
		loss: 3.093900
		loss: 3.117700
		loss: 3.241200
		loss: 3.116700
		loss: 3.047700
		loss: 3.106600
		loss: 3.382300
		loss: 3.107800
		loss: 2.920800
		loss: 3.103500
		loss: 2.728800
		loss: 3.103200
		loss: 3.549000
		loss: 3.102600
		loss: 3.105700
		loss: 3.099600
		loss: 2.955000
		loss: 3.099000
		loss: 3.134500
		loss: 3.097000
		loss: 3.171200
		loss: 3.095600
		loss: 2.873500
		loss: 3.094400
		loss: 3.165900
		loss: 3.093600
		loss: 2.907600
		loss: 3.092700
		loss: 2.482300
		loss: 3.091500
		loss: 3.392100
		loss: 3.090600
		loss: 3.003200
		loss: 3.089400
		loss: 3.245900
		loss: 3.088800
		loss: 2.893600
		loss: 3.088000
		loss: 3.238900
		loss: 3.087000
		loss: 3.191400
		loss: 3.086500
		loss: 2.940900
		loss: 3.085600
		loss: 2.903500
		loss: 3.084900
		loss: 2.965900
		loss: 3.084100
		loss: 3.132100
		loss: 3.083400
		loss: 3.431300
		loss: 3.082700
		loss: 2.780600
		loss: 3.082000
		loss: 2.945400
		loss: 3.081400
		loss: 2.934300
		loss: 3.080700
		loss: 3.314100
		loss: 3.080100
		loss: 3.227500
		loss: 3.079400
		loss: 2.813300
		loss: 3.078800
		loss: 3.135900
		loss: 3.078300
		loss: 3.476700
		loss: 3.077600
		loss: 3.053300
		loss: 3.077100
		loss: 2.915300
		loss: 3.076400
		loss: 3.132500
		loss: 3.075800
		loss: 3.100700
		loss: 3.075300
		loss: 3.271900
		loss: 3.074700
		loss: 2.985600
		loss: 3.074200
		loss: 3.022800
		loss: 3.073600
		loss: 2.414800
		loss: 3.073000
		loss: 3.086300
		loss: 3.072500
		loss: 2.709400
		loss: 3.071800
		loss: 3.145200
		loss: 3.071300
		loss: 3.077500
		loss: 3.070700
		loss: 2.782000
		loss: 3.070100
		loss: 3.022300
		loss: 3.069600
		loss: 3.325900
		loss: 3.069000
		loss: 3.188000
		loss: 3.068500
		loss: 3.381000
		loss: 3.068000
		loss: 3.044900
		loss: 3.067500
		loss: 3.257500
		loss: 3.067000
		loss: 2.960900
		loss: 3.066400
		loss: 3.091900
		loss: 3.065900
		loss: 3.355500
		loss: 3.065400
		loss: 3.033200
		loss: 3.065000
		loss: 2.976100
		loss: 3.064400
		loss: 2.881900
		loss: 3.063900
		loss: 3.343200
		loss: 3.063400
		loss: 3.426400
		loss: 3.062900
		loss: 3.228400
		loss: 3.062400
		loss: 2.833200
		loss: 3.061900
		loss: 3.365200
		loss: 3.061400
		loss: 2.924900
		loss: 3.060900
		loss: 3.558900
		loss: 3.060500
		loss: 2.725000
		loss: 3.060000
		loss: 2.707100
		loss: 3.059500
		loss: 3.049100
		loss: 3.059200
		loss: 2.913500
		loss: 3.058700
		loss: 3.024800
		loss: 3.058200
		loss: 2.990000
		loss: 3.057700
		loss: 2.999800
		loss: 3.057200
		loss: 2.720900
		loss: 3.056700
		loss: 3.135800
		loss: 3.056300
		loss: 2.725500
		loss: 3.055900
		loss: 3.354300
		loss: 3.055500
		loss: 3.097500
		loss: 3.055000
		loss: 3.370500
		loss: 3.054500
		loss: 2.575500
		loss: 3.054100
		loss: 2.956500
		loss: 3.053600
		loss: 2.958400
		loss: 3.053200
		loss: 3.468900
		loss: 3.052700
		loss: 2.827700
		loss: 3.052400
		loss: 2.759400
		loss: 3.051900
		loss: 3.488100
		loss: 3.051500
		loss: 2.902700
		loss: 3.051000
		loss: 3.128100
		loss: 3.050600
		loss: 3.135800
		loss: 3.050200
		loss: 2.983100
		loss: 3.049700
	Overall the loss development was 3.914400 -> 3.049700
In the epoch 1 for problem d-02.pddl 0 explorations in the sampling searches reached a goal
Success rate: 0

Epoch 2:
Training data for problem d-01.pddl in epoch 2:
model creation time: 8.08070182800293s
problem epoch data for epoch 2, problem epoch 1
	sampling search time: 2.0475053787231445s
	during this search the following actions were chosen:
		close boot was chosen with probability 0.000000
	training time: 38.03259515762329s
	during the training the following losses were computed:
		loss: 1.768200
		loss: 1.747200
		loss: 1.744200
		loss: 1.737800
		loss: 1.732900
		loss: 1.728800
		loss: 1.726700
		loss: 1.727200
		loss: 1.726900
		loss: 1.724100
		loss: 1.721000
		loss: 1.720700
		loss: 1.722200
		loss: 1.722500
		loss: 1.721100
		loss: 1.719700
		loss: 1.719300
		loss: 1.719200
		loss: 1.718600
		loss: 1.717900
		loss: 1.717200
		loss: 1.716000
		loss: 1.714900
		loss: 1.714400
		loss: 1.714500
		loss: 1.714300
		loss: 1.713400
		loss: 1.712700
		loss: 1.712300
		loss: 1.712100
		loss: 1.711900
		loss: 1.711600
		loss: 1.711200
		loss: 1.710700
		loss: 1.710200
		loss: 1.709900
		loss: 1.709700
		loss: 1.709300
		loss: 1.708800
		loss: 1.708300
		loss: 1.708000
		loss: 1.707700
		loss: 1.707300
		loss: 1.706900
		loss: 1.706600
		loss: 1.706200
		loss: 1.705900
		loss: 1.705600
		loss: 1.705300
		loss: 1.704900
		loss: 1.704600
		loss: 1.704300
		loss: 1.703900
		loss: 1.703600
		loss: 1.703200
		loss: 1.702900
		loss: 1.702600
		loss: 1.702200
		loss: 1.701900
		loss: 1.701600
		loss: 1.701300
		loss: 1.700900
		loss: 1.700600
		loss: 1.700300
		loss: 1.700000
		loss: 1.699700
		loss: 1.699400
		loss: 1.699100
		loss: 1.698700
		loss: 1.698400
		loss: 1.698100
		loss: 1.697800
		loss: 1.697500
		loss: 1.697200
		loss: 1.696900
		loss: 1.696600
		loss: 1.696300
		loss: 1.696000
		loss: 1.695600
		loss: 1.695300
		loss: 1.695000
		loss: 1.694700
		loss: 1.694400
		loss: 1.694100
		loss: 1.693800
		loss: 1.693500
		loss: 1.693300
		loss: 1.693000
		loss: 1.692700
		loss: 1.692400
		loss: 1.692100
		loss: 1.691800
		loss: 1.691500
		loss: 1.691200
		loss: 1.690900
		loss: 1.690600
		loss: 1.690400
		loss: 1.690100
		loss: 1.689800
		loss: 1.689500
	Overall the loss development was 1.768200 -> 1.689500
problem epoch data for epoch 2, problem epoch 2
	sampling search time: 1.938591718673706s
	during this search the following actions were chosen:
		close boot was chosen with probability 0.000000
	training time: 10.12887954711914s
	during the training the following losses were computed:
		loss: 1.689200
		loss: 1.688900
		loss: 1.688700
		loss: 1.688400
		loss: 1.688100
		loss: 1.687800
		loss: 1.687600
		loss: 1.687300
		loss: 1.687000
		loss: 1.686700
		loss: 1.686500
		loss: 1.686200
		loss: 1.685900
		loss: 1.685700
		loss: 1.685400
		loss: 1.685100
		loss: 1.684900
		loss: 1.684600
		loss: 1.684300
		loss: 1.684100
		loss: 1.683800
		loss: 1.683600
		loss: 1.683300
		loss: 1.683000
		loss: 1.682800
		loss: 1.682500
		loss: 1.682300
		loss: 1.682000
		loss: 1.681800
		loss: 1.681500
		loss: 1.681300
		loss: 1.681000
		loss: 1.680800
		loss: 1.680500
		loss: 1.680300
		loss: 1.680000
		loss: 1.679800
		loss: 1.679500
		loss: 1.679300
		loss: 1.679000
		loss: 1.678800
		loss: 1.678600
		loss: 1.678300
		loss: 1.678100
		loss: 1.677800
		loss: 1.677600
		loss: 1.677400
		loss: 1.677100
		loss: 1.676900
		loss: 1.676700
		loss: 1.676400
		loss: 1.676200
		loss: 1.676000
		loss: 1.675700
		loss: 1.675500
		loss: 1.675300
		loss: 1.675100
		loss: 1.674800
		loss: 1.674600
		loss: 1.674400
		loss: 1.674200
		loss: 1.673900
		loss: 1.673700
		loss: 1.673500
		loss: 1.673300
		loss: 1.673100
		loss: 1.672800
		loss: 1.672600
		loss: 1.672400
		loss: 1.672200
		loss: 1.672000
		loss: 1.671800
		loss: 1.671600
		loss: 1.671300
		loss: 1.671100
		loss: 1.670900
		loss: 1.670700
		loss: 1.670500
		loss: 1.670300
		loss: 1.670100
		loss: 1.669900
		loss: 1.669700
		loss: 1.669500
		loss: 1.669300
		loss: 1.669100
		loss: 1.668900
		loss: 1.668700
		loss: 1.668500
		loss: 1.668300
		loss: 1.668100
		loss: 1.667900
		loss: 1.667700
		loss: 1.667500
		loss: 1.667300
		loss: 1.667100
		loss: 1.666900
		loss: 1.666700
		loss: 1.666500
		loss: 1.666300
		loss: 1.666100
	Overall the loss development was 1.689200 -> 1.666100
problem epoch data for epoch 2, problem epoch 3
	sampling search time: 3.6816465854644775s
	during this search the following actions were chosen:
		open boot was chosen with probability 1.000000
		fetch pump boot was chosen with probability 0.264170
		fetch r1 boot was chosen with probability 0.316720
		fetch wrench boot was chosen with probability 0.461869
		fetch jack boot was chosen with probability 0.484151
		loosen nuts1 the-hub1 was chosen with probability 0.811911
		jack-up the-hub1 was chosen with probability 0.835051
		undo nuts1 the-hub1 was chosen with probability 0.861651
		remove-wheel w1 the-hub1 was chosen with probability 0.861025
		put-on-wheel r1 the-hub1 was chosen with probability 0.603653
		put-away w1 boot was chosen with probability 0.840972
		inflate r1 was chosen with probability 0.808933
		do-up nuts1 the-hub1 was chosen with probability 0.433821
		jack-down the-hub1 was chosen with probability 0.506745
		tighten nuts1 the-hub1 was chosen with probability 0.708211
		put-away pump boot was chosen with probability 0.446624
		loosen nuts1 the-hub1 was chosen with probability 0.400916
		tighten nuts1 the-hub1 was chosen with probability 0.780010
	training time: 10.14189600944519s
	during the training the following losses were computed:
		loss: 1.823800
		loss: 1.779400
		loss: 1.739400
		loss: 1.703000
		loss: 1.690800
		loss: 1.682400
		loss: 1.680300
		loss: 1.681400
		loss: 1.676500
		loss: 1.674400
		loss: 1.675500
		loss: 1.676600
		loss: 1.677800
		loss: 1.675800
		loss: 1.670000
		loss: 1.664600
		loss: 1.660500
		loss: 1.656900
		loss: 1.655400
		loss: 1.654900
		loss: 1.654000
		loss: 1.653800
		loss: 1.653600
		loss: 1.652700
		loss: 1.652200
		loss: 1.651600
		loss: 1.650300
		loss: 1.649200
		loss: 1.648200
		loss: 1.647500
		loss: 1.647300
		loss: 1.647000
		loss: 1.646400
		loss: 1.645900
		loss: 1.645300
		loss: 1.644800
		loss: 1.644600
		loss: 1.644400
		loss: 1.644200
		loss: 1.644100
		loss: 1.644000
		loss: 1.643700
		loss: 1.643500
		loss: 1.643200
		loss: 1.642900
		loss: 1.642500
		loss: 1.642200
		loss: 1.642000
		loss: 1.641900
		loss: 1.641800
		loss: 1.641700
		loss: 1.641600
		loss: 1.641500
		loss: 1.641300
		loss: 1.641100
		loss: 1.640900
		loss: 1.640700
		loss: 1.640500
		loss: 1.640400
		loss: 1.640300
		loss: 1.640100
		loss: 1.640000
		loss: 1.639900
		loss: 1.639800
		loss: 1.639700
		loss: 1.639600
		loss: 1.639400
		loss: 1.639300
		loss: 1.639100
		loss: 1.639000
		loss: 1.638900
		loss: 1.638800
		loss: 1.638700
		loss: 1.638600
		loss: 1.638500
		loss: 1.638300
		loss: 1.638200
		loss: 1.638100
		loss: 1.638000
		loss: 1.637900
		loss: 1.637800
		loss: 1.637700
		loss: 1.637600
		loss: 1.637400
		loss: 1.637300
		loss: 1.637200
		loss: 1.637100
		loss: 1.637000
		loss: 1.636900
		loss: 1.636800
		loss: 1.636700
		loss: 1.636600
		loss: 1.636500
		loss: 1.636400
		loss: 1.636300
		loss: 1.636200
		loss: 1.636100
		loss: 1.636000
		loss: 1.635900
		loss: 1.635800
	Overall the loss development was 1.823800 -> 1.635800
In the epoch 2 for problem d-01.pddl 0 explorations in the sampling searches reached a goal
Training data for problem d-02.pddl in epoch 2:
model creation time: 15.785462856292725s
problem epoch data for epoch 2, problem epoch 1
	sampling search time: 135.15048241615295s
	during this search the following actions were chosen:
		open boot was chosen with probability 1.000000
		fetch pump boot was chosen with probability 0.334463
		inflate r1 was chosen with probability 0.274295
		inflate r2 was chosen with probability 0.325418
		fetch jack boot was chosen with probability 0.348240
		fetch wrench boot was chosen with probability 0.421151
		loosen nuts2 the-hub2 was chosen with probability 0.327942
		loosen nuts1 the-hub1 was chosen with probability 0.468111
		jack-up the-hub2 was chosen with probability 0.314796
		undo nuts2 the-hub2 was chosen with probability 0.540638
		remove-wheel w2 the-hub2 was chosen with probability 0.490371
		put-away w2 boot was chosen with probability 0.477706
		fetch r2 boot was chosen with probability 0.805762
		put-on-wheel r2 the-hub2 was chosen with probability 0.870889
		fetch r1 boot was chosen with probability 0.726357
		do-up nuts2 the-hub2 was chosen with probability 0.648367
		undo nuts2 the-hub2 was chosen with probability 0.422414
	training time: 71.84206175804138s
	during the training the following losses were computed:
		loss: 3.602500
		loss: 2.683000
		loss: 2.667600
		loss: 2.598600
		loss: 2.755700
		loss: 2.556600
		loss: 2.636400
		loss: 2.518300
		loss: 2.578000
		loss: 2.507100
		loss: 2.393000
		loss: 2.500500
		loss: 2.236600
		loss: 2.483000
		loss: 2.234600
		loss: 2.481100
		loss: 2.448400
		loss: 2.481400
		loss: 2.265700
		loss: 2.471200
		loss: 2.496800
		loss: 2.464400
		loss: 2.234500
		loss: 2.462000
		loss: 2.464300
		loss: 2.460400
		loss: 2.352800
		loss: 2.454400
		loss: 2.310200
		loss: 2.453300
		loss: 2.388500
		loss: 2.453000
		loss: 2.758100
		loss: 2.448900
		loss: 2.369500
		loss: 2.447700
		loss: 2.469100
		loss: 2.446700
		loss: 2.469500
		loss: 2.444300
		loss: 2.896600
		loss: 2.445100
		loss: 2.504100
		loss: 2.442100
		loss: 2.578500
		loss: 2.440100
		loss: 2.369900
		loss: 2.439200
		loss: 2.342800
		loss: 2.439700
		loss: 2.246200
		loss: 2.438700
		loss: 2.601700
		loss: 2.437600
		loss: 2.259600
		loss: 2.435200
		loss: 2.752200
		loss: 2.433400
		loss: 2.079200
		loss: 2.436100
		loss: 2.408800
		loss: 2.433800
		loss: 2.206000
		loss: 2.434100
		loss: 2.711300
		loss: 2.430800
		loss: 2.819900
		loss: 2.429600
		loss: 2.106100
		loss: 2.429400
		loss: 2.422300
		loss: 2.430600
		loss: 2.337300
		loss: 2.429700
		loss: 2.327600
		loss: 2.430200
		loss: 2.170600
		loss: 2.427900
		loss: 2.175900
		loss: 2.427600
		loss: 2.508700
		loss: 2.428000
		loss: 2.476600
		loss: 2.427800
		loss: 2.502800
		loss: 2.427400
		loss: 2.230200
		loss: 2.426400
		loss: 2.606200
		loss: 2.428000
		loss: 2.584300
		loss: 2.427600
		loss: 2.680200
		loss: 2.425200
		loss: 2.365000
		loss: 2.425900
		loss: 2.306300
		loss: 2.425400
		loss: 2.682900
		loss: 2.427000
		loss: 2.169600
		loss: 2.424200
		loss: 2.496500
		loss: 2.425600
		loss: 2.817000
		loss: 2.427100
		loss: 2.361300
		loss: 2.425200
		loss: 2.401700
		loss: 2.424500
		loss: 2.313500
		loss: 2.423800
		loss: 2.523300
		loss: 2.423700
		loss: 2.695900
		loss: 2.425500
		loss: 2.277500
		loss: 2.424600
		loss: 2.046400
		loss: 2.421700
		loss: 1.999800
		loss: 2.425700
		loss: 2.194600
		loss: 2.424500
		loss: 1.859400
		loss: 2.420200
		loss: 2.640700
		loss: 2.421900
		loss: 2.396800
		loss: 2.422700
		loss: 2.620000
		loss: 2.423700
		loss: 2.759000
		loss: 2.420700
		loss: 2.402900
		loss: 2.422200
		loss: 2.417000
		loss: 2.422200
		loss: 2.435400
		loss: 2.422200
		loss: 2.561400
		loss: 2.421200
		loss: 2.468100
		loss: 2.422000
		loss: 2.140800
		loss: 2.420200
		loss: 2.573800
		loss: 2.422200
		loss: 2.509700
		loss: 2.421800
		loss: 2.776900
		loss: 2.419400
		loss: 2.552200
		loss: 2.420400
		loss: 2.532900
		loss: 2.420300
		loss: 2.671500
		loss: 2.422100
		loss: 2.297600
		loss: 2.421300
		loss: 2.213600
		loss: 2.419600
		loss: 2.660400
		loss: 2.421600
		loss: 2.333300
		loss: 2.420900
		loss: 2.118800
		loss: 2.421900
		loss: 2.537900
		loss: 2.420600
		loss: 2.549100
		loss: 2.420700
		loss: 2.776600
		loss: 2.421600
		loss: 2.487600
		loss: 2.419400
		loss: 2.745100
		loss: 2.417900
		loss: 2.494300
		loss: 2.419800
		loss: 2.673200
		loss: 2.418000
		loss: 2.369300
		loss: 2.418900
		loss: 2.492400
		loss: 2.419400
		loss: 2.854400
		loss: 2.416600
		loss: 2.555800
		loss: 2.418000
		loss: 2.320500
		loss: 2.418100
		loss: 2.565200
		loss: 2.419200
		loss: 2.525400
		loss: 2.417900
		loss: 2.160400
		loss: 2.419600
		loss: 2.185600
		loss: 2.419400
	Overall the loss development was 3.602500 -> 2.419400
problem epoch data for epoch 2, problem epoch 2
	sampling search time: 200.27349877357483s
	during this search the following actions were chosen:
		open boot was chosen with probability 1.000000
		fetch r1 boot was chosen with probability 0.204877
		fetch jack boot was chosen with probability 0.261491
		fetch wrench boot was chosen with probability 0.341050
		fetch r2 boot was chosen with probability 0.293221
		loosen nuts1 the-hub1 was chosen with probability 0.348262
		fetch pump boot was chosen with probability 0.375918
		inflate r1 was chosen with probability 0.301231
		inflate r2 was chosen with probability 0.391527
		loosen nuts2 the-hub2 was chosen with probability 0.559989
		jack-up the-hub2 was chosen with probability 0.515089
		undo nuts2 the-hub2 was chosen with probability 0.987421
		remove-wheel w2 the-hub2 was chosen with probability 0.986906
		put-on-wheel r2 the-hub2 was chosen with probability 0.665975
		put-away w2 boot was chosen with probability 0.932275
		do-up nuts2 the-hub2 was chosen with probability 0.394333
		jack-down the-hub2 was chosen with probability 0.452262
		jack-up the-hub1 was chosen with probability 0.870600
		undo nuts1 the-hub1 was chosen with probability 0.936850
		remove-wheel w1 the-hub1 was chosen with probability 0.895696
		put-on-wheel r1 the-hub1 was chosen with probability 0.603459
		put-away w1 boot was chosen with probability 0.820597
		tighten nuts2 the-hub2 was chosen with probability 0.725685
		remove-wheel r1 the-hub1 was chosen with probability 0.330646
		put-on-wheel r1 the-hub1 was chosen with probability 0.977553
	training time: 20.025038957595825s
	during the training the following losses were computed:
		loss: 2.984900
		loss: 2.538200
		loss: 2.532300
		loss: 2.538100
		loss: 2.417400
		loss: 2.537900
		loss: 2.346500
		loss: 2.537700
		loss: 2.764900
		loss: 2.537600
		loss: 2.611600
		loss: 2.537400
		loss: 2.694800
		loss: 2.537200
		loss: 2.635200
		loss: 2.537100
		loss: 2.726900
		loss: 2.536900
		loss: 2.466600
		loss: 2.536800
		loss: 2.715400
		loss: 2.536800
		loss: 2.605600
		loss: 2.536500
		loss: 2.541500
		loss: 2.536400
		loss: 2.591300
		loss: 2.536200
		loss: 2.775400
		loss: 2.536200
		loss: 2.105800
		loss: 2.536100
		loss: 2.467800
		loss: 2.536000
		loss: 2.272200
		loss: 2.535900
		loss: 2.619000
		loss: 2.535800
		loss: 2.825500
		loss: 2.535600
		loss: 2.338900
		loss: 2.535500
		loss: 2.416000
		loss: 2.535400
		loss: 2.393200
		loss: 2.535200
		loss: 2.617000
		loss: 2.535100
		loss: 2.323000
		loss: 2.535000
		loss: 2.476000
		loss: 2.534900
		loss: 2.425400
		loss: 2.534900
		loss: 2.442400
		loss: 2.534700
		loss: 2.575600
		loss: 2.534700
		loss: 2.510700
		loss: 2.534600
		loss: 2.671400
		loss: 2.534400
		loss: 2.301300
		loss: 2.534400
		loss: 2.355000
		loss: 2.534200
		loss: 2.594000
		loss: 2.534100
		loss: 2.471900
		loss: 2.534000
		loss: 2.525900
		loss: 2.533900
		loss: 2.593800
		loss: 2.533800
		loss: 2.629900
		loss: 2.533700
		loss: 2.397000
		loss: 2.533600
		loss: 2.856500
		loss: 2.533500
		loss: 2.503500
		loss: 2.533400
		loss: 2.225200
		loss: 2.533400
		loss: 2.339000
		loss: 2.533200
		loss: 2.596100
		loss: 2.533100
		loss: 2.425400
		loss: 2.533000
		loss: 2.358900
		loss: 2.532900
		loss: 2.506700
		loss: 2.533000
		loss: 2.411400
		loss: 2.532800
		loss: 2.585800
		loss: 2.532700
		loss: 2.151300
		loss: 2.532800
		loss: 2.606700
		loss: 2.532700
		loss: 2.644000
		loss: 2.532400
		loss: 2.529700
		loss: 2.532500
		loss: 2.624900
		loss: 2.532400
		loss: 2.592200
		loss: 2.532200
		loss: 2.173600
		loss: 2.532200
		loss: 2.869300
		loss: 2.532100
		loss: 2.418900
		loss: 2.531900
		loss: 2.613900
		loss: 2.531700
		loss: 2.507300
		loss: 2.531700
		loss: 2.542900
		loss: 2.531500
		loss: 2.455900
		loss: 2.531500
		loss: 2.635300
		loss: 2.531400
		loss: 2.767700
		loss: 2.531300
		loss: 2.269700
		loss: 2.531300
		loss: 2.331400
		loss: 2.531200
		loss: 2.205400
		loss: 2.531200
		loss: 2.477300
		loss: 2.531100
		loss: 2.551100
		loss: 2.530900
		loss: 2.549500
		loss: 2.531000
		loss: 2.719400
		loss: 2.531000
		loss: 2.477000
		loss: 2.530800
		loss: 2.220700
		loss: 2.530500
		loss: 2.676500
		loss: 2.530500
		loss: 2.625800
		loss: 2.530400
		loss: 2.440200
		loss: 2.530400
		loss: 2.508400
		loss: 2.530200
		loss: 2.346200
		loss: 2.530300
		loss: 2.597000
		loss: 2.530200
		loss: 2.672100
		loss: 2.530000
		loss: 2.501500
		loss: 2.530000
		loss: 2.615300
		loss: 2.530100
		loss: 2.325500
		loss: 2.529700
		loss: 2.632200
		loss: 2.529700
		loss: 2.432700
		loss: 2.529800
		loss: 2.438000
		loss: 2.529600
		loss: 2.511500
		loss: 2.529400
		loss: 2.344000
		loss: 2.529400
		loss: 2.452300
		loss: 2.529400
		loss: 2.585700
		loss: 2.529200
		loss: 2.594800
		loss: 2.529000
		loss: 2.277600
		loss: 2.529200
		loss: 2.429500
		loss: 2.529100
		loss: 2.722200
		loss: 2.529000
		loss: 2.853000
		loss: 2.528900
		loss: 2.688300
		loss: 2.529000
		loss: 2.436100
		loss: 2.528700
		loss: 2.548100
		loss: 2.528800
		loss: 2.644700
		loss: 2.528800
		loss: 2.324000
		loss: 2.528800
	Overall the loss development was 2.984900 -> 2.528800
problem epoch data for epoch 2, problem epoch 3
	sampling search time: 33.34665513038635s
	during this search the following actions were chosen:
		close boot was chosen with probability 0.000000
	training time: 20.03254723548889s
	during the training the following losses were computed:
		loss: 2.975900
		loss: 2.528600
		loss: 2.409500
		loss: 2.528400
		loss: 2.683600
		loss: 2.528200
		loss: 2.751900
		loss: 2.528100
		loss: 2.502200
		loss: 2.528000
		loss: 2.312500
		loss: 2.528000
		loss: 2.531400
		loss: 2.527900
		loss: 2.175100
		loss: 2.527800
		loss: 2.170300
		loss: 2.527700
		loss: 2.307100
		loss: 2.527600
		loss: 2.453800
		loss: 2.527500
		loss: 2.878300
		loss: 2.527400
		loss: 2.710000
		loss: 2.527300
		loss: 2.440500
		loss: 2.527300
		loss: 2.586500
		loss: 2.527200
		loss: 2.617000
		loss: 2.527100
		loss: 2.230300
		loss: 2.527100
		loss: 2.646600
		loss: 2.526900
		loss: 2.577200
		loss: 2.526900
		loss: 2.495100
		loss: 2.526800
		loss: 2.501500
		loss: 2.526700
		loss: 2.794200
		loss: 2.526800
		loss: 2.640700
		loss: 2.526600
		loss: 2.707200
		loss: 2.526600
		loss: 2.530000
		loss: 2.526400
		loss: 2.548400
		loss: 2.526300
		loss: 2.318200
		loss: 2.526300
		loss: 2.135000
		loss: 2.526300
		loss: 2.392900
		loss: 2.526100
		loss: 2.381100
		loss: 2.526100
		loss: 2.667200
		loss: 2.526000
		loss: 2.631800
		loss: 2.525900
		loss: 2.622200
		loss: 2.525900
		loss: 2.526500
		loss: 2.525800
		loss: 2.433400
		loss: 2.525800
		loss: 2.632800
		loss: 2.525700
		loss: 2.446800
		loss: 2.525600
		loss: 2.543300
		loss: 2.525600
		loss: 2.591500
		loss: 2.525600
		loss: 2.729000
		loss: 2.525500
		loss: 2.173900
		loss: 2.525400
		loss: 2.655000
		loss: 2.525300
		loss: 2.097600
		loss: 2.525200
		loss: 2.334000
		loss: 2.525300
		loss: 2.649500
		loss: 2.525200
		loss: 2.797200
		loss: 2.525100
		loss: 2.855100
		loss: 2.525000
		loss: 2.498600
		loss: 2.525000
		loss: 2.179100
		loss: 2.525000
		loss: 2.381800
		loss: 2.524800
		loss: 2.665700
		loss: 2.524900
		loss: 2.438500
		loss: 2.524700
		loss: 2.386700
		loss: 2.524500
		loss: 2.409000
		loss: 2.524400
		loss: 2.133700
		loss: 2.524500
		loss: 2.407700
		loss: 2.524400
		loss: 2.713600
		loss: 2.524400
		loss: 2.565600
		loss: 2.524200
		loss: 2.825900
		loss: 2.524100
		loss: 2.585700
		loss: 2.524100
		loss: 2.735900
		loss: 2.524100
		loss: 2.623900
		loss: 2.524000
		loss: 2.279500
		loss: 2.523900
		loss: 2.465300
		loss: 2.523800
		loss: 2.392000
		loss: 2.523800
		loss: 2.306900
		loss: 2.523700
		loss: 2.290100
		loss: 2.523600
		loss: 2.598100
		loss: 2.523500
		loss: 2.302900
		loss: 2.523500
		loss: 2.420900
		loss: 2.523400
		loss: 2.536500
		loss: 2.523400
		loss: 2.380600
		loss: 2.523300
		loss: 2.254900
		loss: 2.523300
		loss: 2.642900
		loss: 2.523200
		loss: 2.190700
		loss: 2.523100
		loss: 2.363100
		loss: 2.523100
		loss: 2.417900
		loss: 2.523000
		loss: 2.438300
		loss: 2.523000
		loss: 2.665200
		loss: 2.522900
		loss: 2.620500
		loss: 2.522900
		loss: 2.228000
		loss: 2.522800
		loss: 2.557700
		loss: 2.522800
		loss: 2.797800
		loss: 2.522700
		loss: 2.211700
		loss: 2.522800
		loss: 2.257800
		loss: 2.522900
		loss: 2.481100
		loss: 2.522700
		loss: 2.594600
		loss: 2.522500
		loss: 2.400800
		loss: 2.522400
		loss: 2.708700
		loss: 2.522400
		loss: 2.172200
		loss: 2.522500
		loss: 2.545100
		loss: 2.522400
		loss: 2.498600
		loss: 2.522200
		loss: 2.483400
		loss: 2.522200
		loss: 3.036900
		loss: 2.522300
		loss: 2.540500
		loss: 2.522100
		loss: 2.437400
		loss: 2.522000
		loss: 2.105100
		loss: 2.522100
		loss: 2.581000
		loss: 2.522000
		loss: 2.614800
		loss: 2.521700
		loss: 2.391700
		loss: 2.521700
	Overall the loss development was 2.975900 -> 2.521700
In the epoch 2 for problem d-02.pddl 0 explorations in the sampling searches reached a goal
Success rate: 0

Epoch 3:
Training data for problem d-01.pddl in epoch 3:
model creation time: 8.055943012237549s
problem epoch data for epoch 3, problem epoch 1
	sampling search time: 3.6559157371520996s
	during this search the following actions were chosen:
		open boot was chosen with probability 1.000000
		fetch wrench boot was chosen with probability 0.653835
		fetch r1 boot was chosen with probability 0.274431
		fetch jack boot was chosen with probability 0.368355
		loosen nuts1 the-hub1 was chosen with probability 0.500756
		fetch pump boot was chosen with probability 0.556644
		inflate r1 was chosen with probability 0.561440
		jack-up the-hub1 was chosen with probability 0.979023
		undo nuts1 the-hub1 was chosen with probability 0.988287
		remove-wheel w1 the-hub1 was chosen with probability 0.985095
		put-on-wheel r1 the-hub1 was chosen with probability 0.659444
		put-away w1 boot was chosen with probability 0.939397
		put-away pump boot was chosen with probability 0.385341
		remove-wheel r1 the-hub1 was chosen with probability 0.485166
		put-on-wheel r1 the-hub1 was chosen with probability 0.998396
	training time: 37.61773753166199s
	during the training the following losses were computed:
		loss: 1.486300
		loss: 1.511000
		loss: 1.488900
		loss: 1.489900
		loss: 1.490100
		loss: 1.488000
		loss: 1.487100
		loss: 1.485600
		loss: 1.483200
		loss: 1.481500
		loss: 1.482000
		loss: 1.483300
		loss: 1.483200
		loss: 1.481400
		loss: 1.479600
		loss: 1.479400
		loss: 1.480200
		loss: 1.480500
		loss: 1.479800
		loss: 1.478800
		loss: 1.478400
		loss: 1.478700
		loss: 1.478900
		loss: 1.478500
		loss: 1.478000
		loss: 1.477800
		loss: 1.477800
		loss: 1.477600
		loss: 1.477400
		loss: 1.477400
		loss: 1.477400
		loss: 1.477200
		loss: 1.476900
		loss: 1.476700
		loss: 1.476700
		loss: 1.476800
		loss: 1.476700
		loss: 1.476500
		loss: 1.476200
		loss: 1.476200
		loss: 1.476300
		loss: 1.476200
		loss: 1.476000
		loss: 1.475900
		loss: 1.475900
		loss: 1.475800
		loss: 1.475700
		loss: 1.475600
		loss: 1.475600
		loss: 1.475500
		loss: 1.475400
		loss: 1.475400
		loss: 1.475300
		loss: 1.475300
		loss: 1.475200
		loss: 1.475100
		loss: 1.475000
		loss: 1.475000
		loss: 1.475000
		loss: 1.474900
		loss: 1.474800
		loss: 1.474800
		loss: 1.474700
		loss: 1.474600
		loss: 1.474600
		loss: 1.474500
		loss: 1.474500
		loss: 1.474400
		loss: 1.474400
		loss: 1.474300
		loss: 1.474200
		loss: 1.474200
		loss: 1.474100
		loss: 1.474100
		loss: 1.474000
		loss: 1.474000
		loss: 1.473900
		loss: 1.473900
		loss: 1.473800
		loss: 1.473800
		loss: 1.473700
		loss: 1.473700
		loss: 1.473600
		loss: 1.473600
		loss: 1.473500
		loss: 1.473500
		loss: 1.473400
		loss: 1.473400
		loss: 1.473300
		loss: 1.473300
		loss: 1.473200
		loss: 1.473200
		loss: 1.473100
		loss: 1.473100
		loss: 1.473000
		loss: 1.473000
		loss: 1.472900
		loss: 1.472900
		loss: 1.472800
		loss: 1.472800
	Overall the loss development was 1.486300 -> 1.472800
problem epoch data for epoch 3, problem epoch 2
	sampling search time: 3.6031253337860107s
	during this search the following actions were chosen:
		open boot was chosen with probability 1.000000
		fetch wrench boot was chosen with probability 0.999523
		fetch jack boot was chosen with probability 0.423932
		fetch pump boot was chosen with probability 0.518624
		fetch r1 boot was chosen with probability 0.847267
		inflate r1 was chosen with probability 0.556561
		loosen nuts1 the-hub1 was chosen with probability 0.914346
		jack-up the-hub1 was chosen with probability 0.999075
		undo nuts1 the-hub1 was chosen with probability 0.999981
		remove-wheel w1 the-hub1 was chosen with probability 0.994631
		put-on-wheel r1 the-hub1 was chosen with probability 0.993862
		do-up nuts1 the-hub1 was chosen with probability 0.963813
		undo nuts1 the-hub1 was chosen with probability 0.822284
	training time: 10.137396812438965s
	during the training the following losses were computed:
		loss: 1.569500
		loss: 1.568600
		loss: 1.568500
		loss: 1.568300
		loss: 1.568200
		loss: 1.568200
		loss: 1.567600
		loss: 1.567500
		loss: 1.567200
		loss: 1.567000
		loss: 1.567100
		loss: 1.566700
		loss: 1.566500
		loss: 1.566500
		loss: 1.566400
		loss: 1.566400
		loss: 1.566200
		loss: 1.566100
		loss: 1.566100
		loss: 1.566000
		loss: 1.566000
		loss: 1.565900
		loss: 1.565800
		loss: 1.565800
		loss: 1.565700
		loss: 1.565700
		loss: 1.565600
		loss: 1.565500
		loss: 1.565500
		loss: 1.565500
		loss: 1.565400
		loss: 1.565400
		loss: 1.565300
		loss: 1.565300
		loss: 1.565200
		loss: 1.565200
		loss: 1.565100
		loss: 1.565100
		loss: 1.565000
		loss: 1.565000
		loss: 1.564900
		loss: 1.564900
		loss: 1.564800
		loss: 1.564800
		loss: 1.564700
		loss: 1.564700
		loss: 1.564600
		loss: 1.564600
		loss: 1.564600
		loss: 1.564500
		loss: 1.564500
		loss: 1.564400
		loss: 1.564400
		loss: 1.564300
		loss: 1.564300
		loss: 1.564300
		loss: 1.564200
		loss: 1.564200
		loss: 1.564100
		loss: 1.564100
		loss: 1.564100
		loss: 1.564000
		loss: 1.564000
		loss: 1.563900
		loss: 1.563900
		loss: 1.563900
		loss: 1.563800
		loss: 1.563800
		loss: 1.563700
		loss: 1.563700
		loss: 1.563700
		loss: 1.563600
		loss: 1.563600
		loss: 1.563500
		loss: 1.563500
		loss: 1.563500
		loss: 1.563400
		loss: 1.563400
		loss: 1.563400
		loss: 1.563300
		loss: 1.563300
		loss: 1.563200
		loss: 1.563200
		loss: 1.563200
		loss: 1.563100
		loss: 1.563100
		loss: 1.563100
		loss: 1.563000
		loss: 1.563000
		loss: 1.562900
		loss: 1.562900
		loss: 1.562900
		loss: 1.562800
		loss: 1.562800
		loss: 1.562800
		loss: 1.562700
		loss: 1.562700
		loss: 1.562600
		loss: 1.562600
		loss: 1.562600
	Overall the loss development was 1.569500 -> 1.562600
problem epoch data for epoch 3, problem epoch 3
	sampling search time: 3.5467746257781982s
	during this search the following actions were chosen:
		open boot was chosen with probability 1.000000
		fetch pump boot was chosen with probability 0.257605
		inflate r1 was chosen with probability 0.305536
		fetch r1 boot was chosen with probability 0.335016
		fetch wrench boot was chosen with probability 0.495439
		loosen nuts1 the-hub1 was chosen with probability 0.496646
		fetch jack boot was chosen with probability 0.972899
		jack-up the-hub1 was chosen with probability 0.973530
		undo nuts1 the-hub1 was chosen with probability 0.981045
		remove-wheel w1 the-hub1 was chosen with probability 0.979921
		put-on-wheel r1 the-hub1 was chosen with probability 0.579753
		put-away w1 boot was chosen with probability 0.922460
		do-up nuts1 the-hub1 was chosen with probability 0.392247
		put-away pump boot was chosen with probability 0.445615
		jack-down the-hub1 was chosen with probability 0.484529
		tighten nuts1 the-hub1 was chosen with probability 0.702751
		put-away jack boot was chosen with probability 0.459274
		loosen nuts1 the-hub1 was chosen with probability 0.697768
		tighten nuts1 the-hub1 was chosen with probability 0.970034
	training time: 10.14081072807312s
	during the training the following losses were computed:
		loss: 1.763100
		loss: 1.763000
		loss: 1.763000
		loss: 1.762900
		loss: 1.762900
		loss: 1.762900
		loss: 1.762800
		loss: 1.762800
		loss: 1.762700
		loss: 1.762700
		loss: 1.762600
		loss: 1.762600
		loss: 1.762500
		loss: 1.762500
		loss: 1.762500
		loss: 1.762400
		loss: 1.762400
		loss: 1.762300
		loss: 1.762300
		loss: 1.762300
		loss: 1.762200
		loss: 1.762200
		loss: 1.762100
		loss: 1.762100
		loss: 1.762100
		loss: 1.762000
		loss: 1.762000
		loss: 1.762000
		loss: 1.761900
		loss: 1.761900
		loss: 1.761800
		loss: 1.761800
		loss: 1.761800
		loss: 1.761700
		loss: 1.761700
		loss: 1.761700
		loss: 1.761600
		loss: 1.761600
		loss: 1.761600
		loss: 1.761500
		loss: 1.761500
		loss: 1.761500
		loss: 1.761400
		loss: 1.761400
		loss: 1.761400
		loss: 1.761300
		loss: 1.761300
		loss: 1.761300
		loss: 1.761200
		loss: 1.761200
		loss: 1.761200
		loss: 1.761100
		loss: 1.761100
		loss: 1.761000
		loss: 1.761000
		loss: 1.761000
		loss: 1.760900
		loss: 1.760900
		loss: 1.760900
		loss: 1.760800
		loss: 1.760800
		loss: 1.760800
		loss: 1.760700
		loss: 1.760700
		loss: 1.760700
		loss: 1.760700
		loss: 1.760600
		loss: 1.760600
		loss: 1.760600
		loss: 1.760500
		loss: 1.760500
		loss: 1.760500
		loss: 1.760400
		loss: 1.760400
		loss: 1.760400
		loss: 1.760300
		loss: 1.760300
		loss: 1.760300
		loss: 1.760200
		loss: 1.760200
		loss: 1.760200
		loss: 1.760100
		loss: 1.760100
		loss: 1.760100
		loss: 1.760000
		loss: 1.760000
		loss: 1.760000
		loss: 1.759900
		loss: 1.759900
		loss: 1.759900
		loss: 1.759900
		loss: 1.759800
		loss: 1.759800
		loss: 1.759800
		loss: 1.759700
		loss: 1.759700
		loss: 1.759700
		loss: 1.759600
		loss: 1.759600
		loss: 1.759600
	Overall the loss development was 1.763100 -> 1.759600
In the epoch 3 for problem d-01.pddl 0 explorations in the sampling searches reached a goal
Training data for problem d-02.pddl in epoch 3:
model creation time: 15.671557664871216s
problem epoch data for epoch 3, problem epoch 1
	sampling search time: 131.38594937324524s
	during this search the following actions were chosen:
		open boot was chosen with probability 1.000000
		fetch pump boot was chosen with probability 0.259151
		inflate r1 was chosen with probability 0.240655
		inflate r2 was chosen with probability 0.290304
		fetch wrench boot was chosen with probability 0.304343
		loosen nuts1 the-hub1 was chosen with probability 0.230303
		loosen nuts2 the-hub2 was chosen with probability 0.363420
		fetch jack boot was chosen with probability 0.374294
		jack-up the-hub2 was chosen with probability 0.292597
		undo nuts2 the-hub2 was chosen with probability 0.492248
		remove-wheel w2 the-hub2 was chosen with probability 0.442415
		fetch r2 boot was chosen with probability 0.415289
		put-on-wheel r2 the-hub2 was chosen with probability 0.508438
		put-away w2 boot was chosen with probability 0.560330
		fetch r1 boot was chosen with probability 0.840395
		do-up nuts2 the-hub2 was chosen with probability 0.536166
		undo nuts2 the-hub2 was chosen with probability 0.546411
	training time: 70.80625748634338s
	during the training the following losses were computed:
		loss: 1.695100
		loss: 2.660800
		loss: 2.626000
		loss: 2.617900
		loss: 2.398000
		loss: 2.607100
		loss: 2.981400
		loss: 2.604500
		loss: 2.255500
		loss: 2.603100
		loss: 2.314800
		loss: 2.594400
		loss: 2.579400
		loss: 2.593800
		loss: 2.817400
		loss: 2.590700
		loss: 2.712000
		loss: 2.585400
		loss: 2.166300
		loss: 2.588600
		loss: 2.545200
		loss: 2.583300
		loss: 2.265100
		loss: 2.583600
		loss: 2.944400
		loss: 2.582400
		loss: 2.573000
		loss: 2.578900
		loss: 2.303900
		loss: 2.576700
		loss: 2.755600
		loss: 2.576100
		loss: 2.328000
		loss: 2.578100
		loss: 2.723100
		loss: 2.574600
		loss: 2.631300
		loss: 2.574700
		loss: 2.695300
		loss: 2.573700
		loss: 2.676800
		loss: 2.573400
		loss: 2.783500
		loss: 2.572500
		loss: 2.591700
		loss: 2.573200
		loss: 2.406900
		loss: 2.571700
		loss: 2.506300
		loss: 2.572000
		loss: 2.375800
		loss: 2.571100
		loss: 2.451700
		loss: 2.571100
		loss: 2.621700
		loss: 2.571900
		loss: 2.766300
		loss: 2.570300
		loss: 2.431200
		loss: 2.572000
		loss: 2.197800
		loss: 2.569000
		loss: 2.422300
		loss: 2.570100
		loss: 2.807000
		loss: 2.569400
		loss: 2.944800
		loss: 2.572800
		loss: 2.452500
		loss: 2.571300
		loss: 2.390100
		loss: 2.569300
		loss: 2.609800
		loss: 2.570500
		loss: 1.921600
		loss: 2.566500
		loss: 2.557200
		loss: 2.570200
		loss: 2.652000
		loss: 2.570300
		loss: 2.308500
		loss: 2.568400
		loss: 2.941100
		loss: 2.571800
		loss: 2.731700
		loss: 2.570500
		loss: 1.946800
		loss: 2.566100
		loss: 2.564900
		loss: 2.569500
		loss: 2.338500
		loss: 2.568100
		loss: 2.519500
		loss: 2.569700
		loss: 2.886500
		loss: 2.567600
		loss: 2.559500
		loss: 2.569200
		loss: 3.131500
		loss: 2.566000
		loss: 2.194300
		loss: 2.567100
		loss: 2.849000
		loss: 2.567500
		loss: 2.693200
		loss: 2.568200
		loss: 2.504000
		loss: 2.568600
		loss: 2.249700
		loss: 2.567100
		loss: 2.216500
		loss: 2.570800
		loss: 2.501200
		loss: 2.568400
		loss: 2.332100
		loss: 2.570000
		loss: 2.467000
		loss: 2.569200
		loss: 2.723400
		loss: 2.569500
		loss: 2.626800
		loss: 2.568900
		loss: 2.688200
		loss: 2.567800
		loss: 2.602900
		loss: 2.568200
		loss: 2.439300
		loss: 2.569100
		loss: 1.996000
		loss: 2.571600
		loss: 2.830400
		loss: 2.566800
		loss: 2.642300
		loss: 2.567900
		loss: 2.529400
		loss: 2.568500
		loss: 2.475200
		loss: 2.568600
		loss: 2.559100
		loss: 2.568100
		loss: 2.784000
		loss: 2.569200
		loss: 2.910300
		loss: 2.569900
		loss: 2.416900
		loss: 2.567100
		loss: 2.444200
		loss: 2.568600
		loss: 2.353200
		loss: 2.566600
		loss: 2.755600
		loss: 2.569000
		loss: 2.330700
		loss: 2.569200
		loss: 2.019300
		loss: 2.571100
		loss: 2.851100
		loss: 2.569500
		loss: 2.711100
		loss: 2.566900
		loss: 2.396700
		loss: 2.568800
		loss: 2.795000
		loss: 2.566400
		loss: 2.663100
		loss: 2.568300
		loss: 2.893500
		loss: 2.565900
		loss: 2.650900
		loss: 2.567200
		loss: 2.923100
		loss: 2.569700
		loss: 2.282100
		loss: 2.569400
		loss: 2.553300
		loss: 2.567700
		loss: 2.783800
		loss: 2.568900
		loss: 3.040100
		loss: 2.570400
		loss: 2.800500
		loss: 2.568800
		loss: 2.299700
		loss: 2.566000
		loss: 2.852200
		loss: 2.568900
		loss: 2.517800
		loss: 2.567000
		loss: 2.571200
		loss: 2.567300
		loss: 2.251500
		loss: 2.565500
		loss: 2.449900
		loss: 2.566800
		loss: 2.558700
		loss: 2.567500
		loss: 2.600400
		loss: 2.567100
		loss: 2.506400
		loss: 2.567500
	Overall the loss development was 1.695100 -> 2.567500
problem epoch data for epoch 3, problem epoch 2
	sampling search time: 198.659348487854s
	during this search the following actions were chosen:
		open boot was chosen with probability 1.000000
		fetch wrench boot was chosen with probability 0.202234
		fetch r1 boot was chosen with probability 0.201132
		loosen nuts1 the-hub1 was chosen with probability 0.209071
		fetch jack boot was chosen with probability 0.261676
		fetch r2 boot was chosen with probability 0.300532
		fetch pump boot was chosen with probability 0.344473
		inflate r1 was chosen with probability 0.290186
		inflate r2 was chosen with probability 0.396436
		loosen nuts2 the-hub2 was chosen with probability 0.514953
		jack-up the-hub2 was chosen with probability 0.512786
		undo nuts2 the-hub2 was chosen with probability 0.976904
		remove-wheel w2 the-hub2 was chosen with probability 0.976257
		put-on-wheel r2 the-hub2 was chosen with probability 0.621820
		put-away w2 boot was chosen with probability 0.914577
		put-away pump boot was chosen with probability 0.378113
		do-up nuts2 the-hub2 was chosen with probability 0.526578
		undo nuts2 the-hub2 was chosen with probability 0.559305
	training time: 19.031615734100342s
	during the training the following losses were computed:
		loss: 3.186400
		loss: 2.805600
		loss: 2.694500
		loss: 2.805600
		loss: 3.046500
		loss: 2.805800
		loss: 2.819100
		loss: 2.805700
		loss: 2.758500
		loss: 2.805500
		loss: 2.950000
		loss: 2.805500
		loss: 2.883400
		loss: 2.805300
		loss: 2.928900
		loss: 2.805300
		loss: 2.653400
		loss: 2.805300
		loss: 2.520200
		loss: 2.805300
		loss: 2.732000
		loss: 2.805200
		loss: 3.165200
		loss: 2.805200
		loss: 2.762400
		loss: 2.805100
		loss: 2.784500
		loss: 2.805200
		loss: 2.882100
		loss: 2.805000
		loss: 2.718900
		loss: 2.805100
		loss: 2.772600
		loss: 2.805100
		loss: 3.093000
		loss: 2.805000
		loss: 2.606700
		loss: 2.804900
		loss: 2.908800
		loss: 2.804900
		loss: 2.293400
		loss: 2.804800
		loss: 2.675000
		loss: 2.804700
		loss: 2.845000
		loss: 2.804700
		loss: 2.720600
		loss: 2.804600
		loss: 2.249300
		loss: 2.804600
		loss: 2.760000
		loss: 2.804600
		loss: 3.018700
		loss: 2.804500
		loss: 3.043400
		loss: 2.804500
		loss: 2.875900
		loss: 2.804400
		loss: 2.883700
		loss: 2.804400
		loss: 3.232400
		loss: 2.804400
		loss: 2.638700
		loss: 2.804300
		loss: 3.170100
		loss: 2.804400
		loss: 2.680700
		loss: 2.804400
		loss: 2.499800
		loss: 2.804200
		loss: 2.858100
		loss: 2.804200
		loss: 3.224500
		loss: 2.804200
		loss: 2.824300
		loss: 2.804100
		loss: 3.088700
		loss: 2.804100
		loss: 2.813400
		loss: 2.804100
		loss: 2.664000
		loss: 2.804100
		loss: 3.115500
		loss: 2.804100
		loss: 2.783000
		loss: 2.804000
		loss: 2.920200
		loss: 2.804000
		loss: 2.350100
		loss: 2.803900
		loss: 2.483600
		loss: 2.803900
		loss: 2.770800
		loss: 2.803900
		loss: 3.046400
		loss: 2.803900
		loss: 2.932900
		loss: 2.803900
		loss: 2.926600
		loss: 2.803800
		loss: 3.130300
		loss: 2.803800
		loss: 2.644100
		loss: 2.803800
		loss: 2.754500
		loss: 2.803800
		loss: 2.800500
		loss: 2.803700
		loss: 3.061900
		loss: 2.803800
		loss: 2.697200
		loss: 2.803700
		loss: 2.784300
		loss: 2.803600
		loss: 3.196800
		loss: 2.803600
		loss: 3.079800
		loss: 2.803600
		loss: 2.805000
		loss: 2.803600
		loss: 2.879200
		loss: 2.803700
		loss: 2.664000
		loss: 2.803500
		loss: 2.538900
		loss: 2.803600
		loss: 2.650500
		loss: 2.803400
		loss: 2.849000
		loss: 2.803500
		loss: 3.135300
		loss: 2.803400
		loss: 2.984300
		loss: 2.803300
		loss: 2.633200
		loss: 2.803300
		loss: 2.963700
		loss: 2.803200
		loss: 2.727500
		loss: 2.803200
		loss: 2.820700
		loss: 2.803200
		loss: 3.183100
		loss: 2.803200
		loss: 3.180400
		loss: 2.803200
		loss: 2.882700
		loss: 2.803100
		loss: 2.912000
		loss: 2.803100
		loss: 2.840000
		loss: 2.803100
		loss: 2.775800
		loss: 2.803100
		loss: 2.884700
		loss: 2.803100
		loss: 2.366800
		loss: 2.803100
		loss: 2.778600
		loss: 2.803200
		loss: 2.448900
		loss: 2.803200
		loss: 3.173400
		loss: 2.803100
		loss: 2.914000
		loss: 2.803100
		loss: 2.846600
		loss: 2.803100
		loss: 2.893100
		loss: 2.803000
		loss: 2.645100
		loss: 2.803200
		loss: 3.352400
		loss: 2.803100
		loss: 2.720100
		loss: 2.803200
		loss: 3.026500
		loss: 2.803000
		loss: 2.493900
		loss: 2.803100
		loss: 3.044000
		loss: 2.803200
		loss: 2.378300
		loss: 2.803400
		loss: 2.792000
		loss: 2.803700
		loss: 2.720100
		loss: 2.803500
		loss: 2.684800
		loss: 2.803300
		loss: 2.622400
		loss: 2.803600
		loss: 2.975500
		loss: 2.803300
		loss: 2.973300
		loss: 2.803200
		loss: 2.815300
		loss: 2.803400
		loss: 3.104800
		loss: 2.803100
	Overall the loss development was 3.186400 -> 2.803100
problem epoch data for epoch 3, problem epoch 3
	sampling search time: 33.26454830169678s
	during this search the following actions were chosen:
		close boot was chosen with probability 0.000000
	training time: 18.9208562374115s
	during the training the following losses were computed:
		loss: 3.183900
		loss: 2.802900
		loss: 2.556800
		loss: 2.802900
		loss: 2.999600
		loss: 2.803000
		loss: 2.897400
		loss: 2.803000
		loss: 2.998600
		loss: 2.802700
		loss: 2.980400
		loss: 2.802700
		loss: 2.709900
		loss: 2.802800
		loss: 2.497200
		loss: 2.802800
		loss: 2.754600
		loss: 2.803100
		loss: 2.917500
		loss: 2.803000
		loss: 2.836300
		loss: 2.803100
		loss: 3.372100
		loss: 2.803100
		loss: 3.009800
		loss: 2.803700
		loss: 2.567600
		loss: 2.804800
		loss: 2.564600
		loss: 2.805900
		loss: 2.987100
		loss: 2.806000
		loss: 2.781100
		loss: 2.805500
		loss: 2.577700
		loss: 2.804800
		loss: 3.061600
		loss: 2.803700
		loss: 2.566000
		loss: 2.803700
		loss: 2.319100
		loss: 2.803400
		loss: 3.120900
		loss: 2.803200
		loss: 2.710700
		loss: 2.802800
		loss: 2.811600
		loss: 2.802900
		loss: 2.704000
		loss: 2.802800
		loss: 2.843800
		loss: 2.802500
		loss: 2.978900
		loss: 2.802300
		loss: 2.958400
		loss: 2.802300
		loss: 2.999900
		loss: 2.802300
		loss: 3.031400
		loss: 2.802100
		loss: 2.596500
		loss: 2.802000
		loss: 2.321300
		loss: 2.801800
		loss: 2.487400
		loss: 2.801900
		loss: 2.749400
		loss: 2.801800
		loss: 2.807400
		loss: 2.801700
		loss: 3.083900
		loss: 2.801700
		loss: 2.868100
		loss: 2.801700
		loss: 2.550800
		loss: 2.801700
		loss: 2.864000
		loss: 2.801700
		loss: 2.903100
		loss: 2.801700
		loss: 2.895800
		loss: 2.801600
		loss: 3.251500
		loss: 2.801600
		loss: 2.690500
		loss: 2.801600
		loss: 2.720200
		loss: 2.801600
		loss: 2.810600
		loss: 2.801600
		loss: 2.989900
		loss: 2.801500
		loss: 2.411400
		loss: 2.801600
		loss: 2.902000
		loss: 2.801500
		loss: 3.004500
		loss: 2.801400
		loss: 2.957700
		loss: 2.801500
		loss: 2.657600
		loss: 2.801400
		loss: 2.611200
		loss: 2.801400
		loss: 2.939800
		loss: 2.801400
		loss: 2.689100
		loss: 2.801400
		loss: 2.925600
		loss: 2.801300
		loss: 2.665100
		loss: 2.801300
		loss: 3.048200
		loss: 2.801300
		loss: 3.137800
		loss: 2.801300
		loss: 2.747500
		loss: 2.801300
		loss: 2.948200
		loss: 2.801200
		loss: 3.099100
		loss: 2.801200
		loss: 2.812600
		loss: 2.801200
		loss: 2.769600
		loss: 2.801200
		loss: 2.677600
		loss: 2.801100
		loss: 2.682200
		loss: 2.801100
		loss: 2.573100
		loss: 2.801100
		loss: 3.110200
		loss: 2.801100
		loss: 2.786100
		loss: 2.801100
		loss: 2.985600
		loss: 2.801000
		loss: 2.730200
		loss: 2.801000
		loss: 2.686700
		loss: 2.801000
		loss: 2.831000
		loss: 2.801000
		loss: 2.863300
		loss: 2.800900
		loss: 2.850000
		loss: 2.801000
		loss: 3.214000
		loss: 2.801000
		loss: 3.015600
		loss: 2.800900
		loss: 2.644200
		loss: 2.800900
		loss: 3.006800
		loss: 2.800900
		loss: 2.688400
		loss: 2.800900
		loss: 2.977800
		loss: 2.800900
		loss: 2.671200
		loss: 2.800800
		loss: 2.731900
		loss: 2.800800
		loss: 2.618400
		loss: 2.800800
		loss: 3.081600
		loss: 2.800800
		loss: 2.813400
		loss: 2.800700
		loss: 2.584800
		loss: 2.800700
		loss: 2.929000
		loss: 2.800700
		loss: 2.828600
		loss: 2.800700
		loss: 2.931100
		loss: 2.800700
		loss: 2.729500
		loss: 2.800700
		loss: 2.816600
		loss: 2.800600
		loss: 3.269800
		loss: 2.800600
		loss: 3.078700
		loss: 2.800600
		loss: 2.897500
		loss: 2.800700
		loss: 2.811400
		loss: 2.800600
		loss: 2.729000
		loss: 2.800600
		loss: 2.594400
		loss: 2.800600
		loss: 2.801000
		loss: 2.800600
		loss: 3.174800
		loss: 2.800600
		loss: 2.504400
		loss: 2.800500
	Overall the loss development was 3.183900 -> 2.800500
In the epoch 3 for problem d-02.pddl 0 explorations in the sampling searches reached a goal
Success rate: 0

Epoch 4:
Training data for problem d-01.pddl in epoch 4:
model creation time: 8.13284707069397s
problem epoch data for epoch 4, problem epoch 1
	sampling search time: 3.6291921138763428s
	during this search the following actions were chosen:
		open boot was chosen with probability 1.000000
		fetch r1 boot was chosen with probability 0.370474
		fetch pump boot was chosen with probability 0.504644
		inflate r1 was chosen with probability 0.577486
		fetch jack boot was chosen with probability 0.984537
		put-away pump boot was chosen with probability 0.876774
		jack-up the-hub1 was chosen with probability 0.598281
		fetch pump boot was chosen with probability 0.936752
		put-away pump boot was chosen with probability 0.995389
	training time: 38.19296145439148s
	during the training the following losses were computed:
		loss: 2.000000
		loss: 1.959500
		loss: 1.911700
		loss: 1.866700
		loss: 1.823000
		loss: 1.781300
		loss: 1.740300
		loss: 1.701600
		loss: 1.664700
		loss: 1.629200
		loss: 1.595900
		loss: 1.564600
		loss: 1.535000
		loss: 1.507600
		loss: 1.482500
		loss: 1.459400
		loss: 1.438800
		loss: 1.420800
		loss: 1.405600
		loss: 1.393200
		loss: 1.383500
		loss: 1.376200
		loss: 1.371100
		loss: 1.367500
		loss: 1.364700
		loss: 1.362500
		loss: 1.360400
		loss: 1.358100
		loss: 1.355800
		loss: 1.353400
		loss: 1.351000
		loss: 1.348500
		loss: 1.346200
		loss: 1.344000
		loss: 1.341800
		loss: 1.339800
		loss: 1.337800
		loss: 1.335800
		loss: 1.333900
		loss: 1.332100
		loss: 1.330400
		loss: 1.328700
		loss: 1.327200
		loss: 1.326000
		loss: 1.324900
		loss: 1.324000
		loss: 1.323200
		loss: 1.322500
		loss: 1.321900
		loss: 1.321200
		loss: 1.320600
		loss: 1.319900
		loss: 1.319300
		loss: 1.318600
		loss: 1.318000
		loss: 1.317500
		loss: 1.317000
		loss: 1.316600
		loss: 1.316300
		loss: 1.315900
		loss: 1.315500
		loss: 1.315100
		loss: 1.314700
		loss: 1.314300
		loss: 1.314000
		loss: 1.313700
		loss: 1.313400
		loss: 1.313100
		loss: 1.312900
		loss: 1.312600
		loss: 1.312400
		loss: 1.312100
		loss: 1.311900
		loss: 1.311700
		loss: 1.311600
		loss: 1.311400
		loss: 1.311300
		loss: 1.311100
		loss: 1.310900
		loss: 1.310800
		loss: 1.310600
		loss: 1.310500
		loss: 1.310300
		loss: 1.310200
		loss: 1.310100
		loss: 1.310000
		loss: 1.309800
		loss: 1.309700
		loss: 1.309600
		loss: 1.309500
		loss: 1.309400
		loss: 1.309300
		loss: 1.309200
		loss: 1.309100
		loss: 1.309000
		loss: 1.308900
		loss: 1.308800
		loss: 1.308700
		loss: 1.308600
		loss: 1.308500
	Overall the loss development was 2.000000 -> 1.308500
problem epoch data for epoch 4, problem epoch 2
	sampling search time: 1.9533803462982178s
	during this search the following actions were chosen:
		close boot was chosen with probability 0.000000
	training time: 10.136687278747559s
	during the training the following losses were computed:
		loss: 1.308400
		loss: 1.308300
		loss: 1.308300
		loss: 1.308200
		loss: 1.308100
		loss: 1.308000
		loss: 1.307900
		loss: 1.307800
		loss: 1.307800
		loss: 1.307700
		loss: 1.307600
		loss: 1.307500
		loss: 1.307500
		loss: 1.307400
		loss: 1.307300
		loss: 1.307200
		loss: 1.307200
		loss: 1.307100
		loss: 1.307000
		loss: 1.307000
		loss: 1.306900
		loss: 1.306800
		loss: 1.306800
		loss: 1.306700
		loss: 1.306600
		loss: 1.306600
		loss: 1.306500
		loss: 1.306400
		loss: 1.306400
		loss: 1.306300
		loss: 1.306300
		loss: 1.306200
		loss: 1.306100
		loss: 1.306100
		loss: 1.306000
		loss: 1.306000
		loss: 1.305900
		loss: 1.305800
		loss: 1.305800
		loss: 1.305700
		loss: 1.305700
		loss: 1.305600
		loss: 1.305600
		loss: 1.305500
		loss: 1.305500
		loss: 1.305400
		loss: 1.305400
		loss: 1.305300
		loss: 1.305200
		loss: 1.305200
		loss: 1.305100
		loss: 1.305100
		loss: 1.305000
		loss: 1.305000
		loss: 1.304900
		loss: 1.304900
		loss: 1.304800
		loss: 1.304800
		loss: 1.304700
		loss: 1.304700
		loss: 1.304600
		loss: 1.304600
		loss: 1.304500
		loss: 1.304500
		loss: 1.304500
		loss: 1.304400
		loss: 1.304400
		loss: 1.304300
		loss: 1.304300
		loss: 1.304200
		loss: 1.304200
		loss: 1.304100
		loss: 1.304100
		loss: 1.304000
		loss: 1.304000
		loss: 1.304000
		loss: 1.303900
		loss: 1.303900
		loss: 1.303800
		loss: 1.303800
		loss: 1.303700
		loss: 1.303700
		loss: 1.303700
		loss: 1.303700
		loss: 1.303700
		loss: 1.303800
		loss: 1.303900
		loss: 1.303900
		loss: 1.303700
		loss: 1.303400
		loss: 1.303400
		loss: 1.303500
		loss: 1.303500
		loss: 1.303200
		loss: 1.303200
		loss: 1.303300
		loss: 1.303200
		loss: 1.303100
		loss: 1.303000
		loss: 1.303100
	Overall the loss development was 1.308400 -> 1.303100
problem epoch data for epoch 4, problem epoch 3
	sampling search time: 1.8934204578399658s
	during this search the following actions were chosen:
		close boot was chosen with probability 0.000000
	training time: 10.136333465576172s
	during the training the following losses were computed:
		loss: 1.303000
		loss: 1.302900
		loss: 1.302900
		loss: 1.302900
		loss: 1.302800
		loss: 1.302800
		loss: 1.302800
		loss: 1.302700
		loss: 1.302700
		loss: 1.302600
		loss: 1.302600
		loss: 1.302600
		loss: 1.302500
		loss: 1.302500
		loss: 1.302500
		loss: 1.302400
		loss: 1.302400
		loss: 1.302300
		loss: 1.302300
		loss: 1.302300
		loss: 1.302200
		loss: 1.302200
		loss: 1.302200
		loss: 1.302100
		loss: 1.302100
		loss: 1.302100
		loss: 1.302000
		loss: 1.302000
		loss: 1.302000
		loss: 1.301900
		loss: 1.301900
		loss: 1.301900
		loss: 1.301800
		loss: 1.301800
		loss: 1.301800
		loss: 1.301700
		loss: 1.301700
		loss: 1.301700
		loss: 1.301600
		loss: 1.301600
		loss: 1.301600
		loss: 1.301500
		loss: 1.301500
		loss: 1.301500
		loss: 1.301400
		loss: 1.301400
		loss: 1.301400
		loss: 1.301300
		loss: 1.301300
		loss: 1.301300
		loss: 1.301300
		loss: 1.301200
		loss: 1.301200
		loss: 1.301200
		loss: 1.301100
		loss: 1.301100
		loss: 1.301100
		loss: 1.301000
		loss: 1.301000
		loss: 1.301000
		loss: 1.300900
		loss: 1.300900
		loss: 1.300900
		loss: 1.300900
		loss: 1.300800
		loss: 1.300800
		loss: 1.300800
		loss: 1.300700
		loss: 1.300700
		loss: 1.300700
		loss: 1.300700
		loss: 1.300600
		loss: 1.300600
		loss: 1.300600
		loss: 1.300500
		loss: 1.300500
		loss: 1.300500
		loss: 1.300500
		loss: 1.300400
		loss: 1.300400
		loss: 1.300400
		loss: 1.300300
		loss: 1.300300
		loss: 1.300300
		loss: 1.300300
		loss: 1.300200
		loss: 1.300200
		loss: 1.300200
		loss: 1.300100
		loss: 1.300100
		loss: 1.300100
		loss: 1.300100
		loss: 1.300000
		loss: 1.300000
		loss: 1.300000
		loss: 1.300000
		loss: 1.300000
		loss: 1.299900
		loss: 1.300000
		loss: 1.300000
	Overall the loss development was 1.303000 -> 1.300000
In the epoch 4 for problem d-01.pddl 0 explorations in the sampling searches reached a goal
Training data for problem d-02.pddl in epoch 4:
model creation time: 15.575743913650513s
problem epoch data for epoch 4, problem epoch 1
	sampling search time: 33.30935859680176s
	during this search the following actions were chosen:
		close boot was chosen with probability 0.000000
	training time: 62.665255308151245s
	during the training the following losses were computed:
		loss: 2.694500
		loss: 2.604500
		loss: 2.584600
		loss: 2.571200
		loss: 2.566600
		loss: 2.569300
		loss: 2.568500
		loss: 2.560100
		loss: 2.548800
		loss: 2.541200
		loss: 2.538600
		loss: 2.537800
		loss: 2.536000
		loss: 2.533300
		loss: 2.530200
		loss: 2.526900
		loss: 2.523400
		loss: 2.520000
		loss: 2.517500
		loss: 2.516300
		loss: 2.515800
		loss: 2.515200
		loss: 2.513700
		loss: 2.511600
		loss: 2.509400
		loss: 2.507600
		loss: 2.505900
		loss: 2.504500
		loss: 2.503500
		loss: 2.503000
		loss: 2.502700
		loss: 2.502000
		loss: 2.500900
		loss: 2.499700
		loss: 2.498600
		loss: 2.497800
		loss: 2.497100
		loss: 2.496500
		loss: 2.496000
		loss: 2.495500
		loss: 2.495000
		loss: 2.494300
		loss: 2.493700
		loss: 2.493200
		loss: 2.492800
		loss: 2.492400
		loss: 2.491900
		loss: 2.491400
		loss: 2.491000
		loss: 2.490600
		loss: 2.490200
		loss: 2.489900
		loss: 2.489700
		loss: 2.489300
		loss: 2.489000
		loss: 2.488600
		loss: 2.488300
		loss: 2.488100
		loss: 2.487800
		loss: 2.487600
		loss: 2.487400
		loss: 2.487100
		loss: 2.486900
		loss: 2.486700
		loss: 2.486500
		loss: 2.486400
		loss: 2.486200
		loss: 2.486000
		loss: 2.485900
		loss: 2.485700
		loss: 2.485600
		loss: 2.485500
		loss: 2.485400
		loss: 2.485200
		loss: 2.485100
		loss: 2.485000
		loss: 2.484900
		loss: 2.484800
		loss: 2.484700
		loss: 2.484600
		loss: 2.484600
		loss: 2.484500
		loss: 2.484400
		loss: 2.484300
		loss: 2.484200
		loss: 2.484200
		loss: 2.484100
		loss: 2.484000
		loss: 2.484000
		loss: 2.483900
		loss: 2.483900
		loss: 2.483800
		loss: 2.483700
		loss: 2.483700
		loss: 2.483600
		loss: 2.483600
		loss: 2.483500
		loss: 2.483500
		loss: 2.483400
		loss: 2.483400
	Overall the loss development was 2.694500 -> 2.483400
problem epoch data for epoch 4, problem epoch 2
	sampling search time: 33.35136342048645s
	during this search the following actions were chosen:
		close boot was chosen with probability 0.000000
	training time: 10.14068865776062s
	during the training the following losses were computed:
		loss: 2.483300
		loss: 2.483300
		loss: 2.483200
		loss: 2.483200
		loss: 2.483100
		loss: 2.483100
		loss: 2.483000
		loss: 2.483000
		loss: 2.483000
		loss: 2.482900
		loss: 2.482900
		loss: 2.482800
		loss: 2.482800
		loss: 2.482800
		loss: 2.482700
		loss: 2.482700
		loss: 2.482700
		loss: 2.482600
		loss: 2.482600
		loss: 2.482500
		loss: 2.482500
		loss: 2.482500
		loss: 2.482400
		loss: 2.482400
		loss: 2.482400
		loss: 2.482300
		loss: 2.482300
		loss: 2.482300
		loss: 2.482200
		loss: 2.482200
		loss: 2.482200
		loss: 2.482100
		loss: 2.482100
		loss: 2.482100
		loss: 2.482000
		loss: 2.482000
		loss: 2.482000
		loss: 2.482000
		loss: 2.481900
		loss: 2.481900
		loss: 2.481900
		loss: 2.481800
		loss: 2.481800
		loss: 2.481800
		loss: 2.481800
		loss: 2.481700
		loss: 2.481700
		loss: 2.481700
		loss: 2.481700
		loss: 2.481600
		loss: 2.481600
		loss: 2.481600
		loss: 2.481500
		loss: 2.481500
		loss: 2.481500
		loss: 2.481500
		loss: 2.481400
		loss: 2.481400
		loss: 2.481400
		loss: 2.481400
		loss: 2.481300
		loss: 2.481300
		loss: 2.481300
		loss: 2.481300
		loss: 2.481300
		loss: 2.481200
		loss: 2.481200
		loss: 2.481200
		loss: 2.481200
		loss: 2.481100
		loss: 2.481100
		loss: 2.481100
		loss: 2.481100
		loss: 2.481100
		loss: 2.481000
		loss: 2.481000
		loss: 2.481000
		loss: 2.481000
		loss: 2.480900
		loss: 2.480900
		loss: 2.480900
		loss: 2.480900
		loss: 2.480900
		loss: 2.480800
		loss: 2.480800
		loss: 2.480800
		loss: 2.480800
		loss: 2.480800
		loss: 2.480700
		loss: 2.480700
		loss: 2.480700
		loss: 2.480700
		loss: 2.480700
		loss: 2.480600
		loss: 2.480600
		loss: 2.480600
		loss: 2.480600
		loss: 2.480600
		loss: 2.480500
		loss: 2.480500
	Overall the loss development was 2.483300 -> 2.480500
problem epoch data for epoch 4, problem epoch 3
	sampling search time: 188.0634036064148s
	during this search the following actions were chosen:
		open boot was chosen with probability 1.000000
		fetch jack boot was chosen with probability 0.200425
		fetch pump boot was chosen with probability 0.259211
		fetch r2 boot was chosen with probability 0.314539
		fetch r1 boot was chosen with probability 0.446045
		fetch wrench boot was chosen with probability 0.729715
		loosen nuts1 the-hub1 was chosen with probability 0.446454
		loosen nuts2 the-hub2 was chosen with probability 0.575283
		jack-up the-hub2 was chosen with probability 0.477358
		undo nuts2 the-hub2 was chosen with probability 0.852535
		remove-wheel w2 the-hub2 was chosen with probability 0.833463
		put-on-wheel r2 the-hub2 was chosen with probability 0.589083
		put-away w2 boot was chosen with probability 0.853593
		inflate r1 was chosen with probability 0.389691
		inflate r2 was chosen with probability 0.638221
		do-up nuts2 the-hub2 was chosen with probability 0.469841
		undo nuts2 the-hub2 was chosen with probability 0.475736
	training time: 17.61197519302368s
	during the training the following losses were computed:
		loss: 3.267900
		loss: 2.304400
		loss: 1.887300
		loss: 2.178900
		loss: 2.065000
		loss: 2.098200
		loss: 2.115500
		loss: 2.065700
		loss: 1.833600
		loss: 2.022300
		loss: 2.100100
		loss: 2.025200
		loss: 2.050100
		loss: 2.020600
		loss: 1.868100
		loss: 2.017800
		loss: 2.197600
		loss: 2.012400
		loss: 2.132200
		loss: 2.012600
		loss: 1.797200
		loss: 1.998000
		loss: 1.970700
		loss: 1.995600
		loss: 1.729700
		loss: 1.993500
		loss: 1.861400
		loss: 1.994100
		loss: 1.944000
		loss: 1.987700
		loss: 1.942400
		loss: 1.985600
		loss: 2.035500
		loss: 1.982300
		loss: 2.080400
		loss: 1.978300
		loss: 1.857100
		loss: 1.977700
		loss: 2.029900
		loss: 1.976800
		loss: 2.131200
		loss: 1.975100
		loss: 1.702400
		loss: 1.977500
		loss: 1.727300
		loss: 1.976600
		loss: 1.992300
		loss: 1.974400
		loss: 2.092800
		loss: 1.974000
		loss: 1.745600
		loss: 1.971700
		loss: 2.012700
		loss: 1.972600
		loss: 2.236000
		loss: 1.973800
		loss: 1.725600
		loss: 1.970300
		loss: 2.039200
		loss: 1.971200
		loss: 1.902900
		loss: 1.971900
		loss: 1.955000
		loss: 1.971100
		loss: 1.990300
		loss: 1.971200
		loss: 2.312100
		loss: 1.968800
		loss: 1.607900
		loss: 1.968700
		loss: 2.011100
		loss: 1.970400
		loss: 2.135900
		loss: 1.971500
		loss: 1.967600
		loss: 1.970400
		loss: 1.894500
		loss: 1.970700
		loss: 2.055400
		loss: 1.969800
		loss: 2.010000
		loss: 1.970300
		loss: 1.977000
		loss: 1.970100
		loss: 2.109900
		loss: 1.969100
		loss: 1.766500
		loss: 1.968700
		loss: 1.717700
		loss: 1.971400
		loss: 1.821700
		loss: 1.970700
		loss: 1.927800
		loss: 1.969400
		loss: 1.994600
		loss: 1.969800
		loss: 2.078300
		loss: 1.969000
		loss: 2.068600
		loss: 1.968900
		loss: 2.073100
		loss: 1.968900
		loss: 2.155500
		loss: 1.968300
		loss: 2.072700
		loss: 1.970000
		loss: 2.053800
		loss: 1.968800
		loss: 1.841400
		loss: 1.968600
		loss: 1.918400
		loss: 1.969000
		loss: 1.871000
		loss: 1.969800
		loss: 2.017700
		loss: 1.969000
		loss: 2.063900
		loss: 1.969700
		loss: 1.675700
		loss: 1.970900
		loss: 1.944200
		loss: 1.969200
		loss: 2.014800
		loss: 1.969300
		loss: 2.400200
		loss: 1.966300
		loss: 2.019400
		loss: 1.969200
		loss: 1.993100
		loss: 1.968800
		loss: 2.038900
		loss: 1.968400
		loss: 2.093500
		loss: 1.968100
		loss: 1.986900
		loss: 1.968800
		loss: 1.934600
		loss: 1.969000
		loss: 2.030000
		loss: 1.969200
		loss: 2.465100
		loss: 1.971700
		loss: 1.887800
		loss: 1.968200
		loss: 2.014600
		loss: 1.968400
		loss: 1.875600
		loss: 1.969200
		loss: 1.778000
		loss: 1.967500
		loss: 2.092800
		loss: 1.967800
		loss: 2.036000
		loss: 1.969000
		loss: 1.801400
		loss: 1.969600
		loss: 2.170300
		loss: 1.969700
		loss: 1.981800
		loss: 1.968600
		loss: 1.859800
		loss: 1.967800
		loss: 1.901100
		loss: 1.968000
		loss: 2.106000
		loss: 1.969300
		loss: 2.098800
		loss: 1.969200
		loss: 1.899900
		loss: 1.968700
		loss: 1.978100
		loss: 1.968500
		loss: 2.028000
		loss: 1.968700
		loss: 1.811100
		loss: 1.967300
		loss: 1.782200
		loss: 1.969500
		loss: 1.916700
		loss: 1.967900
		loss: 2.011700
		loss: 1.968600
		loss: 1.825300
		loss: 1.967400
		loss: 2.226700
		loss: 1.969700
		loss: 1.973600
		loss: 1.968200
		loss: 1.900200
		loss: 1.968500
		loss: 2.204200
		loss: 1.966700
		loss: 1.816000
		loss: 1.967100
		loss: 1.898700
		loss: 1.967600
		loss: 1.752100
		loss: 1.969300
		loss: 2.171100
		loss: 1.966700
	Overall the loss development was 3.267900 -> 1.966700
In the epoch 4 for problem d-02.pddl 0 explorations in the sampling searches reached a goal
Success rate: 0

Epoch 5:
Training data for problem d-01.pddl in epoch 5:
model creation time: 7.596772193908691s
problem epoch data for epoch 5, problem epoch 1
	sampling search time: 3.712618112564087s
	during this search the following actions were chosen:
		open boot was chosen with probability 1.000000
		fetch r1 boot was chosen with probability 0.385808
		fetch wrench boot was chosen with probability 0.348761
		loosen nuts1 the-hub1 was chosen with probability 0.353622
		fetch jack boot was chosen with probability 0.630836
		fetch pump boot was chosen with probability 0.612424
		inflate r1 was chosen with probability 0.667379
		jack-up the-hub1 was chosen with probability 0.954324
		undo nuts1 the-hub1 was chosen with probability 0.980631
		remove-wheel w1 the-hub1 was chosen with probability 0.976457
		put-away w1 boot was chosen with probability 0.530434
		put-on-wheel r1 the-hub1 was chosen with probability 0.976023
		remove-wheel r1 the-hub1 was chosen with probability 0.409743
	training time: 37.915183782577515s
	during the training the following losses were computed:
		loss: 1.318400
		loss: 1.355000
		loss: 1.313400
		loss: 1.318600
		loss: 1.329300
		loss: 1.318200
		loss: 1.307100
		loss: 1.309200
		loss: 1.315400
		loss: 1.313900
		loss: 1.307500
		loss: 1.304300
		loss: 1.306600
		loss: 1.309300
		loss: 1.308300
		loss: 1.305000
		loss: 1.303200
		loss: 1.304200
		loss: 1.305700
		loss: 1.305600
		loss: 1.304000
		loss: 1.302900
		loss: 1.303200
		loss: 1.303900
		loss: 1.304000
		loss: 1.303200
		loss: 1.302500
		loss: 1.302500
		loss: 1.302800
		loss: 1.302900
		loss: 1.302600
		loss: 1.302100
		loss: 1.302000
		loss: 1.302100
		loss: 1.302200
		loss: 1.302000
		loss: 1.301700
		loss: 1.301600
		loss: 1.301700
		loss: 1.301700
		loss: 1.301600
		loss: 1.301400
		loss: 1.301400
		loss: 1.301400
		loss: 1.301400
		loss: 1.301300
		loss: 1.301200
		loss: 1.301200
		loss: 1.301200
		loss: 1.301100
		loss: 1.301100
		loss: 1.301000
		loss: 1.301000
		loss: 1.300900
		loss: 1.300900
		loss: 1.300900
		loss: 1.300800
		loss: 1.300800
		loss: 1.300700
		loss: 1.300700
		loss: 1.300700
		loss: 1.300700
		loss: 1.300600
		loss: 1.300600
		loss: 1.300600
		loss: 1.300500
		loss: 1.300500
		loss: 1.300500
		loss: 1.300400
		loss: 1.300400
		loss: 1.300400
		loss: 1.300300
		loss: 1.300300
		loss: 1.300300
		loss: 1.300300
		loss: 1.300200
		loss: 1.300200
		loss: 1.300200
		loss: 1.300100
		loss: 1.300100
		loss: 1.300100
		loss: 1.300100
		loss: 1.300000
		loss: 1.300000
		loss: 1.300000
		loss: 1.300000
		loss: 1.299900
		loss: 1.299900
		loss: 1.299900
		loss: 1.299900
		loss: 1.299800
		loss: 1.299800
		loss: 1.299800
		loss: 1.299800
		loss: 1.299700
		loss: 1.299700
		loss: 1.299700
		loss: 1.299700
		loss: 1.299600
		loss: 1.299600
	Overall the loss development was 1.318400 -> 1.299600
problem epoch data for epoch 5, problem epoch 2
	sampling search time: 3.528352975845337s
	during this search the following actions were chosen:
		open boot was chosen with probability 1.000000
		fetch r1 boot was chosen with probability 0.257293
		fetch pump boot was chosen with probability 0.339129
		inflate r1 was chosen with probability 0.377797
		fetch wrench boot was chosen with probability 0.496384
		loosen nuts1 the-hub1 was chosen with probability 0.498602
		fetch jack boot was chosen with probability 0.972827
		jack-up the-hub1 was chosen with probability 0.960539
		undo nuts1 the-hub1 was chosen with probability 0.981017
		remove-wheel w1 the-hub1 was chosen with probability 0.977061
		put-on-wheel r1 the-hub1 was chosen with probability 0.581300
		put-away w1 boot was chosen with probability 0.884841
		remove-wheel r1 the-hub1 was chosen with probability 0.435236
		put-on-wheel r1 the-hub1 was chosen with probability 0.980339
	training time: 10.137987852096558s
	during the training the following losses were computed:
		loss: 1.433100
		loss: 1.433000
		loss: 1.432900
		loss: 1.432900
		loss: 1.432800
		loss: 1.432800
		loss: 1.432800
		loss: 1.432700
		loss: 1.432700
		loss: 1.432700
		loss: 1.432600
		loss: 1.432600
		loss: 1.432500
		loss: 1.432500
		loss: 1.432500
		loss: 1.432500
		loss: 1.432400
		loss: 1.432400
		loss: 1.432400
		loss: 1.432300
		loss: 1.432300
		loss: 1.432300
		loss: 1.432200
		loss: 1.432200
		loss: 1.432200
		loss: 1.432200
		loss: 1.432200
		loss: 1.432100
		loss: 1.432100
		loss: 1.432100
		loss: 1.432100
		loss: 1.432000
		loss: 1.432000
		loss: 1.432000
		loss: 1.432000
		loss: 1.432000
		loss: 1.431900
		loss: 1.431900
		loss: 1.431900
		loss: 1.431900
		loss: 1.431900
		loss: 1.431800
		loss: 1.431800
		loss: 1.431800
		loss: 1.431800
		loss: 1.431800
		loss: 1.431700
		loss: 1.431700
		loss: 1.431700
		loss: 1.431700
		loss: 1.431700
		loss: 1.431600
		loss: 1.431600
		loss: 1.431600
		loss: 1.431600
		loss: 1.431600
		loss: 1.431500
		loss: 1.431500
		loss: 1.431500
		loss: 1.431500
		loss: 1.431500
		loss: 1.431500
		loss: 1.431400
		loss: 1.431400
		loss: 1.431400
		loss: 1.431400
		loss: 1.431400
		loss: 1.431300
		loss: 1.431300
		loss: 1.431300
		loss: 1.431300
		loss: 1.431300
		loss: 1.431300
		loss: 1.431200
		loss: 1.431200
		loss: 1.431200
		loss: 1.431200
		loss: 1.431200
		loss: 1.431200
		loss: 1.431100
		loss: 1.431100
		loss: 1.431100
		loss: 1.431100
		loss: 1.431100
		loss: 1.431100
		loss: 1.431000
		loss: 1.431000
		loss: 1.431000
		loss: 1.431000
		loss: 1.431000
		loss: 1.431000
		loss: 1.430900
		loss: 1.430900
		loss: 1.430900
		loss: 1.430900
		loss: 1.430900
		loss: 1.430900
		loss: 1.430800
		loss: 1.430800
		loss: 1.430800
	Overall the loss development was 1.433100 -> 1.430800
problem epoch data for epoch 5, problem epoch 3
	sampling search time: 3.5646111965179443s
	during this search the following actions were chosen:
		open boot was chosen with probability 1.000000
		fetch r1 boot was chosen with probability 0.258567
		fetch wrench boot was chosen with probability 0.335940
		loosen nuts1 the-hub1 was chosen with probability 0.368159
		fetch jack boot was chosen with probability 0.502855
		fetch pump boot was chosen with probability 0.611880
		inflate r1 was chosen with probability 0.658533
		jack-up the-hub1 was chosen with probability 0.955262
		undo nuts1 the-hub1 was chosen with probability 0.979722
		remove-wheel w1 the-hub1 was chosen with probability 0.976305
		put-on-wheel r1 the-hub1 was chosen with probability 0.577641
		put-away w1 boot was chosen with probability 0.891791
		remove-wheel r1 the-hub1 was chosen with probability 0.400122
		put-on-wheel r1 the-hub1 was chosen with probability 0.979649
	training time: 10.137237310409546s
	during the training the following losses were computed:
		loss: 1.430800
		loss: 1.430800
		loss: 1.430800
		loss: 1.430700
		loss: 1.430700
		loss: 1.430700
		loss: 1.430700
		loss: 1.430700
		loss: 1.430700
		loss: 1.430600
		loss: 1.430600
		loss: 1.430600
		loss: 1.430600
		loss: 1.430600
		loss: 1.430600
		loss: 1.430600
		loss: 1.430500
		loss: 1.430500
		loss: 1.430500
		loss: 1.430500
		loss: 1.430500
		loss: 1.430500
		loss: 1.430500
		loss: 1.430400
		loss: 1.430400
		loss: 1.430400
		loss: 1.430400
		loss: 1.430400
		loss: 1.430400
		loss: 1.430300
		loss: 1.430300
		loss: 1.430300
		loss: 1.430300
		loss: 1.430300
		loss: 1.430300
		loss: 1.430300
		loss: 1.430200
		loss: 1.430200
		loss: 1.430200
		loss: 1.430200
		loss: 1.430200
		loss: 1.430200
		loss: 1.430200
		loss: 1.430100
		loss: 1.430100
		loss: 1.430100
		loss: 1.430100
		loss: 1.430100
		loss: 1.430100
		loss: 1.430100
		loss: 1.430000
		loss: 1.430000
		loss: 1.430000
		loss: 1.430000
		loss: 1.430000
		loss: 1.430000
		loss: 1.430000
		loss: 1.430000
		loss: 1.429900
		loss: 1.429900
		loss: 1.429900
		loss: 1.429900
		loss: 1.429900
		loss: 1.429900
		loss: 1.429900
		loss: 1.429800
		loss: 1.429800
		loss: 1.429800
		loss: 1.429800
		loss: 1.429800
		loss: 1.429800
		loss: 1.429800
		loss: 1.429700
		loss: 1.429700
		loss: 1.429700
		loss: 1.429700
		loss: 1.429700
		loss: 1.429700
		loss: 1.429700
		loss: 1.429700
		loss: 1.429600
		loss: 1.429600
		loss: 1.429600
		loss: 1.429600
		loss: 1.429600
		loss: 1.429600
		loss: 1.429600
		loss: 1.429600
		loss: 1.429500
		loss: 1.429500
		loss: 1.429500
		loss: 1.429500
		loss: 1.429500
		loss: 1.429500
		loss: 1.429500
		loss: 1.429500
		loss: 1.429400
		loss: 1.429400
		loss: 1.429400
		loss: 1.429400
	Overall the loss development was 1.430800 -> 1.429400
In the epoch 5 for problem d-01.pddl 0 explorations in the sampling searches reached a goal
Training data for problem d-02.pddl in epoch 5:
model creation time: 15.682127237319946s
problem epoch data for epoch 5, problem epoch 1
	sampling search time: 175.79509091377258s
	during this search the following actions were chosen:
		open boot was chosen with probability 1.000000
		fetch wrench boot was chosen with probability 0.285223
		loosen nuts2 the-hub2 was chosen with probability 0.211650
		loosen nuts1 the-hub1 was chosen with probability 0.370246
		fetch pump boot was chosen with probability 0.340107
		inflate r1 was chosen with probability 0.282864
		inflate r2 was chosen with probability 0.393614
		fetch jack boot was chosen with probability 0.465748
		fetch r2 boot was chosen with probability 0.253553
		jack-up the-hub2 was chosen with probability 0.357791
		undo nuts2 the-hub2 was chosen with probability 0.764638
		remove-wheel w2 the-hub2 was chosen with probability 0.778362
		put-on-wheel r2 the-hub2 was chosen with probability 0.621179
		put-away w2 boot was chosen with probability 0.651368
		fetch r1 boot was chosen with probability 0.709795
		do-up nuts2 the-hub2 was chosen with probability 0.438300
		undo nuts2 the-hub2 was chosen with probability 0.681053
	training time: 71.24122619628906s
	during the training the following losses were computed:
		loss: 1.437600
		loss: 2.522400
		loss: 2.531200
		loss: 2.454800
		loss: 2.156300
		loss: 2.430400
		loss: 2.652900
		loss: 2.427800
		loss: 2.100500
		loss: 2.420900
		loss: 2.378700
		loss: 2.413100
		loss: 2.495000
		loss: 2.410300
		loss: 2.319200
		loss: 2.404300
		loss: 2.513600
		loss: 2.404900
		loss: 2.298200
		loss: 2.399600
		loss: 1.992400
		loss: 2.396200
		loss: 2.087400
		loss: 2.394200
		loss: 1.926000
		loss: 2.391500
		loss: 2.320700
		loss: 2.391100
		loss: 2.503000
		loss: 2.388700
		loss: 2.531600
		loss: 2.387700
		loss: 2.453800
		loss: 2.386600
		loss: 2.657800
		loss: 2.385800
		loss: 2.323700
		loss: 2.384600
		loss: 2.290100
		loss: 2.383300
		loss: 2.378100
		loss: 2.382300
		loss: 2.870700
		loss: 2.381400
		loss: 2.038500
		loss: 2.380900
		loss: 2.205700
		loss: 2.379800
		loss: 2.231700
		loss: 2.379400
		loss: 2.683400
		loss: 2.378500
		loss: 2.338800
		loss: 2.378000
		loss: 2.324200
		loss: 2.377100
		loss: 2.200400
		loss: 2.377000
		loss: 2.506800
		loss: 2.376200
		loss: 2.374200
		loss: 2.376000
		loss: 2.740700
		loss: 2.375400
		loss: 2.199200
		loss: 2.375200
		loss: 2.645800
		loss: 2.374700
		loss: 2.219900
		loss: 2.374500
		loss: 2.388800
		loss: 2.374100
		loss: 2.343500
		loss: 2.373900
		loss: 2.839200
		loss: 2.373700
		loss: 2.478200
		loss: 2.373400
		loss: 2.313500
		loss: 2.373200
		loss: 2.450700
		loss: 2.373000
		loss: 2.533200
		loss: 2.372900
		loss: 2.380400
		loss: 2.372700
		loss: 2.619800
		loss: 2.372500
		loss: 2.029800
		loss: 2.372500
		loss: 2.347500
		loss: 2.372200
		loss: 2.090600
		loss: 2.372200
		loss: 2.044900
		loss: 2.372000
		loss: 2.829400
		loss: 2.371900
		loss: 2.428000
		loss: 2.371800
		loss: 2.209600
		loss: 2.371800
		loss: 2.368700
		loss: 2.371600
		loss: 2.193100
		loss: 2.371600
		loss: 2.327200
		loss: 2.371500
		loss: 2.327200
		loss: 2.371400
		loss: 2.488300
		loss: 2.371300
		loss: 2.134200
		loss: 2.371200
		loss: 2.502900
		loss: 2.371200
		loss: 2.248100
		loss: 2.371100
		loss: 2.505900
		loss: 2.371000
		loss: 2.634000
		loss: 2.370900
		loss: 2.412300
		loss: 2.370900
		loss: 2.286700
		loss: 2.370800
		loss: 2.248500
		loss: 2.370800
		loss: 2.159000
		loss: 2.370700
		loss: 2.795400
		loss: 2.370700
		loss: 2.463400
		loss: 2.370700
		loss: 2.243800
		loss: 2.370500
		loss: 2.473100
		loss: 2.370500
		loss: 2.238900
		loss: 2.370500
		loss: 2.272000
		loss: 2.370500
		loss: 2.416000
		loss: 2.370400
		loss: 2.457800
		loss: 2.370400
		loss: 2.249300
		loss: 2.370300
		loss: 2.450300
		loss: 2.370300
		loss: 2.174500
		loss: 2.370300
		loss: 2.375000
		loss: 2.370500
		loss: 2.502200
		loss: 2.370100
		loss: 2.254900
		loss: 2.370300
		loss: 2.540700
		loss: 2.370300
		loss: 2.364500
		loss: 2.370100
		loss: 2.092200
		loss: 2.370100
		loss: 2.276700
		loss: 2.370100
		loss: 2.438700
		loss: 2.370000
		loss: 2.041600
		loss: 2.369900
		loss: 2.480700
		loss: 2.370000
		loss: 1.847800
		loss: 2.369800
		loss: 2.632500
		loss: 2.369800
		loss: 2.310700
		loss: 2.369700
		loss: 2.266800
		loss: 2.369700
		loss: 2.352800
		loss: 2.369600
		loss: 2.384800
		loss: 2.369600
		loss: 2.169100
		loss: 2.369600
		loss: 2.471500
		loss: 2.369600
		loss: 2.276100
		loss: 2.369500
		loss: 2.295000
		loss: 2.369500
		loss: 2.146900
		loss: 2.369400
		loss: 2.298500
		loss: 2.369500
		loss: 2.164700
		loss: 2.369400
		loss: 2.338300
		loss: 2.369500
	Overall the loss development was 1.437600 -> 2.369500
problem epoch data for epoch 5, problem epoch 2
	sampling search time: 33.22680592536926s
	during this search the following actions were chosen:
		close boot was chosen with probability 0.000000
	training time: 18.715038061141968s
	during the training the following losses were computed:
		loss: 1.346900
		loss: 2.369400
		loss: 2.423300
		loss: 2.369300
		loss: 2.346100
		loss: 2.369400
		loss: 2.510100
		loss: 2.369500
		loss: 2.601900
		loss: 2.369600
		loss: 2.355800
		loss: 2.369300
		loss: 2.240000
		loss: 2.369500
		loss: 2.796400
		loss: 2.369600
		loss: 2.124800
		loss: 2.369400
		loss: 2.315100
		loss: 2.369400
		loss: 2.073400
		loss: 2.369400
		loss: 2.546700
		loss: 2.369200
		loss: 1.897500
		loss: 2.369200
		loss: 2.351700
		loss: 2.369000
		loss: 2.483100
		loss: 2.369000
		loss: 2.457100
		loss: 2.369000
		loss: 2.219600
		loss: 2.368800
		loss: 2.661200
		loss: 2.368900
		loss: 2.518200
		loss: 2.368900
		loss: 2.490700
		loss: 2.368900
		loss: 2.340800
		loss: 2.368800
		loss: 2.375200
		loss: 2.368800
		loss: 2.592400
		loss: 2.368800
		loss: 2.395700
		loss: 2.368700
		loss: 2.253500
		loss: 2.368600
		loss: 2.578200
		loss: 2.368700
		loss: 2.576000
		loss: 2.368600
		loss: 2.461800
		loss: 2.368600
		loss: 2.266300
		loss: 2.368500
		loss: 2.220700
		loss: 2.368600
		loss: 2.463500
		loss: 2.368500
		loss: 2.369800
		loss: 2.368500
		loss: 2.618000
		loss: 2.368500
		loss: 2.056600
		loss: 2.368500
		loss: 2.599000
		loss: 2.368500
		loss: 2.602600
		loss: 2.368400
		loss: 2.371500
		loss: 2.368500
		loss: 2.014500
		loss: 2.368400
		loss: 2.820000
		loss: 2.368300
		loss: 2.546100
		loss: 2.368400
		loss: 2.414300
		loss: 2.368300
		loss: 2.527000
		loss: 2.368300
		loss: 2.544700
		loss: 2.368400
		loss: 2.667600
		loss: 2.368300
		loss: 1.873800
		loss: 2.368300
		loss: 2.818000
		loss: 2.368400
		loss: 2.373600
		loss: 2.368400
		loss: 2.678100
		loss: 2.368400
		loss: 2.535400
		loss: 2.368500
		loss: 2.256800
		loss: 2.368400
		loss: 2.313800
		loss: 2.368300
		loss: 2.373200
		loss: 2.368200
		loss: 2.962800
		loss: 2.368100
		loss: 2.293500
		loss: 2.368200
		loss: 2.062300
		loss: 2.368200
		loss: 2.271600
		loss: 2.368100
		loss: 2.237300
		loss: 2.368300
		loss: 2.257200
		loss: 2.368100
		loss: 2.063100
		loss: 2.368200
		loss: 2.405800
		loss: 2.368100
		loss: 2.437200
		loss: 2.368200
		loss: 2.391400
		loss: 2.368200
		loss: 2.076800
		loss: 2.368200
		loss: 2.398900
		loss: 2.368000
		loss: 2.460200
		loss: 2.368100
		loss: 2.516700
		loss: 2.368100
		loss: 2.456000
		loss: 2.368000
		loss: 2.334500
		loss: 2.368000
		loss: 2.474300
		loss: 2.367900
		loss: 2.169100
		loss: 2.367800
		loss: 2.369000
		loss: 2.367700
		loss: 2.143100
		loss: 2.367700
		loss: 2.320000
		loss: 2.367700
		loss: 2.498200
		loss: 2.367600
		loss: 2.539500
		loss: 2.367600
		loss: 2.021600
		loss: 2.367600
		loss: 2.304300
		loss: 2.367700
		loss: 2.676700
		loss: 2.367700
		loss: 1.909700
		loss: 2.367700
		loss: 2.504900
		loss: 2.367500
		loss: 2.583100
		loss: 2.367400
		loss: 2.279400
		loss: 2.367500
		loss: 2.462100
		loss: 2.367600
		loss: 2.158900
		loss: 2.367500
		loss: 2.228300
		loss: 2.367600
		loss: 2.355100
		loss: 2.367500
		loss: 2.453900
		loss: 2.367400
		loss: 2.249000
		loss: 2.367300
		loss: 2.433800
		loss: 2.367400
		loss: 2.460900
		loss: 2.367300
		loss: 2.555400
		loss: 2.367300
		loss: 2.424700
		loss: 2.367300
		loss: 2.283100
		loss: 2.367200
		loss: 2.783700
		loss: 2.367200
		loss: 2.412300
		loss: 2.367200
		loss: 2.063900
		loss: 2.367100
		loss: 2.342900
		loss: 2.367100
		loss: 2.419100
		loss: 2.367100
		loss: 2.573000
		loss: 2.367100
		loss: 2.704400
		loss: 2.367100
	Overall the loss development was 1.346900 -> 2.367100
problem epoch data for epoch 5, problem epoch 3
	sampling search time: 33.469233751297s
	during this search the following actions were chosen:
		close boot was chosen with probability 0.000000
	training time: 18.818195104599s
	during the training the following losses were computed:
		loss: 3.389200
		loss: 2.367100
		loss: 2.544600
		loss: 2.367100
		loss: 2.365200
		loss: 2.367100
		loss: 2.287900
		loss: 2.367000
		loss: 2.678900
		loss: 2.367000
		loss: 2.324200
		loss: 2.367000
		loss: 2.716100
		loss: 2.367000
		loss: 2.322900
		loss: 2.367100
		loss: 2.146600
		loss: 2.367400
		loss: 2.303600
		loss: 2.367300
		loss: 2.169400
		loss: 2.367300
		loss: 2.533700
		loss: 2.367400
		loss: 2.194600
		loss: 2.367100
		loss: 2.379900
		loss: 2.367000
		loss: 2.329600
		loss: 2.367000
		loss: 2.460700
		loss: 2.366900
		loss: 2.296200
		loss: 2.366800
		loss: 2.257000
		loss: 2.366700
		loss: 2.131900
		loss: 2.366900
		loss: 2.792700
		loss: 2.366800
		loss: 2.187700
		loss: 2.366700
		loss: 2.079500
		loss: 2.366600
		loss: 2.236100
		loss: 2.366600
		loss: 2.010600
		loss: 2.366600
		loss: 2.387900
		loss: 2.366600
		loss: 2.177800
		loss: 2.366600
		loss: 2.537500
		loss: 2.366500
		loss: 2.161800
		loss: 2.366500
		loss: 2.567500
		loss: 2.366500
		loss: 2.478400
		loss: 2.366500
		loss: 2.648700
		loss: 2.366500
		loss: 2.081200
		loss: 2.366400
		loss: 2.461100
		loss: 2.366400
		loss: 2.402800
		loss: 2.366400
		loss: 2.130400
		loss: 2.366300
		loss: 2.334700
		loss: 2.366300
		loss: 2.416500
		loss: 2.366300
		loss: 2.587400
		loss: 2.366300
		loss: 1.953400
		loss: 2.366300
		loss: 2.645300
		loss: 2.366200
		loss: 2.326000
		loss: 2.366200
		loss: 2.133800
		loss: 2.366300
		loss: 2.435600
		loss: 2.366300
		loss: 2.113700
		loss: 2.366400
		loss: 2.581200
		loss: 2.366300
		loss: 1.972100
		loss: 2.366200
		loss: 2.667500
		loss: 2.366300
		loss: 2.205300
		loss: 2.366300
		loss: 2.566900
		loss: 2.366300
		loss: 2.579000
		loss: 2.366200
		loss: 2.310500
		loss: 2.366200
		loss: 2.118500
		loss: 2.366300
		loss: 2.432700
		loss: 2.366500
		loss: 2.455600
		loss: 2.366700
		loss: 2.745600
		loss: 2.366700
		loss: 2.173100
		loss: 2.366600
		loss: 2.113600
		loss: 2.366500
		loss: 2.314100
		loss: 2.366400
		loss: 2.377600
		loss: 2.366100
		loss: 2.208500
		loss: 2.366000
		loss: 2.355400
		loss: 2.366200
		loss: 2.569600
		loss: 2.366000
		loss: 2.377400
		loss: 2.366000
		loss: 2.201700
		loss: 2.365900
		loss: 2.359500
		loss: 2.365900
		loss: 2.153500
		loss: 2.365900
		loss: 2.394000
		loss: 2.365900
		loss: 2.243100
		loss: 2.365900
		loss: 2.185200
		loss: 2.366000
		loss: 2.274000
		loss: 2.366000
		loss: 2.282000
		loss: 2.366100
		loss: 1.931700
		loss: 2.366100
		loss: 2.346500
		loss: 2.365900
		loss: 2.295800
		loss: 2.366000
		loss: 2.621500
		loss: 2.366000
		loss: 2.277100
		loss: 2.366000
		loss: 2.126700
		loss: 2.366200
		loss: 2.314700
		loss: 2.366100
		loss: 2.327200
		loss: 2.366300
		loss: 2.407700
		loss: 2.366100
		loss: 2.292200
		loss: 2.366000
		loss: 2.058000
		loss: 2.365800
		loss: 2.651900
		loss: 2.365700
		loss: 2.601800
		loss: 2.365700
		loss: 2.597400
		loss: 2.365700
		loss: 2.161900
		loss: 2.365700
		loss: 2.012400
		loss: 2.365900
		loss: 2.532700
		loss: 2.365900
		loss: 2.493900
		loss: 2.365700
		loss: 2.511100
		loss: 2.365600
		loss: 2.329500
		loss: 2.365600
		loss: 2.540300
		loss: 2.365600
		loss: 2.807800
		loss: 2.365700
		loss: 2.637200
		loss: 2.365800
		loss: 2.643600
		loss: 2.365700
		loss: 2.270300
		loss: 2.365600
		loss: 2.708000
		loss: 2.365600
		loss: 2.307200
		loss: 2.365500
		loss: 2.514500
		loss: 2.365500
		loss: 2.314400
		loss: 2.365500
	Overall the loss development was 3.389200 -> 2.365500
In the epoch 5 for problem d-02.pddl 0 explorations in the sampling searches reached a goal
Success rate: 0

Epoch 6:
Training data for problem d-01.pddl in epoch 6:
model creation time: 8.13246488571167s
problem epoch data for epoch 6, problem epoch 1
	sampling search time: 1.8993258476257324s
	during this search the following actions were chosen:
		close boot was chosen with probability 0.000000
	training time: 38.07025742530823s
	during the training the following losses were computed:
		loss: 1.654700
		loss: 1.655800
		loss: 1.639800
		loss: 1.642100
		loss: 1.637500
		loss: 1.631300
		loss: 1.630600
		loss: 1.631400
		loss: 1.630000
		loss: 1.627400
		loss: 1.626000
		loss: 1.625800
		loss: 1.625500
		loss: 1.624600
		loss: 1.623900
		loss: 1.624000
		loss: 1.624300
		loss: 1.623700
		loss: 1.623100
		loss: 1.623200
		loss: 1.623700
		loss: 1.623600
		loss: 1.623100
		loss: 1.622800
		loss: 1.623000
		loss: 1.622900
		loss: 1.622600
		loss: 1.622400
		loss: 1.622500
		loss: 1.622400
		loss: 1.622100
		loss: 1.621900
		loss: 1.621900
		loss: 1.621900
		loss: 1.621700
		loss: 1.621500
		loss: 1.621400
		loss: 1.621400
		loss: 1.621400
		loss: 1.621300
		loss: 1.621200
		loss: 1.621200
		loss: 1.621100
		loss: 1.621000
		loss: 1.621000
		loss: 1.621000
		loss: 1.621000
		loss: 1.620900
		loss: 1.620900
		loss: 1.620900
		loss: 1.620800
		loss: 1.620800
		loss: 1.620700
		loss: 1.620700
		loss: 1.620700
		loss: 1.620600
		loss: 1.620600
		loss: 1.620600
		loss: 1.620500
		loss: 1.620500
		loss: 1.620500
		loss: 1.620400
		loss: 1.620400
		loss: 1.620400
		loss: 1.620300
		loss: 1.620300
		loss: 1.620300
		loss: 1.620300
		loss: 1.620200
		loss: 1.620200
		loss: 1.620200
		loss: 1.620200
		loss: 1.620100
		loss: 1.620100
		loss: 1.620100
		loss: 1.620100
		loss: 1.620000
		loss: 1.620000
		loss: 1.620000
		loss: 1.620000
		loss: 1.619900
		loss: 1.619900
		loss: 1.619900
		loss: 1.619900
		loss: 1.619800
		loss: 1.619800
		loss: 1.619800
		loss: 1.619800
		loss: 1.619800
		loss: 1.619700
		loss: 1.619700
		loss: 1.619700
		loss: 1.619700
		loss: 1.619700
		loss: 1.619600
		loss: 1.619600
		loss: 1.619600
		loss: 1.619600
		loss: 1.619600
		loss: 1.619500
	Overall the loss development was 1.654700 -> 1.619500
problem epoch data for epoch 6, problem epoch 2
	sampling search time: 3.6422324180603027s
	during this search the following actions were chosen:
		open boot was chosen with probability 1.000000
		fetch r1 boot was chosen with probability 0.252784
		fetch wrench boot was chosen with probability 0.333498
		loosen nuts1 the-hub1 was chosen with probability 0.356530
		fetch jack boot was chosen with probability 0.613493
		fetch pump boot was chosen with probability 0.566581
		jack-up the-hub1 was chosen with probability 0.685405
		undo nuts1 the-hub1 was chosen with probability 0.783664
		remove-wheel w1 the-hub1 was chosen with probability 0.774703
		put-on-wheel r1 the-hub1 was chosen with probability 0.545988
		put-away w1 boot was chosen with probability 0.680118
		inflate r1 was chosen with probability 0.771299
		put-away pump boot was chosen with probability 0.577041
		remove-wheel r1 the-hub1 was chosen with probability 0.633217
		put-on-wheel r1 the-hub1 was chosen with probability 0.998647
	training time: 10.13587498664856s
	during the training the following losses were computed:
		loss: 1.474400
		loss: 1.446500
		loss: 1.432000
		loss: 1.415700
		loss: 1.395400
		loss: 1.388300
		loss: 1.383500
		loss: 1.374600
		loss: 1.373300
		loss: 1.376500
		loss: 1.377600
		loss: 1.379900
		loss: 1.382200
		loss: 1.380000
		loss: 1.375900
		loss: 1.373700
		loss: 1.372200
		loss: 1.370400
		loss: 1.369500
		loss: 1.369000
		loss: 1.367900
		loss: 1.367100
		loss: 1.367200
		loss: 1.367200
		loss: 1.366400
		loss: 1.365700
		loss: 1.365400
		loss: 1.364800
		loss: 1.364400
		loss: 1.364600
		loss: 1.364600
		loss: 1.364300
		loss: 1.364100
		loss: 1.364000
		loss: 1.363700
		loss: 1.363400
		loss: 1.363200
		loss: 1.362800
		loss: 1.362600
		loss: 1.362600
		loss: 1.362600
		loss: 1.362600
		loss: 1.362500
		loss: 1.362500
		loss: 1.362300
		loss: 1.362100
		loss: 1.362000
		loss: 1.362000
		loss: 1.361900
		loss: 1.361800
		loss: 1.361800
		loss: 1.361700
		loss: 1.361700
		loss: 1.361700
		loss: 1.361700
		loss: 1.361600
		loss: 1.361600
		loss: 1.361500
		loss: 1.361500
		loss: 1.361500
		loss: 1.361500
		loss: 1.361400
		loss: 1.361400
		loss: 1.361400
		loss: 1.361300
		loss: 1.361300
		loss: 1.361300
		loss: 1.361300
		loss: 1.361300
		loss: 1.361300
		loss: 1.361200
		loss: 1.361200
		loss: 1.361200
		loss: 1.361200
		loss: 1.361200
		loss: 1.361200
		loss: 1.361100
		loss: 1.361100
		loss: 1.361100
		loss: 1.361100
		loss: 1.361100
		loss: 1.361100
		loss: 1.361100
		loss: 1.361000
		loss: 1.361000
		loss: 1.361000
		loss: 1.361000
		loss: 1.361000
		loss: 1.361000
		loss: 1.361000
		loss: 1.361000
		loss: 1.360900
		loss: 1.360900
		loss: 1.360900
		loss: 1.360900
		loss: 1.360900
		loss: 1.360900
		loss: 1.360900
		loss: 1.360900
		loss: 1.360900
	Overall the loss development was 1.474400 -> 1.360900
problem epoch data for epoch 6, problem epoch 3
	sampling search time: 1.8752963542938232s
	during this search the following actions were chosen:
		close boot was chosen with probability 0.000000
	training time: 10.136183738708496s
	during the training the following losses were computed:
		loss: 1.360900
		loss: 1.360800
		loss: 1.360800
		loss: 1.360800
		loss: 1.360800
		loss: 1.360800
		loss: 1.360800
		loss: 1.360800
		loss: 1.360800
		loss: 1.360800
		loss: 1.360800
		loss: 1.360700
		loss: 1.360700
		loss: 1.360700
		loss: 1.360700
		loss: 1.360700
		loss: 1.360700
		loss: 1.360700
		loss: 1.360700
		loss: 1.360700
		loss: 1.360700
		loss: 1.360600
		loss: 1.360600
		loss: 1.360600
		loss: 1.360600
		loss: 1.360600
		loss: 1.360600
		loss: 1.360600
		loss: 1.360600
		loss: 1.360600
		loss: 1.360600
		loss: 1.360600
		loss: 1.360500
		loss: 1.360500
		loss: 1.360500
		loss: 1.360500
		loss: 1.360500
		loss: 1.360500
		loss: 1.360500
		loss: 1.360500
		loss: 1.360500
		loss: 1.360500
		loss: 1.360500
		loss: 1.360400
		loss: 1.360400
		loss: 1.360400
		loss: 1.360400
		loss: 1.360400
		loss: 1.360400
		loss: 1.360400
		loss: 1.360400
		loss: 1.360400
		loss: 1.360400
		loss: 1.360400
		loss: 1.360400
		loss: 1.360300
		loss: 1.360300
		loss: 1.360300
		loss: 1.360300
		loss: 1.360300
		loss: 1.360300
		loss: 1.360300
		loss: 1.360300
		loss: 1.360300
		loss: 1.360300
		loss: 1.360300
		loss: 1.360300
		loss: 1.360200
		loss: 1.360200
		loss: 1.360200
		loss: 1.360200
		loss: 1.360200
		loss: 1.360200
		loss: 1.360200
		loss: 1.360200
		loss: 1.360200
		loss: 1.360200
		loss: 1.360200
		loss: 1.360200
		loss: 1.360100
		loss: 1.360100
		loss: 1.360100
		loss: 1.360100
		loss: 1.360100
		loss: 1.360100
		loss: 1.360100
		loss: 1.360100
		loss: 1.360100
		loss: 1.360100
		loss: 1.360100
		loss: 1.360100
		loss: 1.360100
		loss: 1.360000
		loss: 1.360000
		loss: 1.360000
		loss: 1.360000
		loss: 1.360000
		loss: 1.360000
		loss: 1.360000
		loss: 1.360000
	Overall the loss development was 1.360900 -> 1.360000
In the epoch 6 for problem d-01.pddl 0 explorations in the sampling searches reached a goal
Training data for problem d-02.pddl in epoch 6:
model creation time: 15.567076444625854s
problem epoch data for epoch 6, problem epoch 1
	sampling search time: 159.7629840373993s
	during this search the following actions were chosen:
		open boot was chosen with probability 1.000000
		fetch wrench boot was chosen with probability 0.282179
		fetch pump boot was chosen with probability 0.215151
		inflate r1 was chosen with probability 0.213295
		inflate r2 was chosen with probability 0.270838
		loosen nuts2 the-hub2 was chosen with probability 0.269593
		loosen nuts1 the-hub1 was chosen with probability 0.451138
		fetch jack boot was chosen with probability 0.527493
		jack-up the-hub2 was chosen with probability 0.298266
		undo nuts2 the-hub2 was chosen with probability 0.548374
		remove-wheel w2 the-hub2 was chosen with probability 0.436712
		fetch r2 boot was chosen with probability 0.582876
		put-on-wheel r2 the-hub2 was chosen with probability 0.559832
		put-away w2 boot was chosen with probability 0.608894
		fetch r1 boot was chosen with probability 0.698504
		remove-wheel r2 the-hub2 was chosen with probability 0.471316
		put-on-wheel r2 the-hub2 was chosen with probability 0.932548
	training time: 71.17323327064514s
	during the training the following losses were computed:
		loss: 3.956300
		loss: 2.848800
		loss: 2.400000
		loss: 2.784100
		loss: 2.535800
		loss: 2.763700
		loss: 2.667200
		loss: 2.740800
		loss: 2.937700
		loss: 2.727800
		loss: 2.275600
		loss: 2.726500
		loss: 2.754000
		loss: 2.723900
		loss: 2.637900
		loss: 2.721500
		loss: 2.274900
		loss: 2.717000
		loss: 2.783500
		loss: 2.713400
		loss: 2.268600
		loss: 2.710400
		loss: 2.652600
		loss: 2.707900
		loss: 2.690600
		loss: 2.705300
		loss: 2.752500
		loss: 2.703600
		loss: 2.672700
		loss: 2.701900
		loss: 2.301300
		loss: 2.701300
		loss: 2.607500
		loss: 2.700200
		loss: 2.420700
		loss: 2.699500
		loss: 2.478800
		loss: 2.698900
		loss: 2.512800
		loss: 2.698100
		loss: 2.581200
		loss: 2.697300
		loss: 2.847000
		loss: 2.696700
		loss: 2.420000
		loss: 2.696500
		loss: 2.752700
		loss: 2.696000
		loss: 2.805000
		loss: 2.695800
		loss: 2.945600
		loss: 2.695200
		loss: 2.793900
		loss: 2.695000
		loss: 2.629800
		loss: 2.694500
		loss: 2.403400
		loss: 2.694100
		loss: 2.839300
		loss: 2.693900
		loss: 2.972700
		loss: 2.693600
		loss: 2.642100
		loss: 2.693200
		loss: 2.099600
		loss: 2.693000
		loss: 2.795800
		loss: 2.692700
		loss: 2.765700
		loss: 2.692500
		loss: 2.637800
		loss: 2.692200
		loss: 2.376400
		loss: 2.692100
		loss: 2.843400
		loss: 2.691900
		loss: 2.983900
		loss: 2.691700
		loss: 2.207400
		loss: 2.691500
		loss: 3.279400
		loss: 2.691300
		loss: 2.506100
		loss: 2.691100
		loss: 3.307300
		loss: 2.690900
		loss: 2.598000
		loss: 2.690800
		loss: 2.554000
		loss: 2.690600
		loss: 2.376000
		loss: 2.690600
		loss: 2.326400
		loss: 2.690300
		loss: 2.348200
		loss: 2.690400
		loss: 2.590700
		loss: 2.690000
		loss: 3.062000
		loss: 2.689900
		loss: 2.704000
		loss: 2.689700
		loss: 2.485800
		loss: 2.689700
		loss: 2.866400
		loss: 2.689600
		loss: 2.667700
		loss: 2.689200
		loss: 2.201100
		loss: 2.689300
		loss: 2.661100
		loss: 2.689100
		loss: 3.223200
		loss: 2.689000
		loss: 2.446200
		loss: 2.688900
		loss: 3.068900
		loss: 2.688800
		loss: 2.457700
		loss: 2.688700
		loss: 2.720500
		loss: 2.688600
		loss: 2.701800
		loss: 2.688400
		loss: 2.363200
		loss: 2.688700
		loss: 2.761400
		loss: 2.688500
		loss: 2.879200
		loss: 2.688300
		loss: 2.645200
		loss: 2.688500
		loss: 2.886300
		loss: 2.688100
		loss: 3.061800
		loss: 2.688200
		loss: 2.551200
		loss: 2.688200
		loss: 2.569100
		loss: 2.687800
		loss: 2.967500
		loss: 2.687700
		loss: 2.808600
		loss: 2.687700
		loss: 2.899700
		loss: 2.687700
		loss: 2.518500
		loss: 2.687500
		loss: 2.563500
		loss: 2.687300
		loss: 3.107900
		loss: 2.687300
		loss: 2.593700
		loss: 2.687300
		loss: 2.558500
		loss: 2.687200
		loss: 2.967600
		loss: 2.687300
		loss: 2.741100
		loss: 2.687000
		loss: 2.986100
		loss: 2.687200
		loss: 2.850100
		loss: 2.687000
		loss: 2.644200
		loss: 2.687200
		loss: 2.407300
		loss: 2.686900
		loss: 2.842200
		loss: 2.687300
		loss: 2.804500
		loss: 2.686900
		loss: 2.232100
		loss: 2.687100
		loss: 2.900900
		loss: 2.687100
		loss: 2.556400
		loss: 2.686700
		loss: 2.766900
		loss: 2.686700
		loss: 2.499400
		loss: 2.686800
		loss: 2.457900
		loss: 2.686900
		loss: 2.568400
		loss: 2.686600
		loss: 2.993900
		loss: 2.687400
		loss: 2.763000
		loss: 2.687100
		loss: 2.850100
		loss: 2.687200
		loss: 2.521700
		loss: 2.687500
		loss: 2.646300
		loss: 2.687300
		loss: 2.696300
		loss: 2.686800
		loss: 2.779400
		loss: 2.686700
	Overall the loss development was 3.956300 -> 2.686700
problem epoch data for epoch 6, problem epoch 2
	sampling search time: 33.381369829177856s
	during this search the following actions were chosen:
		close boot was chosen with probability 0.000000
	training time: 18.819345235824585s
	during the training the following losses were computed:
		loss: 1.627800
		loss: 2.686900
		loss: 2.871200
		loss: 2.686800
		loss: 2.565200
		loss: 2.686300
		loss: 3.045800
		loss: 2.686800
		loss: 2.648900
		loss: 2.686800
		loss: 2.521000
		loss: 2.686100
		loss: 2.725100
		loss: 2.686200
		loss: 2.291700
		loss: 2.686100
		loss: 3.216200
		loss: 2.686000
		loss: 2.861000
		loss: 2.686000
		loss: 2.293900
		loss: 2.685900
		loss: 2.355900
		loss: 2.685800
		loss: 3.340100
		loss: 2.685900
		loss: 2.726100
		loss: 2.685900
		loss: 2.619300
		loss: 2.685700
		loss: 2.883300
		loss: 2.685900
		loss: 2.821700
		loss: 2.685800
		loss: 2.628600
		loss: 2.685800
		loss: 2.474200
		loss: 2.685800
		loss: 2.961600
		loss: 2.685800
		loss: 2.707700
		loss: 2.685800
		loss: 2.553100
		loss: 2.685700
		loss: 2.552800
		loss: 2.685800
		loss: 2.595200
		loss: 2.685700
		loss: 2.658100
		loss: 2.685600
		loss: 2.416300
		loss: 2.685600
		loss: 2.833700
		loss: 2.685700
		loss: 2.207400
		loss: 2.685500
		loss: 2.478500
		loss: 2.685500
		loss: 2.498000
		loss: 2.685500
		loss: 2.860600
		loss: 2.685600
		loss: 2.496500
		loss: 2.685500
		loss: 3.153900
		loss: 2.685600
		loss: 2.604500
		loss: 2.685800
		loss: 2.775300
		loss: 2.685600
		loss: 2.936300
		loss: 2.685700
		loss: 2.900000
		loss: 2.685800
		loss: 2.680700
		loss: 2.685700
		loss: 2.769300
		loss: 2.686000
		loss: 2.770500
		loss: 2.685900
		loss: 2.448800
		loss: 2.685900
		loss: 2.606700
		loss: 2.685900
		loss: 2.990600
		loss: 2.685600
		loss: 2.426800
		loss: 2.685600
		loss: 2.110100
		loss: 2.685600
		loss: 2.535300
		loss: 2.685500
		loss: 2.996100
		loss: 2.685400
		loss: 2.989300
		loss: 2.685400
		loss: 2.414700
		loss: 2.685300
		loss: 2.619800
		loss: 2.685300
		loss: 2.925200
		loss: 2.685200
		loss: 2.525400
		loss: 2.685200
		loss: 2.321500
		loss: 2.685400
		loss: 2.657600
		loss: 2.685300
		loss: 3.240500
		loss: 2.685100
		loss: 2.330100
		loss: 2.685300
		loss: 2.841500
		loss: 2.685300
		loss: 2.955300
		loss: 2.685200
		loss: 2.599300
		loss: 2.685100
		loss: 2.628100
		loss: 2.685000
		loss: 2.581900
		loss: 2.685100
		loss: 2.827100
		loss: 2.684900
		loss: 2.299900
		loss: 2.684900
		loss: 2.849700
		loss: 2.685000
		loss: 2.462900
		loss: 2.685000
		loss: 2.490500
		loss: 2.684900
		loss: 2.641000
		loss: 2.684900
		loss: 2.898400
		loss: 2.684800
		loss: 2.298700
		loss: 2.684800
		loss: 2.386500
		loss: 2.684800
		loss: 2.391300
		loss: 2.684900
		loss: 2.643200
		loss: 2.684800
		loss: 2.724700
		loss: 2.684800
		loss: 2.285400
		loss: 2.684800
		loss: 3.013200
		loss: 2.684800
		loss: 2.330500
		loss: 2.684900
		loss: 2.624000
		loss: 2.684700
		loss: 2.920400
		loss: 2.684800
		loss: 2.879000
		loss: 2.684700
		loss: 2.549200
		loss: 2.684800
		loss: 2.942500
		loss: 2.684700
		loss: 2.745800
		loss: 2.684700
		loss: 3.047100
		loss: 2.684700
		loss: 2.653600
		loss: 2.684700
		loss: 2.575700
		loss: 2.684600
		loss: 2.661300
		loss: 2.684600
		loss: 3.085800
		loss: 2.684700
		loss: 2.544100
		loss: 2.684600
		loss: 2.353400
		loss: 2.684600
		loss: 2.250700
		loss: 2.684800
		loss: 2.797100
		loss: 2.684900
		loss: 2.491100
		loss: 2.684700
		loss: 2.821000
		loss: 2.684600
		loss: 2.469800
		loss: 2.684600
		loss: 2.693500
		loss: 2.684600
		loss: 2.939700
		loss: 2.684600
		loss: 2.615200
		loss: 2.684600
		loss: 2.467500
		loss: 2.684500
		loss: 2.815400
		loss: 2.684500
		loss: 2.487400
		loss: 2.684500
	Overall the loss development was 1.627800 -> 2.684500
problem epoch data for epoch 6, problem epoch 3
	sampling search time: 179.78166341781616s
	during this search the following actions were chosen:
		open boot was chosen with probability 1.000000
		fetch r2 boot was chosen with probability 0.201692
		fetch jack boot was chosen with probability 0.251701
		fetch r1 boot was chosen with probability 0.380308
		fetch pump boot was chosen with probability 0.493674
		inflate r1 was chosen with probability 0.379924
		inflate r2 was chosen with probability 0.612607
		fetch wrench boot was chosen with probability 0.938934
		loosen nuts1 the-hub1 was chosen with probability 0.510549
		loosen nuts2 the-hub2 was chosen with probability 0.636135
		jack-up the-hub2 was chosen with probability 0.551295
		undo nuts2 the-hub2 was chosen with probability 0.987081
		remove-wheel w2 the-hub2 was chosen with probability 0.987976
		put-on-wheel r2 the-hub2 was chosen with probability 0.737420
		put-away w2 boot was chosen with probability 0.835115
		remove-wheel r2 the-hub2 was chosen with probability 0.589620
		put-on-wheel r2 the-hub2 was chosen with probability 0.950181
	training time: 19.221483945846558s
	during the training the following losses were computed:
		loss: 3.414500
		loss: 2.649400
		loss: 2.728900
		loss: 2.649000
		loss: 2.884100
		loss: 2.648600
		loss: 2.720200
		loss: 2.648500
		loss: 2.718900
		loss: 2.648100
		loss: 2.777700
		loss: 2.647800
		loss: 2.679400
		loss: 2.647800
		loss: 2.353600
		loss: 2.647700
		loss: 2.878100
		loss: 2.647600
		loss: 2.899200
		loss: 2.647700
		loss: 2.771100
		loss: 2.647700
		loss: 2.482800
		loss: 2.647900
		loss: 2.781800
		loss: 2.647900
		loss: 2.684900
		loss: 2.648000
		loss: 2.442000
		loss: 2.647900
		loss: 2.484600
		loss: 2.647700
		loss: 3.058500
		loss: 2.647600
		loss: 2.643300
		loss: 2.647700
		loss: 2.446700
		loss: 2.647900
		loss: 2.625200
		loss: 2.647500
		loss: 2.626800
		loss: 2.647500
		loss: 2.713100
		loss: 2.647400
		loss: 2.967300
		loss: 2.647600
		loss: 2.689800
		loss: 2.647500
		loss: 2.745300
		loss: 2.647600
		loss: 2.607900
		loss: 2.647800
		loss: 2.470300
		loss: 2.647800
		loss: 2.954300
		loss: 2.648000
		loss: 2.103000
		loss: 2.647600
		loss: 2.341300
		loss: 2.647600
		loss: 2.739600
		loss: 2.647700
		loss: 2.770600
		loss: 2.647400
		loss: 2.408000
		loss: 2.647400
		loss: 2.594100
		loss: 2.647600
		loss: 2.773600
		loss: 2.647500
		loss: 2.668100
		loss: 2.647500
		loss: 2.473300
		loss: 2.647300
		loss: 2.221100
		loss: 2.647200
		loss: 2.532000
		loss: 2.647300
		loss: 2.751000
		loss: 2.647300
		loss: 2.726800
		loss: 2.647200
		loss: 2.501700
		loss: 2.647100
		loss: 2.636700
		loss: 2.647100
		loss: 2.630800
		loss: 2.647300
		loss: 3.089100
		loss: 2.647400
		loss: 2.758400
		loss: 2.647200
		loss: 2.721700
		loss: 2.647100
		loss: 2.049300
		loss: 2.647100
		loss: 2.629100
		loss: 2.647100
		loss: 2.478500
		loss: 2.647000
		loss: 2.892100
		loss: 2.647200
		loss: 2.809400
		loss: 2.647100
		loss: 3.041900
		loss: 2.647000
		loss: 2.661200
		loss: 2.647000
		loss: 2.798700
		loss: 2.647000
		loss: 2.738200
		loss: 2.647100
		loss: 2.452700
		loss: 2.646900
		loss: 2.789800
		loss: 2.647000
		loss: 2.256700
		loss: 2.647000
		loss: 2.658200
		loss: 2.647000
		loss: 2.958600
		loss: 2.647000
		loss: 2.834300
		loss: 2.647100
		loss: 2.752400
		loss: 2.647100
		loss: 2.815000
		loss: 2.647400
		loss: 2.670600
		loss: 2.647700
		loss: 2.841500
		loss: 2.648100
		loss: 2.774100
		loss: 2.648500
		loss: 2.702800
		loss: 2.648300
		loss: 2.989200
		loss: 2.648400
		loss: 2.934800
		loss: 2.648100
		loss: 3.020700
		loss: 2.648500
		loss: 2.671600
		loss: 2.649200
		loss: 2.693000
		loss: 2.649000
		loss: 2.788100
		loss: 2.649100
		loss: 2.755900
		loss: 2.649200
		loss: 2.341400
		loss: 2.648900
		loss: 2.401700
		loss: 2.648300
		loss: 2.861000
		loss: 2.647800
		loss: 2.705900
		loss: 2.647500
		loss: 2.442800
		loss: 2.647500
		loss: 2.418000
		loss: 2.647700
		loss: 2.644600
		loss: 2.647800
		loss: 2.998000
		loss: 2.648700
		loss: 2.829500
		loss: 2.648200
		loss: 2.640600
		loss: 2.647800
		loss: 2.102400
		loss: 2.647500
		loss: 2.500300
		loss: 2.647400
		loss: 2.492200
		loss: 2.647400
		loss: 2.646000
		loss: 2.646900
		loss: 3.181600
		loss: 2.647100
		loss: 2.519800
		loss: 2.647400
		loss: 2.455600
		loss: 2.647000
		loss: 2.644500
		loss: 2.647000
		loss: 2.660800
		loss: 2.646800
		loss: 2.722700
		loss: 2.646900
		loss: 2.726200
		loss: 2.646800
		loss: 2.731300
		loss: 2.646800
		loss: 2.502900
		loss: 2.646900
		loss: 2.529800
		loss: 2.647000
		loss: 2.587200
		loss: 2.647200
	Overall the loss development was 3.414500 -> 2.647200
In the epoch 6 for problem d-02.pddl 0 explorations in the sampling searches reached a goal
Success rate: 0

Epoch 7:
Training data for problem d-01.pddl in epoch 7:
model creation time: 8.003064155578613s
problem epoch data for epoch 7, problem epoch 1
	sampling search time: 2.066419839859009s
	during this search the following actions were chosen:
		close boot was chosen with probability 0.000000
	training time: 37.70255422592163s
	during the training the following losses were computed:
		loss: 1.632500
		loss: 1.634100
		loss: 1.633100
		loss: 1.625700
		loss: 1.630400
		loss: 1.626900
		loss: 1.624800
		loss: 1.625800
		loss: 1.624900
		loss: 1.624800
		loss: 1.624900
		loss: 1.623500
		loss: 1.623000
		loss: 1.623900
		loss: 1.623700
		loss: 1.622500
		loss: 1.622300
		loss: 1.622600
		loss: 1.622600
		loss: 1.622400
		loss: 1.622100
		loss: 1.621800
		loss: 1.621900
		loss: 1.622000
		loss: 1.621600
		loss: 1.621200
		loss: 1.621400
		loss: 1.621500
		loss: 1.621200
		loss: 1.621000
		loss: 1.621000
		loss: 1.621000
		loss: 1.621000
		loss: 1.620900
		loss: 1.620800
		loss: 1.620700
		loss: 1.620800
		loss: 1.620700
		loss: 1.620600
		loss: 1.620600
		loss: 1.620500
		loss: 1.620500
		loss: 1.620500
		loss: 1.620400
		loss: 1.620400
		loss: 1.620400
		loss: 1.620300
		loss: 1.620300
		loss: 1.620200
		loss: 1.620200
		loss: 1.620200
		loss: 1.620100
		loss: 1.620100
		loss: 1.620100
		loss: 1.620100
		loss: 1.620000
		loss: 1.620000
		loss: 1.620000
		loss: 1.619900
		loss: 1.619900
		loss: 1.619900
		loss: 1.619800
		loss: 1.619800
		loss: 1.619800
		loss: 1.619700
		loss: 1.619700
		loss: 1.619700
		loss: 1.619700
		loss: 1.619600
		loss: 1.619600
		loss: 1.619600
		loss: 1.619600
		loss: 1.619500
		loss: 1.619500
		loss: 1.619500
		loss: 1.619500
		loss: 1.619400
		loss: 1.619400
		loss: 1.619400
		loss: 1.619400
		loss: 1.619300
		loss: 1.619300
		loss: 1.619300
		loss: 1.619300
		loss: 1.619200
		loss: 1.619200
		loss: 1.619200
		loss: 1.619200
		loss: 1.619100
		loss: 1.619100
		loss: 1.619100
		loss: 1.619100
		loss: 1.619100
		loss: 1.619000
		loss: 1.619000
		loss: 1.619000
		loss: 1.619000
		loss: 1.619000
		loss: 1.618900
		loss: 1.618900
	Overall the loss development was 1.632500 -> 1.618900
problem epoch data for epoch 7, problem epoch 2
	sampling search time: 3.6142637729644775s
	during this search the following actions were chosen:
		open boot was chosen with probability 1.000000
		fetch r1 boot was chosen with probability 0.253440
		fetch pump boot was chosen with probability 0.333975
		fetch wrench boot was chosen with probability 0.415462
		loosen nuts1 the-hub1 was chosen with probability 0.441604
		fetch jack boot was chosen with probability 0.776336
		jack-up the-hub1 was chosen with probability 0.655700
		undo nuts1 the-hub1 was chosen with probability 0.736368
		remove-wheel w1 the-hub1 was chosen with probability 0.736798
		put-on-wheel r1 the-hub1 was chosen with probability 0.591936
		put-away w1 boot was chosen with probability 0.654988
		inflate r1 was chosen with probability 0.753180
		remove-wheel r1 the-hub1 was chosen with probability 0.433166
		put-on-wheel r1 the-hub1 was chosen with probability 0.968256
	training time: 10.13895869255066s
	during the training the following losses were computed:
		loss: 1.607900
		loss: 1.566100
		loss: 1.550900
		loss: 1.529900
		loss: 1.498800
		loss: 1.491800
		loss: 1.494600
		loss: 1.485200
		loss: 1.483000
		loss: 1.488300
		loss: 1.485700
		loss: 1.481100
		loss: 1.483300
		loss: 1.485100
		loss: 1.482400
		loss: 1.481200
		loss: 1.481800
		loss: 1.479000
		loss: 1.474500
		loss: 1.472500
		loss: 1.471700
		loss: 1.469600
		loss: 1.468300
		loss: 1.469400
		loss: 1.470300
		loss: 1.469800
		loss: 1.469600
		loss: 1.469900
		loss: 1.469300
		loss: 1.468400
		loss: 1.468200
		loss: 1.468200
		loss: 1.467600
		loss: 1.467200
		loss: 1.467300
		loss: 1.467100
		loss: 1.466700
		loss: 1.466700
		loss: 1.466800
		loss: 1.466700
		loss: 1.466500
		loss: 1.466600
		loss: 1.466500
		loss: 1.466300
		loss: 1.466100
		loss: 1.466000
		loss: 1.465800
		loss: 1.465700
		loss: 1.465800
		loss: 1.465800
		loss: 1.465700
		loss: 1.465600
		loss: 1.465600
		loss: 1.465500
		loss: 1.465500
		loss: 1.465400
		loss: 1.465400
		loss: 1.465300
		loss: 1.465300
		loss: 1.465300
		loss: 1.465200
		loss: 1.465200
		loss: 1.465200
		loss: 1.465200
		loss: 1.465100
		loss: 1.465100
		loss: 1.465100
		loss: 1.465100
		loss: 1.465100
		loss: 1.465000
		loss: 1.465000
		loss: 1.465000
		loss: 1.465000
		loss: 1.465000
		loss: 1.465000
		loss: 1.464900
		loss: 1.464900
		loss: 1.464900
		loss: 1.464900
		loss: 1.464900
		loss: 1.464900
		loss: 1.464900
		loss: 1.464800
		loss: 1.464800
		loss: 1.464800
		loss: 1.464800
		loss: 1.464800
		loss: 1.464800
		loss: 1.464800
		loss: 1.464800
		loss: 1.464700
		loss: 1.464700
		loss: 1.464700
		loss: 1.464700
		loss: 1.464700
		loss: 1.464700
		loss: 1.464700
		loss: 1.464700
		loss: 1.464700
		loss: 1.464600
	Overall the loss development was 1.607900 -> 1.464600
problem epoch data for epoch 7, problem epoch 3
	sampling search time: 1.875859260559082s
	during this search the following actions were chosen:
		close boot was chosen with probability 0.000000
	training time: 10.1386239528656s
	during the training the following losses were computed:
		loss: 1.464600
		loss: 1.464600
		loss: 1.464600
		loss: 1.464600
		loss: 1.464600
		loss: 1.464600
		loss: 1.464600
		loss: 1.464600
		loss: 1.464500
		loss: 1.464500
		loss: 1.464500
		loss: 1.464500
		loss: 1.464500
		loss: 1.464500
		loss: 1.464500
		loss: 1.464500
		loss: 1.464500
		loss: 1.464500
		loss: 1.464400
		loss: 1.464400
		loss: 1.464400
		loss: 1.464400
		loss: 1.464400
		loss: 1.464400
		loss: 1.464400
		loss: 1.464400
		loss: 1.464400
		loss: 1.464400
		loss: 1.464400
		loss: 1.464300
		loss: 1.464300
		loss: 1.464300
		loss: 1.464300
		loss: 1.464300
		loss: 1.464300
		loss: 1.464300
		loss: 1.464300
		loss: 1.464300
		loss: 1.464300
		loss: 1.464300
		loss: 1.464200
		loss: 1.464200
		loss: 1.464200
		loss: 1.464200
		loss: 1.464200
		loss: 1.464200
		loss: 1.464200
		loss: 1.464200
		loss: 1.464200
		loss: 1.464200
		loss: 1.464200
		loss: 1.464200
		loss: 1.464100
		loss: 1.464100
		loss: 1.464100
		loss: 1.464100
		loss: 1.464100
		loss: 1.464100
		loss: 1.464100
		loss: 1.464100
		loss: 1.464100
		loss: 1.464100
		loss: 1.464100
		loss: 1.464100
		loss: 1.464000
		loss: 1.464000
		loss: 1.464000
		loss: 1.464000
		loss: 1.464000
		loss: 1.464000
		loss: 1.464000
		loss: 1.464000
		loss: 1.464000
		loss: 1.464000
		loss: 1.464000
		loss: 1.464000
		loss: 1.463900
		loss: 1.463900
		loss: 1.463900
		loss: 1.463900
		loss: 1.463900
		loss: 1.463900
		loss: 1.463900
		loss: 1.463900
		loss: 1.463900
		loss: 1.463900
		loss: 1.463900
		loss: 1.463900
		loss: 1.463900
		loss: 1.463800
		loss: 1.463800
		loss: 1.463800
		loss: 1.463800
		loss: 1.463800
		loss: 1.463800
		loss: 1.463800
		loss: 1.463800
		loss: 1.463800
		loss: 1.463800
		loss: 1.463800
	Overall the loss development was 1.464600 -> 1.463800
In the epoch 7 for problem d-01.pddl 0 explorations in the sampling searches reached a goal
Training data for problem d-02.pddl in epoch 7:
model creation time: 15.966558456420898s
problem epoch data for epoch 7, problem epoch 1
	sampling search time: 175.94602417945862s
	during this search the following actions were chosen:
		open boot was chosen with probability 1.000000
		fetch wrench boot was chosen with probability 0.244828
		loosen nuts2 the-hub2 was chosen with probability 0.203820
		loosen nuts1 the-hub1 was chosen with probability 0.329233
		fetch pump boot was chosen with probability 0.304164
		inflate r1 was chosen with probability 0.281255
		inflate r2 was chosen with probability 0.391032
		fetch jack boot was chosen with probability 0.418799
		jack-up the-hub1 was chosen with probability 0.253733
		undo nuts1 the-hub1 was chosen with probability 0.438778
		remove-wheel w1 the-hub1 was chosen with probability 0.440937
		fetch r1 boot was chosen with probability 0.426371
		put-on-wheel r1 the-hub1 was chosen with probability 0.553336
		put-away w1 boot was chosen with probability 0.528859
		fetch r2 boot was chosen with probability 0.775850
		remove-wheel r1 the-hub1 was chosen with probability 0.586673
		put-on-wheel r1 the-hub1 was chosen with probability 0.930696
	training time: 70.6558153629303s
	during the training the following losses were computed:
		loss: 3.758300
		loss: 2.787000
		loss: 2.644900
		loss: 2.743800
		loss: 2.623000
		loss: 2.746500
		loss: 2.674600
		loss: 2.729100
		loss: 2.459700
		loss: 2.724100
		loss: 2.529000
		loss: 2.721900
		loss: 2.770400
		loss: 2.721500
		loss: 2.153900
		loss: 2.717800
		loss: 3.079600
		loss: 2.715600
		loss: 2.873900
		loss: 2.712500
		loss: 3.099600
		loss: 2.709800
		loss: 2.513700
		loss: 2.709100
		loss: 2.892700
		loss: 2.707700
		loss: 2.824000
		loss: 2.706400
		loss: 2.615000
		loss: 2.705700
		loss: 2.575000
		loss: 2.705000
		loss: 2.603100
		loss: 2.704400
		loss: 2.805600
		loss: 2.703100
		loss: 2.663000
		loss: 2.702400
		loss: 2.606300
		loss: 2.701700
		loss: 2.615800
		loss: 2.701300
		loss: 2.560100
		loss: 2.700700
		loss: 2.814500
		loss: 2.700400
		loss: 2.671100
		loss: 2.699700
		loss: 2.725500
		loss: 2.699300
		loss: 2.594300
		loss: 2.698900
		loss: 2.984600
		loss: 2.698600
		loss: 2.635500
		loss: 2.698200
		loss: 2.688300
		loss: 2.698000
		loss: 2.486100
		loss: 2.697800
		loss: 3.055600
		loss: 2.697600
		loss: 2.675400
		loss: 2.697200
		loss: 2.847100
		loss: 2.697000
		loss: 2.553600
		loss: 2.696700
		loss: 3.010300
		loss: 2.696600
		loss: 2.965200
		loss: 2.696500
		loss: 3.001100
		loss: 2.696200
		loss: 2.401000
		loss: 2.696100
		loss: 2.708900
		loss: 2.695900
		loss: 2.694600
		loss: 2.695900
		loss: 2.517200
		loss: 2.695600
		loss: 2.961500
		loss: 2.695600
		loss: 2.689400
		loss: 2.695400
		loss: 2.698200
		loss: 2.695300
		loss: 2.197900
		loss: 2.695200
		loss: 2.616700
		loss: 2.695100
		loss: 2.980800
		loss: 2.694900
		loss: 2.583100
		loss: 2.694900
		loss: 2.265600
		loss: 2.694800
		loss: 2.836600
		loss: 2.694700
		loss: 2.605700
		loss: 2.694600
		loss: 2.690500
		loss: 2.694500
		loss: 2.822700
		loss: 2.694500
		loss: 2.615400
		loss: 2.694400
		loss: 2.860700
		loss: 2.694400
		loss: 2.871600
		loss: 2.694300
		loss: 2.772000
		loss: 2.694100
		loss: 2.628900
		loss: 2.694300
		loss: 2.890700
		loss: 2.694300
		loss: 2.641900
		loss: 2.694100
		loss: 2.435600
		loss: 2.694000
		loss: 2.675200
		loss: 2.694200
		loss: 2.752900
		loss: 2.693900
		loss: 2.442200
		loss: 2.693800
		loss: 2.674100
		loss: 2.693700
		loss: 2.418800
		loss: 2.693700
		loss: 2.593400
		loss: 2.693600
		loss: 2.598600
		loss: 2.693500
		loss: 3.239300
		loss: 2.693600
		loss: 2.950600
		loss: 2.693600
		loss: 2.630500
		loss: 2.693500
		loss: 2.684600
		loss: 2.693700
		loss: 2.449500
		loss: 2.693500
		loss: 2.895000
		loss: 2.693400
		loss: 2.507000
		loss: 2.693500
		loss: 2.521200
		loss: 2.693500
		loss: 2.769400
		loss: 2.693400
		loss: 2.561100
		loss: 2.693400
		loss: 2.754900
		loss: 2.693300
		loss: 2.496000
		loss: 2.693200
		loss: 3.023200
		loss: 2.693000
		loss: 2.282600
		loss: 2.693000
		loss: 3.062100
		loss: 2.692900
		loss: 2.630800
		loss: 2.692900
		loss: 2.801300
		loss: 2.692800
		loss: 2.788400
		loss: 2.692900
		loss: 2.726300
		loss: 2.692800
		loss: 2.689500
		loss: 2.692800
		loss: 2.732600
		loss: 2.692800
		loss: 2.641600
		loss: 2.692800
		loss: 2.896600
		loss: 2.692900
		loss: 2.774300
		loss: 2.692900
		loss: 2.782600
		loss: 2.692600
		loss: 2.654100
		loss: 2.692600
		loss: 2.667700
		loss: 2.692700
		loss: 2.546300
		loss: 2.692900
		loss: 2.979100
		loss: 2.692900
		loss: 2.912500
		loss: 2.693000
		loss: 3.051300
		loss: 2.692800
		loss: 2.637400
		loss: 2.692600
	Overall the loss development was 3.758300 -> 2.692600
problem epoch data for epoch 7, problem epoch 2
	sampling search time: 172.8688461780548s
	during this search the following actions were chosen:
		open boot was chosen with probability 1.000000
		fetch r2 boot was chosen with probability 0.202219
		fetch r1 boot was chosen with probability 0.253191
		fetch jack boot was chosen with probability 0.335638
		fetch pump boot was chosen with probability 0.490531
		inflate r1 was chosen with probability 0.384277
		inflate r2 was chosen with probability 0.624082
		fetch wrench boot was chosen with probability 0.917616
		loosen nuts1 the-hub1 was chosen with probability 0.521104
		loosen nuts2 the-hub2 was chosen with probability 0.581832
		jack-up the-hub2 was chosen with probability 0.513012
		undo nuts2 the-hub2 was chosen with probability 0.985732
		remove-wheel w2 the-hub2 was chosen with probability 0.987738
		put-on-wheel r2 the-hub2 was chosen with probability 0.703093
		put-away w2 boot was chosen with probability 0.809733
		remove-wheel r2 the-hub2 was chosen with probability 0.735593
		put-on-wheel r2 the-hub2 was chosen with probability 0.964553
	training time: 20.129558801651s
	during the training the following losses were computed:
		loss: 1.379700
		loss: 2.327100
		loss: 2.557900
		loss: 2.326600
		loss: 2.464200
		loss: 2.326200
		loss: 2.430100
		loss: 2.326000
		loss: 2.221600
		loss: 2.325700
		loss: 2.740000
		loss: 2.325400
		loss: 2.288300
		loss: 2.325200
		loss: 2.210300
		loss: 2.325200
		loss: 2.204800
		loss: 2.325100
		loss: 2.119300
		loss: 2.325000
		loss: 2.566700
		loss: 2.324900
		loss: 2.389700
		loss: 2.324900
		loss: 2.531800
		loss: 2.325000
		loss: 2.432600
		loss: 2.324900
		loss: 2.221800
		loss: 2.324800
		loss: 2.434700
		loss: 2.324800
		loss: 2.242000
		loss: 2.324800
		loss: 2.214200
		loss: 2.324700
		loss: 2.088800
		loss: 2.324700
		loss: 2.220500
		loss: 2.324600
		loss: 2.343000
		loss: 2.324600
		loss: 2.470000
		loss: 2.324700
		loss: 2.423300
		loss: 2.324700
		loss: 2.395900
		loss: 2.324700
		loss: 2.207200
		loss: 2.324600
		loss: 2.661700
		loss: 2.324400
		loss: 2.231900
		loss: 2.324400
		loss: 2.015200
		loss: 2.324500
		loss: 2.130600
		loss: 2.324500
		loss: 2.434500
		loss: 2.324400
		loss: 2.292800
		loss: 2.324400
		loss: 2.465000
		loss: 2.324500
		loss: 2.145900
		loss: 2.324500
		loss: 2.331200
		loss: 2.324500
		loss: 2.573700
		loss: 2.324400
		loss: 2.297600
		loss: 2.324400
		loss: 2.466800
		loss: 2.324300
		loss: 2.370000
		loss: 2.324400
		loss: 2.436300
		loss: 2.324400
		loss: 2.421500
		loss: 2.324400
		loss: 2.400900
		loss: 2.324300
		loss: 2.180100
		loss: 2.324400
		loss: 2.150100
		loss: 2.324200
		loss: 2.295800
		loss: 2.324300
		loss: 2.368000
		loss: 2.324100
		loss: 2.169600
		loss: 2.324300
		loss: 2.241600
		loss: 2.324100
		loss: 2.344300
		loss: 2.324100
		loss: 2.424300
		loss: 2.324100
		loss: 2.627500
		loss: 2.324000
		loss: 2.315300
		loss: 2.324000
		loss: 2.351800
		loss: 2.324100
		loss: 2.424100
		loss: 2.324000
		loss: 2.470900
		loss: 2.324000
		loss: 2.421700
		loss: 2.324100
		loss: 2.162400
		loss: 2.324100
		loss: 2.143500
		loss: 2.324300
		loss: 2.540000
		loss: 2.324200
		loss: 2.365200
		loss: 2.324000
		loss: 2.281200
		loss: 2.324000
		loss: 2.386800
		loss: 2.323900
		loss: 2.469400
		loss: 2.324000
		loss: 2.169300
		loss: 2.324000
		loss: 2.375300
		loss: 2.324000
		loss: 2.127900
		loss: 2.324100
		loss: 2.385300
		loss: 2.324200
		loss: 2.412100
		loss: 2.324200
		loss: 2.253400
		loss: 2.324000
		loss: 2.011700
		loss: 2.324200
		loss: 2.264400
		loss: 2.324200
		loss: 2.197200
		loss: 2.324100
		loss: 2.321700
		loss: 2.324100
		loss: 2.545500
		loss: 2.324000
		loss: 1.927100
		loss: 2.323900
		loss: 2.209500
		loss: 2.324100
		loss: 2.381500
		loss: 2.324600
		loss: 2.344600
		loss: 2.324400
		loss: 2.162700
		loss: 2.324600
		loss: 2.572300
		loss: 2.324800
		loss: 2.516100
		loss: 2.324500
		loss: 2.243400
		loss: 2.324200
		loss: 2.058800
		loss: 2.324100
		loss: 2.671800
		loss: 2.324300
		loss: 2.513000
		loss: 2.324600
		loss: 2.327800
		loss: 2.324700
		loss: 2.278900
		loss: 2.324600
		loss: 1.992800
		loss: 2.324700
		loss: 2.382800
		loss: 2.324500
		loss: 2.311300
		loss: 2.324700
		loss: 2.659400
		loss: 2.325100
		loss: 2.063900
		loss: 2.324800
		loss: 2.455300
		loss: 2.324500
		loss: 2.393900
		loss: 2.324100
		loss: 2.255100
		loss: 2.324300
		loss: 2.492800
		loss: 2.324300
		loss: 2.649500
		loss: 2.324200
		loss: 2.261400
		loss: 2.323900
		loss: 2.465600
		loss: 2.323900
		loss: 2.469300
		loss: 2.324100
		loss: 2.544300
		loss: 2.324100
	Overall the loss development was 1.379700 -> 2.324100
problem epoch data for epoch 7, problem epoch 3
	sampling search time: 206.80011129379272s
	during this search the following actions were chosen:
		open boot was chosen with probability 1.000000
		fetch wrench boot was chosen with probability 0.208251
		fetch r1 boot was chosen with probability 0.207546
		loosen nuts1 the-hub1 was chosen with probability 0.265427
		fetch jack boot was chosen with probability 0.288954
		fetch r2 boot was chosen with probability 0.377516
		fetch pump boot was chosen with probability 0.470658
		inflate r1 was chosen with probability 0.380355
		inflate r2 was chosen with probability 0.613818
		loosen nuts2 the-hub2 was chosen with probability 0.513687
		jack-up the-hub1 was chosen with probability 0.602168
		undo nuts1 the-hub1 was chosen with probability 0.983448
		remove-wheel w1 the-hub1 was chosen with probability 0.984496
		put-on-wheel r1 the-hub1 was chosen with probability 0.660172
		put-away w1 boot was chosen with probability 0.869613
		remove-wheel r1 the-hub1 was chosen with probability 0.695660
		put-on-wheel r1 the-hub1 was chosen with probability 0.961444
	training time: 20.432127714157104s
	during the training the following losses were computed:
		loss: 1.749200
		loss: 2.439700
		loss: 2.507100
		loss: 2.436600
		loss: 2.711800
		loss: 2.437800
		loss: 2.555600
		loss: 2.436300
		loss: 2.520000
		loss: 2.436400
		loss: 2.612700
		loss: 2.436000
		loss: 2.517000
		loss: 2.436300
		loss: 2.333400
		loss: 2.436000
		loss: 2.547100
		loss: 2.436000
		loss: 2.610400
		loss: 2.437200
		loss: 2.602100
		loss: 2.435700
		loss: 2.512300
		loss: 2.436000
		loss: 2.240800
		loss: 2.437000
		loss: 2.393100
		loss: 2.436500
		loss: 2.359100
		loss: 2.436700
		loss: 2.176100
		loss: 2.435300
		loss: 2.107400
		loss: 2.435000
		loss: 2.295000
		loss: 2.436800
		loss: 2.391800
		loss: 2.436100
		loss: 2.549400
		loss: 2.436700
		loss: 2.486000
		loss: 2.436500
		loss: 2.242300
		loss: 2.435500
		loss: 2.612300
		loss: 2.436900
		loss: 2.202800
		loss: 2.435300
		loss: 2.206900
		loss: 2.435300
		loss: 2.464100
		loss: 2.436200
		loss: 2.351800
		loss: 2.436600
		loss: 2.425700
		loss: 2.436200
		loss: 2.414500
		loss: 2.436100
		loss: 2.448000
		loss: 2.436200
		loss: 2.341500
		loss: 2.436500
		loss: 2.323100
		loss: 2.436600
		loss: 2.608600
		loss: 2.435500
		loss: 2.589500
		loss: 2.436800
		loss: 2.399900
		loss: 2.436000
		loss: 2.305900
		loss: 2.435600
		loss: 2.444400
		loss: 2.436100
		loss: 2.097400
		loss: 2.434800
		loss: 2.371800
		loss: 2.435900
		loss: 2.348900
		loss: 2.435800
		loss: 2.321600
		loss: 2.435700
		loss: 2.311800
		loss: 2.435700
		loss: 2.665300
		loss: 2.437100
		loss: 2.619800
		loss: 2.436900
		loss: 2.691400
		loss: 2.437200
		loss: 2.444000
		loss: 2.436200
		loss: 2.636600
		loss: 2.435500
		loss: 2.647000
		loss: 2.437400
		loss: 2.366800
		loss: 2.436100
		loss: 2.412400
		loss: 2.436300
		loss: 2.352900
		loss: 2.436300
		loss: 2.323600
		loss: 2.436000
		loss: 2.521400
		loss: 2.436200
		loss: 2.486700
		loss: 2.436100
		loss: 2.124000
		loss: 2.435300
		loss: 2.335800
		loss: 2.436900
		loss: 2.399700
		loss: 2.436400
		loss: 2.619900
		loss: 2.435600
		loss: 2.324200
		loss: 2.435700
		loss: 2.301700
		loss: 2.436700
		loss: 2.308100
		loss: 2.436600
		loss: 2.169600
		loss: 2.437400
		loss: 2.241700
		loss: 2.437400
		loss: 2.387100
		loss: 2.437300
		loss: 2.214300
		loss: 2.436700
		loss: 2.157100
		loss: 2.436500
		loss: 2.600800
		loss: 2.437800
		loss: 2.208800
		loss: 2.437200
		loss: 2.463500
		loss: 2.438200
		loss: 2.597300
		loss: 2.437200
		loss: 2.524800
		loss: 2.437600
		loss: 2.528300
		loss: 2.436700
		loss: 2.481400
		loss: 2.437000
		loss: 2.621100
		loss: 2.437000
		loss: 2.404200
		loss: 2.436400
		loss: 2.450500
		loss: 2.436200
		loss: 2.611900
		loss: 2.436800
		loss: 2.463900
		loss: 2.436100
		loss: 2.217100
		loss: 2.436900
		loss: 2.437900
		loss: 2.436000
		loss: 2.262600
		loss: 2.435300
		loss: 2.501200
		loss: 2.435700
		loss: 2.291200
		loss: 2.436600
		loss: 2.364100
		loss: 2.435800
		loss: 2.537400
		loss: 2.435600
		loss: 2.718100
		loss: 2.435000
		loss: 2.291900
		loss: 2.436600
		loss: 2.304700
		loss: 2.436600
		loss: 2.489900
		loss: 2.436200
		loss: 2.453100
		loss: 2.436100
		loss: 2.485900
		loss: 2.436000
		loss: 2.696900
		loss: 2.435100
		loss: 2.630300
		loss: 2.435300
		loss: 2.505800
		loss: 2.435900
		loss: 2.890200
		loss: 2.434400
		loss: 2.263700
		loss: 2.435500
		loss: 2.552100
		loss: 2.435600
		loss: 2.539000
		loss: 2.435600
		loss: 2.539800
		loss: 2.436300
		loss: 2.549000
		loss: 2.435500
	Overall the loss development was 1.749200 -> 2.435500
In the epoch 7 for problem d-02.pddl 0 explorations in the sampling searches reached a goal
Success rate: 0

Epoch 8:
Training data for problem d-01.pddl in epoch 8:
model creation time: 8.085016965866089s
problem epoch data for epoch 8, problem epoch 1
	sampling search time: 3.605769634246826s
	during this search the following actions were chosen:
		open boot was chosen with probability 1.000000
		fetch r1 boot was chosen with probability 0.359186
		fetch pump boot was chosen with probability 0.336995
		inflate r1 was chosen with probability 0.479948
		fetch jack boot was chosen with probability 0.500624
		fetch wrench boot was chosen with probability 0.977131
		loosen nuts1 the-hub1 was chosen with probability 0.982975
		jack-up the-hub1 was chosen with probability 0.975819
		undo nuts1 the-hub1 was chosen with probability 0.983986
		remove-wheel w1 the-hub1 was chosen with probability 0.984176
		put-away w1 boot was chosen with probability 0.570011
		put-on-wheel r1 the-hub1 was chosen with probability 0.988246
		remove-wheel r1 the-hub1 was chosen with probability 0.711516
	training time: 37.69361090660095s
	during the training the following losses were computed:
		loss: 1.371300
		loss: 1.374700
		loss: 1.356800
		loss: 1.348700
		loss: 1.357000
		loss: 1.354500
		loss: 1.346700
		loss: 1.346300
		loss: 1.349600
		loss: 1.348500
		loss: 1.345200
		loss: 1.344500
		loss: 1.346100
		loss: 1.346500
		loss: 1.345200
		loss: 1.343900
		loss: 1.344000
		loss: 1.344600
		loss: 1.344400
		loss: 1.343400
		loss: 1.342700
		loss: 1.342800
		loss: 1.343100
		loss: 1.342900
		loss: 1.342300
		loss: 1.342100
		loss: 1.342400
		loss: 1.342500
		loss: 1.342100
		loss: 1.341600
		loss: 1.341600
		loss: 1.341900
		loss: 1.341900
		loss: 1.341600
		loss: 1.341400
		loss: 1.341500
		loss: 1.341500
		loss: 1.341300
		loss: 1.341200
		loss: 1.341200
		loss: 1.341300
		loss: 1.341200
		loss: 1.341100
		loss: 1.341000
		loss: 1.341100
		loss: 1.341000
		loss: 1.341000
		loss: 1.340900
		loss: 1.340900
		loss: 1.340900
		loss: 1.340800
		loss: 1.340800
		loss: 1.340800
		loss: 1.340800
		loss: 1.340700
		loss: 1.340700
		loss: 1.340700
		loss: 1.340700
		loss: 1.340600
		loss: 1.340600
		loss: 1.340600
		loss: 1.340600
		loss: 1.340500
		loss: 1.340500
		loss: 1.340500
		loss: 1.340500
		loss: 1.340500
		loss: 1.340400
		loss: 1.340400
		loss: 1.340400
		loss: 1.340400
		loss: 1.340400
		loss: 1.340400
		loss: 1.340300
		loss: 1.340300
		loss: 1.340300
		loss: 1.340300
		loss: 1.340300
		loss: 1.340300
		loss: 1.340200
		loss: 1.340200
		loss: 1.340200
		loss: 1.340200
		loss: 1.340200
		loss: 1.340200
		loss: 1.340100
		loss: 1.340100
		loss: 1.340100
		loss: 1.340100
		loss: 1.340100
		loss: 1.340100
		loss: 1.340000
		loss: 1.340000
		loss: 1.340000
		loss: 1.340000
		loss: 1.340000
		loss: 1.340000
		loss: 1.339900
		loss: 1.339900
		loss: 1.339900
	Overall the loss development was 1.371300 -> 1.339900
problem epoch data for epoch 8, problem epoch 2
	sampling search time: 3.628100633621216s
	during this search the following actions were chosen:
		open boot was chosen with probability 1.000000
		fetch r1 boot was chosen with probability 0.259951
		fetch wrench boot was chosen with probability 0.341915
		loosen nuts1 the-hub1 was chosen with probability 0.360420
		fetch jack boot was chosen with probability 0.566168
		fetch pump boot was chosen with probability 0.602983
		inflate r1 was chosen with probability 0.714578
		jack-up the-hub1 was chosen with probability 0.977220
		undo nuts1 the-hub1 was chosen with probability 0.986179
		remove-wheel w1 the-hub1 was chosen with probability 0.985780
		put-on-wheel r1 the-hub1 was chosen with probability 0.678800
		put-away w1 boot was chosen with probability 0.846903
		remove-wheel r1 the-hub1 was chosen with probability 0.621903
		put-on-wheel r1 the-hub1 was chosen with probability 0.992579
	training time: 10.13846492767334s
	during the training the following losses were computed:
		loss: 1.389200
		loss: 1.389200
		loss: 1.389200
		loss: 1.389100
		loss: 1.389100
		loss: 1.389000
		loss: 1.389000
		loss: 1.388900
		loss: 1.388900
		loss: 1.388900
		loss: 1.388800
		loss: 1.388800
		loss: 1.388700
		loss: 1.388700
		loss: 1.388700
		loss: 1.388700
		loss: 1.388600
		loss: 1.388600
		loss: 1.388600
		loss: 1.388600
		loss: 1.388600
		loss: 1.388600
		loss: 1.388500
		loss: 1.388500
		loss: 1.388500
		loss: 1.388500
		loss: 1.388500
		loss: 1.388500
		loss: 1.388500
		loss: 1.388500
		loss: 1.388400
		loss: 1.388400
		loss: 1.388400
		loss: 1.388400
		loss: 1.388400
		loss: 1.388400
		loss: 1.388400
		loss: 1.388400
		loss: 1.388300
		loss: 1.388300
		loss: 1.388300
		loss: 1.388300
		loss: 1.388300
		loss: 1.388300
		loss: 1.388300
		loss: 1.388300
		loss: 1.388200
		loss: 1.388200
		loss: 1.388200
		loss: 1.388200
		loss: 1.388200
		loss: 1.388200
		loss: 1.388200
		loss: 1.388200
		loss: 1.388200
		loss: 1.388100
		loss: 1.388100
		loss: 1.388100
		loss: 1.388100
		loss: 1.388100
		loss: 1.388100
		loss: 1.388100
		loss: 1.388100
		loss: 1.388100
		loss: 1.388000
		loss: 1.388000
		loss: 1.388000
		loss: 1.388000
		loss: 1.388000
		loss: 1.388000
		loss: 1.388000
		loss: 1.388000
		loss: 1.388000
		loss: 1.387900
		loss: 1.387900
		loss: 1.387900
		loss: 1.387900
		loss: 1.387900
		loss: 1.387900
		loss: 1.387900
		loss: 1.387900
		loss: 1.387900
		loss: 1.387900
		loss: 1.387800
		loss: 1.387800
		loss: 1.387800
		loss: 1.387800
		loss: 1.387800
		loss: 1.387800
		loss: 1.387800
		loss: 1.387800
		loss: 1.387800
		loss: 1.387800
		loss: 1.387700
		loss: 1.387700
		loss: 1.387700
		loss: 1.387700
		loss: 1.387700
		loss: 1.387700
		loss: 1.387700
	Overall the loss development was 1.389200 -> 1.387700
problem epoch data for epoch 8, problem epoch 3
	sampling search time: 3.594599485397339s
	during this search the following actions were chosen:
		open boot was chosen with probability 1.000000
		fetch r1 boot was chosen with probability 0.259099
		fetch wrench boot was chosen with probability 0.335770
		loosen nuts1 the-hub1 was chosen with probability 0.369848
		fetch jack boot was chosen with probability 0.513095
		fetch pump boot was chosen with probability 0.603935
		inflate r1 was chosen with probability 0.708408
		jack-up the-hub1 was chosen with probability 0.974578
		undo nuts1 the-hub1 was chosen with probability 0.984884
		remove-wheel w1 the-hub1 was chosen with probability 0.984980
		put-on-wheel r1 the-hub1 was chosen with probability 0.674023
		put-away w1 boot was chosen with probability 0.855966
		remove-wheel r1 the-hub1 was chosen with probability 0.577203
		put-on-wheel r1 the-hub1 was chosen with probability 0.991774
	training time: 10.137032985687256s
	during the training the following losses were computed:
		loss: 1.387700
		loss: 1.387700
		loss: 1.387700
		loss: 1.387700
		loss: 1.387600
		loss: 1.387600
		loss: 1.387600
		loss: 1.387600
		loss: 1.387600
		loss: 1.387600
		loss: 1.387600
		loss: 1.387600
		loss: 1.387600
		loss: 1.387600
		loss: 1.387500
		loss: 1.387500
		loss: 1.387500
		loss: 1.387500
		loss: 1.387500
		loss: 1.387500
		loss: 1.387500
		loss: 1.387500
		loss: 1.387500
		loss: 1.387500
		loss: 1.387500
		loss: 1.387400
		loss: 1.387400
		loss: 1.387400
		loss: 1.387400
		loss: 1.387400
		loss: 1.387400
		loss: 1.387400
		loss: 1.387400
		loss: 1.387400
		loss: 1.387400
		loss: 1.387400
		loss: 1.387300
		loss: 1.387300
		loss: 1.387300
		loss: 1.387300
		loss: 1.387300
		loss: 1.387300
		loss: 1.387300
		loss: 1.387300
		loss: 1.387300
		loss: 1.387300
		loss: 1.387300
		loss: 1.387300
		loss: 1.387200
		loss: 1.387200
		loss: 1.387200
		loss: 1.387200
		loss: 1.387200
		loss: 1.387200
		loss: 1.387200
		loss: 1.387200
		loss: 1.387200
		loss: 1.387200
		loss: 1.387200
		loss: 1.387200
		loss: 1.387100
		loss: 1.387100
		loss: 1.387100
		loss: 1.387100
		loss: 1.387100
		loss: 1.387100
		loss: 1.387100
		loss: 1.387100
		loss: 1.387100
		loss: 1.387100
		loss: 1.387100
		loss: 1.387100
		loss: 1.387000
		loss: 1.387000
		loss: 1.387000
		loss: 1.387000
		loss: 1.387000
		loss: 1.387000
		loss: 1.387000
		loss: 1.387000
		loss: 1.387000
		loss: 1.387000
		loss: 1.387000
		loss: 1.387000
		loss: 1.387000
		loss: 1.386900
		loss: 1.386900
		loss: 1.386900
		loss: 1.386900
		loss: 1.386900
		loss: 1.386900
		loss: 1.386900
		loss: 1.386900
		loss: 1.386900
		loss: 1.386900
		loss: 1.386900
		loss: 1.386900
		loss: 1.386900
		loss: 1.386800
		loss: 1.386800
	Overall the loss development was 1.387700 -> 1.386800
In the epoch 8 for problem d-01.pddl 0 explorations in the sampling searches reached a goal
Training data for problem d-02.pddl in epoch 8:
model creation time: 15.674129247665405s
problem epoch data for epoch 8, problem epoch 1
	sampling search time: 175.67167377471924s
	during this search the following actions were chosen:
		open boot was chosen with probability 1.000000
		fetch wrench boot was chosen with probability 0.259812
		loosen nuts2 the-hub2 was chosen with probability 0.206977
		loosen nuts1 the-hub1 was chosen with probability 0.299100
		fetch pump boot was chosen with probability 0.310684
		inflate r1 was chosen with probability 0.292304
		inflate r2 was chosen with probability 0.412816
		fetch jack boot was chosen with probability 0.429035
		fetch r2 boot was chosen with probability 0.284541
		fetch r1 boot was chosen with probability 0.354558
		jack-up the-hub1 was chosen with probability 0.491472
		undo nuts1 the-hub1 was chosen with probability 0.981876
		remove-wheel w1 the-hub1 was chosen with probability 0.982920
		put-on-wheel r1 the-hub1 was chosen with probability 0.734166
		put-away w1 boot was chosen with probability 0.817194
		remove-wheel r1 the-hub1 was chosen with probability 0.486213
		put-on-wheel r1 the-hub1 was chosen with probability 0.957632
	training time: 70.27153587341309s
	during the training the following losses were computed:
		loss: 1.806700
		loss: 2.679700
		loss: 2.557300
		loss: 2.636200
		loss: 2.704100
		loss: 2.639600
		loss: 2.376000
		loss: 2.618500
		loss: 2.544500
		loss: 2.622000
		loss: 2.669200
		loss: 2.616600
		loss: 2.715100
		loss: 2.614000
		loss: 2.119100
		loss: 2.610200
		loss: 2.605500
		loss: 2.606000
		loss: 2.680700
		loss: 2.606200
		loss: 2.726200
		loss: 2.604300
		loss: 2.500900
		loss: 2.601000
		loss: 2.866600
		loss: 2.602300
		loss: 2.477200
		loss: 2.600200
		loss: 2.187800
		loss: 2.595100
		loss: 2.963400
		loss: 2.594900
		loss: 2.601200
		loss: 2.595800
		loss: 2.495800
		loss: 2.595000
		loss: 2.593100
		loss: 2.594400
		loss: 2.808600
		loss: 2.592300
		loss: 2.692400
		loss: 2.592900
		loss: 2.136800
		loss: 2.590000
		loss: 2.517900
		loss: 2.592800
		loss: 2.536800
		loss: 2.591800
		loss: 2.939300
		loss: 2.589400
		loss: 2.433800
		loss: 2.590200
		loss: 2.506200
		loss: 2.591300
		loss: 2.816700
		loss: 2.589200
		loss: 2.791700
		loss: 2.589000
		loss: 2.639900
		loss: 2.590300
		loss: 2.537800
		loss: 2.590100
		loss: 2.828100
		loss: 2.588000
		loss: 2.728600
		loss: 2.590100
		loss: 2.868800
		loss: 2.587400
		loss: 2.382200
		loss: 2.590300
		loss: 2.691000
		loss: 2.589500
		loss: 2.547600
		loss: 2.588400
		loss: 2.696300
		loss: 2.589200
		loss: 2.452300
		loss: 2.587600
		loss: 2.716400
		loss: 2.588900
		loss: 2.516300
		loss: 2.587600
		loss: 2.593500
		loss: 2.588000
		loss: 2.574000
		loss: 2.587800
		loss: 2.893400
		loss: 2.589800
		loss: 2.284600
		loss: 2.585700
		loss: 2.527100
		loss: 2.587200
		loss: 2.365600
		loss: 2.586000
		loss: 2.717800
		loss: 2.586300
		loss: 2.921200
		loss: 2.589400
		loss: 2.394300
		loss: 2.588300
		loss: 2.431800
		loss: 2.587900
		loss: 2.665200
		loss: 2.587400
		loss: 2.617800
		loss: 2.586700
		loss: 2.146100
		loss: 2.584200
		loss: 2.711200
		loss: 2.585900
		loss: 2.475100
		loss: 2.587300
		loss: 2.392700
		loss: 2.587800
		loss: 2.758000
		loss: 2.585400
		loss: 2.672600
		loss: 2.585900
		loss: 2.644900
		loss: 2.586100
		loss: 2.721200
		loss: 2.585600
		loss: 2.830300
		loss: 2.584800
		loss: 2.613600
		loss: 2.586100
		loss: 2.490200
		loss: 2.585700
		loss: 2.864400
		loss: 2.587900
		loss: 2.484400
		loss: 2.585500
		loss: 2.599900
		loss: 2.586100
		loss: 2.491700
		loss: 2.586600
		loss: 2.575600
		loss: 2.586000
		loss: 2.847800
		loss: 2.587500
		loss: 2.923100
		loss: 2.588000
		loss: 2.254300
		loss: 2.583800
		loss: 2.844000
		loss: 2.587400
		loss: 2.860200
		loss: 2.587600
		loss: 2.099200
		loss: 2.582800
		loss: 2.542900
		loss: 2.586000
		loss: 3.016400
		loss: 2.583100
		loss: 2.757500
		loss: 2.584700
		loss: 2.591800
		loss: 2.585800
		loss: 2.350200
		loss: 2.584200
		loss: 2.392800
		loss: 2.586800
		loss: 2.420700
		loss: 2.584800
		loss: 3.139800
		loss: 2.582400
		loss: 2.176900
		loss: 2.583500
		loss: 2.438300
		loss: 2.585000
		loss: 2.556100
		loss: 2.585300
		loss: 2.542800
		loss: 2.586200
		loss: 2.730100
		loss: 2.584900
		loss: 2.854000
		loss: 2.587600
		loss: 2.663400
		loss: 2.586400
		loss: 2.438400
		loss: 2.586600
		loss: 2.747400
		loss: 2.586400
		loss: 2.634800
		loss: 2.585800
		loss: 2.557900
		loss: 2.585200
		loss: 2.344900
		loss: 2.586900
		loss: 2.382800
		loss: 2.586600
		loss: 2.293600
		loss: 2.587100
		loss: 2.596800
		loss: 2.585300
		loss: 2.781100
		loss: 2.584100
		loss: 2.366700
		loss: 2.586700
	Overall the loss development was 1.806700 -> 2.586700
problem epoch data for epoch 8, problem epoch 2
	sampling search time: 33.30004405975342s
	during this search the following actions were chosen:
		close boot was chosen with probability 0.000000
	training time: 17.396451950073242s
	during the training the following losses were computed:
		loss: 3.450000
		loss: 2.590600
		loss: 2.487400
		loss: 2.585800
		loss: 2.583800
		loss: 2.585300
		loss: 2.217300
		loss: 2.587700
		loss: 2.285100
		loss: 2.587300
		loss: 2.893100
		loss: 2.587200
		loss: 2.520400
		loss: 2.585800
		loss: 2.686600
		loss: 2.584500
		loss: 2.217900
		loss: 2.587500
		loss: 2.776700
		loss: 2.584000
		loss: 2.416700
		loss: 2.584200
		loss: 2.666300
		loss: 2.584600
		loss: 3.032300
		loss: 2.582300
		loss: 2.583200
		loss: 2.585000
		loss: 2.431800
		loss: 2.584200
		loss: 2.737300
		loss: 2.586100
		loss: 3.129000
		loss: 2.581700
		loss: 2.260300
		loss: 2.583100
		loss: 2.248400
		loss: 2.583000
		loss: 2.677600
		loss: 2.585700
		loss: 2.665600
		loss: 2.584500
		loss: 2.818400
		loss: 2.586400
		loss: 2.636200
		loss: 2.585400
		loss: 2.970100
		loss: 2.587400
		loss: 2.505100
		loss: 2.585500
		loss: 2.884900
		loss: 2.583200
		loss: 2.905500
		loss: 2.587000
		loss: 2.997300
		loss: 2.587500
		loss: 2.433000
		loss: 2.586000
		loss: 2.827400
		loss: 2.586400
		loss: 2.724700
		loss: 2.585700
		loss: 2.732100
		loss: 2.584000
		loss: 2.457800
		loss: 2.585700
		loss: 2.218500
		loss: 2.587200
		loss: 3.017900
		loss: 2.587600
		loss: 2.537000
		loss: 2.585100
		loss: 2.687300
		loss: 2.584200
		loss: 2.604600
		loss: 2.584900
		loss: 2.669900
		loss: 2.585300
		loss: 2.640000
		loss: 2.585100
		loss: 2.789300
		loss: 2.586000
		loss: 2.950000
		loss: 2.582500
		loss: 2.968000
		loss: 2.582300
		loss: 2.469000
		loss: 2.585500
		loss: 2.515600
		loss: 2.585300
		loss: 2.500000
		loss: 2.584300
		loss: 2.700000
		loss: 2.584000
		loss: 2.610900
		loss: 2.584600
		loss: 2.819300
		loss: 2.586300
		loss: 2.191000
		loss: 2.587300
		loss: 2.551700
		loss: 2.585100
		loss: 2.888900
		loss: 2.582800
		loss: 2.622600
		loss: 2.584400
		loss: 2.888000
		loss: 2.586600
		loss: 2.266600
		loss: 2.582800
		loss: 2.528000
		loss: 2.584400
		loss: 2.248200
		loss: 2.586800
		loss: 2.746700
		loss: 2.583700
		loss: 2.605900
		loss: 2.584500
		loss: 2.606700
		loss: 2.584700
		loss: 2.387100
		loss: 2.586300
		loss: 2.671000
		loss: 2.585500
		loss: 2.812900
		loss: 2.583400
		loss: 2.799400
		loss: 2.586200
		loss: 2.326300
		loss: 2.586400
		loss: 2.279600
		loss: 2.586600
		loss: 2.315000
		loss: 2.586500
		loss: 2.437300
		loss: 2.585700
		loss: 2.824600
		loss: 2.586200
		loss: 3.027200
		loss: 2.581800
		loss: 2.498200
		loss: 2.585300
		loss: 2.680800
		loss: 2.585400
		loss: 3.040800
		loss: 2.587800
		loss: 2.280400
		loss: 2.582900
		loss: 2.719500
		loss: 2.585500
		loss: 2.421200
		loss: 2.585800
		loss: 2.656100
		loss: 2.585200
		loss: 2.548000
		loss: 2.584600
		loss: 2.573800
		loss: 2.584800
		loss: 2.765200
		loss: 2.585900
		loss: 2.792600
		loss: 2.586100
		loss: 2.226900
		loss: 2.586900
		loss: 2.834000
		loss: 2.586400
		loss: 2.943400
		loss: 2.587100
		loss: 2.974000
		loss: 2.587200
		loss: 2.465900
		loss: 2.584000
		loss: 2.477800
		loss: 2.585700
		loss: 2.792100
		loss: 2.586500
		loss: 3.000900
		loss: 2.587600
		loss: 2.995800
		loss: 2.587600
		loss: 2.434600
		loss: 2.584800
		loss: 2.468200
		loss: 2.585100
		loss: 2.637000
		loss: 2.585000
		loss: 2.736600
		loss: 2.584200
		loss: 2.385400
		loss: 2.586900
		loss: 2.671900
		loss: 2.586200
		loss: 2.874100
		loss: 2.586600
		loss: 2.654400
		loss: 2.585400
		loss: 2.794800
		loss: 2.586800
		loss: 2.675100
		loss: 2.585400
	Overall the loss development was 3.450000 -> 2.585400
problem epoch data for epoch 8, problem epoch 3
	sampling search time: 33.44761395454407s
	during this search the following actions were chosen:
		close boot was chosen with probability 0.000000
	training time: 17.494045972824097s
	during the training the following losses were computed:
		loss: 1.736300
		loss: 2.590200
		loss: 2.537400
		loss: 2.585500
		loss: 2.591500
		loss: 2.584900
		loss: 2.907100
		loss: 2.586600
		loss: 2.839200
		loss: 2.586400
		loss: 3.124100
		loss: 2.588000
		loss: 2.171100
		loss: 2.581900
		loss: 2.721600
		loss: 2.583500
		loss: 2.624800
		loss: 2.584100
		loss: 2.706500
		loss: 2.585200
		loss: 2.228300
		loss: 2.586700
		loss: 2.264300
		loss: 2.582600
		loss: 2.571400
		loss: 2.584500
		loss: 2.489500
		loss: 2.583900
		loss: 2.494600
		loss: 2.583800
		loss: 2.526200
		loss: 2.583900
		loss: 2.494700
		loss: 2.584900
		loss: 2.904600
		loss: 2.586300
		loss: 2.529700
		loss: 2.583900
		loss: 2.264400
		loss: 2.586300
		loss: 2.108900
		loss: 2.581400
		loss: 2.500000
		loss: 2.584900
		loss: 2.309200
		loss: 2.586000
		loss: 2.457200
		loss: 2.583500
		loss: 2.488000
		loss: 2.583600
		loss: 2.771000
		loss: 2.585400
		loss: 2.472000
		loss: 2.584900
		loss: 2.836300
		loss: 2.582600
		loss: 2.464500
		loss: 2.585000
		loss: 2.626500
		loss: 2.584600
		loss: 2.461700
		loss: 2.585100
		loss: 2.828000
		loss: 2.582800
		loss: 2.792600
		loss: 2.583000
		loss: 2.735700
		loss: 2.583400
		loss: 2.824300
		loss: 2.585800
		loss: 2.582100
		loss: 2.584300
		loss: 2.073500
		loss: 2.587400
		loss: 2.878300
		loss: 2.586000
		loss: 2.719300
		loss: 2.583500
		loss: 2.688400
		loss: 2.583800
		loss: 2.979400
		loss: 2.587000
		loss: 2.630600
		loss: 2.584800
		loss: 2.342300
		loss: 2.582900
		loss: 2.583800
		loss: 2.584300
		loss: 2.784900
		loss: 2.585500
		loss: 2.385200
		loss: 2.585600
		loss: 2.869500
		loss: 2.582600
		loss: 2.546800
		loss: 2.584000
		loss: 2.521100
		loss: 2.583800
		loss: 2.909500
		loss: 2.582200
		loss: 2.865700
		loss: 2.582300
		loss: 2.518300
		loss: 2.583700
		loss: 2.186900
		loss: 2.586700
		loss: 2.952400
		loss: 2.581800
		loss: 2.653900
		loss: 2.583600
		loss: 2.273600
		loss: 2.582200
		loss: 3.076900
		loss: 2.587100
		loss: 2.441300
		loss: 2.585000
		loss: 2.631300
		loss: 2.583800
		loss: 2.456300
		loss: 2.583200
		loss: 2.571500
		loss: 2.584100
		loss: 2.499800
		loss: 2.584600
		loss: 2.319300
		loss: 2.582400
		loss: 2.680700
		loss: 2.583400
		loss: 2.623200
		loss: 2.584200
		loss: 2.685100
		loss: 2.583300
		loss: 2.838600
		loss: 2.585600
		loss: 2.805800
		loss: 2.585400
		loss: 2.200100
		loss: 2.581600
		loss: 2.673700
		loss: 2.583400
		loss: 2.259000
		loss: 2.586000
		loss: 2.485400
		loss: 2.583400
		loss: 2.110300
		loss: 2.587000
		loss: 2.261900
		loss: 2.586100
		loss: 2.774800
		loss: 2.585500
		loss: 2.802700
		loss: 2.583200
		loss: 2.926600
		loss: 2.586700
		loss: 2.522300
		loss: 2.584800
		loss: 2.760400
		loss: 2.583400
		loss: 2.964400
		loss: 2.587000
		loss: 2.762000
		loss: 2.583800
		loss: 2.880700
		loss: 2.583000
		loss: 2.424900
		loss: 2.586800
		loss: 2.568100
		loss: 2.585200
		loss: 2.835900
		loss: 2.587200
		loss: 2.552200
		loss: 2.585300
		loss: 2.510800
		loss: 2.586100
		loss: 2.729200
		loss: 2.584900
		loss: 2.747400
		loss: 2.584600
		loss: 2.575100
		loss: 2.585400
		loss: 2.578300
		loss: 2.585500
		loss: 2.576700
		loss: 2.585400
		loss: 2.659800
		loss: 2.584800
		loss: 2.886000
		loss: 2.587200
		loss: 2.562100
		loss: 2.584800
		loss: 3.069000
		loss: 2.587600
		loss: 2.729200
		loss: 2.583400
		loss: 2.478200
		loss: 2.583400
		loss: 2.173400
		loss: 2.586700
		loss: 2.502700
		loss: 2.584500
	Overall the loss development was 1.736300 -> 2.584500
In the epoch 8 for problem d-02.pddl 0 explorations in the sampling searches reached a goal
Success rate: 0

Epoch 9:
Training data for problem d-01.pddl in epoch 9:
model creation time: 8.111374378204346s
problem epoch data for epoch 9, problem epoch 1
	sampling search time: 1.9187707901000977s
	during this search the following actions were chosen:
		close boot was chosen with probability 0.000000
	training time: 37.65933561325073s
	during the training the following losses were computed:
		loss: 1.638900
		loss: 1.645600
		loss: 1.633200
		loss: 1.637000
		loss: 1.631700
		loss: 1.626300
		loss: 1.628000
		loss: 1.629300
		loss: 1.626100
		loss: 1.623300
		loss: 1.623800
		loss: 1.624200
		loss: 1.622600
		loss: 1.621000
		loss: 1.621200
		loss: 1.621700
		loss: 1.620600
		loss: 1.619400
		loss: 1.619700
		loss: 1.620400
		loss: 1.620100
		loss: 1.619300
		loss: 1.619200
		loss: 1.619500
		loss: 1.619500
		loss: 1.619100
		loss: 1.619000
		loss: 1.619200
		loss: 1.619200
		loss: 1.618900
		loss: 1.618800
		loss: 1.618900
		loss: 1.618800
		loss: 1.618600
		loss: 1.618500
		loss: 1.618600
		loss: 1.618500
		loss: 1.618400
		loss: 1.618300
		loss: 1.618400
		loss: 1.618300
		loss: 1.618200
		loss: 1.618100
		loss: 1.618200
		loss: 1.618100
		loss: 1.618000
		loss: 1.618000
		loss: 1.618000
		loss: 1.618000
		loss: 1.617900
		loss: 1.617900
		loss: 1.617900
		loss: 1.617800
		loss: 1.617800
		loss: 1.617800
		loss: 1.617800
		loss: 1.617700
		loss: 1.617700
		loss: 1.617700
		loss: 1.617700
		loss: 1.617600
		loss: 1.617600
		loss: 1.617600
		loss: 1.617600
		loss: 1.617500
		loss: 1.617500
		loss: 1.617500
		loss: 1.617500
		loss: 1.617500
		loss: 1.617400
		loss: 1.617400
		loss: 1.617400
		loss: 1.617400
		loss: 1.617400
		loss: 1.617300
		loss: 1.617300
		loss: 1.617300
		loss: 1.617300
		loss: 1.617300
		loss: 1.617200
		loss: 1.617200
		loss: 1.617200
		loss: 1.617200
		loss: 1.617200
		loss: 1.617200
		loss: 1.617100
		loss: 1.617100
		loss: 1.617100
		loss: 1.617100
		loss: 1.617100
		loss: 1.617100
		loss: 1.617000
		loss: 1.617000
		loss: 1.617000
		loss: 1.617000
		loss: 1.617000
		loss: 1.617000
		loss: 1.616900
		loss: 1.616900
		loss: 1.616900
	Overall the loss development was 1.638900 -> 1.616900
problem epoch data for epoch 9, problem epoch 2
	sampling search time: 3.703521966934204s
	during this search the following actions were chosen:
		open boot was chosen with probability 1.000000
		fetch r1 boot was chosen with probability 0.252919
		fetch jack boot was chosen with probability 0.334081
		fetch wrench boot was chosen with probability 0.493195
		loosen nuts1 the-hub1 was chosen with probability 0.521583
		fetch pump boot was chosen with probability 0.556940
		jack-up the-hub1 was chosen with probability 0.644287
		undo nuts1 the-hub1 was chosen with probability 0.700118
		remove-wheel w1 the-hub1 was chosen with probability 0.728995
		put-on-wheel r1 the-hub1 was chosen with probability 0.535785
		put-away w1 boot was chosen with probability 0.643051
		inflate r1 was chosen with probability 0.728236
		remove-wheel r1 the-hub1 was chosen with probability 0.491971
		put-on-wheel r1 the-hub1 was chosen with probability 0.952724
	training time: 10.136914014816284s
	during the training the following losses were computed:
		loss: 1.448400
		loss: 1.423800
		loss: 1.413300
		loss: 1.397400
		loss: 1.382600
		loss: 1.380800
		loss: 1.373800
		loss: 1.368000
		loss: 1.371000
		loss: 1.372900
		loss: 1.374700
		loss: 1.377200
		loss: 1.375000
		loss: 1.371500
		loss: 1.370600
		loss: 1.369500
		loss: 1.368000
		loss: 1.367400
		loss: 1.365900
		loss: 1.363900
		loss: 1.363600
		loss: 1.363900
		loss: 1.363200
		loss: 1.363100
		loss: 1.363000
		loss: 1.362300
		loss: 1.362500
		loss: 1.363000
		loss: 1.362600
		loss: 1.362300
		loss: 1.361900
		loss: 1.361200
		loss: 1.361000
		loss: 1.361000
		loss: 1.361000
		loss: 1.361000
		loss: 1.361000
		loss: 1.360900
		loss: 1.360800
		loss: 1.360700
		loss: 1.360500
		loss: 1.360400
		loss: 1.360400
		loss: 1.360300
		loss: 1.360200
		loss: 1.360200
		loss: 1.360100
		loss: 1.360000
		loss: 1.360000
		loss: 1.360000
		loss: 1.360000
		loss: 1.359900
		loss: 1.359900
		loss: 1.359800
		loss: 1.359800
		loss: 1.359800
		loss: 1.359700
		loss: 1.359700
		loss: 1.359700
		loss: 1.359700
		loss: 1.359600
		loss: 1.359600
		loss: 1.359600
		loss: 1.359600
		loss: 1.359600
		loss: 1.359500
		loss: 1.359500
		loss: 1.359500
		loss: 1.359500
		loss: 1.359500
		loss: 1.359500
		loss: 1.359500
		loss: 1.359400
		loss: 1.359400
		loss: 1.359400
		loss: 1.359400
		loss: 1.359400
		loss: 1.359400
		loss: 1.359400
		loss: 1.359400
		loss: 1.359300
		loss: 1.359300
		loss: 1.359300
		loss: 1.359300
		loss: 1.359300
		loss: 1.359300
		loss: 1.359300
		loss: 1.359300
		loss: 1.359300
		loss: 1.359200
		loss: 1.359200
		loss: 1.359200
		loss: 1.359200
		loss: 1.359200
		loss: 1.359200
		loss: 1.359200
		loss: 1.359200
		loss: 1.359200
		loss: 1.359200
		loss: 1.359200
	Overall the loss development was 1.448400 -> 1.359200
problem epoch data for epoch 9, problem epoch 3
	sampling search time: 1.8883836269378662s
	during this search the following actions were chosen:
		close boot was chosen with probability 0.000000
	training time: 10.136048793792725s
	during the training the following losses were computed:
		loss: 1.359100
		loss: 1.359100
		loss: 1.359100
		loss: 1.359100
		loss: 1.359100
		loss: 1.359100
		loss: 1.359100
		loss: 1.359100
		loss: 1.359100
		loss: 1.359100
		loss: 1.359100
		loss: 1.359100
		loss: 1.359100
		loss: 1.359000
		loss: 1.359000
		loss: 1.359000
		loss: 1.359000
		loss: 1.359000
		loss: 1.359000
		loss: 1.359000
		loss: 1.359000
		loss: 1.359000
		loss: 1.359000
		loss: 1.359000
		loss: 1.359000
		loss: 1.359000
		loss: 1.358900
		loss: 1.358900
		loss: 1.358900
		loss: 1.358900
		loss: 1.358900
		loss: 1.358900
		loss: 1.358900
		loss: 1.358900
		loss: 1.358900
		loss: 1.358900
		loss: 1.358900
		loss: 1.358900
		loss: 1.358900
		loss: 1.358900
		loss: 1.358900
		loss: 1.358800
		loss: 1.358800
		loss: 1.358800
		loss: 1.358800
		loss: 1.358800
		loss: 1.358800
		loss: 1.358800
		loss: 1.358800
		loss: 1.358800
		loss: 1.358800
		loss: 1.358800
		loss: 1.358800
		loss: 1.358800
		loss: 1.358800
		loss: 1.358800
		loss: 1.358700
		loss: 1.358700
		loss: 1.358700
		loss: 1.358700
		loss: 1.358700
		loss: 1.358700
		loss: 1.358700
		loss: 1.358700
		loss: 1.358700
		loss: 1.358700
		loss: 1.358700
		loss: 1.358700
		loss: 1.358700
		loss: 1.358700
		loss: 1.358700
		loss: 1.358700
		loss: 1.358600
		loss: 1.358600
		loss: 1.358600
		loss: 1.358600
		loss: 1.358600
		loss: 1.358600
		loss: 1.358600
		loss: 1.358600
		loss: 1.358600
		loss: 1.358600
		loss: 1.358600
		loss: 1.358600
		loss: 1.358600
		loss: 1.358600
		loss: 1.358600
		loss: 1.358600
		loss: 1.358600
		loss: 1.358500
		loss: 1.358500
		loss: 1.358500
		loss: 1.358500
		loss: 1.358500
		loss: 1.358500
		loss: 1.358500
		loss: 1.358500
		loss: 1.358500
		loss: 1.358500
		loss: 1.358500
	Overall the loss development was 1.359100 -> 1.358500
In the epoch 9 for problem d-01.pddl 0 explorations in the sampling searches reached a goal
Training data for problem d-02.pddl in epoch 9:
model creation time: 15.664810419082642s
problem epoch data for epoch 9, problem epoch 1
	sampling search time: 33.57614278793335s
	during this search the following actions were chosen:
		close boot was chosen with probability 0.000000
	training time: 62.23120617866516s
	during the training the following losses were computed:
		loss: 2.543100
		loss: 2.524000
		loss: 2.511400
		loss: 2.514600
		loss: 2.509800
		loss: 2.506600
		loss: 2.500800
		loss: 2.494900
		loss: 2.493400
		loss: 2.492900
		loss: 2.491800
		loss: 2.491100
		loss: 2.489800
		loss: 2.487700
		loss: 2.485700
		loss: 2.484600
		loss: 2.483800
		loss: 2.483000
		loss: 2.482500
		loss: 2.482200
		loss: 2.481300
		loss: 2.480100
		loss: 2.479300
		loss: 2.479000
		loss: 2.478600
		loss: 2.478500
		loss: 2.478300
		loss: 2.477700
		loss: 2.477000
		loss: 2.476600
		loss: 2.476400
		loss: 2.476200
		loss: 2.476100
		loss: 2.475900
		loss: 2.475500
		loss: 2.475200
		loss: 2.475200
		loss: 2.475200
		loss: 2.475100
		loss: 2.475000
		loss: 2.474800
		loss: 2.474600
		loss: 2.474500
		loss: 2.474500
		loss: 2.474400
		loss: 2.474300
		loss: 2.474100
		loss: 2.474000
		loss: 2.474000
		loss: 2.473900
		loss: 2.473800
		loss: 2.473700
		loss: 2.473600
		loss: 2.473600
		loss: 2.473500
		loss: 2.473500
		loss: 2.473400
		loss: 2.473300
		loss: 2.473300
		loss: 2.473300
		loss: 2.473200
		loss: 2.473200
		loss: 2.473100
		loss: 2.473100
		loss: 2.473000
		loss: 2.473000
		loss: 2.473000
		loss: 2.472900
		loss: 2.472900
		loss: 2.472900
		loss: 2.472900
		loss: 2.472800
		loss: 2.472800
		loss: 2.472800
		loss: 2.472700
		loss: 2.472700
		loss: 2.472700
		loss: 2.472700
		loss: 2.472600
		loss: 2.472600
		loss: 2.472600
		loss: 2.472600
		loss: 2.472500
		loss: 2.472500
		loss: 2.472500
		loss: 2.472500
		loss: 2.472400
		loss: 2.472400
		loss: 2.472400
		loss: 2.472400
		loss: 2.472400
		loss: 2.472300
		loss: 2.472300
		loss: 2.472300
		loss: 2.472300
		loss: 2.472300
		loss: 2.472300
		loss: 2.472200
		loss: 2.472200
		loss: 2.472200
	Overall the loss development was 2.543100 -> 2.472200
problem epoch data for epoch 9, problem epoch 2
	sampling search time: 167.70189762115479s
	during this search the following actions were chosen:
		open boot was chosen with probability 1.000000
		fetch pump boot was chosen with probability 0.203076
		fetch r1 boot was chosen with probability 0.217657
		fetch jack boot was chosen with probability 0.286365
		fetch r2 boot was chosen with probability 0.385998
		fetch wrench boot was chosen with probability 0.597821
		loosen nuts1 the-hub1 was chosen with probability 0.408048
		loosen nuts2 the-hub2 was chosen with probability 0.450128
		jack-up the-hub2 was chosen with probability 0.384868
		undo nuts2 the-hub2 was chosen with probability 0.636291
		remove-wheel w2 the-hub2 was chosen with probability 0.654410
		put-on-wheel r2 the-hub2 was chosen with probability 0.498346
		put-away w2 boot was chosen with probability 0.606081
		inflate r1 was chosen with probability 0.420752
		inflate r2 was chosen with probability 0.726370
		remove-wheel r2 the-hub2 was chosen with probability 0.586824
		put-on-wheel r2 the-hub2 was chosen with probability 0.970506
	training time: 18.002595901489258s
	during the training the following losses were computed:
		loss: 1.173200
		loss: 2.279600
		loss: 2.502700
		loss: 2.204200
		loss: 2.041600
		loss: 2.161800
		loss: 2.315400
		loss: 2.159000
		loss: 1.834000
		loss: 2.147700
		loss: 2.713600
		loss: 2.144200
		loss: 2.188300
		loss: 2.137600
		loss: 1.958100
		loss: 2.135700
		loss: 2.124900
		loss: 2.135000
		loss: 2.235700
		loss: 2.132400
		loss: 2.044100
		loss: 2.127500
		loss: 2.428600
		loss: 2.124100
		loss: 1.585800
		loss: 2.116600
		loss: 2.020900
		loss: 2.120100
		loss: 2.170500
		loss: 2.121000
		loss: 2.111400
		loss: 2.119900
		loss: 1.903600
		loss: 2.120000
		loss: 2.239700
		loss: 2.117600
		loss: 2.034300
		loss: 2.118600
		loss: 2.184100
		loss: 2.117100
		loss: 2.310300
		loss: 2.118100
		loss: 2.328000
		loss: 2.115600
		loss: 2.140500
		loss: 2.116600
		loss: 1.595300
		loss: 2.113500
		loss: 1.834500
		loss: 2.118000
		loss: 2.027500
		loss: 2.116600
		loss: 2.141500
		loss: 2.116000
		loss: 1.776700
		loss: 2.117800
		loss: 2.043400
		loss: 2.115600
		loss: 1.980900
		loss: 2.116500
		loss: 2.092800
		loss: 2.115600
		loss: 1.920900
		loss: 2.114400
		loss: 2.265600
		loss: 2.114500
		loss: 1.943200
		loss: 2.114200
		loss: 2.145000
		loss: 2.115300
		loss: 2.041300
		loss: 2.114700
		loss: 2.164500
		loss: 2.115600
		loss: 1.889600
		loss: 2.113800
		loss: 1.850400
		loss: 2.113900
		loss: 2.319300
		loss: 2.116700
		loss: 2.424000
		loss: 2.117200
		loss: 2.140400
		loss: 2.115300
		loss: 2.039400
		loss: 2.115900
		loss: 1.981600
		loss: 2.116400
		loss: 2.393900
		loss: 2.113600
		loss: 2.250800
		loss: 2.114000
		loss: 1.985100
		loss: 2.115800
		loss: 1.937800
		loss: 2.113900
		loss: 2.088700
		loss: 2.114700
		loss: 1.932500
		loss: 2.113800
		loss: 2.351900
		loss: 2.116400
		loss: 2.322900
		loss: 2.115900
		loss: 1.945700
		loss: 2.114000
		loss: 2.137500
		loss: 2.115400
		loss: 2.433800
		loss: 2.116800
		loss: 1.946500
		loss: 2.113600
		loss: 1.986900
		loss: 2.116000
		loss: 2.407000
		loss: 2.113300
		loss: 2.032900
		loss: 2.114200
		loss: 1.727700
		loss: 2.112300
		loss: 1.999700
		loss: 2.115300
		loss: 2.319200
		loss: 2.115500
		loss: 1.878500
		loss: 2.115800
		loss: 1.862100
		loss: 2.115900
		loss: 2.267000
		loss: 2.113400
		loss: 2.351600
		loss: 2.112800
		loss: 2.028400
		loss: 2.113800
		loss: 2.150500
		loss: 2.114500
		loss: 1.997700
		loss: 2.115000
		loss: 2.241600
		loss: 2.113500
		loss: 1.898900
		loss: 2.115400
		loss: 2.372600
		loss: 2.115700
		loss: 2.012400
		loss: 2.114700
		loss: 2.003700
		loss: 2.113500
		loss: 1.922700
		loss: 2.113200
		loss: 2.121900
		loss: 2.114400
		loss: 2.109200
		loss: 2.114200
		loss: 2.017000
		loss: 2.113500
		loss: 2.047500
		loss: 2.114500
		loss: 2.080100
		loss: 2.114400
		loss: 2.398500
		loss: 2.112700
		loss: 2.149500
		loss: 2.114400
		loss: 1.823800
		loss: 2.112400
		loss: 2.062400
		loss: 2.114300
		loss: 1.869400
		loss: 2.115500
		loss: 2.541400
		loss: 2.111600
		loss: 1.792400
		loss: 2.116000
		loss: 2.088200
		loss: 2.113900
		loss: 1.994000
		loss: 2.113300
		loss: 1.818800
		loss: 2.112200
		loss: 1.887700
		loss: 2.112500
		loss: 2.098900
		loss: 2.113900
		loss: 2.032200
		loss: 2.114300
		loss: 1.937000
		loss: 2.114900
		loss: 2.056400
		loss: 2.114100
		loss: 2.214800
		loss: 2.114400
		loss: 2.238700
		loss: 2.113100
		loss: 2.220900
		loss: 2.114400
		loss: 1.998300
		loss: 2.114400
		loss: 1.931300
		loss: 2.114900
	Overall the loss development was 1.173200 -> 2.114900
problem epoch data for epoch 9, problem epoch 3
	sampling search time: 133.29959869384766s
	during this search the following actions were chosen:
		open boot was chosen with probability 1.000000
		fetch pump boot was chosen with probability 0.204704
		inflate r1 was chosen with probability 0.204266
		inflate r2 was chosen with probability 0.256608
		fetch r1 boot was chosen with probability 0.252010
		fetch jack boot was chosen with probability 0.339223
		fetch wrench boot was chosen with probability 0.506808
		loosen nuts1 the-hub1 was chosen with probability 0.380274
		fetch r2 boot was chosen with probability 0.419646
		loosen nuts2 the-hub2 was chosen with probability 0.652396
		jack-up the-hub2 was chosen with probability 0.541983
		undo nuts2 the-hub2 was chosen with probability 0.980691
		remove-wheel w2 the-hub2 was chosen with probability 0.983746
		put-on-wheel r2 the-hub2 was chosen with probability 0.576035
		put-away w2 boot was chosen with probability 0.856342
		remove-wheel r2 the-hub2 was chosen with probability 0.661232
		put-on-wheel r2 the-hub2 was chosen with probability 0.979221
	training time: 18.91744041442871s
	during the training the following losses were computed:
		loss: 1.947300
		loss: 2.404600
		loss: 2.428800
		loss: 2.403500
		loss: 2.313100
		loss: 2.403200
		loss: 2.363600
		loss: 2.403300
		loss: 2.298600
		loss: 2.403100
		loss: 2.550600
		loss: 2.402800
		loss: 2.214700
		loss: 2.402700
		loss: 2.656400
		loss: 2.402800
		loss: 2.352200
		loss: 2.402700
		loss: 2.205100
		loss: 2.402600
		loss: 2.417400
		loss: 2.402500
		loss: 2.356400
		loss: 2.402400
		loss: 2.551500
		loss: 2.402500
		loss: 2.756400
		loss: 2.402400
		loss: 2.630200
		loss: 2.402400
		loss: 2.520600
		loss: 2.402300
		loss: 2.516000
		loss: 2.402300
		loss: 2.542600
		loss: 2.402400
		loss: 2.425700
		loss: 2.402200
		loss: 2.248000
		loss: 2.402200
		loss: 2.518700
		loss: 2.402300
		loss: 2.280400
		loss: 2.402300
		loss: 2.585500
		loss: 2.402300
		loss: 2.444200
		loss: 2.402200
		loss: 2.735000
		loss: 2.402300
		loss: 2.598600
		loss: 2.402200
		loss: 2.438200
		loss: 2.402100
		loss: 2.198300
		loss: 2.402200
		loss: 2.420100
		loss: 2.402300
		loss: 2.489800
		loss: 2.402100
		loss: 2.527200
		loss: 2.402000
		loss: 2.316700
		loss: 2.402300
		loss: 2.508200
		loss: 2.402200
		loss: 2.544700
		loss: 2.402300
		loss: 2.206600
		loss: 2.402200
		loss: 2.086400
		loss: 2.402300
		loss: 2.743800
		loss: 2.402400
		loss: 2.526800
		loss: 2.402200
		loss: 2.134300
		loss: 2.402200
		loss: 2.335900
		loss: 2.402200
		loss: 2.338700
		loss: 2.402300
		loss: 2.479100
		loss: 2.402100
		loss: 2.451700
		loss: 2.402200
		loss: 2.314400
		loss: 2.402000
		loss: 2.377500
		loss: 2.402000
		loss: 2.669000
		loss: 2.402000
		loss: 2.421200
		loss: 2.402100
		loss: 2.265700
		loss: 2.402200
		loss: 2.572100
		loss: 2.402200
		loss: 2.395700
		loss: 2.402200
		loss: 2.320200
		loss: 2.402200
		loss: 2.315700
		loss: 2.402100
		loss: 2.554700
		loss: 2.402100
		loss: 2.433700
		loss: 2.402100
		loss: 2.453600
		loss: 2.402000
		loss: 2.358400
		loss: 2.401900
		loss: 2.533100
		loss: 2.401900
		loss: 2.612800
		loss: 2.401900
		loss: 2.318700
		loss: 2.401900
		loss: 2.626500
		loss: 2.402000
		loss: 2.665000
		loss: 2.402000
		loss: 2.475200
		loss: 2.402100
		loss: 2.287100
		loss: 2.402200
		loss: 2.537700
		loss: 2.401900
		loss: 2.415700
		loss: 2.401900
		loss: 2.554400
		loss: 2.401900
		loss: 2.332400
		loss: 2.401800
		loss: 2.366500
		loss: 2.402000
		loss: 2.460300
		loss: 2.402000
		loss: 2.671700
		loss: 2.401700
		loss: 2.332600
		loss: 2.401700
		loss: 2.524600
		loss: 2.401800
		loss: 2.460200
		loss: 2.401800
		loss: 2.475500
		loss: 2.401800
		loss: 2.305400
		loss: 2.401800
		loss: 2.585600
		loss: 2.401800
		loss: 2.672900
		loss: 2.401700
		loss: 2.632200
		loss: 2.401700
		loss: 2.438000
		loss: 2.401700
		loss: 2.123600
		loss: 2.401700
		loss: 2.264300
		loss: 2.401700
		loss: 2.451000
		loss: 2.401600
		loss: 2.247700
		loss: 2.401700
		loss: 2.089900
		loss: 2.401700
		loss: 2.492900
		loss: 2.401700
		loss: 2.420500
		loss: 2.401700
		loss: 2.215200
		loss: 2.401700
		loss: 2.410200
		loss: 2.401700
		loss: 2.412800
		loss: 2.401700
		loss: 2.284600
		loss: 2.401700
		loss: 2.494100
		loss: 2.401600
		loss: 2.277200
		loss: 2.401600
		loss: 2.474900
		loss: 2.401600
		loss: 2.400500
		loss: 2.401600
		loss: 2.173400
		loss: 2.401600
		loss: 2.522500
		loss: 2.401600
		loss: 2.265700
		loss: 2.401600
		loss: 2.404700
		loss: 2.401600
		loss: 2.207900
		loss: 2.401600
		loss: 2.478200
		loss: 2.401600
	Overall the loss development was 1.947300 -> 2.401600
In the epoch 9 for problem d-02.pddl 0 explorations in the sampling searches reached a goal
Success rate: 0

Epoch 10:
Training data for problem d-01.pddl in epoch 10:
model creation time: 7.998186111450195s
problem epoch data for epoch 10, problem epoch 1
	sampling search time: 3.844027042388916s
	during this search the following actions were chosen:
		open boot was chosen with probability 1.000000
		fetch r1 boot was chosen with probability 0.411455
		fetch jack boot was chosen with probability 0.343141
		fetch wrench boot was chosen with probability 0.500488
		loosen nuts1 the-hub1 was chosen with probability 0.525036
		fetch pump boot was chosen with probability 0.616033
		inflate r1 was chosen with probability 0.682719
		jack-up the-hub1 was chosen with probability 0.968089
		undo nuts1 the-hub1 was chosen with probability 0.979166
		remove-wheel w1 the-hub1 was chosen with probability 0.980714
		put-on-wheel r1 the-hub1 was chosen with probability 0.573841
		put-away w1 boot was chosen with probability 0.867020
		remove-wheel r1 the-hub1 was chosen with probability 0.688955
		put-on-wheel r1 the-hub1 was chosen with probability 0.987109
	training time: 37.61352038383484s
	during the training the following losses were computed:
		loss: 1.364400
		loss: 1.401700
		loss: 1.363300
		loss: 1.370900
		loss: 1.372200
		loss: 1.367700
		loss: 1.363100
		loss: 1.358900
		loss: 1.360400
		loss: 1.363300
		loss: 1.359900
		loss: 1.354600
		loss: 1.354400
		loss: 1.357200
		loss: 1.357500
		loss: 1.355500
		loss: 1.353900
		loss: 1.353300
		loss: 1.353400
		loss: 1.354200
		loss: 1.354500
		loss: 1.353200
		loss: 1.351600
		loss: 1.351400
		loss: 1.352300
		loss: 1.352600
		loss: 1.352100
		loss: 1.351500
		loss: 1.351100
		loss: 1.350900
		loss: 1.351200
		loss: 1.351400
		loss: 1.351000
		loss: 1.350400
		loss: 1.350400
		loss: 1.350600
		loss: 1.350600
		loss: 1.350500
		loss: 1.350300
		loss: 1.350100
		loss: 1.350100
		loss: 1.350200
		loss: 1.350200
		loss: 1.350000
		loss: 1.350000
		loss: 1.350000
		loss: 1.350000
		loss: 1.350000
		loss: 1.349900
		loss: 1.349800
		loss: 1.349800
		loss: 1.349800
		loss: 1.349800
		loss: 1.349700
		loss: 1.349700
		loss: 1.349700
		loss: 1.349700
		loss: 1.349700
		loss: 1.349700
		loss: 1.349600
		loss: 1.349600
		loss: 1.349600
		loss: 1.349600
		loss: 1.349600
		loss: 1.349600
		loss: 1.349600
		loss: 1.349600
		loss: 1.349500
		loss: 1.349500
		loss: 1.349500
		loss: 1.349500
		loss: 1.349500
		loss: 1.349500
		loss: 1.349400
		loss: 1.349400
		loss: 1.349400
		loss: 1.349400
		loss: 1.349400
		loss: 1.349400
		loss: 1.349400
		loss: 1.349400
		loss: 1.349300
		loss: 1.349300
		loss: 1.349300
		loss: 1.349300
		loss: 1.349300
		loss: 1.349300
		loss: 1.349300
		loss: 1.349300
		loss: 1.349300
		loss: 1.349200
		loss: 1.349200
		loss: 1.349200
		loss: 1.349200
		loss: 1.349200
		loss: 1.349200
		loss: 1.349200
		loss: 1.349200
		loss: 1.349200
		loss: 1.349100
	Overall the loss development was 1.364400 -> 1.349100
problem epoch data for epoch 10, problem epoch 2
	sampling search time: 3.6290838718414307s
	during this search the following actions were chosen:
		open boot was chosen with probability 1.000000
		fetch r1 boot was chosen with probability 0.257995
		fetch wrench boot was chosen with probability 0.334171
		loosen nuts1 the-hub1 was chosen with probability 0.348444
		fetch jack boot was chosen with probability 0.622177
		fetch pump boot was chosen with probability 0.581193
		inflate r1 was chosen with probability 0.638217
		jack-up the-hub1 was chosen with probability 0.977072
		undo nuts1 the-hub1 was chosen with probability 0.983108
		remove-wheel w1 the-hub1 was chosen with probability 0.984620
		put-on-wheel r1 the-hub1 was chosen with probability 0.597004
		put-away w1 boot was chosen with probability 0.844850
		remove-wheel r1 the-hub1 was chosen with probability 0.661215
		put-on-wheel r1 the-hub1 was chosen with probability 0.989771
	training time: 10.135701656341553s
	during the training the following losses were computed:
		loss: 1.353100
		loss: 1.353000
		loss: 1.352800
		loss: 1.352700
		loss: 1.352700
		loss: 1.352600
		loss: 1.352500
		loss: 1.352300
		loss: 1.352200
		loss: 1.352100
		loss: 1.352000
		loss: 1.351900
		loss: 1.351800
		loss: 1.351800
		loss: 1.351700
		loss: 1.351600
		loss: 1.351600
		loss: 1.351600
		loss: 1.351500
		loss: 1.351500
		loss: 1.351500
		loss: 1.351500
		loss: 1.351400
		loss: 1.351400
		loss: 1.351400
		loss: 1.351400
		loss: 1.351400
		loss: 1.351400
		loss: 1.351400
		loss: 1.351400
		loss: 1.351300
		loss: 1.351300
		loss: 1.351300
		loss: 1.351300
		loss: 1.351300
		loss: 1.351300
		loss: 1.351300
		loss: 1.351300
		loss: 1.351300
		loss: 1.351200
		loss: 1.351200
		loss: 1.351200
		loss: 1.351200
		loss: 1.351200
		loss: 1.351200
		loss: 1.351200
		loss: 1.351200
		loss: 1.351200
		loss: 1.351200
		loss: 1.351100
		loss: 1.351100
		loss: 1.351100
		loss: 1.351100
		loss: 1.351100
		loss: 1.351100
		loss: 1.351100
		loss: 1.351100
		loss: 1.351100
		loss: 1.351100
		loss: 1.351100
		loss: 1.351000
		loss: 1.351000
		loss: 1.351000
		loss: 1.351000
		loss: 1.351000
		loss: 1.351000
		loss: 1.351000
		loss: 1.351000
		loss: 1.351000
		loss: 1.351000
		loss: 1.351000
		loss: 1.351000
		loss: 1.350900
		loss: 1.350900
		loss: 1.350900
		loss: 1.350900
		loss: 1.350900
		loss: 1.350900
		loss: 1.350900
		loss: 1.350900
		loss: 1.350900
		loss: 1.350900
		loss: 1.350900
		loss: 1.350900
		loss: 1.350900
		loss: 1.350800
		loss: 1.350800
		loss: 1.350800
		loss: 1.350800
		loss: 1.350800
		loss: 1.350800
		loss: 1.350800
		loss: 1.350800
		loss: 1.350800
		loss: 1.350800
		loss: 1.350800
		loss: 1.350800
		loss: 1.350800
		loss: 1.350700
		loss: 1.350700
	Overall the loss development was 1.353100 -> 1.350700
problem epoch data for epoch 10, problem epoch 3
	sampling search time: 3.383898973464966s
	during this search the following actions were chosen:
		open boot was chosen with probability 1.000000
		fetch pump boot was chosen with probability 0.256893
		inflate r1 was chosen with probability 0.304282
		fetch r1 boot was chosen with probability 0.342013
		fetch wrench boot was chosen with probability 0.499601
		loosen nuts1 the-hub1 was chosen with probability 0.513573
		fetch jack boot was chosen with probability 0.982143
		jack-up the-hub1 was chosen with probability 0.972474
		undo nuts1 the-hub1 was chosen with probability 0.980418
		remove-wheel w1 the-hub1 was chosen with probability 0.982290
		put-on-wheel r1 the-hub1 was chosen with probability 0.599727
		put-away w1 boot was chosen with probability 0.847054
		remove-wheel r1 the-hub1 was chosen with probability 0.633651
		put-on-wheel r1 the-hub1 was chosen with probability 0.988291
	training time: 10.139179944992065s
	during the training the following losses were computed:
		loss: 1.623600
		loss: 1.623500
		loss: 1.623500
		loss: 1.623500
		loss: 1.623500
		loss: 1.623500
		loss: 1.623500
		loss: 1.623500
		loss: 1.623500
		loss: 1.623500
		loss: 1.623500
		loss: 1.623400
		loss: 1.623400
		loss: 1.623400
		loss: 1.623400
		loss: 1.623400
		loss: 1.623400
		loss: 1.623400
		loss: 1.623400
		loss: 1.623400
		loss: 1.623400
		loss: 1.623400
		loss: 1.623400
		loss: 1.623300
		loss: 1.623300
		loss: 1.623300
		loss: 1.623300
		loss: 1.623300
		loss: 1.623300
		loss: 1.623300
		loss: 1.623300
		loss: 1.623300
		loss: 1.623300
		loss: 1.623300
		loss: 1.623300
		loss: 1.623300
		loss: 1.623300
		loss: 1.623300
		loss: 1.623200
		loss: 1.623200
		loss: 1.623200
		loss: 1.623200
		loss: 1.623200
		loss: 1.623200
		loss: 1.623200
		loss: 1.623200
		loss: 1.623200
		loss: 1.623200
		loss: 1.623200
		loss: 1.623200
		loss: 1.623200
		loss: 1.623200
		loss: 1.623200
		loss: 1.623200
		loss: 1.623100
		loss: 1.623100
		loss: 1.623100
		loss: 1.623100
		loss: 1.623100
		loss: 1.623100
		loss: 1.623100
		loss: 1.623100
		loss: 1.623100
		loss: 1.623100
		loss: 1.623100
		loss: 1.623100
		loss: 1.623100
		loss: 1.623100
		loss: 1.623100
		loss: 1.623100
		loss: 1.623100
		loss: 1.623100
		loss: 1.623000
		loss: 1.623000
		loss: 1.623000
		loss: 1.623000
		loss: 1.623000
		loss: 1.623000
		loss: 1.623000
		loss: 1.623000
		loss: 1.623000
		loss: 1.623000
		loss: 1.623000
		loss: 1.623000
		loss: 1.623000
		loss: 1.623000
		loss: 1.623000
		loss: 1.623000
		loss: 1.623000
		loss: 1.623000
		loss: 1.623000
		loss: 1.622900
		loss: 1.622900
		loss: 1.622900
		loss: 1.622900
		loss: 1.622900
		loss: 1.622900
		loss: 1.622900
		loss: 1.622900
		loss: 1.622900
	Overall the loss development was 1.623600 -> 1.622900
In the epoch 10 for problem d-01.pddl 0 explorations in the sampling searches reached a goal
Training data for problem d-02.pddl in epoch 10:
model creation time: 15.613351821899414s
problem epoch data for epoch 10, problem epoch 1
	sampling search time: 33.210750341415405s
	during this search the following actions were chosen:
		close boot was chosen with probability 0.000000
	training time: 62.21799898147583s
	during the training the following losses were computed:
		loss: 2.522500
		loss: 2.510200
		loss: 2.508600
		loss: 2.504800
		loss: 2.495900
		loss: 2.491200
		loss: 2.490300
		loss: 2.490200
		loss: 2.489200
		loss: 2.488400
		loss: 2.486300
		loss: 2.483900
		loss: 2.483800
		loss: 2.484300
		loss: 2.483600
		loss: 2.482300
		loss: 2.481300
		loss: 2.480400
		loss: 2.479700
		loss: 2.479300
		loss: 2.479200
		loss: 2.478700
		loss: 2.477800
		loss: 2.477300
		loss: 2.477200
		loss: 2.477000
		loss: 2.476800
		loss: 2.476500
		loss: 2.476100
		loss: 2.475600
		loss: 2.475300
		loss: 2.475300
		loss: 2.475100
		loss: 2.474900
		loss: 2.474700
		loss: 2.474500
		loss: 2.474500
		loss: 2.474400
		loss: 2.474400
		loss: 2.474200
		loss: 2.474000
		loss: 2.473900
		loss: 2.473900
		loss: 2.473800
		loss: 2.473700
		loss: 2.473500
		loss: 2.473400
		loss: 2.473400
		loss: 2.473300
		loss: 2.473200
		loss: 2.473200
		loss: 2.473100
		loss: 2.473000
		loss: 2.473000
		loss: 2.472900
		loss: 2.472900
		loss: 2.472800
		loss: 2.472800
		loss: 2.472700
		loss: 2.472700
		loss: 2.472700
		loss: 2.472600
		loss: 2.472600
		loss: 2.472600
		loss: 2.472500
		loss: 2.472500
		loss: 2.472400
		loss: 2.472400
		loss: 2.472400
		loss: 2.472400
		loss: 2.472300
		loss: 2.472300
		loss: 2.472300
		loss: 2.472300
		loss: 2.472200
		loss: 2.472200
		loss: 2.472200
		loss: 2.472200
		loss: 2.472100
		loss: 2.472100
		loss: 2.472100
		loss: 2.472100
		loss: 2.472100
		loss: 2.472000
		loss: 2.472000
		loss: 2.472000
		loss: 2.472000
		loss: 2.472000
		loss: 2.471900
		loss: 2.471900
		loss: 2.471900
		loss: 2.471900
		loss: 2.471900
		loss: 2.471900
		loss: 2.471800
		loss: 2.471800
		loss: 2.471800
		loss: 2.471800
		loss: 2.471800
		loss: 2.471800
	Overall the loss development was 2.522500 -> 2.471800
problem epoch data for epoch 10, problem epoch 2
	sampling search time: 168.12825179100037s
	during this search the following actions were chosen:
		open boot was chosen with probability 1.000000
		fetch pump boot was chosen with probability 0.202031
		fetch r1 boot was chosen with probability 0.216548
		fetch jack boot was chosen with probability 0.279992
		fetch r2 boot was chosen with probability 0.379583
		fetch wrench boot was chosen with probability 0.601162
		loosen nuts1 the-hub1 was chosen with probability 0.408512
		loosen nuts2 the-hub2 was chosen with probability 0.451584
		jack-up the-hub2 was chosen with probability 0.362040
		undo nuts2 the-hub2 was chosen with probability 0.608133
		remove-wheel w2 the-hub2 was chosen with probability 0.635548
		put-on-wheel r2 the-hub2 was chosen with probability 0.499626
		put-away w2 boot was chosen with probability 0.626733
		inflate r1 was chosen with probability 0.418750
		inflate r2 was chosen with probability 0.720384
		remove-wheel r2 the-hub2 was chosen with probability 0.588809
		put-on-wheel r2 the-hub2 was chosen with probability 0.974743
	training time: 17.805269241333008s
	during the training the following losses were computed:
		loss: 3.424000
		loss: 2.284700
		loss: 2.602900
		loss: 2.204100
		loss: 2.152200
		loss: 2.153900
		loss: 1.931700
		loss: 2.149100
		loss: 2.052700
		loss: 2.144800
		loss: 2.301900
		loss: 2.140100
		loss: 2.284500
		loss: 2.134900
		loss: 2.007100
		loss: 2.132400
		loss: 2.352700
		loss: 2.128100
		loss: 2.317200
		loss: 2.127400
		loss: 2.162000
		loss: 2.124400
		loss: 2.312100
		loss: 2.120200
		loss: 2.269700
		loss: 2.118600
		loss: 1.793300
		loss: 2.122300
		loss: 2.075100
		loss: 2.119600
		loss: 2.172900
		loss: 2.118100
		loss: 1.838000
		loss: 2.115800
		loss: 2.170900
		loss: 2.116700
		loss: 2.359600
		loss: 2.118200
		loss: 1.815000
		loss: 2.118300
		loss: 2.418500
		loss: 2.114300
		loss: 2.238800
		loss: 2.116800
		loss: 2.382900
		loss: 2.114300
		loss: 1.948300
		loss: 2.114500
		loss: 1.953000
		loss: 2.114500
		loss: 2.246600
		loss: 2.116000
		loss: 2.107700
		loss: 2.115100
		loss: 2.119600
		loss: 2.115000
		loss: 2.328300
		loss: 2.113700
		loss: 1.866400
		loss: 2.116200
		loss: 2.296900
		loss: 2.115700
		loss: 2.239700
		loss: 2.115300
		loss: 1.813600
		loss: 2.116300
		loss: 2.290700
		loss: 2.113500
		loss: 2.138900
		loss: 2.114600
		loss: 2.007100
		loss: 2.113700
		loss: 2.369500
		loss: 2.112800
		loss: 2.376400
		loss: 2.112700
		loss: 2.382500
		loss: 2.112600
		loss: 2.115600
		loss: 2.114200
		loss: 2.442600
		loss: 2.112200
		loss: 1.951400
		loss: 2.115100
		loss: 2.095200
		loss: 2.114200
		loss: 2.076700
		loss: 2.114300
		loss: 2.385600
		loss: 2.112400
		loss: 1.850200
		loss: 2.112500
		loss: 1.791800
		loss: 2.112100
		loss: 2.045900
		loss: 2.113500
		loss: 2.303500
		loss: 2.112800
		loss: 1.798000
		loss: 2.115700
		loss: 1.993300
		loss: 2.113200
		loss: 2.201600
		loss: 2.113400
		loss: 1.968900
		loss: 2.113000
		loss: 2.298800
		loss: 2.112700
		loss: 2.362400
		loss: 2.115200
		loss: 2.187700
		loss: 2.113300
		loss: 2.036600
		loss: 2.113300
		loss: 2.117900
		loss: 2.113900
		loss: 2.046100
		loss: 2.114500
		loss: 1.926600
		loss: 2.115100
		loss: 1.921500
		loss: 2.112700
		loss: 1.958200
		loss: 2.114700
		loss: 1.948600
		loss: 2.112800
		loss: 2.141900
		loss: 2.113600
		loss: 2.037900
		loss: 2.113200
		loss: 2.112600
		loss: 2.113500
		loss: 2.302800
		loss: 2.114700
		loss: 2.113600
		loss: 2.113600
		loss: 2.194900
		loss: 2.114000
		loss: 1.915600
		loss: 2.112400
		loss: 1.968200
		loss: 2.114400
		loss: 2.232200
		loss: 2.114200
		loss: 2.351400
		loss: 2.112100
		loss: 1.988700
		loss: 2.112800
		loss: 2.211200
		loss: 2.114100
		loss: 2.032300
		loss: 2.113000
		loss: 2.139200
		loss: 2.113600
		loss: 1.995000
		loss: 2.112800
		loss: 2.438700
		loss: 2.111600
		loss: 2.087200
		loss: 2.113600
		loss: 2.103700
		loss: 2.113400
		loss: 1.584800
		loss: 2.116500
		loss: 2.065900
		loss: 2.113200
		loss: 2.512500
		loss: 2.115700
		loss: 2.264500
		loss: 2.114300
		loss: 2.195100
		loss: 2.112900
		loss: 2.027600
		loss: 2.112800
		loss: 2.044500
		loss: 2.113800
		loss: 2.148700
		loss: 2.113200
		loss: 1.851300
		loss: 2.111900
		loss: 2.263200
		loss: 2.114200
		loss: 2.528200
		loss: 2.110900
		loss: 2.322600
		loss: 2.112000
		loss: 2.092700
		loss: 2.113200
		loss: 1.870400
		loss: 2.111900
		loss: 2.232000
		loss: 2.112600
		loss: 2.106700
		loss: 2.113300
		loss: 1.925700
		loss: 2.112200
		loss: 1.941900
		loss: 2.112200
		loss: 2.298800
		loss: 2.114300
	Overall the loss development was 3.424000 -> 2.114300
problem epoch data for epoch 10, problem epoch 3
	sampling search time: 33.32990574836731s
	during this search the following actions were chosen:
		close boot was chosen with probability 0.000000
	training time: 17.907683849334717s
	during the training the following losses were computed:
		loss: 3.180700
		loss: 2.119400
		loss: 2.438600
		loss: 2.115200
		loss: 2.271700
		loss: 2.114200
		loss: 1.712000
		loss: 2.111100
		loss: 2.141100
		loss: 2.113400
		loss: 2.277000
		loss: 2.112400
		loss: 2.173200
		loss: 2.113700
		loss: 2.468200
		loss: 2.115400
		loss: 1.909100
		loss: 2.114500
		loss: 1.828200
		loss: 2.111700
		loss: 1.876900
		loss: 2.112000
		loss: 2.103500
		loss: 2.113400
		loss: 1.712500
		loss: 2.111200
		loss: 2.048600
		loss: 2.113000
		loss: 2.073400
		loss: 2.113600
		loss: 1.775600
		loss: 2.111500
		loss: 1.848100
		loss: 2.111900
		loss: 2.203200
		loss: 2.114000
		loss: 2.527400
		loss: 2.115900
		loss: 2.361400
		loss: 2.114800
		loss: 1.761700
		loss: 2.115500
		loss: 1.990300
		loss: 2.114000
		loss: 1.846100
		loss: 2.111800
		loss: 2.474400
		loss: 2.115400
		loss: 1.828700
		loss: 2.111700
		loss: 1.779800
		loss: 2.115500
		loss: 1.737300
		loss: 2.115600
		loss: 1.892200
		loss: 2.112100
		loss: 2.194000
		loss: 2.112800
		loss: 2.212900
		loss: 2.112600
		loss: 1.936400
		loss: 2.114200
		loss: 2.002300
		loss: 2.113800
		loss: 1.943300
		loss: 2.112300
		loss: 1.940700
		loss: 2.112300
		loss: 2.497300
		loss: 2.115500
		loss: 2.451400
		loss: 2.111100
		loss: 1.891000
		loss: 2.111900
		loss: 2.687800
		loss: 2.116600
		loss: 1.951700
		loss: 2.114400
		loss: 1.965300
		loss: 2.112700
		loss: 2.235000
		loss: 2.112600
		loss: 2.145100
		loss: 2.113400
		loss: 1.926800
		loss: 2.111900
		loss: 2.407200
		loss: 2.111300
		loss: 1.795900
		loss: 2.115000
		loss: 1.797400
		loss: 2.115100
		loss: 2.134100
		loss: 2.113400
		loss: 2.215900
		loss: 2.112500
		loss: 2.353600
		loss: 2.114500
		loss: 2.182400
		loss: 2.113500
		loss: 2.370100
		loss: 2.114600
		loss: 2.187800
		loss: 2.112900
		loss: 2.162400
		loss: 2.113000
		loss: 2.529000
		loss: 2.111200
		loss: 2.021800
		loss: 2.112900
		loss: 1.942100
		loss: 2.112800
		loss: 2.139100
		loss: 2.113600
		loss: 2.389300
		loss: 2.111700
		loss: 1.863100
		loss: 2.114600
		loss: 2.219600
		loss: 2.112500
		loss: 2.183500
		loss: 2.113600
		loss: 2.331700
		loss: 2.114500
		loss: 2.256000
		loss: 2.114100
		loss: 1.387300
		loss: 2.117600
		loss: 2.288600
		loss: 2.112200
		loss: 2.253900
		loss: 2.112300
		loss: 2.474400
		loss: 2.110800
		loss: 2.113800
		loss: 2.113100
		loss: 1.903000
		loss: 2.112000
		loss: 2.351100
		loss: 2.112100
		loss: 2.259000
		loss: 2.114500
		loss: 2.142100
		loss: 2.113500
		loss: 1.940500
		loss: 2.112200
		loss: 1.911100
		loss: 2.114400
		loss: 2.078900
		loss: 2.113500
		loss: 1.828200
		loss: 2.111500
		loss: 1.566300
		loss: 2.110300
		loss: 2.114700
		loss: 2.113400
		loss: 2.093100
		loss: 2.113200
		loss: 2.173200
		loss: 2.113400
		loss: 2.408300
		loss: 2.114800
		loss: 2.286300
		loss: 2.114100
		loss: 1.940100
		loss: 2.112000
		loss: 2.054400
		loss: 2.113600
		loss: 1.841500
		loss: 2.111700
		loss: 1.750100
		loss: 2.115100
		loss: 2.208000
		loss: 2.112400
		loss: 1.909200
		loss: 2.114200
		loss: 1.828600
		loss: 2.111400
		loss: 2.255900
		loss: 2.112200
		loss: 1.816900
		loss: 2.111500
		loss: 2.145200
		loss: 2.113400
		loss: 2.238500
		loss: 2.112400
		loss: 2.269800
		loss: 2.114200
		loss: 2.367100
		loss: 2.111600
		loss: 2.339900
		loss: 2.111900
		loss: 1.992400
		loss: 2.112500
		loss: 2.033000
		loss: 2.113500
		loss: 1.805000
		loss: 2.114600
		loss: 2.108200
		loss: 2.113000
	Overall the loss development was 3.180700 -> 2.113000
In the epoch 10 for problem d-02.pddl 0 explorations in the sampling searches reached a goal
Success rate: 0

