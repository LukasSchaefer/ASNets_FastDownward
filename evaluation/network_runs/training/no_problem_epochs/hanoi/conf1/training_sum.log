Training log data for domain hanoi:
printing the data chronological
Epoch 1:
Training data for problem d-01.pddl in epoch 1:
model creation time: 1.9339230060577393s
problem epoch data for epoch 1, problem epoch 1
	sampling search time: 1.328848123550415s
	during this search the following actions were chosen:
		move d1 peg3 peg2 was chosen with probability 0.500670
		move d1 peg2 peg3 was chosen with probability 0.500670
	training time: 36.70121765136719s
	during the training the following losses were computed:
		loss: 0.546100
		loss: 0.544800
		loss: 0.543700
		loss: 0.542700
		loss: 0.541800
		loss: 0.540800
		loss: 0.539800
		loss: 0.538900
		loss: 0.537900
		loss: 0.537000
		loss: 0.536200
		loss: 0.535200
		loss: 0.534300
		loss: 0.533300
		loss: 0.532400
		loss: 0.531400
		loss: 0.530500
		loss: 0.529500
		loss: 0.528400
		loss: 0.527600
		loss: 0.526700
		loss: 0.525600
		loss: 0.524500
		loss: 0.523200
		loss: 0.522200
		loss: 0.521200
		loss: 0.520200
		loss: 0.519000
		loss: 0.518100
		loss: 0.517000
		loss: 0.515800
		loss: 0.514600
		loss: 0.513400
		loss: 0.512100
		loss: 0.510700
		loss: 0.509200
		loss: 0.507700
		loss: 0.506100
		loss: 0.504700
		loss: 0.503200
		loss: 0.501400
		loss: 0.499600
		loss: 0.498000
		loss: 0.496300
		loss: 0.495000
		loss: 0.493100
		loss: 0.491300
		loss: 0.489100
		loss: 0.487000
		loss: 0.485000
		loss: 0.483400
		loss: 0.481100
		loss: 0.478900
		loss: 0.476600
		loss: 0.474500
		loss: 0.472000
		loss: 0.469500
		loss: 0.467000
		loss: 0.464600
		loss: 0.462100
		loss: 0.459200
		loss: 0.456100
		loss: 0.453200
		loss: 0.450100
		loss: 0.446900
		loss: 0.443600
		loss: 0.440600
		loss: 0.437200
		loss: 0.433700
		loss: 0.430400
		loss: 0.426800
		loss: 0.422900
		loss: 0.419000
		loss: 0.414800
		loss: 0.410800
		loss: 0.406600
		loss: 0.402100
		loss: 0.398500
		loss: 0.393000
		loss: 0.388200
		loss: 0.383300
		loss: 0.378700
		loss: 0.373300
		loss: 0.367300
		loss: 0.361400
		loss: 0.355700
		loss: 0.350100
		loss: 0.343900
		loss: 0.337500
		loss: 0.331300
		loss: 0.325400
		loss: 0.318000
		loss: 0.311800
		loss: 0.304800
		loss: 0.297200
		loss: 0.290300
		loss: 0.283300
		loss: 0.276100
		loss: 0.268800
		loss: 0.261800
		loss: 0.254800
		loss: 0.247700
		loss: 0.240300
		loss: 0.232800
		loss: 0.225100
		loss: 0.217800
		loss: 0.210700
		loss: 0.203200
		loss: 0.196000
		loss: 0.189000
		loss: 0.181900
		loss: 0.175700
		loss: 0.169300
		loss: 0.163200
		loss: 0.157100
		loss: 0.151300
		loss: 0.145600
		loss: 0.140500
		loss: 0.135500
		loss: 0.130800
		loss: 0.126100
		loss: 0.121700
		loss: 0.117200
		loss: 0.113100
		loss: 0.109400
		loss: 0.105700
		loss: 0.102000
		loss: 0.099000
		loss: 0.096000
		loss: 0.092900
		loss: 0.090100
		loss: 0.087600
		loss: 0.085200
		loss: 0.082900
		loss: 0.080800
		loss: 0.078900
		loss: 0.077100
		loss: 0.075300
		loss: 0.073700
		loss: 0.072200
		loss: 0.070900
		loss: 0.069500
		loss: 0.068300
		loss: 0.067200
		loss: 0.066100
		loss: 0.065100
		loss: 0.064200
		loss: 0.063400
		loss: 0.062600
		loss: 0.061800
		loss: 0.061100
		loss: 0.060500
		loss: 0.059800
		loss: 0.059200
		loss: 0.058700
		loss: 0.058100
		loss: 0.057600
		loss: 0.057100
		loss: 0.056700
		loss: 0.056200
		loss: 0.055800
		loss: 0.055500
		loss: 0.055100
		loss: 0.054700
		loss: 0.054400
		loss: 0.054000
		loss: 0.053700
		loss: 0.053400
		loss: 0.053100
		loss: 0.052800
		loss: 0.052600
		loss: 0.052300
		loss: 0.052000
		loss: 0.051800
		loss: 0.051600
		loss: 0.051300
		loss: 0.051100
		loss: 0.050900
		loss: 0.050700
		loss: 0.050500
		loss: 0.050300
		loss: 0.050100
		loss: 0.049900
		loss: 0.049700
		loss: 0.049500
		loss: 0.049300
		loss: 0.049200
		loss: 0.049000
		loss: 0.048800
		loss: 0.048700
		loss: 0.048500
		loss: 0.048300
		loss: 0.048200
		loss: 0.048000
		loss: 0.047900
		loss: 0.047700
		loss: 0.047600
		loss: 0.047400
		loss: 0.047300
		loss: 0.047200
		loss: 0.047000
		loss: 0.046900
		loss: 0.046800
		loss: 0.046600
		loss: 0.046500
		loss: 0.046400
		loss: 0.046300
		loss: 0.046100
		loss: 0.046000
		loss: 0.045900
		loss: 0.045800
		loss: 0.045600
		loss: 0.045500
		loss: 0.045400
		loss: 0.045300
		loss: 0.045200
		loss: 0.045100
		loss: 0.045000
		loss: 0.044900
		loss: 0.044700
		loss: 0.044600
		loss: 0.044500
		loss: 0.044400
		loss: 0.044300
		loss: 0.044200
		loss: 0.044100
		loss: 0.044000
		loss: 0.043900
		loss: 0.043800
		loss: 0.043700
		loss: 0.043600
		loss: 0.043500
		loss: 0.043500
		loss: 0.043400
		loss: 0.043300
		loss: 0.043200
		loss: 0.043100
		loss: 0.043000
		loss: 0.042900
		loss: 0.042800
		loss: 0.042700
		loss: 0.042700
		loss: 0.042600
		loss: 0.042500
		loss: 0.042400
		loss: 0.042300
		loss: 0.042200
		loss: 0.042100
		loss: 0.042100
		loss: 0.042000
		loss: 0.041900
		loss: 0.041800
		loss: 0.041700
		loss: 0.041700
		loss: 0.041600
		loss: 0.041500
		loss: 0.041400
		loss: 0.041400
		loss: 0.041300
		loss: 0.041200
		loss: 0.041100
		loss: 0.041100
		loss: 0.041000
		loss: 0.040900
		loss: 0.040800
		loss: 0.040800
		loss: 0.040700
		loss: 0.040600
		loss: 0.040600
		loss: 0.040500
		loss: 0.040400
		loss: 0.040300
		loss: 0.040300
		loss: 0.040200
		loss: 0.040100
		loss: 0.040100
		loss: 0.040000
		loss: 0.039900
		loss: 0.039900
		loss: 0.039800
		loss: 0.039700
		loss: 0.039700
		loss: 0.039600
		loss: 0.039600
		loss: 0.039500
		loss: 0.039400
		loss: 0.039400
		loss: 0.039300
		loss: 0.039200
		loss: 0.039200
		loss: 0.039100
		loss: 0.039100
		loss: 0.039000
		loss: 0.038900
		loss: 0.038900
		loss: 0.038800
		loss: 0.038800
		loss: 0.038700
		loss: 0.038600
		loss: 0.038600
	Overall the loss development was 0.546100 -> 0.038600

Training data for problem d-02.pddl in epoch 1:
model creation time: 5.360654354095459s
problem epoch data for epoch 1, problem epoch 1
	sampling search time: 1.3251957893371582s
	during this search the following actions were chosen:
		move d1 d2 peg1 was chosen with probability 0.889202
		move d1 peg1 d2 was chosen with probability 0.793035
	training time: 45.03314137458801s
	during the training the following losses were computed:
		loss: 1.333000
		loss: 1.292000
		loss: 1.253900
		loss: 1.215900
		loss: 1.176500
		loss: 1.136300
		loss: 1.094400
		loss: 1.053100
		loss: 1.010900
		loss: 0.970700
		loss: 0.938400
		loss: 0.915800
		loss: 0.902600
		loss: 0.893800
		loss: 0.888800
		loss: 0.883400
		loss: 0.877400
		loss: 0.871700
		loss: 0.866300
		loss: 0.860800
		loss: 0.855300
		loss: 0.849800
		loss: 0.844000
		loss: 0.837600
		loss: 0.831500
		loss: 0.826300
		loss: 0.822000
		loss: 0.818700
		loss: 0.815800
		loss: 0.812800
		loss: 0.809700
		loss: 0.806600
		loss: 0.803700
		loss: 0.800700
		loss: 0.797500
		loss: 0.794700
		loss: 0.791800
		loss: 0.788900
		loss: 0.786000
		loss: 0.783100
		loss: 0.780100
		loss: 0.777100
		loss: 0.773700
		loss: 0.770500
		loss: 0.767600
		loss: 0.764900
		loss: 0.762700
		loss: 0.760900
		loss: 0.758500
		loss: 0.755400
		loss: 0.752100
		loss: 0.748700
		loss: 0.745400
		loss: 0.742300
		loss: 0.739400
		loss: 0.736600
		loss: 0.734200
		loss: 0.731200
		loss: 0.727000
		loss: 0.722200
		loss: 0.717200
		loss: 0.712100
		loss: 0.706800
		loss: 0.701600
		loss: 0.696900
		loss: 0.693600
		loss: 0.689900
		loss: 0.687100
		loss: 0.684400
		loss: 0.681500
		loss: 0.678200
		loss: 0.674400
		loss: 0.670200
		loss: 0.665800
		loss: 0.662300
		loss: 0.659100
		loss: 0.655700
		loss: 0.652100
		loss: 0.648500
		loss: 0.644400
		loss: 0.640500
		loss: 0.636100
		loss: 0.631400
		loss: 0.626900
		loss: 0.622300
		loss: 0.618300
		loss: 0.614400
		loss: 0.609800
		loss: 0.604700
		loss: 0.599500
		loss: 0.594600
		loss: 0.590200
		loss: 0.585000
		loss: 0.579200
		loss: 0.573800
		loss: 0.568100
		loss: 0.562800
		loss: 0.557000
		loss: 0.551000
		loss: 0.545000
		loss: 0.538500
		loss: 0.531900
		loss: 0.525600
		loss: 0.519500
		loss: 0.512900
		loss: 0.505700
		loss: 0.499700
		loss: 0.492500
		loss: 0.485100
		loss: 0.478200
		loss: 0.471100
		loss: 0.463800
		loss: 0.455900
		loss: 0.448200
		loss: 0.440600
		loss: 0.433200
		loss: 0.424700
		loss: 0.416900
		loss: 0.409100
		loss: 0.400900
		loss: 0.392600
		loss: 0.384700
		loss: 0.377000
		loss: 0.369000
		loss: 0.360600
		loss: 0.352500
		loss: 0.344300
		loss: 0.336100
		loss: 0.327900
		loss: 0.320100
		loss: 0.311900
		loss: 0.304200
		loss: 0.296300
		loss: 0.288700
		loss: 0.281000
		loss: 0.273300
		loss: 0.266000
		loss: 0.258700
		loss: 0.250900
		loss: 0.244500
		loss: 0.237400
		loss: 0.230900
		loss: 0.224100
		loss: 0.217500
		loss: 0.211100
		loss: 0.205100
		loss: 0.199100
		loss: 0.193300
		loss: 0.187600
		loss: 0.182300
		loss: 0.177400
		loss: 0.172400
		loss: 0.168200
		loss: 0.163400
		loss: 0.159100
		loss: 0.155500
		loss: 0.151100
		loss: 0.147600
		loss: 0.143800
		loss: 0.140100
		loss: 0.136800
		loss: 0.133600
		loss: 0.130600
		loss: 0.127700
		loss: 0.124800
		loss: 0.122000
		loss: 0.119600
		loss: 0.117200
		loss: 0.114800
		loss: 0.112600
		loss: 0.110600
		loss: 0.108500
		loss: 0.106700
		loss: 0.104900
		loss: 0.102900
		loss: 0.101400
		loss: 0.099900
		loss: 0.098400
		loss: 0.096800
		loss: 0.095500
		loss: 0.094100
		loss: 0.093000
		loss: 0.091800
		loss: 0.090600
		loss: 0.089500
		loss: 0.088500
		loss: 0.087500
		loss: 0.086500
		loss: 0.085500
		loss: 0.084700
		loss: 0.083900
		loss: 0.083100
		loss: 0.082300
		loss: 0.081600
		loss: 0.080900
		loss: 0.080200
		loss: 0.079500
		loss: 0.078900
		loss: 0.078400
		loss: 0.077800
		loss: 0.077300
		loss: 0.076700
		loss: 0.076300
		loss: 0.075800
		loss: 0.075400
		loss: 0.074900
		loss: 0.074500
		loss: 0.074100
		loss: 0.073700
		loss: 0.073300
		loss: 0.073000
		loss: 0.072600
		loss: 0.072300
		loss: 0.072000
		loss: 0.071700
		loss: 0.071300
		loss: 0.071000
		loss: 0.070800
		loss: 0.070500
		loss: 0.070200
		loss: 0.070000
		loss: 0.069700
		loss: 0.069500
		loss: 0.069200
		loss: 0.069000
		loss: 0.068800
		loss: 0.068600
		loss: 0.068400
		loss: 0.068200
		loss: 0.068000
		loss: 0.067800
		loss: 0.067600
		loss: 0.067400
		loss: 0.067300
		loss: 0.067100
		loss: 0.066900
		loss: 0.066800
		loss: 0.066600
		loss: 0.066500
		loss: 0.066300
		loss: 0.066200
		loss: 0.066000
		loss: 0.065900
		loss: 0.065800
		loss: 0.065700
		loss: 0.065500
		loss: 0.065400
		loss: 0.065300
		loss: 0.065200
		loss: 0.065100
		loss: 0.065000
		loss: 0.064800
		loss: 0.064700
		loss: 0.064700
		loss: 0.064600
		loss: 0.064500
		loss: 0.064400
		loss: 0.064300
		loss: 0.064200
		loss: 0.064100
		loss: 0.064000
		loss: 0.063900
		loss: 0.063900
		loss: 0.063800
		loss: 0.063700
		loss: 0.063600
		loss: 0.063600
		loss: 0.063500
		loss: 0.063400
		loss: 0.063400
		loss: 0.063300
		loss: 0.063200
		loss: 0.063200
		loss: 0.063100
		loss: 0.063100
		loss: 0.063000
		loss: 0.062900
		loss: 0.062900
		loss: 0.062800
		loss: 0.062800
		loss: 0.062700
		loss: 0.062700
		loss: 0.062600
		loss: 0.062600
		loss: 0.062500
		loss: 0.062500
		loss: 0.062400
		loss: 0.062400
		loss: 0.062300
		loss: 0.062300
		loss: 0.062200
		loss: 0.062200
		loss: 0.062100
		loss: 0.062100
		loss: 0.062100
		loss: 0.062000
		loss: 0.062000
		loss: 0.061900
		loss: 0.061900
		loss: 0.061800
	Overall the loss development was 1.333000 -> 0.061800

Training data for problem d-03.pddl in epoch 1:
model creation time: 10.7666654586792s
problem epoch data for epoch 1, problem epoch 1
	sampling search time: 2.6080803871154785s
	during this search the following actions were chosen:
		move d1 d2 peg2 was chosen with probability 0.990684
		move d1 peg2 d2 was chosen with probability 0.957388
	training time: 57.641032457351685s
	during the training the following losses were computed:
		loss: 2.064800
		loss: 1.945400
		loss: 1.823100
		loss: 1.714500
		loss: 1.626800
		loss: 1.568800
		loss: 1.525000
		loss: 1.478100
		loss: 1.427100
		loss: 1.375500
		loss: 1.324200
		loss: 1.270900
		loss: 1.220500
		loss: 1.170600
		loss: 1.127000
		loss: 1.087400
		loss: 1.051500
		loss: 1.018800
		loss: 0.988900
		loss: 0.963700
		loss: 0.941800
		loss: 0.926200
		loss: 0.914300
		loss: 0.907000
		loss: 0.897900
		loss: 0.890500
		loss: 0.883700
		loss: 0.876800
		loss: 0.870400
		loss: 0.864500
		loss: 0.858700
		loss: 0.853100
		loss: 0.847400
		loss: 0.843200
		loss: 0.838300
		loss: 0.833100
		loss: 0.827400
		loss: 0.821300
		loss: 0.816100
		loss: 0.811500
		loss: 0.807100
		loss: 0.802800
		loss: 0.798800
		loss: 0.794800
		loss: 0.791400
		loss: 0.789400
		loss: 0.787300
		loss: 0.784200
		loss: 0.780200
		loss: 0.776800
		loss: 0.773600
		loss: 0.770200
		loss: 0.766300
		loss: 0.762300
		loss: 0.758100
		loss: 0.754000
		loss: 0.750800
		loss: 0.747500
		loss: 0.745400
		loss: 0.743100
		loss: 0.740300
		loss: 0.737100
		loss: 0.733900
		loss: 0.730300
		loss: 0.726900
		loss: 0.722900
		loss: 0.719200
		loss: 0.715500
		loss: 0.712100
		loss: 0.708200
		loss: 0.704700
		loss: 0.701800
		loss: 0.699000
		loss: 0.695700
		loss: 0.692300
		loss: 0.689000
		loss: 0.686500
		loss: 0.683500
		loss: 0.680300
		loss: 0.677100
		loss: 0.673900
		loss: 0.670400
		loss: 0.667300
		loss: 0.663900
		loss: 0.660500
		loss: 0.656500
		loss: 0.652900
		loss: 0.649100
		loss: 0.645900
		loss: 0.641600
		loss: 0.638500
		loss: 0.634900
		loss: 0.631200
		loss: 0.626700
		loss: 0.622100
		loss: 0.618200
		loss: 0.613400
		loss: 0.609100
		loss: 0.605100
		loss: 0.600200
		loss: 0.595600
		loss: 0.592000
		loss: 0.587400
		loss: 0.581800
		loss: 0.578100
		loss: 0.573200
		loss: 0.567800
		loss: 0.563100
		loss: 0.558100
		loss: 0.553200
		loss: 0.549400
		loss: 0.542900
		loss: 0.537800
		loss: 0.533500
		loss: 0.528900
		loss: 0.522900
		loss: 0.517900
		loss: 0.513100
		loss: 0.508000
		loss: 0.503000
		loss: 0.497300
		loss: 0.491100
		loss: 0.486800
		loss: 0.481400
		loss: 0.475700
		loss: 0.468900
		loss: 0.462900
		loss: 0.458900
		loss: 0.453100
		loss: 0.447200
		loss: 0.440900
		loss: 0.434600
		loss: 0.429200
		loss: 0.423300
		loss: 0.417500
		loss: 0.411400
		loss: 0.406100
		loss: 0.400300
		loss: 0.392200
		loss: 0.385200
		loss: 0.381500
		loss: 0.376800
		loss: 0.371000
		loss: 0.364700
		loss: 0.358200
		loss: 0.351200
		loss: 0.346500
		loss: 0.341300
		loss: 0.335500
		loss: 0.328900
		loss: 0.322500
		loss: 0.316200
		loss: 0.312300
		loss: 0.307000
		loss: 0.301300
		loss: 0.294800
		loss: 0.289000
		loss: 0.284100
		loss: 0.278400
		loss: 0.274200
		loss: 0.269200
		loss: 0.263400
		loss: 0.258800
		loss: 0.252900
		loss: 0.248600
		loss: 0.244400
		loss: 0.239800
		loss: 0.234800
		loss: 0.230100
		loss: 0.225800
		loss: 0.221700
		loss: 0.217700
		loss: 0.213500
		loss: 0.210100
		loss: 0.206200
		loss: 0.202900
		loss: 0.199300
		loss: 0.196100
		loss: 0.193100
		loss: 0.190100
		loss: 0.186700
		loss: 0.183800
		loss: 0.181000
		loss: 0.177900
		loss: 0.175300
		loss: 0.172600
		loss: 0.169900
		loss: 0.167500
		loss: 0.165200
		loss: 0.162900
		loss: 0.160700
		loss: 0.158700
		loss: 0.156600
		loss: 0.154600
		loss: 0.152800
		loss: 0.151300
		loss: 0.149400
		loss: 0.147700
		loss: 0.146000
		loss: 0.144400
		loss: 0.142800
		loss: 0.141600
		loss: 0.139900
		loss: 0.138700
		loss: 0.137500
		loss: 0.136000
		loss: 0.134900
		loss: 0.133800
		loss: 0.132500
		loss: 0.131400
		loss: 0.130500
		loss: 0.129400
		loss: 0.128300
		loss: 0.127300
		loss: 0.126400
		loss: 0.125400
		loss: 0.124700
		loss: 0.123800
		loss: 0.123000
		loss: 0.122200
		loss: 0.121500
		loss: 0.120700
		loss: 0.119900
		loss: 0.119200
		loss: 0.118600
		loss: 0.117900
		loss: 0.117300
		loss: 0.116600
		loss: 0.116100
		loss: 0.115400
		loss: 0.115000
		loss: 0.114400
		loss: 0.113800
		loss: 0.113200
		loss: 0.112700
		loss: 0.112100
		loss: 0.111500
		loss: 0.111000
		loss: 0.110500
		loss: 0.110100
		loss: 0.109700
		loss: 0.109200
		loss: 0.108800
		loss: 0.108300
		loss: 0.107900
		loss: 0.107500
		loss: 0.107100
		loss: 0.106700
		loss: 0.106300
		loss: 0.106000
		loss: 0.105600
		loss: 0.105300
		loss: 0.105000
		loss: 0.104600
		loss: 0.104300
		loss: 0.104000
		loss: 0.103700
		loss: 0.103400
		loss: 0.103100
		loss: 0.102800
		loss: 0.102600
		loss: 0.102300
		loss: 0.102000
		loss: 0.101800
		loss: 0.101600
		loss: 0.101300
		loss: 0.101100
		loss: 0.100900
		loss: 0.100600
		loss: 0.100400
		loss: 0.100200
		loss: 0.100000
		loss: 0.099800
		loss: 0.099600
		loss: 0.099400
		loss: 0.099200
		loss: 0.099100
		loss: 0.098900
		loss: 0.098700
		loss: 0.098500
		loss: 0.098400
		loss: 0.098200
		loss: 0.098000
		loss: 0.097900
		loss: 0.097700
		loss: 0.097500
		loss: 0.097400
		loss: 0.097200
		loss: 0.097100
		loss: 0.096900
		loss: 0.096800
		loss: 0.096600
		loss: 0.096500
		loss: 0.096300
		loss: 0.096200
		loss: 0.096100
		loss: 0.095900
		loss: 0.095800
		loss: 0.095700
		loss: 0.095600
	Overall the loss development was 2.064800 -> 0.095600

Epoch 2:
Training data for problem d-01.pddl in epoch 2:
model creation time: 2.0146706104278564s
problem epoch data for epoch 2, problem epoch 1
	sampling search time: 0.6247549057006836s
	during this search the following actions were chosen:
	training time: 36.79367280006409s
	during the training the following losses were computed:
		loss: 0.082000
		loss: 0.081500
		loss: 0.080900
		loss: 0.080200
		loss: 0.079600
		loss: 0.079000
		loss: 0.078300
		loss: 0.077700
		loss: 0.077100
		loss: 0.076500
		loss: 0.075800
		loss: 0.075200
		loss: 0.074600
		loss: 0.074000
		loss: 0.073400
		loss: 0.072800
		loss: 0.072300
		loss: 0.071700
		loss: 0.071100
		loss: 0.070500
		loss: 0.070000
		loss: 0.069400
		loss: 0.068900
		loss: 0.068300
		loss: 0.067800
		loss: 0.067200
		loss: 0.066700
		loss: 0.066200
		loss: 0.065600
		loss: 0.065100
		loss: 0.064600
		loss: 0.064100
		loss: 0.063600
		loss: 0.063100
		loss: 0.062600
		loss: 0.062100
		loss: 0.061600
		loss: 0.061200
		loss: 0.060700
		loss: 0.060200
		loss: 0.059700
		loss: 0.059300
		loss: 0.058800
		loss: 0.058400
		loss: 0.057900
		loss: 0.057500
		loss: 0.057000
		loss: 0.056600
		loss: 0.056200
		loss: 0.055700
		loss: 0.055300
		loss: 0.054900
		loss: 0.054500
		loss: 0.054100
		loss: 0.053700
		loss: 0.053300
		loss: 0.052900
		loss: 0.052500
		loss: 0.052100
		loss: 0.051700
		loss: 0.051300
		loss: 0.051000
		loss: 0.050600
		loss: 0.050200
		loss: 0.049900
		loss: 0.049500
		loss: 0.049100
		loss: 0.048800
		loss: 0.048400
		loss: 0.048100
		loss: 0.047800
		loss: 0.047400
		loss: 0.047100
		loss: 0.046800
		loss: 0.046400
		loss: 0.046100
		loss: 0.045800
		loss: 0.045500
		loss: 0.045200
		loss: 0.044900
		loss: 0.044600
		loss: 0.044300
		loss: 0.044000
		loss: 0.043700
		loss: 0.043400
		loss: 0.043100
		loss: 0.042800
		loss: 0.042600
		loss: 0.042300
		loss: 0.042000
		loss: 0.041800
		loss: 0.041500
		loss: 0.041300
		loss: 0.041000
		loss: 0.040800
		loss: 0.040500
		loss: 0.040300
		loss: 0.040000
		loss: 0.039800
		loss: 0.039600
		loss: 0.039400
		loss: 0.039100
		loss: 0.038900
		loss: 0.038700
		loss: 0.038500
		loss: 0.038200
		loss: 0.038000
		loss: 0.037800
		loss: 0.037600
		loss: 0.037400
		loss: 0.037200
		loss: 0.037000
		loss: 0.036800
		loss: 0.036600
		loss: 0.036400
		loss: 0.036300
		loss: 0.036100
		loss: 0.035900
		loss: 0.035700
		loss: 0.035500
		loss: 0.035300
		loss: 0.035200
		loss: 0.035000
		loss: 0.034800
		loss: 0.034600
		loss: 0.034500
		loss: 0.034300
		loss: 0.034100
		loss: 0.034000
		loss: 0.033800
		loss: 0.033600
		loss: 0.033500
		loss: 0.033300
		loss: 0.033200
		loss: 0.033000
		loss: 0.032900
		loss: 0.032700
		loss: 0.032600
		loss: 0.032400
		loss: 0.032300
		loss: 0.032100
		loss: 0.032000
		loss: 0.031900
		loss: 0.031700
		loss: 0.031600
		loss: 0.031400
		loss: 0.031300
		loss: 0.031200
		loss: 0.031100
		loss: 0.030900
		loss: 0.030800
		loss: 0.030700
		loss: 0.030500
		loss: 0.030400
		loss: 0.030300
		loss: 0.030200
		loss: 0.030000
		loss: 0.029900
		loss: 0.029800
		loss: 0.029700
		loss: 0.029600
		loss: 0.029500
		loss: 0.029400
		loss: 0.029200
		loss: 0.029100
		loss: 0.029000
		loss: 0.028900
		loss: 0.028800
		loss: 0.028700
		loss: 0.028600
		loss: 0.028500
		loss: 0.028400
		loss: 0.028300
		loss: 0.028200
		loss: 0.028100
		loss: 0.028000
		loss: 0.027900
		loss: 0.027800
		loss: 0.027700
		loss: 0.027600
		loss: 0.027500
		loss: 0.027400
		loss: 0.027300
		loss: 0.027200
		loss: 0.027100
		loss: 0.027000
		loss: 0.027000
		loss: 0.026900
		loss: 0.026800
		loss: 0.026700
		loss: 0.026600
		loss: 0.026500
		loss: 0.026400
		loss: 0.026400
		loss: 0.026300
		loss: 0.026200
		loss: 0.026100
		loss: 0.026000
		loss: 0.026000
		loss: 0.025900
		loss: 0.025800
		loss: 0.025700
		loss: 0.025600
		loss: 0.025600
		loss: 0.025500
		loss: 0.025400
		loss: 0.025300
		loss: 0.025300
		loss: 0.025200
		loss: 0.025100
		loss: 0.025100
		loss: 0.025000
		loss: 0.024900
		loss: 0.024800
		loss: 0.024800
		loss: 0.024700
		loss: 0.024600
		loss: 0.024600
		loss: 0.024500
		loss: 0.024400
		loss: 0.024400
		loss: 0.024300
		loss: 0.024200
		loss: 0.024200
		loss: 0.024100
		loss: 0.024100
		loss: 0.024000
		loss: 0.023900
		loss: 0.023900
		loss: 0.023800
		loss: 0.023800
		loss: 0.023700
		loss: 0.023600
		loss: 0.023600
		loss: 0.023500
		loss: 0.023500
		loss: 0.023400
		loss: 0.023400
		loss: 0.023300
		loss: 0.023200
		loss: 0.023200
		loss: 0.023100
		loss: 0.023100
		loss: 0.023000
		loss: 0.023000
		loss: 0.022900
		loss: 0.022900
		loss: 0.022800
		loss: 0.022800
		loss: 0.022700
		loss: 0.022700
		loss: 0.022600
		loss: 0.022600
		loss: 0.022500
		loss: 0.022500
		loss: 0.022400
		loss: 0.022400
		loss: 0.022300
		loss: 0.022300
		loss: 0.022200
		loss: 0.022200
		loss: 0.022200
		loss: 0.022100
		loss: 0.022100
		loss: 0.022000
		loss: 0.022000
		loss: 0.021900
		loss: 0.021900
		loss: 0.021900
		loss: 0.021800
		loss: 0.021800
		loss: 0.021700
		loss: 0.021700
		loss: 0.021700
		loss: 0.021600
		loss: 0.021600
		loss: 0.021500
		loss: 0.021500
		loss: 0.021500
		loss: 0.021400
		loss: 0.021400
		loss: 0.021300
		loss: 0.021300
		loss: 0.021300
		loss: 0.021200
		loss: 0.021200
		loss: 0.021100
		loss: 0.021100
		loss: 0.021100
		loss: 0.021000
		loss: 0.021000
		loss: 0.021000
		loss: 0.020900
		loss: 0.020900
		loss: 0.020900
		loss: 0.020800
		loss: 0.020800
		loss: 0.020800
		loss: 0.020700
		loss: 0.020700
	Overall the loss development was 0.082000 -> 0.020700

Training data for problem d-02.pddl in epoch 2:
model creation time: 5.414186477661133s
problem epoch data for epoch 2, problem epoch 1
	sampling search time: 1.302229881286621s
	during this search the following actions were chosen:
		move d1 d2 peg1 was chosen with probability 0.763388
		move d1 peg1 d2 was chosen with probability 0.710250
	training time: 44.70178723335266s
	during the training the following losses were computed:
		loss: 1.063200
		loss: 1.034100
		loss: 1.006600
		loss: 0.980400
		loss: 0.955500
		loss: 0.932900
		loss: 0.913500
		loss: 0.895800
		loss: 0.879100
		loss: 0.864000
		loss: 0.852600
		loss: 0.841600
		loss: 0.831000
		loss: 0.820700
		loss: 0.811700
		loss: 0.803200
		loss: 0.795000
		loss: 0.787200
		loss: 0.779600
		loss: 0.772000
		loss: 0.764500
		loss: 0.757200
		loss: 0.750300
		loss: 0.744200
		loss: 0.738800
		loss: 0.733300
		loss: 0.728500
		loss: 0.722600
		loss: 0.716800
		loss: 0.711500
		loss: 0.706500
		loss: 0.700800
		loss: 0.695400
		loss: 0.690400
		loss: 0.685500
		loss: 0.680400
		loss: 0.675100
		loss: 0.669700
		loss: 0.663900
		loss: 0.657800
		loss: 0.651800
		loss: 0.645800
		loss: 0.639500
		loss: 0.632600
		loss: 0.625400
		loss: 0.618000
		loss: 0.610500
		loss: 0.602300
		loss: 0.594300
		loss: 0.586400
		loss: 0.578200
		loss: 0.569600
		loss: 0.561400
		loss: 0.553200
		loss: 0.545500
		loss: 0.537100
		loss: 0.528500
		loss: 0.520200
		loss: 0.511900
		loss: 0.503300
		loss: 0.495000
		loss: 0.486700
		loss: 0.478500
		loss: 0.470400
		loss: 0.462000
		loss: 0.453700
		loss: 0.445300
		loss: 0.436700
		loss: 0.428200
		loss: 0.419600
		loss: 0.411200
		loss: 0.403600
		loss: 0.395200
		loss: 0.387400
		loss: 0.379400
		loss: 0.371300
		loss: 0.363600
		loss: 0.355900
		loss: 0.348100
		loss: 0.340600
		loss: 0.332900
		loss: 0.325100
		loss: 0.317300
		loss: 0.310000
		loss: 0.302000
		loss: 0.294700
		loss: 0.287500
		loss: 0.281200
		loss: 0.274200
		loss: 0.267500
		loss: 0.260900
		loss: 0.253800
		loss: 0.246600
		loss: 0.239600
		loss: 0.232700
		loss: 0.225600
		loss: 0.218500
		loss: 0.211700
		loss: 0.205000
		loss: 0.198100
		loss: 0.191400
		loss: 0.185100
		loss: 0.179000
		loss: 0.173000
		loss: 0.166800
		loss: 0.160900
		loss: 0.155500
		loss: 0.150100
		loss: 0.145000
		loss: 0.140000
		loss: 0.135100
		loss: 0.130400
		loss: 0.125800
		loss: 0.121400
		loss: 0.117400
		loss: 0.113500
		loss: 0.109600
		loss: 0.106000
		loss: 0.102600
		loss: 0.099300
		loss: 0.096300
		loss: 0.093500
		loss: 0.090700
		loss: 0.088200
		loss: 0.085800
		loss: 0.083400
		loss: 0.081300
		loss: 0.079300
		loss: 0.077500
		loss: 0.075600
		loss: 0.073900
		loss: 0.072300
		loss: 0.070800
		loss: 0.069400
		loss: 0.068100
		loss: 0.066900
		loss: 0.065600
		loss: 0.064600
		loss: 0.063600
		loss: 0.062600
		loss: 0.061700
		loss: 0.060900
		loss: 0.060100
		loss: 0.059400
		loss: 0.058700
		loss: 0.058000
		loss: 0.057400
		loss: 0.056900
		loss: 0.056400
		loss: 0.055900
		loss: 0.055400
		loss: 0.055000
		loss: 0.054600
		loss: 0.054200
		loss: 0.053900
		loss: 0.053500
		loss: 0.053200
		loss: 0.052900
		loss: 0.052600
		loss: 0.052300
		loss: 0.052100
		loss: 0.051800
		loss: 0.051600
		loss: 0.051400
		loss: 0.051100
		loss: 0.050900
		loss: 0.050700
		loss: 0.050600
		loss: 0.050400
		loss: 0.050200
		loss: 0.050000
		loss: 0.049900
		loss: 0.049700
		loss: 0.049600
		loss: 0.049500
		loss: 0.049300
		loss: 0.049200
		loss: 0.049100
		loss: 0.049000
		loss: 0.048900
		loss: 0.048800
		loss: 0.048700
		loss: 0.048600
		loss: 0.048500
		loss: 0.048400
		loss: 0.048300
		loss: 0.048200
		loss: 0.048100
		loss: 0.048100
		loss: 0.048000
		loss: 0.047900
		loss: 0.047800
		loss: 0.047800
		loss: 0.047700
		loss: 0.047600
		loss: 0.047600
		loss: 0.047500
		loss: 0.047400
		loss: 0.047400
		loss: 0.047300
		loss: 0.047300
		loss: 0.047200
		loss: 0.047100
		loss: 0.047100
		loss: 0.047000
		loss: 0.047000
		loss: 0.046900
		loss: 0.046900
		loss: 0.046800
		loss: 0.046800
		loss: 0.046700
		loss: 0.046700
		loss: 0.046700
		loss: 0.046600
		loss: 0.046600
		loss: 0.046500
		loss: 0.046500
		loss: 0.046400
		loss: 0.046400
		loss: 0.046400
		loss: 0.046300
		loss: 0.046300
		loss: 0.046300
		loss: 0.046200
		loss: 0.046200
		loss: 0.046100
		loss: 0.046100
		loss: 0.046100
		loss: 0.046000
		loss: 0.046000
		loss: 0.046000
		loss: 0.045900
		loss: 0.045900
		loss: 0.045900
		loss: 0.045800
		loss: 0.045800
		loss: 0.045800
		loss: 0.045800
		loss: 0.045700
		loss: 0.045700
		loss: 0.045700
		loss: 0.045600
		loss: 0.045600
		loss: 0.045600
		loss: 0.045500
		loss: 0.045500
		loss: 0.045500
		loss: 0.045500
		loss: 0.045400
		loss: 0.045400
		loss: 0.045400
		loss: 0.045400
		loss: 0.045300
		loss: 0.045300
		loss: 0.045300
		loss: 0.045200
		loss: 0.045200
		loss: 0.045200
		loss: 0.045200
		loss: 0.045100
		loss: 0.045100
		loss: 0.045100
		loss: 0.045100
		loss: 0.045000
		loss: 0.045000
		loss: 0.045000
		loss: 0.045000
		loss: 0.044900
		loss: 0.044900
		loss: 0.044900
		loss: 0.044900
		loss: 0.044900
		loss: 0.044800
		loss: 0.044800
		loss: 0.044800
		loss: 0.044800
		loss: 0.044700
		loss: 0.044700
		loss: 0.044700
		loss: 0.044700
		loss: 0.044600
		loss: 0.044600
		loss: 0.044600
		loss: 0.044600
		loss: 0.044600
		loss: 0.044500
		loss: 0.044500
		loss: 0.044500
		loss: 0.044500
		loss: 0.044400
		loss: 0.044400
		loss: 0.044400
		loss: 0.044400
		loss: 0.044400
		loss: 0.044300
		loss: 0.044300
		loss: 0.044300
		loss: 0.044300
		loss: 0.044300
		loss: 0.044200
	Overall the loss development was 1.063200 -> 0.044200

Training data for problem d-03.pddl in epoch 2:
model creation time: 10.46353268623352s
problem epoch data for epoch 2, problem epoch 1
	sampling search time: 2.4811320304870605s
	during this search the following actions were chosen:
		move d1 d2 peg2 was chosen with probability 0.997343
		move d1 peg2 d2 was chosen with probability 0.993779
	training time: 56.807403564453125s
	during the training the following losses were computed:
		loss: 2.448600
		loss: 2.277800
		loss: 2.109400
		loss: 1.953800
		loss: 1.814700
		loss: 1.674000
		loss: 1.529000
		loss: 1.347700
		loss: 1.184200
		loss: 1.031700
		loss: 0.908300
		loss: 0.830500
		loss: 0.814500
		loss: 0.815000
		loss: 0.811200
		loss: 0.802800
		loss: 0.793400
		loss: 0.784900
		loss: 0.776400
		loss: 0.769200
		loss: 0.761700
		loss: 0.755400
		loss: 0.749900
		loss: 0.745300
		loss: 0.741400
		loss: 0.738100
		loss: 0.735300
		loss: 0.732700
		loss: 0.730300
		loss: 0.728800
		loss: 0.727200
		loss: 0.725000
		loss: 0.722600
		loss: 0.720000
		loss: 0.717200
		loss: 0.714100
		loss: 0.711000
		loss: 0.707500
		loss: 0.703900
		loss: 0.700900
		loss: 0.697600
		loss: 0.694300
		loss: 0.690900
		loss: 0.687600
		loss: 0.684400
		loss: 0.681000
		loss: 0.677800
		loss: 0.674500
		loss: 0.671100
		loss: 0.667900
		loss: 0.664600
		loss: 0.661400
		loss: 0.658700
		loss: 0.656000
		loss: 0.653100
		loss: 0.650800
		loss: 0.648600
		loss: 0.646300
		loss: 0.644000
		loss: 0.641300
		loss: 0.638600
		loss: 0.635700
		loss: 0.632600
		loss: 0.628900
		loss: 0.625300
		loss: 0.621700
		loss: 0.618600
		loss: 0.615600
		loss: 0.613000
		loss: 0.610700
		loss: 0.608100
		loss: 0.605600
		loss: 0.603200
		loss: 0.600700
		loss: 0.598000
		loss: 0.595500
		loss: 0.592800
		loss: 0.589800
		loss: 0.587200
		loss: 0.584600
		loss: 0.582200
		loss: 0.579400
		loss: 0.576800
		loss: 0.574200
		loss: 0.571500
		loss: 0.568600
		loss: 0.565600
		loss: 0.562900
		loss: 0.560300
		loss: 0.557500
		loss: 0.554400
		loss: 0.551400
		loss: 0.548400
		loss: 0.545200
		loss: 0.542300
		loss: 0.539300
		loss: 0.536400
		loss: 0.533600
		loss: 0.530700
		loss: 0.528000
		loss: 0.525100
		loss: 0.521900
		loss: 0.519000
		loss: 0.515900
		loss: 0.513000
		loss: 0.509800
		loss: 0.506500
		loss: 0.502900
		loss: 0.499000
		loss: 0.495400
		loss: 0.491700
		loss: 0.487700
		loss: 0.483600
		loss: 0.479800
		loss: 0.476000
		loss: 0.472200
		loss: 0.468900
		loss: 0.465600
		loss: 0.462000
		loss: 0.458200
		loss: 0.454400
		loss: 0.451300
		loss: 0.447800
		loss: 0.443700
		loss: 0.440000
		loss: 0.436600
		loss: 0.432800
		loss: 0.428800
		loss: 0.425600
		loss: 0.422200
		loss: 0.418200
		loss: 0.414600
		loss: 0.411300
		loss: 0.407600
		loss: 0.403800
		loss: 0.400400
		loss: 0.396700
		loss: 0.393100
		loss: 0.389600
		loss: 0.385900
		loss: 0.382200
		loss: 0.378700
		loss: 0.374900
		loss: 0.370800
		loss: 0.367300
		loss: 0.363500
		loss: 0.359500
		loss: 0.355700
		loss: 0.351900
		loss: 0.347800
		loss: 0.344400
		loss: 0.340700
		loss: 0.336600
		loss: 0.333100
		loss: 0.329400
		loss: 0.325600
		loss: 0.321700
		loss: 0.318100
		loss: 0.314600
		loss: 0.311000
		loss: 0.307300
		loss: 0.303700
		loss: 0.300000
		loss: 0.296400
		loss: 0.292800
		loss: 0.289100
		loss: 0.285700
		loss: 0.282100
		loss: 0.278400
		loss: 0.275100
		loss: 0.271300
		loss: 0.267500
		loss: 0.264200
		loss: 0.260600
		loss: 0.256500
		loss: 0.252500
		loss: 0.248500
		loss: 0.244400
		loss: 0.240700
		loss: 0.237300
		loss: 0.233800
		loss: 0.230400
		loss: 0.227000
		loss: 0.223600
		loss: 0.220500
		loss: 0.217200
		loss: 0.214000
		loss: 0.211000
		loss: 0.207900
		loss: 0.204700
		loss: 0.201600
		loss: 0.198800
		loss: 0.195800
		loss: 0.192800
		loss: 0.190100
		loss: 0.187200
		loss: 0.184700
		loss: 0.182000
		loss: 0.179300
		loss: 0.176800
		loss: 0.174300
		loss: 0.171700
		loss: 0.169300
		loss: 0.166900
		loss: 0.164500
		loss: 0.162200
		loss: 0.159900
		loss: 0.157700
		loss: 0.155500
		loss: 0.153300
		loss: 0.151300
		loss: 0.149300
		loss: 0.147200
		loss: 0.145400
		loss: 0.143600
		loss: 0.141800
		loss: 0.140000
		loss: 0.138200
		loss: 0.136600
		loss: 0.135000
		loss: 0.133400
		loss: 0.131900
		loss: 0.130400
		loss: 0.128900
		loss: 0.127500
		loss: 0.126100
		loss: 0.124700
		loss: 0.123400
		loss: 0.122100
		loss: 0.120800
		loss: 0.119600
		loss: 0.118500
		loss: 0.117300
		loss: 0.116200
		loss: 0.115100
		loss: 0.114100
		loss: 0.113100
		loss: 0.112200
		loss: 0.111200
		loss: 0.110400
		loss: 0.109500
		loss: 0.108700
		loss: 0.107900
		loss: 0.107100
		loss: 0.106300
		loss: 0.105600
		loss: 0.104900
		loss: 0.104200
		loss: 0.103500
		loss: 0.102800
		loss: 0.102200
		loss: 0.101600
		loss: 0.101000
		loss: 0.100400
		loss: 0.099800
		loss: 0.099300
		loss: 0.098700
		loss: 0.098200
		loss: 0.097600
		loss: 0.097100
		loss: 0.096500
		loss: 0.096000
		loss: 0.095600
		loss: 0.095100
		loss: 0.094600
		loss: 0.094200
		loss: 0.093700
		loss: 0.093300
		loss: 0.092900
		loss: 0.092500
		loss: 0.092100
		loss: 0.091800
		loss: 0.091400
		loss: 0.091000
		loss: 0.090700
		loss: 0.090300
		loss: 0.090100
		loss: 0.089800
		loss: 0.089500
		loss: 0.089300
		loss: 0.089000
		loss: 0.088800
		loss: 0.088500
		loss: 0.088200
		loss: 0.088000
		loss: 0.087700
		loss: 0.087400
		loss: 0.087200
		loss: 0.086900
		loss: 0.086700
		loss: 0.086500
		loss: 0.086300
		loss: 0.086100
		loss: 0.085900
		loss: 0.085700
		loss: 0.085600
		loss: 0.085400
		loss: 0.085200
		loss: 0.085100
		loss: 0.084900
	Overall the loss development was 2.448600 -> 0.084900

Epoch 3:
Training data for problem d-01.pddl in epoch 3:
model creation time: 2.0579469203948975s
problem epoch data for epoch 3, problem epoch 1
	sampling search time: 0.6051483154296875s
	during this search the following actions were chosen:
	training time: 36.86803078651428s
	during the training the following losses were computed:
		loss: 0.067500
		loss: 0.066800
		loss: 0.066200
		loss: 0.065500
		loss: 0.064900
		loss: 0.064300
		loss: 0.063700
		loss: 0.063000
		loss: 0.062400
		loss: 0.061800
		loss: 0.061200
		loss: 0.060600
		loss: 0.060000
		loss: 0.059400
		loss: 0.058800
		loss: 0.058300
		loss: 0.057700
		loss: 0.057100
		loss: 0.056600
		loss: 0.056000
		loss: 0.055500
		loss: 0.054900
		loss: 0.054400
		loss: 0.053900
		loss: 0.053300
		loss: 0.052800
		loss: 0.052300
		loss: 0.051800
		loss: 0.051300
		loss: 0.050800
		loss: 0.050300
		loss: 0.049800
		loss: 0.049400
		loss: 0.048900
		loss: 0.048400
		loss: 0.048000
		loss: 0.047500
		loss: 0.047100
		loss: 0.046600
		loss: 0.046200
		loss: 0.045800
		loss: 0.045400
		loss: 0.044900
		loss: 0.044500
		loss: 0.044100
		loss: 0.043700
		loss: 0.043300
		loss: 0.043000
		loss: 0.042600
		loss: 0.042200
		loss: 0.041900
		loss: 0.041500
		loss: 0.041200
		loss: 0.040800
		loss: 0.040500
		loss: 0.040100
		loss: 0.039800
		loss: 0.039500
		loss: 0.039100
		loss: 0.038800
		loss: 0.038500
		loss: 0.038200
		loss: 0.037900
		loss: 0.037600
		loss: 0.037300
		loss: 0.037000
		loss: 0.036700
		loss: 0.036400
		loss: 0.036100
		loss: 0.035900
		loss: 0.035600
		loss: 0.035300
		loss: 0.035100
		loss: 0.034800
		loss: 0.034600
		loss: 0.034300
		loss: 0.034100
		loss: 0.033900
		loss: 0.033600
		loss: 0.033400
		loss: 0.033200
		loss: 0.033000
		loss: 0.032700
		loss: 0.032500
		loss: 0.032300
		loss: 0.032100
		loss: 0.031900
		loss: 0.031700
		loss: 0.031500
		loss: 0.031300
		loss: 0.031100
		loss: 0.030900
		loss: 0.030700
		loss: 0.030500
		loss: 0.030400
		loss: 0.030200
		loss: 0.030000
		loss: 0.029900
		loss: 0.029700
		loss: 0.029500
		loss: 0.029400
		loss: 0.029200
		loss: 0.029000
		loss: 0.028900
		loss: 0.028700
		loss: 0.028600
		loss: 0.028400
		loss: 0.028300
		loss: 0.028100
		loss: 0.028000
		loss: 0.027800
		loss: 0.027700
		loss: 0.027500
		loss: 0.027400
		loss: 0.027200
		loss: 0.027100
		loss: 0.027000
		loss: 0.026800
		loss: 0.026700
		loss: 0.026600
		loss: 0.026400
		loss: 0.026300
		loss: 0.026200
		loss: 0.026100
		loss: 0.025900
		loss: 0.025800
		loss: 0.025700
		loss: 0.025600
		loss: 0.025400
		loss: 0.025300
		loss: 0.025200
		loss: 0.025100
		loss: 0.025000
		loss: 0.024900
		loss: 0.024800
		loss: 0.024700
		loss: 0.024600
		loss: 0.024500
		loss: 0.024400
		loss: 0.024300
		loss: 0.024200
		loss: 0.024100
		loss: 0.024000
		loss: 0.023900
		loss: 0.023800
		loss: 0.023700
		loss: 0.023600
		loss: 0.023500
		loss: 0.023400
		loss: 0.023300
		loss: 0.023200
		loss: 0.023200
		loss: 0.023100
		loss: 0.023000
		loss: 0.022900
		loss: 0.022800
		loss: 0.022800
		loss: 0.022700
		loss: 0.022600
		loss: 0.022500
		loss: 0.022400
		loss: 0.022400
		loss: 0.022300
		loss: 0.022200
		loss: 0.022200
		loss: 0.022100
		loss: 0.022000
		loss: 0.021900
		loss: 0.021900
		loss: 0.021800
		loss: 0.021700
		loss: 0.021700
		loss: 0.021600
		loss: 0.021500
		loss: 0.021500
		loss: 0.021400
		loss: 0.021300
		loss: 0.021300
		loss: 0.021200
		loss: 0.021200
		loss: 0.021100
		loss: 0.021000
		loss: 0.021000
		loss: 0.020900
		loss: 0.020900
		loss: 0.020800
		loss: 0.020800
		loss: 0.020700
		loss: 0.020600
		loss: 0.020600
		loss: 0.020500
		loss: 0.020500
		loss: 0.020400
		loss: 0.020400
		loss: 0.020300
		loss: 0.020300
		loss: 0.020200
		loss: 0.020200
		loss: 0.020100
		loss: 0.020100
		loss: 0.020000
		loss: 0.020000
		loss: 0.019900
		loss: 0.019900
		loss: 0.019800
		loss: 0.019800
		loss: 0.019700
		loss: 0.019700
		loss: 0.019600
		loss: 0.019600
		loss: 0.019500
		loss: 0.019500
		loss: 0.019500
		loss: 0.019400
		loss: 0.019400
		loss: 0.019300
		loss: 0.019300
		loss: 0.019200
		loss: 0.019200
		loss: 0.019200
		loss: 0.019100
		loss: 0.019100
		loss: 0.019000
		loss: 0.019000
		loss: 0.019000
		loss: 0.018900
		loss: 0.018900
		loss: 0.018800
		loss: 0.018800
		loss: 0.018800
		loss: 0.018700
		loss: 0.018700
		loss: 0.018700
		loss: 0.018600
		loss: 0.018600
		loss: 0.018500
		loss: 0.018500
		loss: 0.018500
		loss: 0.018400
		loss: 0.018400
		loss: 0.018400
		loss: 0.018300
		loss: 0.018300
		loss: 0.018300
		loss: 0.018200
		loss: 0.018200
		loss: 0.018200
		loss: 0.018100
		loss: 0.018100
		loss: 0.018100
		loss: 0.018000
		loss: 0.018000
		loss: 0.018000
		loss: 0.017900
		loss: 0.017900
		loss: 0.017900
		loss: 0.017900
		loss: 0.017800
		loss: 0.017800
		loss: 0.017800
		loss: 0.017700
		loss: 0.017700
		loss: 0.017700
		loss: 0.017600
		loss: 0.017600
		loss: 0.017600
		loss: 0.017600
		loss: 0.017500
		loss: 0.017500
		loss: 0.017500
		loss: 0.017500
		loss: 0.017400
		loss: 0.017400
		loss: 0.017400
		loss: 0.017400
		loss: 0.017300
		loss: 0.017300
		loss: 0.017300
		loss: 0.017300
		loss: 0.017200
		loss: 0.017200
		loss: 0.017200
		loss: 0.017100
		loss: 0.017100
		loss: 0.017100
		loss: 0.017100
		loss: 0.017100
		loss: 0.017000
		loss: 0.017000
		loss: 0.017000
		loss: 0.017000
		loss: 0.016900
		loss: 0.016900
		loss: 0.016900
		loss: 0.016900
		loss: 0.016800
		loss: 0.016800
		loss: 0.016800
		loss: 0.016800
		loss: 0.016800
	Overall the loss development was 0.067500 -> 0.016800

Training data for problem d-02.pddl in epoch 3:
model creation time: 5.224605321884155s
problem epoch data for epoch 3, problem epoch 1
	sampling search time: 1.3316893577575684s
	during this search the following actions were chosen:
		move d1 d2 peg1 was chosen with probability 0.600117
		move d1 peg1 d2 was chosen with probability 0.628098
	training time: 44.31762337684631s
	during the training the following losses were computed:
		loss: 0.937200
		loss: 0.918200
		loss: 0.900300
		loss: 0.884200
		loss: 0.869400
		loss: 0.856000
		loss: 0.843900
		loss: 0.832100
		loss: 0.821300
		loss: 0.812900
		loss: 0.804900
		loss: 0.797600
		loss: 0.790400
		loss: 0.783600
		loss: 0.777300
		loss: 0.771100
		loss: 0.765200
		loss: 0.759200
		loss: 0.753500
		loss: 0.747800
		loss: 0.742400
		loss: 0.736900
		loss: 0.731300
		loss: 0.725800
		loss: 0.720300
		loss: 0.715000
		loss: 0.710100
		loss: 0.705600
		loss: 0.701000
		loss: 0.696400
		loss: 0.691500
		loss: 0.686600
		loss: 0.681400
		loss: 0.676300
		loss: 0.671100
		loss: 0.665600
		loss: 0.660100
		loss: 0.655100
		loss: 0.650000
		loss: 0.644500
		loss: 0.638700
		loss: 0.632600
		loss: 0.626500
		loss: 0.620500
		loss: 0.614400
		loss: 0.608300
		loss: 0.602000
		loss: 0.595700
		loss: 0.589200
		loss: 0.582100
		loss: 0.575300
		loss: 0.568400
		loss: 0.560600
		loss: 0.553600
		loss: 0.545800
		loss: 0.537300
		loss: 0.529500
		loss: 0.521100
		loss: 0.512700
		loss: 0.504400
		loss: 0.495700
		loss: 0.486900
		loss: 0.477900
		loss: 0.468900
		loss: 0.459300
		loss: 0.449800
		loss: 0.440500
		loss: 0.431100
		loss: 0.421300
		loss: 0.411300
		loss: 0.401500
		loss: 0.391500
		loss: 0.381600
		loss: 0.371500
		loss: 0.361400
		loss: 0.351400
		loss: 0.341300
		loss: 0.331500
		loss: 0.321500
		loss: 0.311600
		loss: 0.301700
		loss: 0.291600
		loss: 0.282000
		loss: 0.272600
		loss: 0.263300
		loss: 0.254200
		loss: 0.244900
		loss: 0.236000
		loss: 0.227100
		loss: 0.218700
		loss: 0.210400
		loss: 0.202200
		loss: 0.194300
		loss: 0.186800
		loss: 0.179700
		loss: 0.172800
		loss: 0.166000
		loss: 0.159300
		loss: 0.152900
		loss: 0.146800
		loss: 0.140900
		loss: 0.135400
		loss: 0.130000
		loss: 0.125000
		loss: 0.120300
		loss: 0.115800
		loss: 0.111400
		loss: 0.107300
		loss: 0.103400
		loss: 0.099700
		loss: 0.096200
		loss: 0.093100
		loss: 0.090000
		loss: 0.087200
		loss: 0.084600
		loss: 0.082200
		loss: 0.079900
		loss: 0.077800
		loss: 0.075700
		loss: 0.073800
		loss: 0.072100
		loss: 0.070400
		loss: 0.068900
		loss: 0.067500
		loss: 0.066200
		loss: 0.065000
		loss: 0.063900
		loss: 0.062800
		loss: 0.061900
		loss: 0.061000
		loss: 0.060200
		loss: 0.059400
		loss: 0.058700
		loss: 0.058000
		loss: 0.057400
		loss: 0.056800
		loss: 0.056300
		loss: 0.055800
		loss: 0.055300
		loss: 0.054900
		loss: 0.054500
		loss: 0.054100
		loss: 0.053800
		loss: 0.053400
		loss: 0.053100
		loss: 0.052900
		loss: 0.052600
		loss: 0.052300
		loss: 0.052100
		loss: 0.051800
		loss: 0.051600
		loss: 0.051400
		loss: 0.051200
		loss: 0.051100
		loss: 0.050900
		loss: 0.050700
		loss: 0.050600
		loss: 0.050400
		loss: 0.050300
		loss: 0.050200
		loss: 0.050000
		loss: 0.049900
		loss: 0.049800
		loss: 0.049700
		loss: 0.049600
		loss: 0.049500
		loss: 0.049400
		loss: 0.049300
		loss: 0.049200
		loss: 0.049100
		loss: 0.049000
		loss: 0.048900
		loss: 0.048900
		loss: 0.048800
		loss: 0.048700
		loss: 0.048600
		loss: 0.048600
		loss: 0.048500
		loss: 0.048400
		loss: 0.048400
		loss: 0.048300
		loss: 0.048300
		loss: 0.048200
		loss: 0.048100
		loss: 0.048100
		loss: 0.048000
		loss: 0.048000
		loss: 0.047900
		loss: 0.047900
		loss: 0.047800
		loss: 0.047800
		loss: 0.047700
		loss: 0.047700
		loss: 0.047600
		loss: 0.047600
		loss: 0.047500
		loss: 0.047500
		loss: 0.047400
		loss: 0.047400
		loss: 0.047400
		loss: 0.047300
		loss: 0.047300
		loss: 0.047200
		loss: 0.047200
		loss: 0.047200
		loss: 0.047100
		loss: 0.047100
		loss: 0.047000
		loss: 0.047000
		loss: 0.047000
		loss: 0.046900
		loss: 0.046900
		loss: 0.046900
		loss: 0.046800
		loss: 0.046800
		loss: 0.046800
		loss: 0.046700
		loss: 0.046700
		loss: 0.046700
		loss: 0.046600
		loss: 0.046600
		loss: 0.046600
		loss: 0.046500
		loss: 0.046500
		loss: 0.046500
		loss: 0.046400
		loss: 0.046400
		loss: 0.046400
		loss: 0.046400
		loss: 0.046300
		loss: 0.046300
		loss: 0.046300
		loss: 0.046200
		loss: 0.046200
		loss: 0.046200
		loss: 0.046200
		loss: 0.046100
		loss: 0.046100
		loss: 0.046100
		loss: 0.046000
		loss: 0.046000
		loss: 0.046000
		loss: 0.046000
		loss: 0.045900
		loss: 0.045900
		loss: 0.045900
		loss: 0.045900
		loss: 0.045800
		loss: 0.045800
		loss: 0.045800
		loss: 0.045800
		loss: 0.045700
		loss: 0.045700
		loss: 0.045700
		loss: 0.045700
		loss: 0.045600
		loss: 0.045600
		loss: 0.045600
		loss: 0.045600
		loss: 0.045500
		loss: 0.045500
		loss: 0.045500
		loss: 0.045500
		loss: 0.045400
		loss: 0.045400
		loss: 0.045400
		loss: 0.045400
		loss: 0.045300
		loss: 0.045300
		loss: 0.045300
		loss: 0.045300
		loss: 0.045300
		loss: 0.045200
		loss: 0.045200
		loss: 0.045200
		loss: 0.045200
		loss: 0.045100
		loss: 0.045100
		loss: 0.045100
		loss: 0.045100
		loss: 0.045000
		loss: 0.045000
		loss: 0.045000
		loss: 0.045000
		loss: 0.045000
		loss: 0.044900
		loss: 0.044900
		loss: 0.044900
		loss: 0.044900
		loss: 0.044800
		loss: 0.044800
		loss: 0.044800
		loss: 0.044800
		loss: 0.044800
		loss: 0.044700
		loss: 0.044700
		loss: 0.044700
		loss: 0.044700
		loss: 0.044700
		loss: 0.044600
	Overall the loss development was 0.937200 -> 0.044600

Training data for problem d-03.pddl in epoch 3:
model creation time: 10.401702642440796s
problem epoch data for epoch 3, problem epoch 1
	sampling search time: 2.425981283187866s
	during this search the following actions were chosen:
		move d1 d2 peg2 was chosen with probability 0.989446
		move d1 peg2 d2 was chosen with probability 0.937334
	training time: 56.942882776260376s
	during the training the following losses were computed:
		loss: 1.902700
		loss: 1.764200
		loss: 1.635500
		loss: 1.520800
		loss: 1.420300
		loss: 1.328800
		loss: 1.246500
		loss: 1.173300
		loss: 1.085400
		loss: 1.026800
		loss: 0.981900
		loss: 0.938100
		loss: 0.898300
		loss: 0.861800
		loss: 0.828600
		loss: 0.803100
		loss: 0.777600
		loss: 0.754100
		loss: 0.735000
		loss: 0.720400
		loss: 0.706200
		loss: 0.690600
		loss: 0.670600
		loss: 0.651800
		loss: 0.643200
		loss: 0.639400
		loss: 0.634900
		loss: 0.628600
		loss: 0.622200
		loss: 0.618500
		loss: 0.614800
		loss: 0.610400
		loss: 0.604600
		loss: 0.598300
		loss: 0.592100
		loss: 0.586700
		loss: 0.581500
		loss: 0.577000
		loss: 0.572500
		loss: 0.567700
		loss: 0.562400
		loss: 0.556800
		loss: 0.550900
		loss: 0.544800
		loss: 0.538100
		loss: 0.533000
		loss: 0.528200
		loss: 0.523800
		loss: 0.518900
		loss: 0.513400
		loss: 0.507700
		loss: 0.502400
		loss: 0.497900
		loss: 0.494200
		loss: 0.489200
		loss: 0.483400
		loss: 0.477600
		loss: 0.473000
		loss: 0.469200
		loss: 0.465700
		loss: 0.461700
		loss: 0.457300
		loss: 0.453100
		loss: 0.448700
		loss: 0.444300
		loss: 0.439700
		loss: 0.434600
		loss: 0.429900
		loss: 0.425400
		loss: 0.420800
		loss: 0.415900
		loss: 0.411100
		loss: 0.406300
		loss: 0.401200
		loss: 0.395800
		loss: 0.391200
		loss: 0.387300
		loss: 0.383200
		loss: 0.379100
		loss: 0.376300
		loss: 0.372400
		loss: 0.368700
		loss: 0.365000
		loss: 0.361000
		loss: 0.356700
		loss: 0.352400
		loss: 0.349100
		loss: 0.345300
		loss: 0.341400
		loss: 0.337700
		loss: 0.334000
		loss: 0.330300
		loss: 0.326300
		loss: 0.322400
		loss: 0.318700
		loss: 0.315100
		loss: 0.311500
		loss: 0.307800
		loss: 0.304300
		loss: 0.300400
		loss: 0.296600
		loss: 0.293100
		loss: 0.289900
		loss: 0.286700
		loss: 0.283400
		loss: 0.280400
		loss: 0.276900
		loss: 0.274500
		loss: 0.271200
		loss: 0.268600
		loss: 0.265100
		loss: 0.262000
		loss: 0.258300
		loss: 0.255600
		loss: 0.253100
		loss: 0.249900
		loss: 0.246500
		loss: 0.243300
		loss: 0.240300
		loss: 0.237000
		loss: 0.234300
		loss: 0.231500
		loss: 0.228700
		loss: 0.225700
		loss: 0.222800
		loss: 0.219900
		loss: 0.217600
		loss: 0.214900
		loss: 0.212300
		loss: 0.209700
		loss: 0.206800
		loss: 0.204400
		loss: 0.202100
		loss: 0.199500
		loss: 0.199400
		loss: 0.196800
		loss: 0.193600
		loss: 0.193100
		loss: 0.188900
		loss: 0.187200
		loss: 0.185400
		loss: 0.182500
		loss: 0.180900
		loss: 0.178100
		loss: 0.175800
		loss: 0.174200
		loss: 0.171500
		loss: 0.170300
		loss: 0.167600
		loss: 0.165900
		loss: 0.163900
		loss: 0.162600
		loss: 0.160300
		loss: 0.159400
		loss: 0.157200
		loss: 0.155600
		loss: 0.153900
		loss: 0.151600
		loss: 0.150400
		loss: 0.148200
		loss: 0.147400
		loss: 0.145000
		loss: 0.143400
		loss: 0.141500
		loss: 0.139800
		loss: 0.138100
		loss: 0.136500
		loss: 0.135100
		loss: 0.133500
		loss: 0.131900
		loss: 0.130500
		loss: 0.129300
		loss: 0.128100
		loss: 0.125900
		loss: 0.124900
		loss: 0.123400
		loss: 0.121800
		loss: 0.120500
		loss: 0.119000
		loss: 0.117600
		loss: 0.116500
		loss: 0.114700
		loss: 0.113400
		loss: 0.112300
		loss: 0.111200
		loss: 0.110000
		loss: 0.109000
		loss: 0.107800
		loss: 0.107000
		loss: 0.106000
		loss: 0.105000
		loss: 0.104500
		loss: 0.103300
		loss: 0.103000
		loss: 0.101800
		loss: 0.101000
		loss: 0.100400
		loss: 0.099400
		loss: 0.098600
		loss: 0.097800
		loss: 0.097000
		loss: 0.096600
		loss: 0.095700
		loss: 0.095200
		loss: 0.094500
		loss: 0.094000
		loss: 0.093400
		loss: 0.092900
		loss: 0.092200
		loss: 0.091800
		loss: 0.091200
		loss: 0.090800
		loss: 0.090300
		loss: 0.089800
		loss: 0.089300
		loss: 0.089000
		loss: 0.088600
		loss: 0.088000
		loss: 0.087700
		loss: 0.087300
		loss: 0.086700
		loss: 0.086500
		loss: 0.086100
		loss: 0.085600
		loss: 0.085500
		loss: 0.085000
		loss: 0.084600
		loss: 0.084300
		loss: 0.084000
		loss: 0.083700
		loss: 0.083400
		loss: 0.083100
		loss: 0.082800
		loss: 0.082600
		loss: 0.082300
		loss: 0.082000
		loss: 0.081700
		loss: 0.081500
		loss: 0.081200
		loss: 0.080900
		loss: 0.080700
		loss: 0.080500
		loss: 0.080200
		loss: 0.079900
		loss: 0.079800
		loss: 0.079500
		loss: 0.079300
		loss: 0.079100
		loss: 0.078800
		loss: 0.078600
		loss: 0.078500
		loss: 0.078200
		loss: 0.078000
		loss: 0.077800
		loss: 0.077600
		loss: 0.077400
		loss: 0.077200
		loss: 0.077000
		loss: 0.076800
		loss: 0.076700
		loss: 0.076500
		loss: 0.076400
		loss: 0.076200
		loss: 0.076100
		loss: 0.075900
		loss: 0.075800
		loss: 0.075700
		loss: 0.075500
		loss: 0.075400
		loss: 0.075300
		loss: 0.075100
		loss: 0.075000
		loss: 0.074900
		loss: 0.074800
		loss: 0.074700
		loss: 0.074600
		loss: 0.074400
		loss: 0.074300
		loss: 0.074200
		loss: 0.074100
		loss: 0.074000
		loss: 0.073900
		loss: 0.073800
		loss: 0.073700
		loss: 0.073600
		loss: 0.073500
		loss: 0.073500
		loss: 0.073300
		loss: 0.073300
		loss: 0.073200
		loss: 0.073100
		loss: 0.073000
		loss: 0.072900
		loss: 0.072900
		loss: 0.072700
		loss: 0.072700
		loss: 0.072600
		loss: 0.072500
		loss: 0.072500
		loss: 0.072400
	Overall the loss development was 1.902700 -> 0.072400

Epoch 4:
Training data for problem d-01.pddl in epoch 4:
model creation time: 2.305407762527466s
problem epoch data for epoch 4, problem epoch 1
	sampling search time: 0.5959863662719727s
	during this search the following actions were chosen:
	training time: 36.3633086681366s
	during the training the following losses were computed:
		loss: 0.059900
		loss: 0.059300
		loss: 0.058600
		loss: 0.058100
		loss: 0.057500
		loss: 0.056900
		loss: 0.056300
		loss: 0.055700
		loss: 0.055100
		loss: 0.054600
		loss: 0.054000
		loss: 0.053400
		loss: 0.052900
		loss: 0.052300
		loss: 0.051800
		loss: 0.051200
		loss: 0.050700
		loss: 0.050200
		loss: 0.049600
		loss: 0.049100
		loss: 0.048600
		loss: 0.048100
		loss: 0.047600
		loss: 0.047100
		loss: 0.046600
		loss: 0.046100
		loss: 0.045600
		loss: 0.045100
		loss: 0.044700
		loss: 0.044200
		loss: 0.043700
		loss: 0.043300
		loss: 0.042800
		loss: 0.042400
		loss: 0.042000
		loss: 0.041500
		loss: 0.041100
		loss: 0.040700
		loss: 0.040300
		loss: 0.039900
		loss: 0.039400
		loss: 0.039000
		loss: 0.038600
		loss: 0.038300
		loss: 0.037900
		loss: 0.037500
		loss: 0.037100
		loss: 0.036700
		loss: 0.036400
		loss: 0.036000
		loss: 0.035700
		loss: 0.035300
		loss: 0.035000
		loss: 0.034700
		loss: 0.034400
		loss: 0.034000
		loss: 0.033700
		loss: 0.033400
		loss: 0.033100
		loss: 0.032800
		loss: 0.032500
		loss: 0.032200
		loss: 0.032000
		loss: 0.031700
		loss: 0.031400
		loss: 0.031100
		loss: 0.030900
		loss: 0.030600
		loss: 0.030400
		loss: 0.030100
		loss: 0.029900
		loss: 0.029700
		loss: 0.029500
		loss: 0.029200
		loss: 0.029000
		loss: 0.028800
		loss: 0.028600
		loss: 0.028400
		loss: 0.028200
		loss: 0.028000
		loss: 0.027800
		loss: 0.027600
		loss: 0.027500
		loss: 0.027300
		loss: 0.027100
		loss: 0.026900
		loss: 0.026800
		loss: 0.026600
		loss: 0.026400
		loss: 0.026300
		loss: 0.026100
		loss: 0.025900
		loss: 0.025800
		loss: 0.025600
		loss: 0.025500
		loss: 0.025400
		loss: 0.025200
		loss: 0.025100
		loss: 0.025000
		loss: 0.024800
		loss: 0.024700
		loss: 0.024600
		loss: 0.024500
		loss: 0.024300
		loss: 0.024200
		loss: 0.024100
		loss: 0.024000
		loss: 0.023900
		loss: 0.023800
		loss: 0.023700
		loss: 0.023600
		loss: 0.023500
		loss: 0.023400
		loss: 0.023300
		loss: 0.023200
		loss: 0.023100
		loss: 0.023000
		loss: 0.022900
		loss: 0.022800
		loss: 0.022700
		loss: 0.022600
		loss: 0.022500
		loss: 0.022400
		loss: 0.022300
		loss: 0.022200
		loss: 0.022100
		loss: 0.022000
		loss: 0.022000
		loss: 0.021900
		loss: 0.021800
		loss: 0.021700
		loss: 0.021600
		loss: 0.021600
		loss: 0.021500
		loss: 0.021400
		loss: 0.021300
		loss: 0.021300
		loss: 0.021200
		loss: 0.021100
		loss: 0.021100
		loss: 0.021000
		loss: 0.020900
		loss: 0.020800
		loss: 0.020800
		loss: 0.020700
		loss: 0.020600
		loss: 0.020600
		loss: 0.020500
		loss: 0.020500
		loss: 0.020400
		loss: 0.020300
		loss: 0.020300
		loss: 0.020200
		loss: 0.020100
		loss: 0.020100
		loss: 0.020000
		loss: 0.020000
		loss: 0.019900
		loss: 0.019900
		loss: 0.019800
		loss: 0.019800
		loss: 0.019700
		loss: 0.019600
		loss: 0.019600
		loss: 0.019500
		loss: 0.019500
		loss: 0.019400
		loss: 0.019400
		loss: 0.019300
		loss: 0.019300
		loss: 0.019200
		loss: 0.019200
		loss: 0.019200
		loss: 0.019100
		loss: 0.019100
		loss: 0.019000
		loss: 0.019000
		loss: 0.018900
		loss: 0.018900
		loss: 0.018800
		loss: 0.018800
		loss: 0.018800
		loss: 0.018700
		loss: 0.018700
		loss: 0.018600
		loss: 0.018600
		loss: 0.018600
		loss: 0.018500
		loss: 0.018500
		loss: 0.018400
		loss: 0.018400
		loss: 0.018400
		loss: 0.018300
		loss: 0.018300
		loss: 0.018300
		loss: 0.018200
		loss: 0.018200
		loss: 0.018100
		loss: 0.018100
		loss: 0.018100
		loss: 0.018000
		loss: 0.018000
		loss: 0.018000
		loss: 0.017900
		loss: 0.017900
		loss: 0.017900
		loss: 0.017800
		loss: 0.017800
		loss: 0.017800
		loss: 0.017700
		loss: 0.017700
		loss: 0.017700
		loss: 0.017600
		loss: 0.017600
		loss: 0.017600
		loss: 0.017600
		loss: 0.017500
		loss: 0.017500
		loss: 0.017500
		loss: 0.017400
		loss: 0.017400
		loss: 0.017400
		loss: 0.017400
		loss: 0.017300
		loss: 0.017300
		loss: 0.017300
		loss: 0.017200
		loss: 0.017200
		loss: 0.017200
		loss: 0.017200
		loss: 0.017100
		loss: 0.017100
		loss: 0.017100
		loss: 0.017100
		loss: 0.017000
		loss: 0.017000
		loss: 0.017000
		loss: 0.017000
		loss: 0.017000
		loss: 0.016900
		loss: 0.016900
		loss: 0.016900
		loss: 0.016900
		loss: 0.016800
		loss: 0.016800
		loss: 0.016800
		loss: 0.016800
		loss: 0.016700
		loss: 0.016700
		loss: 0.016700
		loss: 0.016700
		loss: 0.016700
		loss: 0.016600
		loss: 0.016600
		loss: 0.016600
		loss: 0.016600
		loss: 0.016600
		loss: 0.016500
		loss: 0.016500
		loss: 0.016500
		loss: 0.016500
		loss: 0.016500
		loss: 0.016400
		loss: 0.016400
		loss: 0.016400
		loss: 0.016400
		loss: 0.016400
		loss: 0.016400
		loss: 0.016300
		loss: 0.016300
		loss: 0.016300
		loss: 0.016300
		loss: 0.016300
		loss: 0.016200
		loss: 0.016200
		loss: 0.016200
		loss: 0.016200
		loss: 0.016200
		loss: 0.016200
		loss: 0.016200
		loss: 0.016100
		loss: 0.016100
		loss: 0.016100
		loss: 0.016100
		loss: 0.016100
		loss: 0.016100
		loss: 0.016000
		loss: 0.016000
		loss: 0.016000
		loss: 0.016000
		loss: 0.016000
		loss: 0.016000
		loss: 0.016000
		loss: 0.015900
		loss: 0.015900
		loss: 0.015900
		loss: 0.015900
		loss: 0.015900
		loss: 0.015900
		loss: 0.015900
	Overall the loss development was 0.059900 -> 0.015900

Training data for problem d-02.pddl in epoch 4:
model creation time: 5.509968996047974s
problem epoch data for epoch 4, problem epoch 1
	sampling search time: 1.2709558010101318s
	during this search the following actions were chosen:
		move d1 d2 peg1 was chosen with probability 0.581426
		move d1 peg1 d2 was chosen with probability 0.633421
	training time: 44.583492040634155s
	during the training the following losses were computed:
		loss: 0.890700
		loss: 0.875400
		loss: 0.860800
		loss: 0.847400
		loss: 0.835100
		loss: 0.823300
		loss: 0.812400
		loss: 0.802700
		loss: 0.795000
		loss: 0.787100
		loss: 0.779300
		loss: 0.771700
		loss: 0.764400
		loss: 0.757700
		loss: 0.751800
		loss: 0.746300
		loss: 0.740700
		loss: 0.735200
		loss: 0.729900
		loss: 0.724900
		loss: 0.720300
		loss: 0.715900
		loss: 0.711800
		loss: 0.707800
		loss: 0.704100
		loss: 0.700200
		loss: 0.696200
		loss: 0.692200
		loss: 0.688200
		loss: 0.684000
		loss: 0.679600
		loss: 0.675200
		loss: 0.670600
		loss: 0.665900
		loss: 0.661100
		loss: 0.656300
		loss: 0.651000
		loss: 0.645700
		loss: 0.640200
		loss: 0.634500
		loss: 0.628600
		loss: 0.622800
		loss: 0.617300
		loss: 0.611400
		loss: 0.605100
		loss: 0.598600
		loss: 0.592100
		loss: 0.584900
		loss: 0.577100
		loss: 0.569700
		loss: 0.562500
		loss: 0.554500
		loss: 0.546400
		loss: 0.538400
		loss: 0.530300
		loss: 0.521700
		loss: 0.512700
		loss: 0.503400
		loss: 0.494000
		loss: 0.484400
		loss: 0.474000
		loss: 0.463700
		loss: 0.452700
		loss: 0.441300
		loss: 0.429200
		loss: 0.416900
		loss: 0.405200
		loss: 0.393600
		loss: 0.382000
		loss: 0.370600
		loss: 0.359300
		loss: 0.347800
		loss: 0.337100
		loss: 0.326700
		loss: 0.316200
		loss: 0.306000
		loss: 0.295800
		loss: 0.286100
		loss: 0.277300
		loss: 0.268000
		loss: 0.259500
		loss: 0.251100
		loss: 0.243100
		loss: 0.235000
		loss: 0.227200
		loss: 0.219800
		loss: 0.212500
		loss: 0.205300
		loss: 0.198400
		loss: 0.191700
		loss: 0.185000
		loss: 0.178800
		loss: 0.172200
		loss: 0.166000
		loss: 0.159800
		loss: 0.153800
		loss: 0.147900
		loss: 0.141900
		loss: 0.136100
		loss: 0.130600
		loss: 0.125900
		loss: 0.121300
		loss: 0.117100
		loss: 0.113000
		loss: 0.109100
		loss: 0.105700
		loss: 0.102400
		loss: 0.099100
		loss: 0.096000
		loss: 0.093200
		loss: 0.090400
		loss: 0.087800
		loss: 0.085300
		loss: 0.083000
		loss: 0.080800
		loss: 0.078600
		loss: 0.076500
		loss: 0.074700
		loss: 0.072900
		loss: 0.071300
		loss: 0.069700
		loss: 0.068300
		loss: 0.066900
		loss: 0.065700
		loss: 0.064500
		loss: 0.063400
		loss: 0.062400
		loss: 0.061400
		loss: 0.060500
		loss: 0.059700
		loss: 0.058900
		loss: 0.058200
		loss: 0.057500
		loss: 0.056900
		loss: 0.056300
		loss: 0.055700
		loss: 0.055200
		loss: 0.054700
		loss: 0.054200
		loss: 0.053800
		loss: 0.053400
		loss: 0.053000
		loss: 0.052600
		loss: 0.052300
		loss: 0.052000
		loss: 0.051700
		loss: 0.051400
		loss: 0.051100
		loss: 0.050900
		loss: 0.050600
		loss: 0.050400
		loss: 0.050200
		loss: 0.050000
		loss: 0.049800
		loss: 0.049600
		loss: 0.049400
		loss: 0.049300
		loss: 0.049100
		loss: 0.049000
		loss: 0.048800
		loss: 0.048700
		loss: 0.048500
		loss: 0.048400
		loss: 0.048300
		loss: 0.048200
		loss: 0.048100
		loss: 0.048000
		loss: 0.047900
		loss: 0.047800
		loss: 0.047700
		loss: 0.047600
		loss: 0.047500
		loss: 0.047400
		loss: 0.047300
		loss: 0.047200
		loss: 0.047100
		loss: 0.047100
		loss: 0.047000
		loss: 0.046900
		loss: 0.046900
		loss: 0.046800
		loss: 0.046700
		loss: 0.046700
		loss: 0.046600
		loss: 0.046500
		loss: 0.046500
		loss: 0.046400
		loss: 0.046400
		loss: 0.046300
		loss: 0.046300
		loss: 0.046200
		loss: 0.046200
		loss: 0.046100
		loss: 0.046100
		loss: 0.046000
		loss: 0.046000
		loss: 0.045900
		loss: 0.045900
		loss: 0.045800
		loss: 0.045800
		loss: 0.045700
		loss: 0.045700
		loss: 0.045700
		loss: 0.045600
		loss: 0.045600
		loss: 0.045500
		loss: 0.045500
		loss: 0.045500
		loss: 0.045400
		loss: 0.045400
		loss: 0.045400
		loss: 0.045300
		loss: 0.045300
		loss: 0.045200
		loss: 0.045200
		loss: 0.045200
		loss: 0.045100
		loss: 0.045100
		loss: 0.045100
		loss: 0.045100
		loss: 0.045000
		loss: 0.045000
		loss: 0.045000
		loss: 0.044900
		loss: 0.044900
		loss: 0.044900
		loss: 0.044800
		loss: 0.044800
		loss: 0.044800
		loss: 0.044800
		loss: 0.044700
		loss: 0.044700
		loss: 0.044700
		loss: 0.044600
		loss: 0.044600
		loss: 0.044600
		loss: 0.044600
		loss: 0.044500
		loss: 0.044500
		loss: 0.044500
		loss: 0.044500
		loss: 0.044400
		loss: 0.044400
		loss: 0.044400
		loss: 0.044300
		loss: 0.044300
		loss: 0.044300
		loss: 0.044300
		loss: 0.044200
		loss: 0.044200
		loss: 0.044200
		loss: 0.044200
		loss: 0.044100
		loss: 0.044100
		loss: 0.044100
		loss: 0.044100
		loss: 0.044100
		loss: 0.044000
		loss: 0.044000
		loss: 0.044000
		loss: 0.044000
		loss: 0.043900
		loss: 0.043900
		loss: 0.043900
		loss: 0.043900
		loss: 0.043800
		loss: 0.043800
		loss: 0.043800
		loss: 0.043800
		loss: 0.043800
		loss: 0.043700
		loss: 0.043700
		loss: 0.043700
		loss: 0.043700
		loss: 0.043600
		loss: 0.043600
		loss: 0.043600
		loss: 0.043600
		loss: 0.043600
		loss: 0.043500
		loss: 0.043500
		loss: 0.043500
		loss: 0.043500
		loss: 0.043500
		loss: 0.043400
		loss: 0.043400
		loss: 0.043400
		loss: 0.043400
		loss: 0.043400
		loss: 0.043300
		loss: 0.043300
		loss: 0.043300
		loss: 0.043300
		loss: 0.043300
		loss: 0.043200
		loss: 0.043200
		loss: 0.043200
		loss: 0.043200
		loss: 0.043200
		loss: 0.043100
	Overall the loss development was 0.890700 -> 0.043100

Training data for problem d-03.pddl in epoch 4:
model creation time: 10.248446226119995s
problem epoch data for epoch 4, problem epoch 1
	sampling search time: 2.451969623565674s
	during this search the following actions were chosen:
		move d1 d2 peg2 was chosen with probability 0.986114
		move d1 peg2 d2 was chosen with probability 0.847892
	training time: 56.88327693939209s
	during the training the following losses were computed:
		loss: 1.815100
		loss: 1.640500
		loss: 1.445100
		loss: 1.239000
		loss: 1.037600
		loss: 0.892700
		loss: 0.834800
		loss: 0.804200
		loss: 0.782400
		loss: 0.760100
		loss: 0.750200
		loss: 0.744300
		loss: 0.732100
		loss: 0.716800
		loss: 0.702400
		loss: 0.688500
		loss: 0.675300
		loss: 0.661600
		loss: 0.647000
		loss: 0.632400
		loss: 0.618000
		loss: 0.600300
		loss: 0.581100
		loss: 0.561200
		loss: 0.541500
		loss: 0.521100
		loss: 0.507000
		loss: 0.501400
		loss: 0.497600
		loss: 0.493300
		loss: 0.490700
		loss: 0.487900
		loss: 0.484700
		loss: 0.480800
		loss: 0.475900
		loss: 0.470400
		loss: 0.464500
		loss: 0.457900
		loss: 0.450900
		loss: 0.444000
		loss: 0.437500
		loss: 0.431100
		loss: 0.424800
		loss: 0.419600
		loss: 0.414800
		loss: 0.411900
		loss: 0.408500
		loss: 0.404700
		loss: 0.400500
		loss: 0.395900
		loss: 0.391300
		loss: 0.387900
		loss: 0.384500
		loss: 0.380800
		loss: 0.376700
		loss: 0.372200
		loss: 0.367200
		loss: 0.361900
		loss: 0.356800
		loss: 0.351600
		loss: 0.346500
		loss: 0.341300
		loss: 0.336200
		loss: 0.331200
		loss: 0.326700
		loss: 0.322700
		loss: 0.319300
		loss: 0.315700
		loss: 0.311900
		loss: 0.308000
		loss: 0.304200
		loss: 0.300700
		loss: 0.297300
		loss: 0.293600
		loss: 0.289700
		loss: 0.286000
		loss: 0.282400
		loss: 0.278800
		loss: 0.275300
		loss: 0.271600
		loss: 0.268500
		loss: 0.265500
		loss: 0.262700
		loss: 0.259600
		loss: 0.256700
		loss: 0.253800
		loss: 0.250500
		loss: 0.248100
		loss: 0.244800
		loss: 0.242500
		loss: 0.239600
		loss: 0.237600
		loss: 0.234700
		loss: 0.233700
		loss: 0.231300
		loss: 0.227800
		loss: 0.226500
		loss: 0.224100
		loss: 0.220900
		loss: 0.220200
		loss: 0.217000
		loss: 0.214900
		loss: 0.213100
		loss: 0.210400
		loss: 0.208300
		loss: 0.206600
		loss: 0.203800
		loss: 0.202300
		loss: 0.199900
		loss: 0.198100
		loss: 0.196300
		loss: 0.194100
		loss: 0.192300
		loss: 0.190500
		loss: 0.188400
		loss: 0.186500
		loss: 0.184700
		loss: 0.183100
		loss: 0.182100
		loss: 0.180300
		loss: 0.178100
		loss: 0.177000
		loss: 0.175000
		loss: 0.173800
		loss: 0.171700
		loss: 0.170000
		loss: 0.168200
		loss: 0.166400
		loss: 0.164900
		loss: 0.163200
		loss: 0.161800
		loss: 0.160500
		loss: 0.158800
		loss: 0.157200
		loss: 0.155800
		loss: 0.154200
		loss: 0.152700
		loss: 0.151300
		loss: 0.149900
		loss: 0.148400
		loss: 0.146700
		loss: 0.145600
		loss: 0.144100
		loss: 0.142800
		loss: 0.141700
		loss: 0.140100
		loss: 0.138900
		loss: 0.137500
		loss: 0.136000
		loss: 0.134700
		loss: 0.133300
		loss: 0.132300
		loss: 0.131100
		loss: 0.129700
		loss: 0.128600
		loss: 0.127700
		loss: 0.126600
		loss: 0.125300
		loss: 0.124300
		loss: 0.123300
		loss: 0.122100
		loss: 0.121100
		loss: 0.120500
		loss: 0.119000
		loss: 0.118000
		loss: 0.117000
		loss: 0.115800
		loss: 0.114700
		loss: 0.113800
		loss: 0.112700
		loss: 0.111500
		loss: 0.110400
		loss: 0.109200
		loss: 0.108100
		loss: 0.107100
		loss: 0.106100
		loss: 0.105100
		loss: 0.104000
		loss: 0.103100
		loss: 0.102000
		loss: 0.101200
		loss: 0.100200
		loss: 0.099500
		loss: 0.098800
		loss: 0.098100
		loss: 0.097500
		loss: 0.096700
		loss: 0.096000
		loss: 0.095300
		loss: 0.094600
		loss: 0.094100
		loss: 0.093600
		loss: 0.093000
		loss: 0.092400
		loss: 0.091800
		loss: 0.091200
		loss: 0.090600
		loss: 0.090100
		loss: 0.089700
		loss: 0.089100
		loss: 0.088700
		loss: 0.088300
		loss: 0.087700
		loss: 0.087300
		loss: 0.086900
		loss: 0.086500
		loss: 0.086100
		loss: 0.085600
		loss: 0.085200
		loss: 0.084800
		loss: 0.084500
		loss: 0.084100
		loss: 0.083700
		loss: 0.083300
		loss: 0.082900
		loss: 0.082500
		loss: 0.082200
		loss: 0.081800
		loss: 0.081500
		loss: 0.081200
		loss: 0.081000
		loss: 0.080700
		loss: 0.080400
		loss: 0.080100
		loss: 0.079800
		loss: 0.079600
		loss: 0.079300
		loss: 0.079200
		loss: 0.078800
		loss: 0.078700
		loss: 0.078500
		loss: 0.078200
		loss: 0.078100
		loss: 0.077900
		loss: 0.077700
		loss: 0.077500
		loss: 0.077200
		loss: 0.077100
		loss: 0.076900
		loss: 0.076700
		loss: 0.076600
		loss: 0.076400
		loss: 0.076300
		loss: 0.076100
		loss: 0.076000
		loss: 0.075800
		loss: 0.075600
		loss: 0.075500
		loss: 0.075400
		loss: 0.075200
		loss: 0.075100
		loss: 0.075000
		loss: 0.074800
		loss: 0.074700
		loss: 0.074600
		loss: 0.074500
		loss: 0.074300
		loss: 0.074200
		loss: 0.074100
		loss: 0.074000
		loss: 0.073900
		loss: 0.073800
		loss: 0.073700
		loss: 0.073600
		loss: 0.073500
		loss: 0.073400
		loss: 0.073300
		loss: 0.073200
		loss: 0.073000
		loss: 0.073000
		loss: 0.072800
		loss: 0.072800
		loss: 0.072600
		loss: 0.072600
		loss: 0.072500
		loss: 0.072400
		loss: 0.072300
		loss: 0.072200
		loss: 0.072100
		loss: 0.072000
		loss: 0.071900
		loss: 0.071800
		loss: 0.071700
		loss: 0.071700
		loss: 0.071600
		loss: 0.071500
		loss: 0.071400
		loss: 0.071400
		loss: 0.071300
		loss: 0.071200
		loss: 0.071200
		loss: 0.071100
		loss: 0.071000
		loss: 0.071000
		loss: 0.070900
		loss: 0.070800
		loss: 0.070800
		loss: 0.070700
		loss: 0.070600
		loss: 0.070600
	Overall the loss development was 1.815100 -> 0.070600

Epoch 5:
Training data for problem d-01.pddl in epoch 5:
model creation time: 2.3598175048828125s
problem epoch data for epoch 5, problem epoch 1
	sampling search time: 0.6070418357849121s
	during this search the following actions were chosen:
	training time: 36.81887125968933s
	during the training the following losses were computed:
		loss: 0.058600
		loss: 0.058000
		loss: 0.057400
		loss: 0.056800
		loss: 0.056200
		loss: 0.055700
		loss: 0.055100
		loss: 0.054500
		loss: 0.053900
		loss: 0.053400
		loss: 0.052800
		loss: 0.052300
		loss: 0.051700
		loss: 0.051200
		loss: 0.050600
		loss: 0.050100
		loss: 0.049600
		loss: 0.049000
		loss: 0.048500
		loss: 0.048000
		loss: 0.047500
		loss: 0.047000
		loss: 0.046500
		loss: 0.046000
		loss: 0.045600
		loss: 0.045100
		loss: 0.044600
		loss: 0.044100
		loss: 0.043700
		loss: 0.043200
		loss: 0.042800
		loss: 0.042300
		loss: 0.041900
		loss: 0.041500
		loss: 0.041000
		loss: 0.040600
		loss: 0.040200
		loss: 0.039800
		loss: 0.039400
		loss: 0.039000
		loss: 0.038600
		loss: 0.038200
		loss: 0.037800
		loss: 0.037400
		loss: 0.037100
		loss: 0.036700
		loss: 0.036400
		loss: 0.036000
		loss: 0.035700
		loss: 0.035300
		loss: 0.035000
		loss: 0.034700
		loss: 0.034300
		loss: 0.034000
		loss: 0.033700
		loss: 0.033400
		loss: 0.033100
		loss: 0.032800
		loss: 0.032500
		loss: 0.032300
		loss: 0.032000
		loss: 0.031700
		loss: 0.031400
		loss: 0.031200
		loss: 0.030900
		loss: 0.030700
		loss: 0.030400
		loss: 0.030200
		loss: 0.029900
		loss: 0.029700
		loss: 0.029400
		loss: 0.029200
		loss: 0.029000
		loss: 0.028800
		loss: 0.028500
		loss: 0.028300
		loss: 0.028100
		loss: 0.027900
		loss: 0.027700
		loss: 0.027500
		loss: 0.027300
		loss: 0.027100
		loss: 0.027000
		loss: 0.026800
		loss: 0.026600
		loss: 0.026500
		loss: 0.026300
		loss: 0.026100
		loss: 0.026000
		loss: 0.025800
		loss: 0.025700
		loss: 0.025500
		loss: 0.025400
		loss: 0.025200
		loss: 0.025100
		loss: 0.025000
		loss: 0.024800
		loss: 0.024700
		loss: 0.024600
		loss: 0.024500
		loss: 0.024300
		loss: 0.024200
		loss: 0.024100
		loss: 0.024000
		loss: 0.023900
		loss: 0.023700
		loss: 0.023600
		loss: 0.023500
		loss: 0.023400
		loss: 0.023300
		loss: 0.023200
		loss: 0.023100
		loss: 0.023000
		loss: 0.022900
		loss: 0.022800
		loss: 0.022700
		loss: 0.022600
		loss: 0.022500
		loss: 0.022400
		loss: 0.022300
		loss: 0.022200
		loss: 0.022100
		loss: 0.022000
		loss: 0.022000
		loss: 0.021900
		loss: 0.021800
		loss: 0.021700
		loss: 0.021600
		loss: 0.021500
		loss: 0.021400
		loss: 0.021400
		loss: 0.021300
		loss: 0.021200
		loss: 0.021100
		loss: 0.021100
		loss: 0.021000
		loss: 0.020900
		loss: 0.020800
		loss: 0.020800
		loss: 0.020700
		loss: 0.020600
		loss: 0.020600
		loss: 0.020500
		loss: 0.020400
		loss: 0.020400
		loss: 0.020300
		loss: 0.020200
		loss: 0.020200
		loss: 0.020100
		loss: 0.020000
		loss: 0.020000
		loss: 0.019900
		loss: 0.019800
		loss: 0.019800
		loss: 0.019700
		loss: 0.019700
		loss: 0.019600
		loss: 0.019600
		loss: 0.019500
		loss: 0.019400
		loss: 0.019400
		loss: 0.019300
		loss: 0.019300
		loss: 0.019200
		loss: 0.019200
		loss: 0.019100
		loss: 0.019100
		loss: 0.019000
		loss: 0.019000
		loss: 0.018900
		loss: 0.018900
		loss: 0.018800
		loss: 0.018800
		loss: 0.018700
		loss: 0.018700
		loss: 0.018600
		loss: 0.018600
		loss: 0.018600
		loss: 0.018500
		loss: 0.018500
		loss: 0.018400
		loss: 0.018400
		loss: 0.018300
		loss: 0.018300
		loss: 0.018300
		loss: 0.018200
		loss: 0.018200
		loss: 0.018100
		loss: 0.018100
		loss: 0.018100
		loss: 0.018000
		loss: 0.018000
		loss: 0.017900
		loss: 0.017900
		loss: 0.017900
		loss: 0.017800
		loss: 0.017800
		loss: 0.017800
		loss: 0.017700
		loss: 0.017700
		loss: 0.017700
		loss: 0.017600
		loss: 0.017600
		loss: 0.017600
		loss: 0.017500
		loss: 0.017500
		loss: 0.017500
		loss: 0.017400
		loss: 0.017400
		loss: 0.017400
		loss: 0.017300
		loss: 0.017300
		loss: 0.017300
		loss: 0.017200
		loss: 0.017200
		loss: 0.017200
		loss: 0.017200
		loss: 0.017100
		loss: 0.017100
		loss: 0.017100
		loss: 0.017000
		loss: 0.017000
		loss: 0.017000
		loss: 0.017000
		loss: 0.016900
		loss: 0.016900
		loss: 0.016900
		loss: 0.016900
		loss: 0.016800
		loss: 0.016800
		loss: 0.016800
		loss: 0.016800
		loss: 0.016700
		loss: 0.016700
		loss: 0.016700
		loss: 0.016700
		loss: 0.016600
		loss: 0.016600
		loss: 0.016600
		loss: 0.016600
		loss: 0.016500
		loss: 0.016500
		loss: 0.016500
		loss: 0.016500
		loss: 0.016500
		loss: 0.016400
		loss: 0.016400
		loss: 0.016400
		loss: 0.016400
		loss: 0.016300
		loss: 0.016300
		loss: 0.016300
		loss: 0.016300
		loss: 0.016300
		loss: 0.016200
		loss: 0.016200
		loss: 0.016200
		loss: 0.016200
		loss: 0.016200
		loss: 0.016200
		loss: 0.016100
		loss: 0.016100
		loss: 0.016100
		loss: 0.016100
		loss: 0.016100
		loss: 0.016000
		loss: 0.016000
		loss: 0.016000
		loss: 0.016000
		loss: 0.016000
		loss: 0.016000
		loss: 0.015900
		loss: 0.015900
		loss: 0.015900
		loss: 0.015900
		loss: 0.015900
		loss: 0.015900
		loss: 0.015900
		loss: 0.015800
		loss: 0.015800
		loss: 0.015800
		loss: 0.015800
		loss: 0.015800
		loss: 0.015800
		loss: 0.015800
		loss: 0.015700
		loss: 0.015700
		loss: 0.015700
		loss: 0.015700
		loss: 0.015700
		loss: 0.015700
		loss: 0.015700
		loss: 0.015600
		loss: 0.015600
		loss: 0.015600
		loss: 0.015600
		loss: 0.015600
		loss: 0.015600
		loss: 0.015600
		loss: 0.015500
	Overall the loss development was 0.058600 -> 0.015500

Training data for problem d-02.pddl in epoch 5:
model creation time: 5.892256259918213s
problem epoch data for epoch 5, problem epoch 1
	sampling search time: 1.4327454566955566s
	during this search the following actions were chosen:
		move d1 d2 peg1 was chosen with probability 0.584374
		move d1 peg1 d2 was chosen with probability 0.654478
	training time: 44.67470622062683s
	during the training the following losses were computed:
		loss: 0.913500
		loss: 0.895400
		loss: 0.878800
		loss: 0.863400
		loss: 0.849500
		loss: 0.837000
		loss: 0.825400
		loss: 0.814700
		loss: 0.804800
		loss: 0.795900
		loss: 0.787700
		loss: 0.780200
		loss: 0.773400
		loss: 0.767300
		loss: 0.761300
		loss: 0.755700
		loss: 0.750300
		loss: 0.745100
		loss: 0.740000
		loss: 0.735000
		loss: 0.730500
		loss: 0.726000
		loss: 0.721700
		loss: 0.717300
		loss: 0.712900
		loss: 0.708500
		loss: 0.704000
		loss: 0.699600
		loss: 0.695200
		loss: 0.690300
		loss: 0.685300
		loss: 0.680500
		loss: 0.675600
		loss: 0.670900
		loss: 0.666100
		loss: 0.661400
		loss: 0.656600
		loss: 0.651600
		loss: 0.646300
		loss: 0.640900
		loss: 0.635200
		loss: 0.629400
		loss: 0.623100
		loss: 0.616600
		loss: 0.609700
		loss: 0.602500
		loss: 0.595500
		loss: 0.588300
		loss: 0.580700
		loss: 0.573400
		loss: 0.566000
		loss: 0.558700
		loss: 0.550500
		loss: 0.542600
		loss: 0.534300
		loss: 0.526100
		loss: 0.516800
		loss: 0.506700
		loss: 0.496600
		loss: 0.487000
		loss: 0.477200
		loss: 0.467100
		loss: 0.456600
		loss: 0.445800
		loss: 0.435400
		loss: 0.424100
		loss: 0.413500
		loss: 0.401800
		loss: 0.390200
		loss: 0.379000
		loss: 0.368800
		loss: 0.358500
		loss: 0.347800
		loss: 0.337200
		loss: 0.326700
		loss: 0.316300
		loss: 0.306000
		loss: 0.296000
		loss: 0.285900
		loss: 0.276000
		loss: 0.266100
		loss: 0.256200
		loss: 0.246800
		loss: 0.237600
		loss: 0.228400
		loss: 0.219300
		loss: 0.210700
		loss: 0.202300
		loss: 0.194600
		loss: 0.186800
		loss: 0.179200
		loss: 0.171700
		loss: 0.165000
		loss: 0.158200
		loss: 0.151700
		loss: 0.145500
		loss: 0.139700
		loss: 0.134100
		loss: 0.128700
		loss: 0.123500
		loss: 0.118500
		loss: 0.113800
		loss: 0.109200
		loss: 0.104900
		loss: 0.101000
		loss: 0.097400
		loss: 0.093900
		loss: 0.090600
		loss: 0.087500
		loss: 0.084700
		loss: 0.082000
		loss: 0.079400
		loss: 0.077100
		loss: 0.074900
		loss: 0.072800
		loss: 0.071000
		loss: 0.069200
		loss: 0.067700
		loss: 0.066200
		loss: 0.064800
		loss: 0.063500
		loss: 0.062400
		loss: 0.061300
		loss: 0.060300
		loss: 0.059400
		loss: 0.058500
		loss: 0.057700
		loss: 0.057000
		loss: 0.056300
		loss: 0.055600
		loss: 0.055100
		loss: 0.054500
		loss: 0.054000
		loss: 0.053500
		loss: 0.053100
		loss: 0.052700
		loss: 0.052300
		loss: 0.051900
		loss: 0.051600
		loss: 0.051300
		loss: 0.051000
		loss: 0.050700
		loss: 0.050500
		loss: 0.050200
		loss: 0.050000
		loss: 0.049800
		loss: 0.049600
		loss: 0.049400
		loss: 0.049200
		loss: 0.049100
		loss: 0.048900
		loss: 0.048800
		loss: 0.048600
		loss: 0.048500
		loss: 0.048300
		loss: 0.048200
		loss: 0.048100
		loss: 0.048000
		loss: 0.047900
		loss: 0.047800
		loss: 0.047700
		loss: 0.047600
		loss: 0.047500
		loss: 0.047400
		loss: 0.047300
		loss: 0.047200
		loss: 0.047100
		loss: 0.047000
		loss: 0.047000
		loss: 0.046900
		loss: 0.046800
		loss: 0.046800
		loss: 0.046700
		loss: 0.046600
		loss: 0.046600
		loss: 0.046500
		loss: 0.046400
		loss: 0.046400
		loss: 0.046300
		loss: 0.046300
		loss: 0.046200
		loss: 0.046200
		loss: 0.046100
		loss: 0.046100
		loss: 0.046000
		loss: 0.046000
		loss: 0.045900
		loss: 0.045900
		loss: 0.045800
		loss: 0.045800
		loss: 0.045800
		loss: 0.045700
		loss: 0.045700
		loss: 0.045600
		loss: 0.045600
		loss: 0.045600
		loss: 0.045500
		loss: 0.045500
		loss: 0.045400
		loss: 0.045400
		loss: 0.045400
		loss: 0.045300
		loss: 0.045300
		loss: 0.045300
		loss: 0.045200
		loss: 0.045200
		loss: 0.045200
		loss: 0.045100
		loss: 0.045100
		loss: 0.045100
		loss: 0.045000
		loss: 0.045000
		loss: 0.045000
		loss: 0.044900
		loss: 0.044900
		loss: 0.044900
		loss: 0.044900
		loss: 0.044800
		loss: 0.044800
		loss: 0.044800
		loss: 0.044700
		loss: 0.044700
		loss: 0.044700
		loss: 0.044700
		loss: 0.044600
		loss: 0.044600
		loss: 0.044600
		loss: 0.044500
		loss: 0.044500
		loss: 0.044500
		loss: 0.044500
		loss: 0.044400
		loss: 0.044400
		loss: 0.044400
		loss: 0.044400
		loss: 0.044300
		loss: 0.044300
		loss: 0.044300
		loss: 0.044300
		loss: 0.044200
		loss: 0.044200
		loss: 0.044200
		loss: 0.044200
		loss: 0.044200
		loss: 0.044100
		loss: 0.044100
		loss: 0.044100
		loss: 0.044100
		loss: 0.044000
		loss: 0.044000
		loss: 0.044000
		loss: 0.044000
		loss: 0.043900
		loss: 0.043900
		loss: 0.043900
		loss: 0.043900
		loss: 0.043900
		loss: 0.043800
		loss: 0.043800
		loss: 0.043800
		loss: 0.043800
		loss: 0.043800
		loss: 0.043700
		loss: 0.043700
		loss: 0.043700
		loss: 0.043700
		loss: 0.043600
		loss: 0.043600
		loss: 0.043600
		loss: 0.043600
		loss: 0.043600
		loss: 0.043500
		loss: 0.043500
		loss: 0.043500
		loss: 0.043500
		loss: 0.043500
		loss: 0.043400
		loss: 0.043400
		loss: 0.043400
		loss: 0.043400
		loss: 0.043400
		loss: 0.043300
		loss: 0.043300
		loss: 0.043300
		loss: 0.043300
		loss: 0.043300
		loss: 0.043200
		loss: 0.043200
		loss: 0.043200
		loss: 0.043200
		loss: 0.043200
		loss: 0.043200
		loss: 0.043100
		loss: 0.043100
		loss: 0.043100
		loss: 0.043100
		loss: 0.043100
		loss: 0.043000
		loss: 0.043000
		loss: 0.043000
	Overall the loss development was 0.913500 -> 0.043000

Training data for problem d-03.pddl in epoch 5:
model creation time: 10.234105825424194s
problem epoch data for epoch 5, problem epoch 1
	sampling search time: 2.4723317623138428s
	during this search the following actions were chosen:
		move d1 d2 peg2 was chosen with probability 0.937426
		move d1 peg2 d2 was chosen with probability 0.740795
	training time: 57.371482610702515s
	during the training the following losses were computed:
		loss: 1.578000
		loss: 1.460000
		loss: 1.339800
		loss: 1.217700
		loss: 1.089200
		loss: 0.962200
		loss: 0.861500
		loss: 0.803700
		loss: 0.779000
		loss: 0.760200
		loss: 0.736800
		loss: 0.706600
		loss: 0.676500
		loss: 0.651900
		loss: 0.640300
		loss: 0.636300
		loss: 0.638300
		loss: 0.639700
		loss: 0.637200
		loss: 0.631700
		loss: 0.624000
		loss: 0.614900
		loss: 0.604500
		loss: 0.597100
		loss: 0.588500
		loss: 0.579900
		loss: 0.571600
		loss: 0.563700
		loss: 0.556300
		loss: 0.549700
		loss: 0.545800
		loss: 0.542400
		loss: 0.538800
		loss: 0.534600
		loss: 0.529000
		loss: 0.522300
		loss: 0.514400
		loss: 0.506100
		loss: 0.499600
		loss: 0.495600
		loss: 0.492100
		loss: 0.488400
		loss: 0.484400
		loss: 0.479800
		loss: 0.475400
		loss: 0.470800
		loss: 0.465700
		loss: 0.461400
		loss: 0.457300
		loss: 0.453100
		loss: 0.448800
		loss: 0.444400
		loss: 0.439400
		loss: 0.433900
		loss: 0.429500
		loss: 0.425000
		loss: 0.420700
		loss: 0.417300
		loss: 0.413400
		loss: 0.409400
		loss: 0.405200
		loss: 0.400800
		loss: 0.397000
		loss: 0.392400
		loss: 0.388700
		loss: 0.385200
		loss: 0.381100
		loss: 0.376900
		loss: 0.373100
		loss: 0.369300
		loss: 0.366400
		loss: 0.362500
		loss: 0.358000
		loss: 0.354900
		loss: 0.351600
		loss: 0.347600
		loss: 0.343800
		loss: 0.340200
		loss: 0.337400
		loss: 0.334000
		loss: 0.330600
		loss: 0.327600
		loss: 0.324200
		loss: 0.321200
		loss: 0.317900
		loss: 0.314500
		loss: 0.311000
		loss: 0.308600
		loss: 0.305600
		loss: 0.302400
		loss: 0.300000
		loss: 0.297300
		loss: 0.294700
		loss: 0.291800
		loss: 0.288900
		loss: 0.285900
		loss: 0.283200
		loss: 0.280400
		loss: 0.277500
		loss: 0.274900
		loss: 0.272200
		loss: 0.269600
		loss: 0.267000
		loss: 0.264400
		loss: 0.262400
		loss: 0.260100
		loss: 0.257600
		loss: 0.255400
		loss: 0.253300
		loss: 0.251200
		loss: 0.249200
		loss: 0.247200
		loss: 0.244800
		loss: 0.243200
		loss: 0.240600
		loss: 0.238700
		loss: 0.236800
		loss: 0.234400
		loss: 0.232500
		loss: 0.230600
		loss: 0.228300
		loss: 0.226600
		loss: 0.224500
		loss: 0.222600
		loss: 0.221100
		loss: 0.218500
		loss: 0.217200
		loss: 0.215100
		loss: 0.213400
		loss: 0.211600
		loss: 0.210000
		loss: 0.208400
		loss: 0.206400
		loss: 0.204800
		loss: 0.203200
		loss: 0.201400
		loss: 0.199800
		loss: 0.198200
		loss: 0.196500
		loss: 0.194900
		loss: 0.193400
		loss: 0.191900
		loss: 0.190100
		loss: 0.188500
		loss: 0.186600
		loss: 0.185300
		loss: 0.183300
		loss: 0.181900
		loss: 0.180400
		loss: 0.178500
		loss: 0.177200
		loss: 0.175400
		loss: 0.174000
		loss: 0.172600
		loss: 0.170900
		loss: 0.168900
		loss: 0.167900
		loss: 0.166200
		loss: 0.164600
		loss: 0.163200
		loss: 0.161600
		loss: 0.160200
		loss: 0.158700
		loss: 0.157400
		loss: 0.156200
		loss: 0.154600
		loss: 0.153500
		loss: 0.152100
		loss: 0.150700
		loss: 0.149300
		loss: 0.148000
		loss: 0.146700
		loss: 0.145300
		loss: 0.143900
		loss: 0.142500
		loss: 0.141200
		loss: 0.139900
		loss: 0.138700
		loss: 0.137300
		loss: 0.136000
		loss: 0.134500
		loss: 0.133400
		loss: 0.132200
		loss: 0.130700
		loss: 0.129500
		loss: 0.128300
		loss: 0.127100
		loss: 0.125900
		loss: 0.124700
		loss: 0.123500
		loss: 0.122400
		loss: 0.121200
		loss: 0.120000
		loss: 0.118800
		loss: 0.117800
		loss: 0.116700
		loss: 0.115800
		loss: 0.114800
		loss: 0.113700
		loss: 0.112700
		loss: 0.111600
		loss: 0.110600
		loss: 0.109800
		loss: 0.109000
		loss: 0.108200
		loss: 0.107300
		loss: 0.106500
		loss: 0.105600
		loss: 0.104800
		loss: 0.104000
		loss: 0.103300
		loss: 0.102500
		loss: 0.101900
		loss: 0.101100
		loss: 0.100400
		loss: 0.099700
		loss: 0.099100
		loss: 0.098400
		loss: 0.097700
		loss: 0.097100
		loss: 0.096500
		loss: 0.095900
		loss: 0.095300
		loss: 0.094700
		loss: 0.094200
		loss: 0.093600
		loss: 0.093200
		loss: 0.092700
		loss: 0.092200
		loss: 0.091700
		loss: 0.091200
		loss: 0.090700
		loss: 0.090300
		loss: 0.089800
		loss: 0.089400
		loss: 0.089000
		loss: 0.088600
		loss: 0.088200
		loss: 0.087800
		loss: 0.087400
		loss: 0.087100
		loss: 0.086700
		loss: 0.086300
		loss: 0.086000
		loss: 0.085700
		loss: 0.085300
		loss: 0.085000
		loss: 0.084700
		loss: 0.084400
		loss: 0.084000
		loss: 0.083700
		loss: 0.083400
		loss: 0.083100
		loss: 0.082900
		loss: 0.082600
		loss: 0.082300
		loss: 0.082000
		loss: 0.081800
		loss: 0.081500
		loss: 0.081200
		loss: 0.081000
		loss: 0.080700
		loss: 0.080500
		loss: 0.080300
		loss: 0.080000
		loss: 0.079800
		loss: 0.079600
		loss: 0.079400
		loss: 0.079200
		loss: 0.079000
		loss: 0.078800
		loss: 0.078600
		loss: 0.078400
		loss: 0.078300
		loss: 0.078100
		loss: 0.077900
		loss: 0.077700
		loss: 0.077600
		loss: 0.077400
		loss: 0.077200
		loss: 0.077100
		loss: 0.076900
		loss: 0.076800
		loss: 0.076600
		loss: 0.076500
		loss: 0.076300
		loss: 0.076200
		loss: 0.076100
		loss: 0.075900
		loss: 0.075800
		loss: 0.075700
		loss: 0.075500
		loss: 0.075400
		loss: 0.075300
		loss: 0.075200
		loss: 0.075100
		loss: 0.075000
		loss: 0.074800
		loss: 0.074700
		loss: 0.074600
	Overall the loss development was 1.578000 -> 0.074600

Epoch 6:
Training data for problem d-01.pddl in epoch 6:
model creation time: 2.102119207382202s
problem epoch data for epoch 6, problem epoch 1
	sampling search time: 0.6401174068450928s
	during this search the following actions were chosen:
	training time: 37.22157144546509s
	during the training the following losses were computed:
		loss: 0.061300
		loss: 0.060800
		loss: 0.060200
		loss: 0.059600
		loss: 0.059000
		loss: 0.058400
		loss: 0.057800
		loss: 0.057200
		loss: 0.056600
		loss: 0.056000
		loss: 0.055400
		loss: 0.054800
		loss: 0.054300
		loss: 0.053700
		loss: 0.053100
		loss: 0.052600
		loss: 0.052100
		loss: 0.051500
		loss: 0.051000
		loss: 0.050400
		loss: 0.049900
		loss: 0.049400
		loss: 0.048900
		loss: 0.048400
		loss: 0.047900
		loss: 0.047400
		loss: 0.046900
		loss: 0.046400
		loss: 0.046000
		loss: 0.045500
		loss: 0.045000
		loss: 0.044600
		loss: 0.044100
		loss: 0.043700
		loss: 0.043200
		loss: 0.042800
		loss: 0.042300
		loss: 0.041900
		loss: 0.041500
		loss: 0.041100
		loss: 0.040700
		loss: 0.040300
		loss: 0.039900
		loss: 0.039500
		loss: 0.039100
		loss: 0.038700
		loss: 0.038300
		loss: 0.037900
		loss: 0.037600
		loss: 0.037200
		loss: 0.036900
		loss: 0.036500
		loss: 0.036200
		loss: 0.035800
		loss: 0.035500
		loss: 0.035200
		loss: 0.034900
		loss: 0.034600
		loss: 0.034300
		loss: 0.034000
		loss: 0.033700
		loss: 0.033400
		loss: 0.033100
		loss: 0.032800
		loss: 0.032500
		loss: 0.032300
		loss: 0.032000
		loss: 0.031800
		loss: 0.031500
		loss: 0.031300
		loss: 0.031000
		loss: 0.030800
		loss: 0.030600
		loss: 0.030300
		loss: 0.030100
		loss: 0.029900
		loss: 0.029700
		loss: 0.029500
		loss: 0.029300
		loss: 0.029100
		loss: 0.028900
		loss: 0.028700
		loss: 0.028500
		loss: 0.028300
		loss: 0.028100
		loss: 0.027900
		loss: 0.027700
		loss: 0.027500
		loss: 0.027400
		loss: 0.027200
		loss: 0.027000
		loss: 0.026900
		loss: 0.026700
		loss: 0.026500
		loss: 0.026400
		loss: 0.026200
		loss: 0.026100
		loss: 0.025900
		loss: 0.025800
		loss: 0.025600
		loss: 0.025500
		loss: 0.025400
		loss: 0.025200
		loss: 0.025100
		loss: 0.025000
		loss: 0.024800
		loss: 0.024700
		loss: 0.024600
		loss: 0.024500
		loss: 0.024400
		loss: 0.024200
		loss: 0.024100
		loss: 0.024000
		loss: 0.023900
		loss: 0.023800
		loss: 0.023700
		loss: 0.023600
		loss: 0.023500
		loss: 0.023400
		loss: 0.023300
		loss: 0.023200
		loss: 0.023100
		loss: 0.023000
		loss: 0.022900
		loss: 0.022800
		loss: 0.022700
		loss: 0.022600
		loss: 0.022500
		loss: 0.022400
		loss: 0.022300
		loss: 0.022200
		loss: 0.022100
		loss: 0.022000
		loss: 0.022000
		loss: 0.021900
		loss: 0.021800
		loss: 0.021700
		loss: 0.021600
		loss: 0.021500
		loss: 0.021500
		loss: 0.021400
		loss: 0.021300
		loss: 0.021200
		loss: 0.021200
		loss: 0.021100
		loss: 0.021000
		loss: 0.020900
		loss: 0.020900
		loss: 0.020800
		loss: 0.020700
		loss: 0.020700
		loss: 0.020600
		loss: 0.020500
		loss: 0.020500
		loss: 0.020400
		loss: 0.020300
		loss: 0.020300
		loss: 0.020200
		loss: 0.020200
		loss: 0.020100
		loss: 0.020000
		loss: 0.020000
		loss: 0.019900
		loss: 0.019900
		loss: 0.019800
		loss: 0.019700
		loss: 0.019700
		loss: 0.019600
		loss: 0.019600
		loss: 0.019500
		loss: 0.019500
		loss: 0.019400
		loss: 0.019400
		loss: 0.019300
		loss: 0.019300
		loss: 0.019200
		loss: 0.019200
		loss: 0.019100
		loss: 0.019100
		loss: 0.019000
		loss: 0.019000
		loss: 0.018900
		loss: 0.018900
		loss: 0.018800
		loss: 0.018800
		loss: 0.018700
		loss: 0.018700
		loss: 0.018600
		loss: 0.018600
		loss: 0.018600
		loss: 0.018500
		loss: 0.018500
		loss: 0.018400
		loss: 0.018400
		loss: 0.018300
		loss: 0.018300
		loss: 0.018300
		loss: 0.018200
		loss: 0.018200
		loss: 0.018100
		loss: 0.018100
		loss: 0.018100
		loss: 0.018000
		loss: 0.018000
		loss: 0.018000
		loss: 0.017900
		loss: 0.017900
		loss: 0.017900
		loss: 0.017800
		loss: 0.017800
		loss: 0.017800
		loss: 0.017700
		loss: 0.017700
		loss: 0.017700
		loss: 0.017600
		loss: 0.017600
		loss: 0.017600
		loss: 0.017500
		loss: 0.017500
		loss: 0.017500
		loss: 0.017400
		loss: 0.017400
		loss: 0.017400
		loss: 0.017400
		loss: 0.017300
		loss: 0.017300
		loss: 0.017300
		loss: 0.017200
		loss: 0.017200
		loss: 0.017200
		loss: 0.017200
		loss: 0.017100
		loss: 0.017100
		loss: 0.017100
		loss: 0.017100
		loss: 0.017000
		loss: 0.017000
		loss: 0.017000
		loss: 0.017000
		loss: 0.016900
		loss: 0.016900
		loss: 0.016900
		loss: 0.016900
		loss: 0.016800
		loss: 0.016800
		loss: 0.016800
		loss: 0.016800
		loss: 0.016700
		loss: 0.016700
		loss: 0.016700
		loss: 0.016700
		loss: 0.016700
		loss: 0.016600
		loss: 0.016600
		loss: 0.016600
		loss: 0.016600
		loss: 0.016500
		loss: 0.016500
		loss: 0.016500
		loss: 0.016500
		loss: 0.016500
		loss: 0.016400
		loss: 0.016400
		loss: 0.016400
		loss: 0.016400
		loss: 0.016400
		loss: 0.016300
		loss: 0.016300
		loss: 0.016300
		loss: 0.016300
		loss: 0.016300
		loss: 0.016300
		loss: 0.016200
		loss: 0.016200
		loss: 0.016200
		loss: 0.016200
		loss: 0.016200
		loss: 0.016200
		loss: 0.016100
		loss: 0.016100
		loss: 0.016100
		loss: 0.016100
		loss: 0.016100
		loss: 0.016100
		loss: 0.016000
		loss: 0.016000
		loss: 0.016000
		loss: 0.016000
		loss: 0.016000
		loss: 0.016000
		loss: 0.015900
		loss: 0.015900
		loss: 0.015900
		loss: 0.015900
		loss: 0.015900
		loss: 0.015900
		loss: 0.015900
		loss: 0.015800
		loss: 0.015800
		loss: 0.015800
	Overall the loss development was 0.061300 -> 0.015800

Training data for problem d-02.pddl in epoch 6:
model creation time: 5.253549814224243s
problem epoch data for epoch 6, problem epoch 1
	sampling search time: 1.2857613563537598s
	during this search the following actions were chosen:
		move d1 d2 peg1 was chosen with probability 0.575146
		move d1 peg1 d2 was chosen with probability 0.658005
	training time: 44.475858211517334s
	during the training the following losses were computed:
		loss: 0.907200
		loss: 0.888900
		loss: 0.872500
		loss: 0.857400
		loss: 0.844100
		loss: 0.831600
		loss: 0.820300
		loss: 0.810100
		loss: 0.801000
		loss: 0.793300
		loss: 0.786500
		loss: 0.779900
		loss: 0.773500
		loss: 0.767000
		loss: 0.760900
		loss: 0.755600
		loss: 0.750800
		loss: 0.746000
		loss: 0.741400
		loss: 0.737000
		loss: 0.732800
		loss: 0.728700
		loss: 0.724500
		loss: 0.720400
		loss: 0.716400
		loss: 0.712200
		loss: 0.707900
		loss: 0.703600
		loss: 0.699200
		loss: 0.695000
		loss: 0.690700
		loss: 0.686200
		loss: 0.681400
		loss: 0.676700
		loss: 0.672200
		loss: 0.667500
		loss: 0.663500
		loss: 0.659500
		loss: 0.654200
		loss: 0.649500
		loss: 0.644500
		loss: 0.639600
		loss: 0.634400
		loss: 0.629000
		loss: 0.623800
		loss: 0.618200
		loss: 0.612300
		loss: 0.607400
		loss: 0.601600
		loss: 0.596100
		loss: 0.590500
		loss: 0.584500
		loss: 0.579000
		loss: 0.573000
		loss: 0.567900
		loss: 0.561400
		loss: 0.555400
		loss: 0.549500
		loss: 0.543700
		loss: 0.537800
		loss: 0.532100
		loss: 0.526200
		loss: 0.520200
		loss: 0.514200
		loss: 0.508200
		loss: 0.502600
		loss: 0.496300
		loss: 0.490300
		loss: 0.484400
		loss: 0.478000
		loss: 0.471900
		loss: 0.465600
		loss: 0.459300
		loss: 0.452700
		loss: 0.445900
		loss: 0.439000
		loss: 0.431800
		loss: 0.424300
		loss: 0.417200
		loss: 0.410100
		loss: 0.402700
		loss: 0.395400
		loss: 0.388200
		loss: 0.380800
		loss: 0.373500
		loss: 0.366100
		loss: 0.358900
		loss: 0.351900
		loss: 0.344900
		loss: 0.338300
		loss: 0.331700
		loss: 0.325200
		loss: 0.318700
		loss: 0.312500
		loss: 0.306300
		loss: 0.300200
		loss: 0.293800
		loss: 0.287800
		loss: 0.281700
		loss: 0.275600
		loss: 0.269300
		loss: 0.263200
		loss: 0.257100
		loss: 0.251100
		loss: 0.245300
		loss: 0.239400
		loss: 0.233500
		loss: 0.227700
		loss: 0.221900
		loss: 0.215900
		loss: 0.210400
		loss: 0.204800
		loss: 0.199300
		loss: 0.194100
		loss: 0.188700
		loss: 0.183100
		loss: 0.176700
		loss: 0.170000
		loss: 0.163700
		loss: 0.157400
		loss: 0.151000
		loss: 0.144500
		loss: 0.137800
		loss: 0.131000
		loss: 0.125800
		loss: 0.120600
		loss: 0.116100
		loss: 0.111900
		loss: 0.107900
		loss: 0.104400
		loss: 0.101100
		loss: 0.098100
		loss: 0.095300
		loss: 0.092400
		loss: 0.089700
		loss: 0.087400
		loss: 0.085000
		loss: 0.082800
		loss: 0.080700
		loss: 0.078600
		loss: 0.076600
		loss: 0.074700
		loss: 0.072900
		loss: 0.071200
		loss: 0.069700
		loss: 0.068400
		loss: 0.067100
		loss: 0.066000
		loss: 0.064900
		loss: 0.063900
		loss: 0.062900
		loss: 0.062000
		loss: 0.061100
		loss: 0.060300
		loss: 0.059500
		loss: 0.058900
		loss: 0.058200
		loss: 0.057700
		loss: 0.057100
		loss: 0.056500
		loss: 0.056000
		loss: 0.055500
		loss: 0.055100
		loss: 0.054700
		loss: 0.054200
		loss: 0.053900
		loss: 0.053500
		loss: 0.053200
		loss: 0.052900
		loss: 0.052600
		loss: 0.052300
		loss: 0.052000
		loss: 0.051800
		loss: 0.051500
		loss: 0.051300
		loss: 0.051100
		loss: 0.050900
		loss: 0.050700
		loss: 0.050500
		loss: 0.050300
		loss: 0.050100
		loss: 0.049900
		loss: 0.049800
		loss: 0.049600
		loss: 0.049500
		loss: 0.049300
		loss: 0.049200
		loss: 0.049100
		loss: 0.049000
		loss: 0.048800
		loss: 0.048700
		loss: 0.048600
		loss: 0.048500
		loss: 0.048400
		loss: 0.048300
		loss: 0.048200
		loss: 0.048100
		loss: 0.048000
		loss: 0.047900
		loss: 0.047800
		loss: 0.047700
		loss: 0.047700
		loss: 0.047600
		loss: 0.047500
		loss: 0.047400
		loss: 0.047300
		loss: 0.047300
		loss: 0.047200
		loss: 0.047100
		loss: 0.047100
		loss: 0.047000
		loss: 0.046900
		loss: 0.046900
		loss: 0.046800
		loss: 0.046800
		loss: 0.046700
		loss: 0.046600
		loss: 0.046600
		loss: 0.046500
		loss: 0.046500
		loss: 0.046400
		loss: 0.046400
		loss: 0.046300
		loss: 0.046300
		loss: 0.046200
		loss: 0.046200
		loss: 0.046100
		loss: 0.046100
		loss: 0.046000
		loss: 0.046000
		loss: 0.045900
		loss: 0.045900
		loss: 0.045800
		loss: 0.045800
		loss: 0.045700
		loss: 0.045700
		loss: 0.045700
		loss: 0.045600
		loss: 0.045600
		loss: 0.045500
		loss: 0.045500
		loss: 0.045500
		loss: 0.045400
		loss: 0.045400
		loss: 0.045300
		loss: 0.045300
		loss: 0.045300
		loss: 0.045200
		loss: 0.045200
		loss: 0.045200
		loss: 0.045100
		loss: 0.045100
		loss: 0.045100
		loss: 0.045000
		loss: 0.045000
		loss: 0.044900
		loss: 0.044900
		loss: 0.044900
		loss: 0.044800
		loss: 0.044800
		loss: 0.044800
		loss: 0.044800
		loss: 0.044700
		loss: 0.044700
		loss: 0.044700
		loss: 0.044600
		loss: 0.044600
		loss: 0.044600
		loss: 0.044500
		loss: 0.044500
		loss: 0.044500
		loss: 0.044400
		loss: 0.044400
		loss: 0.044400
		loss: 0.044400
		loss: 0.044300
		loss: 0.044300
		loss: 0.044300
		loss: 0.044300
		loss: 0.044200
		loss: 0.044200
		loss: 0.044200
		loss: 0.044100
		loss: 0.044100
		loss: 0.044100
		loss: 0.044100
		loss: 0.044000
		loss: 0.044000
		loss: 0.044000
		loss: 0.044000
		loss: 0.043900
		loss: 0.043900
		loss: 0.043900
		loss: 0.043900
		loss: 0.043800
		loss: 0.043800
		loss: 0.043800
		loss: 0.043800
		loss: 0.043700
		loss: 0.043700
	Overall the loss development was 0.907200 -> 0.043700

Training data for problem d-03.pddl in epoch 6:
model creation time: 10.074580192565918s
problem epoch data for epoch 6, problem epoch 1
	sampling search time: 2.4742119312286377s
	during this search the following actions were chosen:
		move d1 d2 peg2 was chosen with probability 0.875736
		move d1 peg2 d2 was chosen with probability 0.651121
	training time: 56.8268666267395s
	during the training the following losses were computed:
		loss: 1.547500
		loss: 1.425500
		loss: 1.291600
		loss: 1.186900
		loss: 1.139900
		loss: 1.092600
		loss: 1.042500
		loss: 0.991300
		loss: 0.944200
		loss: 0.901700
		loss: 0.863600
		loss: 0.828700
		loss: 0.796000
		loss: 0.765500
		loss: 0.738000
		loss: 0.711800
		loss: 0.688400
		loss: 0.666300
		loss: 0.644500
		loss: 0.622800
		loss: 0.601200
		loss: 0.580000
		loss: 0.562700
		loss: 0.546400
		loss: 0.529800
		loss: 0.514500
		loss: 0.502000
		loss: 0.489500
		loss: 0.479100
		loss: 0.470300
		loss: 0.462800
		loss: 0.457500
		loss: 0.453200
		loss: 0.449100
		loss: 0.446500
		loss: 0.443500
		loss: 0.440900
		loss: 0.437600
		loss: 0.433900
		loss: 0.429800
		loss: 0.425300
		loss: 0.420800
		loss: 0.415300
		loss: 0.409800
		loss: 0.404400
		loss: 0.398900
		loss: 0.393000
		loss: 0.387100
		loss: 0.381000
		loss: 0.375400
		loss: 0.370300
		loss: 0.365400
		loss: 0.361000
		loss: 0.357000
		loss: 0.352400
		loss: 0.347700
		loss: 0.343400
		loss: 0.338900
		loss: 0.334300
		loss: 0.329900
		loss: 0.325800
		loss: 0.322000
		loss: 0.318900
		loss: 0.315300
		loss: 0.311900
		loss: 0.308300
		loss: 0.305100
		loss: 0.301700
		loss: 0.298200
		loss: 0.294800
		loss: 0.291400
		loss: 0.288400
		loss: 0.284600
		loss: 0.281300
		loss: 0.277700
		loss: 0.274400
		loss: 0.271400
		loss: 0.268100
		loss: 0.264900
		loss: 0.262000
		loss: 0.258700
		loss: 0.255700
		loss: 0.252500
		loss: 0.250000
		loss: 0.246500
		loss: 0.244000
		loss: 0.240400
		loss: 0.237800
		loss: 0.234600
		loss: 0.231700
		loss: 0.228900
		loss: 0.225600
		loss: 0.222500
		loss: 0.220400
		loss: 0.216900
		loss: 0.215000
		loss: 0.212200
		loss: 0.208200
		loss: 0.207500
		loss: 0.203200
		loss: 0.201800
		loss: 0.199100
		loss: 0.195600
		loss: 0.194600
		loss: 0.191600
		loss: 0.187900
		loss: 0.186900
		loss: 0.183600
		loss: 0.181100
		loss: 0.180000
		loss: 0.176100
		loss: 0.174200
		loss: 0.172400
		loss: 0.169300
		loss: 0.167400
		loss: 0.166000
		loss: 0.162900
		loss: 0.161700
		loss: 0.159500
		loss: 0.156900
		loss: 0.155200
		loss: 0.152900
		loss: 0.151300
		loss: 0.149300
		loss: 0.147500
		loss: 0.145800
		loss: 0.143900
		loss: 0.142300
		loss: 0.140300
		loss: 0.138700
		loss: 0.137600
		loss: 0.135800
		loss: 0.134300
		loss: 0.133600
		loss: 0.131300
		loss: 0.129900
		loss: 0.128900
		loss: 0.126900
		loss: 0.125700
		loss: 0.124500
		loss: 0.122700
		loss: 0.122500
		loss: 0.120700
		loss: 0.120000
		loss: 0.119000
		loss: 0.117000
		loss: 0.116300
		loss: 0.115000
		loss: 0.113900
		loss: 0.113000
		loss: 0.111900
		loss: 0.110700
		loss: 0.109900
		loss: 0.108700
		loss: 0.107800
		loss: 0.107000
		loss: 0.106000
		loss: 0.105100
		loss: 0.104300
		loss: 0.103300
		loss: 0.102700
		loss: 0.101900
		loss: 0.101200
		loss: 0.100400
		loss: 0.099600
		loss: 0.098900
		loss: 0.098200
		loss: 0.097600
		loss: 0.097000
		loss: 0.096400
		loss: 0.095800
		loss: 0.095200
		loss: 0.094600
		loss: 0.094000
		loss: 0.093400
		loss: 0.092900
		loss: 0.092400
		loss: 0.091900
		loss: 0.091300
		loss: 0.091000
		loss: 0.090400
		loss: 0.090100
		loss: 0.089500
		loss: 0.089200
		loss: 0.088700
		loss: 0.088200
		loss: 0.088000
		loss: 0.087500
		loss: 0.087000
		loss: 0.086800
		loss: 0.086300
		loss: 0.086200
		loss: 0.085600
		loss: 0.085300
		loss: 0.084900
		loss: 0.084500
		loss: 0.084300
		loss: 0.083900
		loss: 0.083700
		loss: 0.083300
		loss: 0.083000
		loss: 0.082800
		loss: 0.082500
		loss: 0.082200
		loss: 0.082000
		loss: 0.081700
		loss: 0.081500
		loss: 0.081200
		loss: 0.081000
		loss: 0.080800
		loss: 0.080500
		loss: 0.080300
		loss: 0.080100
		loss: 0.079900
		loss: 0.079700
		loss: 0.079500
		loss: 0.079300
		loss: 0.079100
		loss: 0.078900
		loss: 0.078800
		loss: 0.078500
		loss: 0.078400
		loss: 0.078200
		loss: 0.078000
		loss: 0.077900
		loss: 0.077700
		loss: 0.077500
		loss: 0.077400
		loss: 0.077300
		loss: 0.077100
		loss: 0.077000
		loss: 0.076800
		loss: 0.076700
		loss: 0.076500
		loss: 0.076400
		loss: 0.076300
		loss: 0.076200
		loss: 0.076100
		loss: 0.075900
		loss: 0.075800
		loss: 0.075700
		loss: 0.075600
		loss: 0.075500
		loss: 0.075300
		loss: 0.075300
		loss: 0.075100
		loss: 0.075100
		loss: 0.074900
		loss: 0.074800
		loss: 0.074800
		loss: 0.074600
		loss: 0.074500
		loss: 0.074400
		loss: 0.074400
		loss: 0.074200
		loss: 0.074100
		loss: 0.074100
		loss: 0.074000
		loss: 0.073900
		loss: 0.073800
		loss: 0.073700
		loss: 0.073600
		loss: 0.073600
		loss: 0.073500
		loss: 0.073400
		loss: 0.073300
		loss: 0.073200
		loss: 0.073100
		loss: 0.073100
		loss: 0.073100
		loss: 0.072900
		loss: 0.072900
		loss: 0.072900
		loss: 0.072800
		loss: 0.072700
		loss: 0.072700
		loss: 0.072600
		loss: 0.072500
		loss: 0.072500
		loss: 0.072300
		loss: 0.072300
		loss: 0.072200
		loss: 0.072100
		loss: 0.072100
		loss: 0.072000
		loss: 0.071900
		loss: 0.071900
		loss: 0.071800
		loss: 0.071700
		loss: 0.071700
		loss: 0.071600
		loss: 0.071600
		loss: 0.071500
		loss: 0.071400
		loss: 0.071400
		loss: 0.071300
		loss: 0.071300
		loss: 0.071200
		loss: 0.071100
		loss: 0.071100
	Overall the loss development was 1.547500 -> 0.071100

Epoch 7:
Training data for problem d-01.pddl in epoch 7:
model creation time: 2.079613208770752s
problem epoch data for epoch 7, problem epoch 1
	sampling search time: 0.601980447769165s
	during this search the following actions were chosen:
	training time: 36.58960700035095s
	during the training the following losses were computed:
		loss: 0.061400
		loss: 0.060700
		loss: 0.060100
		loss: 0.059500
		loss: 0.058900
		loss: 0.058300
		loss: 0.057700
		loss: 0.057100
		loss: 0.056500
		loss: 0.055900
		loss: 0.055400
		loss: 0.054800
		loss: 0.054200
		loss: 0.053700
		loss: 0.053100
		loss: 0.052600
		loss: 0.052000
		loss: 0.051500
		loss: 0.050900
		loss: 0.050400
		loss: 0.049900
		loss: 0.049400
		loss: 0.048900
		loss: 0.048400
		loss: 0.047900
		loss: 0.047400
		loss: 0.046900
		loss: 0.046400
		loss: 0.045900
		loss: 0.045500
		loss: 0.045000
		loss: 0.044500
		loss: 0.044100
		loss: 0.043600
		loss: 0.043200
		loss: 0.042700
		loss: 0.042300
		loss: 0.041900
		loss: 0.041400
		loss: 0.041000
		loss: 0.040600
		loss: 0.040200
		loss: 0.039800
		loss: 0.039400
		loss: 0.039000
		loss: 0.038600
		loss: 0.038200
		loss: 0.037900
		loss: 0.037500
		loss: 0.037100
		loss: 0.036800
		loss: 0.036400
		loss: 0.036100
		loss: 0.035700
		loss: 0.035400
		loss: 0.035000
		loss: 0.034700
		loss: 0.034400
		loss: 0.034100
		loss: 0.033800
		loss: 0.033400
		loss: 0.033100
		loss: 0.032800
		loss: 0.032500
		loss: 0.032200
		loss: 0.032000
		loss: 0.031700
		loss: 0.031400
		loss: 0.031100
		loss: 0.030900
		loss: 0.030600
		loss: 0.030400
		loss: 0.030100
		loss: 0.029900
		loss: 0.029600
		loss: 0.029400
		loss: 0.029200
		loss: 0.029000
		loss: 0.028700
		loss: 0.028500
		loss: 0.028300
		loss: 0.028100
		loss: 0.027900
		loss: 0.027700
		loss: 0.027500
		loss: 0.027300
		loss: 0.027100
		loss: 0.026900
		loss: 0.026800
		loss: 0.026600
		loss: 0.026400
		loss: 0.026300
		loss: 0.026100
		loss: 0.025900
		loss: 0.025800
		loss: 0.025600
		loss: 0.025500
		loss: 0.025300
		loss: 0.025200
		loss: 0.025100
		loss: 0.024900
		loss: 0.024800
		loss: 0.024600
		loss: 0.024500
		loss: 0.024400
		loss: 0.024300
		loss: 0.024200
		loss: 0.024000
		loss: 0.023900
		loss: 0.023800
		loss: 0.023700
		loss: 0.023600
		loss: 0.023500
		loss: 0.023400
		loss: 0.023300
		loss: 0.023200
		loss: 0.023100
		loss: 0.022900
		loss: 0.022800
		loss: 0.022700
		loss: 0.022600
		loss: 0.022600
		loss: 0.022500
		loss: 0.022400
		loss: 0.022300
		loss: 0.022200
		loss: 0.022100
		loss: 0.022000
		loss: 0.021900
		loss: 0.021900
		loss: 0.021800
		loss: 0.021700
		loss: 0.021600
		loss: 0.021500
		loss: 0.021500
		loss: 0.021400
		loss: 0.021300
		loss: 0.021200
		loss: 0.021200
		loss: 0.021100
		loss: 0.021000
		loss: 0.020900
		loss: 0.020900
		loss: 0.020800
		loss: 0.020700
		loss: 0.020700
		loss: 0.020600
		loss: 0.020600
		loss: 0.020500
		loss: 0.020400
		loss: 0.020400
		loss: 0.020300
		loss: 0.020200
		loss: 0.020200
		loss: 0.020100
		loss: 0.020100
		loss: 0.020000
		loss: 0.019900
		loss: 0.019900
		loss: 0.019800
		loss: 0.019800
		loss: 0.019700
		loss: 0.019700
		loss: 0.019600
		loss: 0.019600
		loss: 0.019500
		loss: 0.019500
		loss: 0.019400
		loss: 0.019400
		loss: 0.019300
		loss: 0.019300
		loss: 0.019200
		loss: 0.019200
		loss: 0.019100
		loss: 0.019100
		loss: 0.019000
		loss: 0.019000
		loss: 0.018900
		loss: 0.018900
		loss: 0.018800
		loss: 0.018800
		loss: 0.018800
		loss: 0.018700
		loss: 0.018700
		loss: 0.018600
		loss: 0.018600
		loss: 0.018600
		loss: 0.018500
		loss: 0.018500
		loss: 0.018400
		loss: 0.018400
		loss: 0.018400
		loss: 0.018300
		loss: 0.018300
		loss: 0.018200
		loss: 0.018200
		loss: 0.018200
		loss: 0.018100
		loss: 0.018100
		loss: 0.018100
		loss: 0.018000
		loss: 0.018000
		loss: 0.018000
		loss: 0.017900
		loss: 0.017900
		loss: 0.017900
		loss: 0.017800
		loss: 0.017800
		loss: 0.017800
		loss: 0.017700
		loss: 0.017700
		loss: 0.017700
		loss: 0.017600
		loss: 0.017600
		loss: 0.017600
		loss: 0.017500
		loss: 0.017500
		loss: 0.017500
		loss: 0.017500
		loss: 0.017400
		loss: 0.017400
		loss: 0.017400
		loss: 0.017300
		loss: 0.017300
		loss: 0.017300
		loss: 0.017300
		loss: 0.017200
		loss: 0.017200
		loss: 0.017200
		loss: 0.017200
		loss: 0.017100
		loss: 0.017100
		loss: 0.017100
		loss: 0.017000
		loss: 0.017000
		loss: 0.017000
		loss: 0.017000
		loss: 0.016900
		loss: 0.016900
		loss: 0.016900
		loss: 0.016900
		loss: 0.016900
		loss: 0.016800
		loss: 0.016800
		loss: 0.016800
		loss: 0.016800
		loss: 0.016700
		loss: 0.016700
		loss: 0.016700
		loss: 0.016700
		loss: 0.016700
		loss: 0.016600
		loss: 0.016600
		loss: 0.016600
		loss: 0.016600
		loss: 0.016600
		loss: 0.016500
		loss: 0.016500
		loss: 0.016500
		loss: 0.016500
		loss: 0.016500
		loss: 0.016400
		loss: 0.016400
		loss: 0.016400
		loss: 0.016400
		loss: 0.016400
		loss: 0.016400
		loss: 0.016300
		loss: 0.016300
		loss: 0.016300
		loss: 0.016300
		loss: 0.016300
		loss: 0.016200
		loss: 0.016200
		loss: 0.016200
		loss: 0.016200
		loss: 0.016200
		loss: 0.016200
		loss: 0.016100
		loss: 0.016100
		loss: 0.016100
		loss: 0.016100
		loss: 0.016100
		loss: 0.016100
		loss: 0.016100
		loss: 0.016000
		loss: 0.016000
		loss: 0.016000
		loss: 0.016000
		loss: 0.016000
		loss: 0.016000
		loss: 0.016000
		loss: 0.015900
		loss: 0.015900
		loss: 0.015900
		loss: 0.015900
		loss: 0.015900
		loss: 0.015900
		loss: 0.015900
		loss: 0.015900
	Overall the loss development was 0.061400 -> 0.015900

Training data for problem d-02.pddl in epoch 7:
model creation time: 5.615908861160278s
problem epoch data for epoch 7, problem epoch 1
	sampling search time: 1.4038128852844238s
	during this search the following actions were chosen:
		move d1 d2 peg1 was chosen with probability 0.578039
		move d1 peg1 d2 was chosen with probability 0.651912
	training time: 45.26615285873413s
	during the training the following losses were computed:
		loss: 0.900000
		loss: 0.882700
		loss: 0.866300
		loss: 0.850900
		loss: 0.837200
		loss: 0.825900
		loss: 0.817100
		loss: 0.808600
		loss: 0.800700
		loss: 0.793400
		loss: 0.786200
		loss: 0.779400
		loss: 0.773000
		loss: 0.767600
		loss: 0.762900
		loss: 0.758300
		loss: 0.753700
		loss: 0.749300
		loss: 0.745300
		loss: 0.741500
		loss: 0.738300
		loss: 0.735100
		loss: 0.731900
		loss: 0.728400
		loss: 0.724700
		loss: 0.720900
		loss: 0.717100
		loss: 0.713700
		loss: 0.710100
		loss: 0.706300
		loss: 0.702100
		loss: 0.698200
		loss: 0.694500
		loss: 0.691100
		loss: 0.687700
		loss: 0.684200
		loss: 0.680500
		loss: 0.676900
		loss: 0.673400
		loss: 0.669500
		loss: 0.665900
		loss: 0.661600
		loss: 0.657200
		loss: 0.653700
		loss: 0.649400
		loss: 0.644900
		loss: 0.640200
		loss: 0.635800
		loss: 0.631200
		loss: 0.627400
		loss: 0.622500
		loss: 0.618600
		loss: 0.613700
		loss: 0.608400
		loss: 0.604000
		loss: 0.598500
		loss: 0.593400
		loss: 0.588200
		loss: 0.583500
		loss: 0.578300
		loss: 0.573300
		loss: 0.567600
		loss: 0.561600
		loss: 0.555800
		loss: 0.549700
		loss: 0.543500
		loss: 0.537000
		loss: 0.530300
		loss: 0.524300
		loss: 0.518100
		loss: 0.512100
		loss: 0.506600
		loss: 0.501300
		loss: 0.495900
		loss: 0.490600
		loss: 0.485700
		loss: 0.480600
		loss: 0.475800
		loss: 0.471400
		loss: 0.466600
		loss: 0.462300
		loss: 0.457900
		loss: 0.453600
		loss: 0.448900
		loss: 0.444600
		loss: 0.440700
		loss: 0.436900
		loss: 0.433000
		loss: 0.429300
		loss: 0.425700
		loss: 0.422100
		loss: 0.418600
		loss: 0.415200
		loss: 0.412000
		loss: 0.408900
		loss: 0.405300
		loss: 0.402400
		loss: 0.398900
		loss: 0.395600
		loss: 0.392200
		loss: 0.389200
		loss: 0.386000
		loss: 0.382900
		loss: 0.379900
		loss: 0.376900
		loss: 0.373900
		loss: 0.370700
		loss: 0.367600
		loss: 0.364900
		loss: 0.361900
		loss: 0.358800
		loss: 0.355500
		loss: 0.352300
		loss: 0.349400
		loss: 0.346800
		loss: 0.343600
		loss: 0.340000
		loss: 0.336400
		loss: 0.333100
		loss: 0.329900
		loss: 0.327000
		loss: 0.323800
		loss: 0.320400
		loss: 0.317500
		loss: 0.314300
		loss: 0.311600
		loss: 0.308800
		loss: 0.305900
		loss: 0.302300
		loss: 0.299200
		loss: 0.296700
		loss: 0.294100
		loss: 0.290700
		loss: 0.288300
		loss: 0.285200
		loss: 0.282900
		loss: 0.280100
		loss: 0.276800
		loss: 0.274000
		loss: 0.271200
		loss: 0.268200
		loss: 0.265300
		loss: 0.262600
		loss: 0.259800
		loss: 0.256800
		loss: 0.254000
		loss: 0.251200
		loss: 0.248700
		loss: 0.245600
		loss: 0.243200
		loss: 0.240600
		loss: 0.237900
		loss: 0.235600
		loss: 0.233200
		loss: 0.230400
		loss: 0.228000
		loss: 0.225900
		loss: 0.223500
		loss: 0.221100
		loss: 0.218900
		loss: 0.216600
		loss: 0.214800
		loss: 0.213000
		loss: 0.211500
		loss: 0.210000
		loss: 0.208400
		loss: 0.207100
		loss: 0.205900
		loss: 0.204600
		loss: 0.203300
		loss: 0.202200
		loss: 0.201300
		loss: 0.200900
		loss: 0.199400
		loss: 0.198600
		loss: 0.198000
		loss: 0.197400
		loss: 0.196800
		loss: 0.196200
		loss: 0.195500
		loss: 0.194900
		loss: 0.194200
		loss: 0.193500
		loss: 0.193300
		loss: 0.192600
		loss: 0.191900
		loss: 0.191500
		loss: 0.191100
		loss: 0.190700
		loss: 0.190400
		loss: 0.190000
		loss: 0.189700
		loss: 0.189400
		loss: 0.189100
		loss: 0.188800
		loss: 0.188400
		loss: 0.188100
		loss: 0.188000
		loss: 0.187600
		loss: 0.187400
		loss: 0.187300
		loss: 0.187100
		loss: 0.187000
		loss: 0.186800
		loss: 0.186600
		loss: 0.186400
		loss: 0.186300
		loss: 0.186100
		loss: 0.186100
		loss: 0.186000
		loss: 0.185800
		loss: 0.185700
		loss: 0.185600
		loss: 0.185800
		loss: 0.185400
		loss: 0.185200
		loss: 0.185100
		loss: 0.185000
		loss: 0.184900
		loss: 0.184800
		loss: 0.184700
		loss: 0.184500
		loss: 0.184400
		loss: 0.184400
		loss: 0.184200
		loss: 0.184100
		loss: 0.184100
		loss: 0.184000
		loss: 0.183900
		loss: 0.184100
		loss: 0.183900
		loss: 0.183900
		loss: 0.183900
		loss: 0.183900
		loss: 0.183800
		loss: 0.183800
		loss: 0.183700
		loss: 0.183600
		loss: 0.183500
		loss: 0.183500
		loss: 0.183400
		loss: 0.183300
		loss: 0.183200
		loss: 0.183100
		loss: 0.183100
		loss: 0.183000
		loss: 0.182900
		loss: 0.182900
		loss: 0.182800
		loss: 0.183000
		loss: 0.182700
		loss: 0.182700
		loss: 0.182700
		loss: 0.182600
		loss: 0.182600
		loss: 0.182500
		loss: 0.182500
		loss: 0.182500
		loss: 0.182400
		loss: 0.182400
		loss: 0.182300
		loss: 0.182300
		loss: 0.182400
		loss: 0.182300
		loss: 0.182300
		loss: 0.182300
		loss: 0.182300
		loss: 0.182300
		loss: 0.182200
		loss: 0.182200
		loss: 0.182300
		loss: 0.182100
		loss: 0.182100
		loss: 0.182000
		loss: 0.182000
		loss: 0.182000
		loss: 0.181900
		loss: 0.182000
		loss: 0.181900
		loss: 0.181900
		loss: 0.181900
		loss: 0.181800
		loss: 0.181900
		loss: 0.181800
		loss: 0.181800
		loss: 0.181800
		loss: 0.181800
		loss: 0.181800
		loss: 0.181700
		loss: 0.181700
		loss: 0.181700
		loss: 0.181600
		loss: 0.181600
		loss: 0.181600
		loss: 0.181600
		loss: 0.181500
		loss: 0.181400
		loss: 0.181400
		loss: 0.181400
		loss: 0.181400
	Overall the loss development was 0.900000 -> 0.181400

Training data for problem d-03.pddl in epoch 7:
model creation time: 10.52057695388794s
problem epoch data for epoch 7, problem epoch 1
	sampling search time: 2.483436107635498s
	during this search the following actions were chosen:
		move d1 d2 peg2 was chosen with probability 0.819427
		move d1 peg2 d2 was chosen with probability 0.991995
	training time: 57.698466539382935s
	during the training the following losses were computed:
		loss: 2.266900
		loss: 2.106400
		loss: 1.948400
		loss: 1.794800
		loss: 1.653000
		loss: 1.528700
		loss: 1.426500
		loss: 1.342300
		loss: 1.300000
		loss: 1.268000
		loss: 1.212900
		loss: 1.154000
		loss: 1.097000
		loss: 1.062600
		loss: 1.034200
		loss: 1.013700
		loss: 0.992500
		loss: 0.970300
		loss: 0.947100
		loss: 0.925400
		loss: 0.906100
		loss: 0.888200
		loss: 0.871800
		loss: 0.856200
		loss: 0.844200
		loss: 0.830200
		loss: 0.816300
		loss: 0.808000
		loss: 0.801200
		loss: 0.792100
		loss: 0.781800
		loss: 0.771400
		loss: 0.759100
		loss: 0.745500
		loss: 0.736800
		loss: 0.731100
		loss: 0.725600
		loss: 0.720900
		loss: 0.716500
		loss: 0.712300
		loss: 0.708200
		loss: 0.703600
		loss: 0.698600
		loss: 0.694200
		loss: 0.689500
		loss: 0.683600
		loss: 0.680200
		loss: 0.676500
		loss: 0.672400
		loss: 0.668700
		loss: 0.665600
		loss: 0.662800
		loss: 0.659800
		loss: 0.656900
		loss: 0.653900
		loss: 0.650900
		loss: 0.647400
		loss: 0.644100
		loss: 0.640700
		loss: 0.636700
		loss: 0.632800
		loss: 0.628700
		loss: 0.624100
		loss: 0.619200
		loss: 0.614600
		loss: 0.609800
		loss: 0.604800
		loss: 0.599500
		loss: 0.594500
		loss: 0.589300
		loss: 0.584100
		loss: 0.579300
		loss: 0.574400
		loss: 0.569800
		loss: 0.565100
		loss: 0.560100
		loss: 0.554700
		loss: 0.550200
		loss: 0.545400
		loss: 0.540900
		loss: 0.536500
		loss: 0.531800
		loss: 0.527400
		loss: 0.524500
		loss: 0.519900
		loss: 0.516900
		loss: 0.512600
		loss: 0.509100
		loss: 0.505600
		loss: 0.501300
		loss: 0.497400
		loss: 0.492900
		loss: 0.488900
		loss: 0.485700
		loss: 0.481500
		loss: 0.477800
		loss: 0.472800
		loss: 0.469800
		loss: 0.464400
		loss: 0.461000
		loss: 0.456600
		loss: 0.451600
		loss: 0.448300
		loss: 0.443100
		loss: 0.439700
		loss: 0.434000
		loss: 0.429300
		loss: 0.427500
		loss: 0.422200
		loss: 0.418900
		loss: 0.413300
		loss: 0.410600
		loss: 0.406000
		loss: 0.400400
		loss: 0.395600
		loss: 0.391800
		loss: 0.386300
		loss: 0.384100
		loss: 0.376500
		loss: 0.374000
		loss: 0.367400
		loss: 0.366400
		loss: 0.358600
		loss: 0.354400
		loss: 0.352500
		loss: 0.345300
		loss: 0.344700
		loss: 0.340000
		loss: 0.331700
		loss: 0.335700
		loss: 0.329900
		loss: 0.319100
		loss: 0.317600
		loss: 0.312500
		loss: 0.305400
		loss: 0.305300
		loss: 0.296700
		loss: 0.297400
		loss: 0.295800
		loss: 0.289800
		loss: 0.281900
		loss: 0.282600
		loss: 0.278900
		loss: 0.269800
		loss: 0.268300
		loss: 0.264800
		loss: 0.259100
		loss: 0.255800
		loss: 0.251800
		loss: 0.248000
		loss: 0.245000
		loss: 0.241500
		loss: 0.238300
		loss: 0.235000
		loss: 0.231600
		loss: 0.228700
		loss: 0.225400
		loss: 0.222400
		loss: 0.219800
		loss: 0.217800
		loss: 0.214100
		loss: 0.213500
		loss: 0.208500
		loss: 0.206700
		loss: 0.204100
		loss: 0.200800
		loss: 0.198700
		loss: 0.195800
		loss: 0.194100
		loss: 0.191500
		loss: 0.188500
		loss: 0.187000
		loss: 0.184300
		loss: 0.182600
		loss: 0.179800
		loss: 0.177400
		loss: 0.176000
		loss: 0.173500
		loss: 0.172200
		loss: 0.169200
		loss: 0.167500
		loss: 0.165300
		loss: 0.163100
		loss: 0.161300
		loss: 0.159300
		loss: 0.157500
		loss: 0.155500
		loss: 0.154100
		loss: 0.152100
		loss: 0.150700
		loss: 0.148800
		loss: 0.147400
		loss: 0.145600
		loss: 0.144200
		loss: 0.142600
		loss: 0.140900
		loss: 0.139700
		loss: 0.137900
		loss: 0.136800
		loss: 0.135300
		loss: 0.134100
		loss: 0.132500
		loss: 0.131400
		loss: 0.130000
		loss: 0.128800
		loss: 0.127600
		loss: 0.126200
		loss: 0.125100
		loss: 0.123800
		loss: 0.122900
		loss: 0.121700
		loss: 0.120700
		loss: 0.120100
		loss: 0.119100
		loss: 0.117600
		loss: 0.117200
		loss: 0.115700
		loss: 0.115200
		loss: 0.114000
		loss: 0.113300
		loss: 0.112700
		loss: 0.111400
		loss: 0.111000
		loss: 0.110200
		loss: 0.109000
		loss: 0.108500
		loss: 0.108100
		loss: 0.106800
		loss: 0.106400
		loss: 0.106100
		loss: 0.105200
		loss: 0.104200
		loss: 0.103500
		loss: 0.103200
		loss: 0.102300
		loss: 0.101500
		loss: 0.101000
		loss: 0.100600
		loss: 0.099900
		loss: 0.099200
		loss: 0.098700
		loss: 0.098200
		loss: 0.097600
		loss: 0.097000
		loss: 0.096700
		loss: 0.096100
		loss: 0.095600
		loss: 0.095200
		loss: 0.094700
		loss: 0.094200
		loss: 0.093700
		loss: 0.093300
		loss: 0.092900
		loss: 0.092500
		loss: 0.092100
		loss: 0.091700
		loss: 0.091300
		loss: 0.090900
		loss: 0.090500
		loss: 0.090200
		loss: 0.089800
		loss: 0.089500
		loss: 0.089100
		loss: 0.088800
		loss: 0.088500
		loss: 0.088200
		loss: 0.087900
		loss: 0.087600
		loss: 0.087300
		loss: 0.087000
		loss: 0.086600
		loss: 0.086300
		loss: 0.086000
		loss: 0.085800
		loss: 0.085500
		loss: 0.085300
		loss: 0.085000
		loss: 0.084700
		loss: 0.084500
		loss: 0.084200
		loss: 0.084000
		loss: 0.083800
		loss: 0.083600
		loss: 0.083400
		loss: 0.083200
		loss: 0.082900
		loss: 0.082700
		loss: 0.082500
		loss: 0.082300
		loss: 0.082100
		loss: 0.081900
		loss: 0.081800
		loss: 0.081600
		loss: 0.081400
		loss: 0.081200
		loss: 0.081100
		loss: 0.080900
		loss: 0.080800
		loss: 0.080600
		loss: 0.080500
	Overall the loss development was 2.266900 -> 0.080500

Epoch 8:
Training data for problem d-01.pddl in epoch 8:
model creation time: 2.022902727127075s
problem epoch data for epoch 8, problem epoch 1
	sampling search time: 0.6040730476379395s
	during this search the following actions were chosen:
	training time: 36.94265103340149s
	during the training the following losses were computed:
		loss: 0.060100
		loss: 0.059500
		loss: 0.058900
		loss: 0.058400
		loss: 0.057800
		loss: 0.057200
		loss: 0.056600
		loss: 0.056000
		loss: 0.055500
		loss: 0.054900
		loss: 0.054400
		loss: 0.053800
		loss: 0.053300
		loss: 0.052700
		loss: 0.052200
		loss: 0.051700
		loss: 0.051100
		loss: 0.050600
		loss: 0.050100
		loss: 0.049600
		loss: 0.049100
		loss: 0.048600
		loss: 0.048100
		loss: 0.047600
		loss: 0.047200
		loss: 0.046700
		loss: 0.046200
		loss: 0.045800
		loss: 0.045300
		loss: 0.044900
		loss: 0.044400
		loss: 0.044000
		loss: 0.043500
		loss: 0.043100
		loss: 0.042700
		loss: 0.042300
		loss: 0.041900
		loss: 0.041500
		loss: 0.041000
		loss: 0.040700
		loss: 0.040300
		loss: 0.039900
		loss: 0.039500
		loss: 0.039100
		loss: 0.038700
		loss: 0.038400
		loss: 0.038000
		loss: 0.037700
		loss: 0.037300
		loss: 0.037000
		loss: 0.036600
		loss: 0.036300
		loss: 0.036000
		loss: 0.035600
		loss: 0.035300
		loss: 0.035000
		loss: 0.034700
		loss: 0.034400
		loss: 0.034100
		loss: 0.033800
		loss: 0.033500
		loss: 0.033300
		loss: 0.033000
		loss: 0.032700
		loss: 0.032400
		loss: 0.032200
		loss: 0.031900
		loss: 0.031600
		loss: 0.031400
		loss: 0.031100
		loss: 0.030800
		loss: 0.030600
		loss: 0.030300
		loss: 0.030100
		loss: 0.029800
		loss: 0.029600
		loss: 0.029400
		loss: 0.029100
		loss: 0.028900
		loss: 0.028700
		loss: 0.028400
		loss: 0.028200
		loss: 0.028000
		loss: 0.027800
		loss: 0.027600
		loss: 0.027400
		loss: 0.027200
		loss: 0.027000
		loss: 0.026900
		loss: 0.026700
		loss: 0.026500
		loss: 0.026300
		loss: 0.026200
		loss: 0.026000
		loss: 0.025800
		loss: 0.025700
		loss: 0.025500
		loss: 0.025400
		loss: 0.025200
		loss: 0.025100
		loss: 0.024900
		loss: 0.024800
		loss: 0.024600
		loss: 0.024500
		loss: 0.024400
		loss: 0.024200
		loss: 0.024100
		loss: 0.024000
		loss: 0.023900
		loss: 0.023700
		loss: 0.023600
		loss: 0.023500
		loss: 0.023400
		loss: 0.023200
		loss: 0.023100
		loss: 0.023000
		loss: 0.022900
		loss: 0.022800
		loss: 0.022700
		loss: 0.022600
		loss: 0.022400
		loss: 0.022300
		loss: 0.022200
		loss: 0.022100
		loss: 0.022000
		loss: 0.021900
		loss: 0.021800
		loss: 0.021700
		loss: 0.021600
		loss: 0.021500
		loss: 0.021400
		loss: 0.021400
		loss: 0.021300
		loss: 0.021200
		loss: 0.021100
		loss: 0.021000
		loss: 0.020900
		loss: 0.020800
		loss: 0.020800
		loss: 0.020700
		loss: 0.020600
		loss: 0.020500
		loss: 0.020400
		loss: 0.020400
		loss: 0.020300
		loss: 0.020200
		loss: 0.020100
		loss: 0.020100
		loss: 0.020000
		loss: 0.019900
		loss: 0.019900
		loss: 0.019800
		loss: 0.019700
		loss: 0.019700
		loss: 0.019600
		loss: 0.019500
		loss: 0.019500
		loss: 0.019400
		loss: 0.019400
		loss: 0.019300
		loss: 0.019200
		loss: 0.019200
		loss: 0.019100
		loss: 0.019100
		loss: 0.019000
		loss: 0.019000
		loss: 0.018900
		loss: 0.018800
		loss: 0.018800
		loss: 0.018700
		loss: 0.018700
		loss: 0.018600
		loss: 0.018600
		loss: 0.018500
		loss: 0.018500
		loss: 0.018400
		loss: 0.018400
		loss: 0.018300
		loss: 0.018300
		loss: 0.018200
		loss: 0.018200
		loss: 0.018200
		loss: 0.018100
		loss: 0.018100
		loss: 0.018000
		loss: 0.018000
		loss: 0.017900
		loss: 0.017900
		loss: 0.017900
		loss: 0.017800
		loss: 0.017800
		loss: 0.017800
		loss: 0.017700
		loss: 0.017700
		loss: 0.017600
		loss: 0.017600
		loss: 0.017600
		loss: 0.017500
		loss: 0.017500
		loss: 0.017500
		loss: 0.017400
		loss: 0.017400
		loss: 0.017400
		loss: 0.017300
		loss: 0.017300
		loss: 0.017300
		loss: 0.017200
		loss: 0.017200
		loss: 0.017200
		loss: 0.017100
		loss: 0.017100
		loss: 0.017100
		loss: 0.017000
		loss: 0.017000
		loss: 0.017000
		loss: 0.017000
		loss: 0.016900
		loss: 0.016900
		loss: 0.016900
		loss: 0.016800
		loss: 0.016800
		loss: 0.016800
		loss: 0.016800
		loss: 0.016700
		loss: 0.016700
		loss: 0.016700
		loss: 0.016700
		loss: 0.016600
		loss: 0.016600
		loss: 0.016600
		loss: 0.016600
		loss: 0.016600
		loss: 0.016500
		loss: 0.016500
		loss: 0.016500
		loss: 0.016500
		loss: 0.016400
		loss: 0.016400
		loss: 0.016400
		loss: 0.016400
		loss: 0.016400
		loss: 0.016300
		loss: 0.016300
		loss: 0.016300
		loss: 0.016300
		loss: 0.016300
		loss: 0.016200
		loss: 0.016200
		loss: 0.016200
		loss: 0.016200
		loss: 0.016200
		loss: 0.016100
		loss: 0.016100
		loss: 0.016100
		loss: 0.016100
		loss: 0.016100
		loss: 0.016100
		loss: 0.016000
		loss: 0.016000
		loss: 0.016000
		loss: 0.016000
		loss: 0.016000
		loss: 0.016000
		loss: 0.015900
		loss: 0.015900
		loss: 0.015900
		loss: 0.015900
		loss: 0.015900
		loss: 0.015900
		loss: 0.015800
		loss: 0.015800
		loss: 0.015800
		loss: 0.015800
		loss: 0.015800
		loss: 0.015800
		loss: 0.015800
		loss: 0.015800
		loss: 0.015700
		loss: 0.015700
		loss: 0.015700
		loss: 0.015700
		loss: 0.015700
		loss: 0.015700
		loss: 0.015700
		loss: 0.015700
		loss: 0.015600
		loss: 0.015600
		loss: 0.015600
		loss: 0.015600
		loss: 0.015600
		loss: 0.015600
		loss: 0.015600
		loss: 0.015600
		loss: 0.015500
		loss: 0.015500
		loss: 0.015500
		loss: 0.015500
		loss: 0.015500
		loss: 0.015500
		loss: 0.015500
	Overall the loss development was 0.060100 -> 0.015500

Training data for problem d-02.pddl in epoch 8:
model creation time: 5.099163055419922s
problem epoch data for epoch 8, problem epoch 1
	sampling search time: 1.3014953136444092s
	during this search the following actions were chosen:
		move d1 d2 peg1 was chosen with probability 0.571585
		move d1 peg1 d2 was chosen with probability 0.570887
	training time: 44.41402840614319s
	during the training the following losses were computed:
		loss: 0.914800
		loss: 0.898400
		loss: 0.883900
		loss: 0.870000
		loss: 0.857400
		loss: 0.845900
		loss: 0.836400
		loss: 0.827600
		loss: 0.819400
		loss: 0.811600
		loss: 0.804800
		loss: 0.798700
		loss: 0.792900
		loss: 0.787800
		loss: 0.783500
		loss: 0.779800
		loss: 0.776400
		loss: 0.773100
		loss: 0.769900
		loss: 0.766800
		loss: 0.763800
		loss: 0.760800
		loss: 0.757700
		loss: 0.755100
		loss: 0.752500
		loss: 0.749700
		loss: 0.746800
		loss: 0.743800
		loss: 0.740700
		loss: 0.737400
		loss: 0.733800
		loss: 0.730100
		loss: 0.726300
		loss: 0.722100
		loss: 0.717700
		loss: 0.713000
		loss: 0.708200
		loss: 0.703200
		loss: 0.698000
		loss: 0.692600
		loss: 0.686700
		loss: 0.680200
		loss: 0.673600
		loss: 0.666800
		loss: 0.659200
		loss: 0.652000
		loss: 0.644700
		loss: 0.637100
		loss: 0.628900
		loss: 0.620600
		loss: 0.611900
		loss: 0.603000
		loss: 0.593800
		loss: 0.584900
		loss: 0.575400
		loss: 0.565800
		loss: 0.556100
		loss: 0.546500
		loss: 0.536400
		loss: 0.527300
		loss: 0.517300
		loss: 0.507700
		loss: 0.497500
		loss: 0.487300
		loss: 0.477300
		loss: 0.467500
		loss: 0.457800
		loss: 0.448000
		loss: 0.438300
		loss: 0.429100
		loss: 0.420000
		loss: 0.410700
		loss: 0.401400
		loss: 0.392700
		loss: 0.383900
		loss: 0.375100
		loss: 0.366400
		loss: 0.358300
		loss: 0.349900
		loss: 0.341400
		loss: 0.333600
		loss: 0.325100
		loss: 0.317200
		loss: 0.309500
		loss: 0.302100
		loss: 0.295000
		loss: 0.287300
		loss: 0.279800
		loss: 0.272100
		loss: 0.264600
		loss: 0.257800
		loss: 0.250500
		loss: 0.243300
		loss: 0.236500
		loss: 0.229700
		loss: 0.222900
		loss: 0.215800
		loss: 0.208900
		loss: 0.202000
		loss: 0.195200
		loss: 0.188600
		loss: 0.182300
		loss: 0.175900
		loss: 0.169800
		loss: 0.163900
		loss: 0.158200
		loss: 0.152500
		loss: 0.147400
		loss: 0.142400
		loss: 0.137800
		loss: 0.132800
		loss: 0.128200
		loss: 0.123700
		loss: 0.119500
		loss: 0.115400
		loss: 0.111500
		loss: 0.108000
		loss: 0.104500
		loss: 0.101200
		loss: 0.098000
		loss: 0.094700
		loss: 0.092000
		loss: 0.089300
		loss: 0.086700
		loss: 0.084300
		loss: 0.082000
		loss: 0.079800
		loss: 0.077900
		loss: 0.075900
		loss: 0.074100
		loss: 0.072500
		loss: 0.071000
		loss: 0.069600
		loss: 0.068200
		loss: 0.066900
		loss: 0.065700
		loss: 0.064600
		loss: 0.063600
		loss: 0.062600
		loss: 0.061700
		loss: 0.060900
		loss: 0.060100
		loss: 0.059300
		loss: 0.058600
		loss: 0.058000
		loss: 0.057400
		loss: 0.056800
		loss: 0.056300
		loss: 0.055800
		loss: 0.055400
		loss: 0.054900
		loss: 0.054500
		loss: 0.054200
		loss: 0.053800
		loss: 0.053500
		loss: 0.053200
		loss: 0.052900
		loss: 0.052600
		loss: 0.052300
		loss: 0.052100
		loss: 0.051900
		loss: 0.051600
		loss: 0.051400
		loss: 0.051200
		loss: 0.051000
		loss: 0.050800
		loss: 0.050700
		loss: 0.050500
		loss: 0.050300
		loss: 0.050200
		loss: 0.050100
		loss: 0.049900
		loss: 0.049800
		loss: 0.049700
		loss: 0.049500
		loss: 0.049400
		loss: 0.049300
		loss: 0.049200
		loss: 0.049100
		loss: 0.049000
		loss: 0.048900
		loss: 0.048800
		loss: 0.048700
		loss: 0.048700
		loss: 0.048600
		loss: 0.048500
		loss: 0.048400
		loss: 0.048300
		loss: 0.048300
		loss: 0.048200
		loss: 0.048100
		loss: 0.048100
		loss: 0.048000
		loss: 0.047900
		loss: 0.047900
		loss: 0.047800
		loss: 0.047700
		loss: 0.047700
		loss: 0.047600
		loss: 0.047600
		loss: 0.047500
		loss: 0.047400
		loss: 0.047400
		loss: 0.047300
		loss: 0.047300
		loss: 0.047200
		loss: 0.047200
		loss: 0.047100
		loss: 0.047100
		loss: 0.047000
		loss: 0.047000
		loss: 0.047000
		loss: 0.046900
		loss: 0.046900
		loss: 0.046800
		loss: 0.046800
		loss: 0.046700
		loss: 0.046700
		loss: 0.046700
		loss: 0.046600
		loss: 0.046600
		loss: 0.046500
		loss: 0.046500
		loss: 0.046500
		loss: 0.046400
		loss: 0.046400
		loss: 0.046300
		loss: 0.046300
		loss: 0.046300
		loss: 0.046200
		loss: 0.046200
		loss: 0.046200
		loss: 0.046100
		loss: 0.046100
		loss: 0.046100
		loss: 0.046000
		loss: 0.046000
		loss: 0.046000
		loss: 0.045900
		loss: 0.045900
		loss: 0.045900
		loss: 0.045800
		loss: 0.045800
		loss: 0.045800
		loss: 0.045800
		loss: 0.045700
		loss: 0.045700
		loss: 0.045700
		loss: 0.045600
		loss: 0.045600
		loss: 0.045600
		loss: 0.045600
		loss: 0.045500
		loss: 0.045500
		loss: 0.045500
		loss: 0.045400
		loss: 0.045400
		loss: 0.045400
		loss: 0.045400
		loss: 0.045300
		loss: 0.045300
		loss: 0.045300
		loss: 0.045300
		loss: 0.045200
		loss: 0.045200
		loss: 0.045200
		loss: 0.045200
		loss: 0.045100
		loss: 0.045100
		loss: 0.045100
		loss: 0.045000
		loss: 0.045000
		loss: 0.045000
		loss: 0.045000
		loss: 0.044900
		loss: 0.044900
		loss: 0.044900
		loss: 0.044900
		loss: 0.044900
		loss: 0.044800
		loss: 0.044800
		loss: 0.044800
		loss: 0.044800
		loss: 0.044700
		loss: 0.044700
		loss: 0.044700
		loss: 0.044700
		loss: 0.044600
		loss: 0.044600
		loss: 0.044600
		loss: 0.044600
		loss: 0.044500
		loss: 0.044500
		loss: 0.044500
		loss: 0.044500
		loss: 0.044500
		loss: 0.044400
		loss: 0.044400
		loss: 0.044400
		loss: 0.044400
	Overall the loss development was 0.914800 -> 0.044400

Training data for problem d-03.pddl in epoch 8:
model creation time: 10.33226990699768s
problem epoch data for epoch 8, problem epoch 1
	sampling search time: 2.5206961631774902s
	during this search the following actions were chosen:
		move d1 d2 peg2 was chosen with probability 0.913295
		move d1 peg2 d2 was chosen with probability 0.948568
	training time: 57.29175090789795s
	during the training the following losses were computed:
		loss: 1.705800
		loss: 1.550800
		loss: 1.398200
		loss: 1.254700
		loss: 1.133900
		loss: 1.027400
		loss: 0.935800
		loss: 0.860500
		loss: 0.826400
		loss: 0.820900
		loss: 0.823000
		loss: 0.819200
		loss: 0.804700
		loss: 0.779500
		loss: 0.745300
		loss: 0.706800
		loss: 0.671900
		loss: 0.642500
		loss: 0.624400
		loss: 0.620500
		loss: 0.618000
		loss: 0.614500
		loss: 0.607900
		loss: 0.597900
		loss: 0.584800
		loss: 0.568700
		loss: 0.551700
		loss: 0.535800
		loss: 0.524800
		loss: 0.519900
		loss: 0.517000
		loss: 0.508400
		loss: 0.494600
		loss: 0.488400
		loss: 0.485700
		loss: 0.480500
		loss: 0.472900
		loss: 0.463500
		loss: 0.455000
		loss: 0.451500
		loss: 0.445100
		loss: 0.438100
		loss: 0.435000
		loss: 0.430000
		loss: 0.423500
		loss: 0.417800
		loss: 0.412900
		loss: 0.407500
		loss: 0.402700
		loss: 0.397100
		loss: 0.393000
		loss: 0.387300
		loss: 0.385500
		loss: 0.382800
		loss: 0.378100
		loss: 0.372400
		loss: 0.369400
		loss: 0.365100
		loss: 0.360400
		loss: 0.357200
		loss: 0.353000
		loss: 0.349500
		loss: 0.345200
		loss: 0.341600
		loss: 0.337700
		loss: 0.334300
		loss: 0.330200
		loss: 0.326600
		loss: 0.322500
		loss: 0.319400
		loss: 0.315700
		loss: 0.311900
		loss: 0.308100
		loss: 0.304500
		loss: 0.301000
		loss: 0.298200
		loss: 0.294200
		loss: 0.290700
		loss: 0.287100
		loss: 0.284900
		loss: 0.281100
		loss: 0.277800
		loss: 0.275100
		loss: 0.271400
		loss: 0.268000
		loss: 0.265200
		loss: 0.262400
		loss: 0.259000
		loss: 0.256100
		loss: 0.253300
		loss: 0.250200
		loss: 0.246800
		loss: 0.244200
		loss: 0.241200
		loss: 0.238400
		loss: 0.235600
		loss: 0.232500
		loss: 0.230000
		loss: 0.227300
		loss: 0.224400
		loss: 0.221500
		loss: 0.219100
		loss: 0.216600
		loss: 0.213800
		loss: 0.212700
		loss: 0.209000
		loss: 0.207200
		loss: 0.204200
		loss: 0.202300
		loss: 0.200500
		loss: 0.197300
		loss: 0.195500
		loss: 0.193200
		loss: 0.190600
		loss: 0.189500
		loss: 0.186700
		loss: 0.184900
		loss: 0.182600
		loss: 0.181000
		loss: 0.178900
		loss: 0.176800
		loss: 0.174900
		loss: 0.173200
		loss: 0.171300
		loss: 0.169600
		loss: 0.167700
		loss: 0.165900
		loss: 0.164300
		loss: 0.162600
		loss: 0.161000
		loss: 0.159400
		loss: 0.157600
		loss: 0.156300
		loss: 0.154600
		loss: 0.153500
		loss: 0.152000
		loss: 0.150400
		loss: 0.149100
		loss: 0.147500
		loss: 0.146100
		loss: 0.144700
		loss: 0.143300
		loss: 0.141900
		loss: 0.140500
		loss: 0.139500
		loss: 0.138400
		loss: 0.137300
		loss: 0.135800
		loss: 0.135100
		loss: 0.133400
		loss: 0.132400
		loss: 0.131100
		loss: 0.130000
		loss: 0.128900
		loss: 0.127900
		loss: 0.126800
		loss: 0.125800
		loss: 0.124700
		loss: 0.123900
		loss: 0.122900
		loss: 0.121800
		loss: 0.120800
		loss: 0.120000
		loss: 0.119400
		loss: 0.118700
		loss: 0.117600
		loss: 0.116600
		loss: 0.116200
		loss: 0.115000
		loss: 0.114200
		loss: 0.113700
		loss: 0.112900
		loss: 0.112000
		loss: 0.111200
		loss: 0.110400
		loss: 0.109600
		loss: 0.109000
		loss: 0.108300
		loss: 0.107400
		loss: 0.106700
		loss: 0.105900
		loss: 0.105500
		loss: 0.104700
		loss: 0.104000
		loss: 0.103500
		loss: 0.102800
		loss: 0.102100
		loss: 0.101700
		loss: 0.101100
		loss: 0.100600
		loss: 0.100000
		loss: 0.099500
		loss: 0.098900
		loss: 0.098300
		loss: 0.097900
		loss: 0.097400
		loss: 0.096900
		loss: 0.096400
		loss: 0.095800
		loss: 0.095400
		loss: 0.095000
		loss: 0.094500
		loss: 0.094100
		loss: 0.093600
		loss: 0.093200
		loss: 0.092700
		loss: 0.092300
		loss: 0.091800
		loss: 0.091600
		loss: 0.090900
		loss: 0.090500
		loss: 0.090100
		loss: 0.089700
		loss: 0.089300
		loss: 0.088900
		loss: 0.088500
		loss: 0.088100
		loss: 0.087800
		loss: 0.087400
		loss: 0.087100
		loss: 0.086700
		loss: 0.086400
		loss: 0.086100
		loss: 0.085900
		loss: 0.085600
		loss: 0.085300
		loss: 0.085000
		loss: 0.084800
		loss: 0.084500
		loss: 0.084200
		loss: 0.083900
		loss: 0.083700
		loss: 0.083400
		loss: 0.083200
		loss: 0.082900
		loss: 0.082900
		loss: 0.082500
		loss: 0.082300
		loss: 0.082200
		loss: 0.081900
		loss: 0.081600
		loss: 0.081500
		loss: 0.081200
		loss: 0.081100
		loss: 0.081000
		loss: 0.080800
		loss: 0.080500
		loss: 0.080300
		loss: 0.080200
		loss: 0.079900
		loss: 0.079700
		loss: 0.079600
		loss: 0.079400
		loss: 0.079200
		loss: 0.079100
		loss: 0.078900
		loss: 0.078700
		loss: 0.078600
		loss: 0.078400
		loss: 0.078300
		loss: 0.078100
		loss: 0.078000
		loss: 0.077800
		loss: 0.077700
		loss: 0.077600
		loss: 0.077400
		loss: 0.077300
		loss: 0.077100
		loss: 0.077000
		loss: 0.076900
		loss: 0.076800
		loss: 0.076600
		loss: 0.076500
		loss: 0.076400
		loss: 0.076300
		loss: 0.076200
		loss: 0.076000
		loss: 0.075900
		loss: 0.075800
		loss: 0.075800
		loss: 0.075600
		loss: 0.075500
		loss: 0.075400
		loss: 0.075300
		loss: 0.075200
		loss: 0.075100
		loss: 0.075000
		loss: 0.074900
		loss: 0.074800
		loss: 0.074700
		loss: 0.074600
		loss: 0.074500
		loss: 0.074400
		loss: 0.074300
		loss: 0.074300
		loss: 0.074200
		loss: 0.074100
		loss: 0.074000
		loss: 0.073900
		loss: 0.073800
	Overall the loss development was 1.705800 -> 0.073800

Epoch 9:
Training data for problem d-01.pddl in epoch 9:
model creation time: 2.103487968444824s
problem epoch data for epoch 9, problem epoch 1
	sampling search time: 0.6008925437927246s
	during this search the following actions were chosen:
	training time: 36.794642210006714s
	during the training the following losses were computed:
		loss: 0.060600
		loss: 0.059900
		loss: 0.059300
		loss: 0.058700
		loss: 0.058100
		loss: 0.057500
		loss: 0.056900
		loss: 0.056300
		loss: 0.055800
		loss: 0.055200
		loss: 0.054600
		loss: 0.054000
		loss: 0.053500
		loss: 0.052900
		loss: 0.052400
		loss: 0.051800
		loss: 0.051300
		loss: 0.050800
		loss: 0.050200
		loss: 0.049700
		loss: 0.049200
		loss: 0.048700
		loss: 0.048200
		loss: 0.047700
		loss: 0.047200
		loss: 0.046700
		loss: 0.046200
		loss: 0.045700
		loss: 0.045200
		loss: 0.044800
		loss: 0.044300
		loss: 0.043800
		loss: 0.043400
		loss: 0.042900
		loss: 0.042500
		loss: 0.042100
		loss: 0.041600
		loss: 0.041200
		loss: 0.040800
		loss: 0.040400
		loss: 0.039900
		loss: 0.039500
		loss: 0.039100
		loss: 0.038700
		loss: 0.038300
		loss: 0.038000
		loss: 0.037600
		loss: 0.037200
		loss: 0.036800
		loss: 0.036500
		loss: 0.036100
		loss: 0.035800
		loss: 0.035400
		loss: 0.035100
		loss: 0.034700
		loss: 0.034400
		loss: 0.034100
		loss: 0.033800
		loss: 0.033500
		loss: 0.033200
		loss: 0.032900
		loss: 0.032600
		loss: 0.032300
		loss: 0.032000
		loss: 0.031800
		loss: 0.031500
		loss: 0.031200
		loss: 0.031000
		loss: 0.030700
		loss: 0.030500
		loss: 0.030200
		loss: 0.030000
		loss: 0.029800
		loss: 0.029500
		loss: 0.029300
		loss: 0.029100
		loss: 0.028900
		loss: 0.028700
		loss: 0.028500
		loss: 0.028300
		loss: 0.028100
		loss: 0.027900
		loss: 0.027700
		loss: 0.027600
		loss: 0.027400
		loss: 0.027200
		loss: 0.027000
		loss: 0.026900
		loss: 0.026700
		loss: 0.026500
		loss: 0.026400
		loss: 0.026200
		loss: 0.026100
		loss: 0.025900
		loss: 0.025800
		loss: 0.025600
		loss: 0.025500
		loss: 0.025300
		loss: 0.025200
		loss: 0.025000
		loss: 0.024900
		loss: 0.024800
		loss: 0.024600
		loss: 0.024500
		loss: 0.024400
		loss: 0.024200
		loss: 0.024100
		loss: 0.024000
		loss: 0.023900
		loss: 0.023700
		loss: 0.023600
		loss: 0.023500
		loss: 0.023400
		loss: 0.023300
		loss: 0.023200
		loss: 0.023100
		loss: 0.023000
		loss: 0.022900
		loss: 0.022800
		loss: 0.022700
		loss: 0.022600
		loss: 0.022500
		loss: 0.022400
		loss: 0.022300
		loss: 0.022200
		loss: 0.022100
		loss: 0.022000
		loss: 0.021900
		loss: 0.021800
		loss: 0.021800
		loss: 0.021700
		loss: 0.021600
		loss: 0.021500
		loss: 0.021400
		loss: 0.021300
		loss: 0.021300
		loss: 0.021200
		loss: 0.021100
		loss: 0.021100
		loss: 0.021000
		loss: 0.020900
		loss: 0.020800
		loss: 0.020800
		loss: 0.020700
		loss: 0.020600
		loss: 0.020600
		loss: 0.020500
		loss: 0.020400
		loss: 0.020400
		loss: 0.020300
		loss: 0.020300
		loss: 0.020200
		loss: 0.020100
		loss: 0.020100
		loss: 0.020000
		loss: 0.020000
		loss: 0.019900
		loss: 0.019800
		loss: 0.019800
		loss: 0.019700
		loss: 0.019700
		loss: 0.019600
		loss: 0.019600
		loss: 0.019500
		loss: 0.019500
		loss: 0.019400
		loss: 0.019400
		loss: 0.019300
		loss: 0.019300
		loss: 0.019200
		loss: 0.019200
		loss: 0.019100
		loss: 0.019100
		loss: 0.019000
		loss: 0.019000
		loss: 0.018900
		loss: 0.018900
		loss: 0.018900
		loss: 0.018800
		loss: 0.018800
		loss: 0.018700
		loss: 0.018700
		loss: 0.018600
		loss: 0.018600
		loss: 0.018600
		loss: 0.018500
		loss: 0.018500
		loss: 0.018400
		loss: 0.018400
		loss: 0.018400
		loss: 0.018300
		loss: 0.018300
		loss: 0.018300
		loss: 0.018200
		loss: 0.018200
		loss: 0.018100
		loss: 0.018100
		loss: 0.018100
		loss: 0.018000
		loss: 0.018000
		loss: 0.018000
		loss: 0.017900
		loss: 0.017900
		loss: 0.017900
		loss: 0.017800
		loss: 0.017800
		loss: 0.017800
		loss: 0.017700
		loss: 0.017700
		loss: 0.017700
		loss: 0.017600
		loss: 0.017600
		loss: 0.017600
		loss: 0.017600
		loss: 0.017500
		loss: 0.017500
		loss: 0.017500
		loss: 0.017400
		loss: 0.017400
		loss: 0.017400
		loss: 0.017400
		loss: 0.017300
		loss: 0.017300
		loss: 0.017300
		loss: 0.017300
		loss: 0.017200
		loss: 0.017200
		loss: 0.017200
		loss: 0.017200
		loss: 0.017100
		loss: 0.017100
		loss: 0.017100
		loss: 0.017100
		loss: 0.017000
		loss: 0.017000
		loss: 0.017000
		loss: 0.017000
		loss: 0.016900
		loss: 0.016900
		loss: 0.016900
		loss: 0.016900
		loss: 0.016800
		loss: 0.016800
		loss: 0.016800
		loss: 0.016800
		loss: 0.016800
		loss: 0.016700
		loss: 0.016700
		loss: 0.016700
		loss: 0.016700
		loss: 0.016600
		loss: 0.016600
		loss: 0.016600
		loss: 0.016600
		loss: 0.016600
		loss: 0.016500
		loss: 0.016500
		loss: 0.016500
		loss: 0.016500
		loss: 0.016500
		loss: 0.016500
		loss: 0.016400
		loss: 0.016400
		loss: 0.016400
		loss: 0.016400
		loss: 0.016400
		loss: 0.016300
		loss: 0.016300
		loss: 0.016300
		loss: 0.016300
		loss: 0.016300
		loss: 0.016300
		loss: 0.016200
		loss: 0.016200
		loss: 0.016200
		loss: 0.016200
		loss: 0.016200
		loss: 0.016200
		loss: 0.016100
		loss: 0.016100
		loss: 0.016100
		loss: 0.016100
		loss: 0.016100
		loss: 0.016100
		loss: 0.016100
		loss: 0.016000
		loss: 0.016000
		loss: 0.016000
		loss: 0.016000
		loss: 0.016000
		loss: 0.016000
		loss: 0.016000
		loss: 0.015900
		loss: 0.015900
		loss: 0.015900
		loss: 0.015900
		loss: 0.015900
		loss: 0.015900
		loss: 0.015900
		loss: 0.015800
	Overall the loss development was 0.060600 -> 0.015800

Training data for problem d-02.pddl in epoch 9:
model creation time: 5.237641334533691s
problem epoch data for epoch 9, problem epoch 1
	sampling search time: 1.2982280254364014s
	during this search the following actions were chosen:
		move d1 d2 peg1 was chosen with probability 0.550758
		move d1 peg1 d2 was chosen with probability 0.585901
	training time: 44.5349485874176s
	during the training the following losses were computed:
		loss: 0.932100
		loss: 0.912600
		loss: 0.895300
		loss: 0.879200
		loss: 0.864300
		loss: 0.851000
		loss: 0.838300
		loss: 0.826900
		loss: 0.816700
		loss: 0.807500
		loss: 0.799100
		loss: 0.792400
		loss: 0.785900
		loss: 0.779900
		loss: 0.774600
		loss: 0.770000
		loss: 0.765800
		loss: 0.762100
		loss: 0.758700
		loss: 0.754600
		loss: 0.750200
		loss: 0.746700
		loss: 0.743500
		loss: 0.740100
		loss: 0.736700
		loss: 0.733400
		loss: 0.730100
		loss: 0.726800
		loss: 0.723400
		loss: 0.719900
		loss: 0.716200
		loss: 0.712500
		loss: 0.708600
		loss: 0.704600
		loss: 0.700200
		loss: 0.695700
		loss: 0.691200
		loss: 0.686800
		loss: 0.682300
		loss: 0.677200
		loss: 0.671800
		loss: 0.666400
		loss: 0.660600
		loss: 0.654400
		loss: 0.647700
		loss: 0.640900
		loss: 0.633900
		loss: 0.626400
		loss: 0.618800
		loss: 0.610800
		loss: 0.602600
		loss: 0.594000
		loss: 0.585400
		loss: 0.575900
		loss: 0.566500
		loss: 0.556500
		loss: 0.546100
		loss: 0.535600
		loss: 0.524800
		loss: 0.513600
		loss: 0.502300
		loss: 0.490600
		loss: 0.479400
		loss: 0.468500
		loss: 0.458000
		loss: 0.448500
		loss: 0.438900
		loss: 0.429000
		loss: 0.419900
		loss: 0.410500
		loss: 0.401400
		loss: 0.393100
		loss: 0.384200
		loss: 0.376200
		loss: 0.367800
		loss: 0.359300
		loss: 0.351500
		loss: 0.343300
		loss: 0.335200
		loss: 0.326800
		loss: 0.319000
		loss: 0.311100
		loss: 0.303300
		loss: 0.295200
		loss: 0.288500
		loss: 0.279800
		loss: 0.272800
		loss: 0.264800
		loss: 0.256300
		loss: 0.248100
		loss: 0.240600
		loss: 0.232200
		loss: 0.224800
		loss: 0.217300
		loss: 0.210000
		loss: 0.202700
		loss: 0.195500
		loss: 0.188400
		loss: 0.181700
		loss: 0.175000
		loss: 0.168400
		loss: 0.162200
		loss: 0.156300
		loss: 0.150700
		loss: 0.145300
		loss: 0.139900
		loss: 0.134700
		loss: 0.129700
		loss: 0.125000
		loss: 0.120400
		loss: 0.116000
		loss: 0.111800
		loss: 0.107700
		loss: 0.104000
		loss: 0.100400
		loss: 0.097100
		loss: 0.093900
		loss: 0.091000
		loss: 0.088300
		loss: 0.085700
		loss: 0.083200
		loss: 0.081000
		loss: 0.079000
		loss: 0.076900
		loss: 0.075200
		loss: 0.073500
		loss: 0.071800
		loss: 0.070400
		loss: 0.069000
		loss: 0.067700
		loss: 0.066400
		loss: 0.065300
		loss: 0.064300
		loss: 0.063300
		loss: 0.062500
		loss: 0.061600
		loss: 0.060900
		loss: 0.060200
		loss: 0.059500
		loss: 0.058900
		loss: 0.058400
		loss: 0.057800
		loss: 0.057400
		loss: 0.056900
		loss: 0.056500
		loss: 0.056100
		loss: 0.055700
		loss: 0.055400
		loss: 0.055000
		loss: 0.054700
		loss: 0.054400
		loss: 0.054100
		loss: 0.053900
		loss: 0.053600
		loss: 0.053400
		loss: 0.053200
		loss: 0.052900
		loss: 0.052700
		loss: 0.052500
		loss: 0.052400
		loss: 0.052200
		loss: 0.052000
		loss: 0.051900
		loss: 0.051700
		loss: 0.051600
		loss: 0.051500
		loss: 0.051300
		loss: 0.051200
		loss: 0.051100
		loss: 0.051000
		loss: 0.050900
		loss: 0.050800
		loss: 0.050700
		loss: 0.050600
		loss: 0.050500
		loss: 0.050400
		loss: 0.050300
		loss: 0.050200
		loss: 0.050100
		loss: 0.050000
		loss: 0.050000
		loss: 0.049900
		loss: 0.049800
		loss: 0.049700
		loss: 0.049700
		loss: 0.049600
		loss: 0.049500
		loss: 0.049500
		loss: 0.049400
		loss: 0.049400
		loss: 0.049300
		loss: 0.049300
		loss: 0.049200
		loss: 0.049200
		loss: 0.049100
		loss: 0.049100
		loss: 0.049000
		loss: 0.049000
		loss: 0.048900
		loss: 0.048900
		loss: 0.048800
		loss: 0.048800
		loss: 0.048700
		loss: 0.048700
		loss: 0.048600
		loss: 0.048600
		loss: 0.048600
		loss: 0.048500
		loss: 0.048500
		loss: 0.048400
		loss: 0.048400
		loss: 0.048400
		loss: 0.048300
		loss: 0.048300
		loss: 0.048200
		loss: 0.048200
		loss: 0.048200
		loss: 0.048100
		loss: 0.048100
		loss: 0.048100
		loss: 0.048000
		loss: 0.048000
		loss: 0.048000
		loss: 0.047900
		loss: 0.047900
		loss: 0.047900
		loss: 0.047900
		loss: 0.047800
		loss: 0.047800
		loss: 0.047800
		loss: 0.047700
		loss: 0.047700
		loss: 0.047700
		loss: 0.047700
		loss: 0.047600
		loss: 0.047600
		loss: 0.047600
		loss: 0.047500
		loss: 0.047500
		loss: 0.047500
		loss: 0.047500
		loss: 0.047400
		loss: 0.047400
		loss: 0.047400
		loss: 0.047300
		loss: 0.047300
		loss: 0.047300
		loss: 0.047300
		loss: 0.047300
		loss: 0.047200
		loss: 0.047200
		loss: 0.047200
		loss: 0.047100
		loss: 0.047100
		loss: 0.047100
		loss: 0.047100
		loss: 0.047000
		loss: 0.047000
		loss: 0.047000
		loss: 0.047000
		loss: 0.047000
		loss: 0.046900
		loss: 0.046900
		loss: 0.046900
		loss: 0.046900
		loss: 0.046800
		loss: 0.046800
		loss: 0.046800
		loss: 0.046800
		loss: 0.046700
		loss: 0.046700
		loss: 0.046700
		loss: 0.046700
		loss: 0.046700
		loss: 0.046600
		loss: 0.046600
		loss: 0.046600
		loss: 0.046600
		loss: 0.046500
		loss: 0.046500
		loss: 0.046500
		loss: 0.046500
		loss: 0.046500
		loss: 0.046400
		loss: 0.046400
		loss: 0.046400
		loss: 0.046400
		loss: 0.046300
		loss: 0.046300
		loss: 0.046300
		loss: 0.046300
		loss: 0.046300
		loss: 0.046200
		loss: 0.046200
		loss: 0.046200
		loss: 0.046200
		loss: 0.046200
		loss: 0.046100
		loss: 0.046100
		loss: 0.046100
	Overall the loss development was 0.932100 -> 0.046100

Training data for problem d-03.pddl in epoch 9:
model creation time: 10.434040069580078s
problem epoch data for epoch 9, problem epoch 1
	sampling search time: 2.428001642227173s
	during this search the following actions were chosen:
		move d1 d2 peg2 was chosen with probability 0.841415
		move d1 peg2 d2 was chosen with probability 0.984628
	training time: 57.05191397666931s
	during the training the following losses were computed:
		loss: 1.830400
		loss: 1.658500
		loss: 1.478800
		loss: 1.312300
		loss: 1.156700
		loss: 1.020100
		loss: 0.914800
		loss: 0.859000
		loss: 0.850700
		loss: 0.864600
		loss: 0.877400
		loss: 0.876900
		loss: 0.860900
		loss: 0.831900
		loss: 0.795300
		loss: 0.755600
		loss: 0.718700
		loss: 0.690100
		loss: 0.669400
		loss: 0.656900
		loss: 0.654400
		loss: 0.651100
		loss: 0.645800
		loss: 0.637900
		loss: 0.627700
		loss: 0.615700
		loss: 0.604800
		loss: 0.594500
		loss: 0.585900
		loss: 0.578000
		loss: 0.570500
		loss: 0.563300
		loss: 0.556800
		loss: 0.550900
		loss: 0.545600
		loss: 0.540800
		loss: 0.536100
		loss: 0.532100
		loss: 0.527900
		loss: 0.523300
		loss: 0.518300
		loss: 0.513000
		loss: 0.507600
		loss: 0.502300
		loss: 0.497300
		loss: 0.492600
		loss: 0.488100
		loss: 0.483900
		loss: 0.480200
		loss: 0.476300
		loss: 0.472200
		loss: 0.467900
		loss: 0.463400
		loss: 0.459000
		loss: 0.454900
		loss: 0.451100
		loss: 0.447300
		loss: 0.443500
		loss: 0.439700
		loss: 0.435900
		loss: 0.432200
		loss: 0.428500
		loss: 0.424900
		loss: 0.421100
		loss: 0.417300
		loss: 0.413700
		loss: 0.410000
		loss: 0.406500
		loss: 0.403200
		loss: 0.399700
		loss: 0.396300
		loss: 0.392900
		loss: 0.389600
		loss: 0.386300
		loss: 0.383000
		loss: 0.379800
		loss: 0.376500
		loss: 0.373500
		loss: 0.370700
		loss: 0.367800
		loss: 0.364900
		loss: 0.362200
		loss: 0.359400
		loss: 0.356700
		loss: 0.354000
		loss: 0.351400
		loss: 0.348800
		loss: 0.346200
		loss: 0.343600
		loss: 0.341000
		loss: 0.338600
		loss: 0.336100
		loss: 0.333700
		loss: 0.331300
		loss: 0.328800
		loss: 0.326300
		loss: 0.323700
		loss: 0.321300
		loss: 0.318900
		loss: 0.316500
		loss: 0.314100
		loss: 0.311700
		loss: 0.309300
		loss: 0.306200
		loss: 0.303000
		loss: 0.299400
		loss: 0.295700
		loss: 0.293200
		loss: 0.291100
		loss: 0.288900
		loss: 0.286600
		loss: 0.284300
		loss: 0.282000
		loss: 0.279700
		loss: 0.277500
		loss: 0.275200
		loss: 0.272900
		loss: 0.270700
		loss: 0.268400
		loss: 0.266200
		loss: 0.264000
		loss: 0.261800
		loss: 0.259600
		loss: 0.257400
		loss: 0.255200
		loss: 0.253000
		loss: 0.250800
		loss: 0.248600
		loss: 0.246400
		loss: 0.244300
		loss: 0.242200
		loss: 0.239900
		loss: 0.237800
		loss: 0.235600
		loss: 0.233400
		loss: 0.231100
		loss: 0.228800
		loss: 0.226300
		loss: 0.223900
		loss: 0.221500
		loss: 0.219000
		loss: 0.216600
		loss: 0.214200
		loss: 0.211800
		loss: 0.209500
		loss: 0.207200
		loss: 0.204900
		loss: 0.202400
		loss: 0.200200
		loss: 0.198000
		loss: 0.195800
		loss: 0.193600
		loss: 0.191700
		loss: 0.189600
		loss: 0.187300
		loss: 0.185200
		loss: 0.183100
		loss: 0.181000
		loss: 0.179000
		loss: 0.177100
		loss: 0.175100
		loss: 0.173000
		loss: 0.170900
		loss: 0.169000
		loss: 0.167200
		loss: 0.165400
		loss: 0.163800
		loss: 0.162000
		loss: 0.160300
		loss: 0.158600
		loss: 0.156900
		loss: 0.155300
		loss: 0.153700
		loss: 0.152000
		loss: 0.150400
		loss: 0.149100
		loss: 0.147700
		loss: 0.146000
		loss: 0.144900
		loss: 0.143500
		loss: 0.142000
		loss: 0.140400
		loss: 0.139100
		loss: 0.137700
		loss: 0.136400
		loss: 0.135100
		loss: 0.133600
		loss: 0.132600
		loss: 0.131300
		loss: 0.130000
		loss: 0.128900
		loss: 0.127800
		loss: 0.126600
		loss: 0.125400
		loss: 0.124600
		loss: 0.123600
		loss: 0.122300
		loss: 0.121400
		loss: 0.120500
		loss: 0.119500
		loss: 0.118300
		loss: 0.117400
		loss: 0.116600
		loss: 0.115700
		loss: 0.114700
		loss: 0.113900
		loss: 0.113200
		loss: 0.112300
		loss: 0.111500
		loss: 0.110700
		loss: 0.109900
		loss: 0.109200
		loss: 0.108600
		loss: 0.107900
		loss: 0.107200
		loss: 0.106600
		loss: 0.106000
		loss: 0.105200
		loss: 0.104600
		loss: 0.104000
		loss: 0.103400
		loss: 0.102700
		loss: 0.102100
		loss: 0.101500
		loss: 0.101000
		loss: 0.100500
		loss: 0.099900
		loss: 0.099400
		loss: 0.098900
		loss: 0.098400
		loss: 0.097800
		loss: 0.097300
		loss: 0.096800
		loss: 0.096400
		loss: 0.096000
		loss: 0.095500
		loss: 0.095000
		loss: 0.094600
		loss: 0.094100
		loss: 0.093700
		loss: 0.093400
		loss: 0.093000
		loss: 0.092600
		loss: 0.092200
		loss: 0.091800
		loss: 0.091500
		loss: 0.091100
		loss: 0.090700
		loss: 0.090400
		loss: 0.090100
		loss: 0.089700
		loss: 0.089500
		loss: 0.089100
		loss: 0.088800
		loss: 0.088500
		loss: 0.088200
		loss: 0.087900
		loss: 0.087600
		loss: 0.087300
		loss: 0.087000
		loss: 0.086700
		loss: 0.086400
		loss: 0.086200
		loss: 0.085900
		loss: 0.085700
		loss: 0.085400
		loss: 0.085200
		loss: 0.084900
		loss: 0.084700
		loss: 0.084400
		loss: 0.084200
		loss: 0.084000
		loss: 0.083800
		loss: 0.083500
		loss: 0.083400
		loss: 0.083100
		loss: 0.082900
		loss: 0.082700
		loss: 0.082500
		loss: 0.082400
		loss: 0.082200
		loss: 0.082000
		loss: 0.081800
		loss: 0.081600
		loss: 0.081400
		loss: 0.081200
		loss: 0.081100
		loss: 0.080900
		loss: 0.080700
		loss: 0.080600
		loss: 0.080400
		loss: 0.080200
		loss: 0.080100
		loss: 0.079900
		loss: 0.079800
		loss: 0.079600
		loss: 0.079500
		loss: 0.079300
		loss: 0.079200
		loss: 0.079100
	Overall the loss development was 1.830400 -> 0.079100

Epoch 10:
Training data for problem d-01.pddl in epoch 10:
model creation time: 2.1099956035614014s
problem epoch data for epoch 10, problem epoch 1
	sampling search time: 0.6136131286621094s
	during this search the following actions were chosen:
	training time: 37.01844596862793s
	during the training the following losses were computed:
		loss: 0.061500
		loss: 0.060900
		loss: 0.060300
		loss: 0.059700
		loss: 0.059100
		loss: 0.058600
		loss: 0.058000
		loss: 0.057400
		loss: 0.056900
		loss: 0.056300
		loss: 0.055800
		loss: 0.055200
		loss: 0.054700
		loss: 0.054200
		loss: 0.053700
		loss: 0.053100
		loss: 0.052600
		loss: 0.052100
		loss: 0.051600
		loss: 0.051100
		loss: 0.050600
		loss: 0.050100
		loss: 0.049700
		loss: 0.049200
		loss: 0.048700
		loss: 0.048200
		loss: 0.047800
		loss: 0.047300
		loss: 0.046900
		loss: 0.046400
		loss: 0.046000
		loss: 0.045600
		loss: 0.045100
		loss: 0.044700
		loss: 0.044300
		loss: 0.043900
		loss: 0.043500
		loss: 0.043000
		loss: 0.042600
		loss: 0.042200
		loss: 0.041900
		loss: 0.041500
		loss: 0.041100
		loss: 0.040700
		loss: 0.040300
		loss: 0.040000
		loss: 0.039600
		loss: 0.039200
		loss: 0.038900
		loss: 0.038500
		loss: 0.038200
		loss: 0.037800
		loss: 0.037500
		loss: 0.037200
		loss: 0.036800
		loss: 0.036500
		loss: 0.036200
		loss: 0.035900
		loss: 0.035600
		loss: 0.035300
		loss: 0.035000
		loss: 0.034700
		loss: 0.034400
		loss: 0.034100
		loss: 0.033800
		loss: 0.033500
		loss: 0.033300
		loss: 0.033000
		loss: 0.032700
		loss: 0.032500
		loss: 0.032200
		loss: 0.032000
		loss: 0.031700
		loss: 0.031400
		loss: 0.031200
		loss: 0.031000
		loss: 0.030700
		loss: 0.030500
		loss: 0.030300
		loss: 0.030000
		loss: 0.029800
		loss: 0.029600
		loss: 0.029400
		loss: 0.029100
		loss: 0.028900
		loss: 0.028700
		loss: 0.028500
		loss: 0.028300
		loss: 0.028100
		loss: 0.027900
		loss: 0.027700
		loss: 0.027500
		loss: 0.027300
		loss: 0.027200
		loss: 0.027000
		loss: 0.026800
		loss: 0.026600
		loss: 0.026400
		loss: 0.026300
		loss: 0.026100
		loss: 0.025900
		loss: 0.025800
		loss: 0.025600
		loss: 0.025500
		loss: 0.025300
		loss: 0.025200
		loss: 0.025000
		loss: 0.024900
		loss: 0.024700
		loss: 0.024600
		loss: 0.024500
		loss: 0.024400
		loss: 0.024200
		loss: 0.024100
		loss: 0.024000
		loss: 0.023900
		loss: 0.023800
		loss: 0.023700
		loss: 0.023600
		loss: 0.023500
		loss: 0.023400
		loss: 0.023300
		loss: 0.023200
		loss: 0.023100
		loss: 0.023000
		loss: 0.022900
		loss: 0.022800
		loss: 0.022700
		loss: 0.022700
		loss: 0.022600
		loss: 0.022500
		loss: 0.022400
		loss: 0.022300
		loss: 0.022200
		loss: 0.022200
		loss: 0.022100
		loss: 0.022000
		loss: 0.021900
		loss: 0.021900
		loss: 0.021800
		loss: 0.021700
		loss: 0.021700
		loss: 0.021600
		loss: 0.021500
		loss: 0.021500
		loss: 0.021400
		loss: 0.021300
		loss: 0.021300
		loss: 0.021200
		loss: 0.021100
		loss: 0.021100
		loss: 0.021000
		loss: 0.021000
		loss: 0.020900
		loss: 0.020800
		loss: 0.020800
		loss: 0.020700
		loss: 0.020700
		loss: 0.020600
		loss: 0.020600
		loss: 0.020500
		loss: 0.020500
		loss: 0.020400
		loss: 0.020400
		loss: 0.020300
		loss: 0.020300
		loss: 0.020200
		loss: 0.020200
		loss: 0.020100
		loss: 0.020100
		loss: 0.020000
		loss: 0.020000
		loss: 0.019900
		loss: 0.019900
		loss: 0.019800
		loss: 0.019800
		loss: 0.019700
		loss: 0.019700
		loss: 0.019700
		loss: 0.019600
		loss: 0.019600
		loss: 0.019500
		loss: 0.019500
		loss: 0.019400
		loss: 0.019400
		loss: 0.019400
		loss: 0.019300
		loss: 0.019300
		loss: 0.019200
		loss: 0.019200
		loss: 0.019200
		loss: 0.019100
		loss: 0.019100
		loss: 0.019100
		loss: 0.019000
		loss: 0.019000
		loss: 0.018900
		loss: 0.018900
		loss: 0.018900
		loss: 0.018900
		loss: 0.018800
		loss: 0.018800
		loss: 0.018700
		loss: 0.018700
		loss: 0.018700
		loss: 0.018600
		loss: 0.018600
		loss: 0.018600
		loss: 0.018500
		loss: 0.018500
		loss: 0.018500
		loss: 0.018400
		loss: 0.018400
		loss: 0.018400
		loss: 0.018400
		loss: 0.018300
		loss: 0.018300
		loss: 0.018300
		loss: 0.018200
		loss: 0.018200
		loss: 0.018200
		loss: 0.018100
		loss: 0.018100
		loss: 0.018100
		loss: 0.018100
		loss: 0.018000
		loss: 0.018000
		loss: 0.018000
		loss: 0.018000
		loss: 0.017900
		loss: 0.017900
		loss: 0.017900
		loss: 0.017900
		loss: 0.017800
		loss: 0.017800
		loss: 0.017800
		loss: 0.017700
		loss: 0.017700
		loss: 0.017700
		loss: 0.017700
		loss: 0.017600
		loss: 0.017600
		loss: 0.017600
		loss: 0.017600
		loss: 0.017600
		loss: 0.017500
		loss: 0.017500
		loss: 0.017500
		loss: 0.017500
		loss: 0.017400
		loss: 0.017400
		loss: 0.017400
		loss: 0.017400
		loss: 0.017400
		loss: 0.017300
		loss: 0.017300
		loss: 0.017300
		loss: 0.017300
		loss: 0.017200
		loss: 0.017200
		loss: 0.017200
		loss: 0.017200
		loss: 0.017200
		loss: 0.017100
		loss: 0.017100
		loss: 0.017100
		loss: 0.017100
		loss: 0.017100
		loss: 0.017000
		loss: 0.017000
		loss: 0.017000
		loss: 0.017000
		loss: 0.016900
		loss: 0.016900
		loss: 0.016900
		loss: 0.016900
		loss: 0.016800
		loss: 0.016800
		loss: 0.016800
		loss: 0.016700
		loss: 0.016700
		loss: 0.016700
		loss: 0.016700
		loss: 0.016600
		loss: 0.016600
		loss: 0.016600
		loss: 0.016500
		loss: 0.016500
		loss: 0.016500
		loss: 0.016500
		loss: 0.016400
		loss: 0.016400
		loss: 0.016400
		loss: 0.016400
		loss: 0.016300
		loss: 0.016300
		loss: 0.016300
		loss: 0.016300
		loss: 0.016300
		loss: 0.016200
	Overall the loss development was 0.061500 -> 0.016200

Training data for problem d-02.pddl in epoch 10:
model creation time: 5.126268148422241s
problem epoch data for epoch 10, problem epoch 1
	sampling search time: 1.333136796951294s
	during this search the following actions were chosen:
		move d1 d2 peg1 was chosen with probability 0.538695
		move d1 peg1 d2 was chosen with probability 0.453214
	training time: 44.80309557914734s
	during the training the following losses were computed:
		loss: 0.856400
		loss: 0.844300
		loss: 0.833000
		loss: 0.822500
		loss: 0.812500
		loss: 0.805300
		loss: 0.797800
		loss: 0.791400
		loss: 0.785500
		loss: 0.780200
		loss: 0.775500
		loss: 0.771600
		loss: 0.768800
		loss: 0.766400
		loss: 0.764200
		loss: 0.761700
		loss: 0.759400
		loss: 0.757300
		loss: 0.755000
		loss: 0.752600
		loss: 0.749900
		loss: 0.746900
		loss: 0.743800
		loss: 0.740600
		loss: 0.737600
		loss: 0.734400
		loss: 0.731200
		loss: 0.728000
		loss: 0.724600
		loss: 0.721200
		loss: 0.717500
		loss: 0.714200
		loss: 0.710700
		loss: 0.706800
		loss: 0.702900
		loss: 0.699000
		loss: 0.694900
		loss: 0.690500
		loss: 0.686200
		loss: 0.681400
		loss: 0.676700
		loss: 0.671500
		loss: 0.666300
		loss: 0.660800
		loss: 0.655000
		loss: 0.648900
		loss: 0.643200
		loss: 0.636900
		loss: 0.629700
		loss: 0.622900
		loss: 0.615900
		loss: 0.608600
		loss: 0.601300
		loss: 0.593100
		loss: 0.585100
		loss: 0.576700
		loss: 0.567800
		loss: 0.558800
		loss: 0.549300
		loss: 0.539600
		loss: 0.529400
		loss: 0.520000
		loss: 0.509000
		loss: 0.498500
		loss: 0.487800
		loss: 0.476800
		loss: 0.465300
		loss: 0.453500
		loss: 0.442000
		loss: 0.429900
		loss: 0.418100
		loss: 0.405600
		loss: 0.393300
		loss: 0.380900
		loss: 0.368300
		loss: 0.356600
		loss: 0.344200
		loss: 0.331700
		loss: 0.320000
		loss: 0.308300
		loss: 0.296300
		loss: 0.284600
		loss: 0.272800
		loss: 0.261700
		loss: 0.250500
		loss: 0.239300
		loss: 0.229300
		loss: 0.219100
		loss: 0.209200
		loss: 0.200000
		loss: 0.190200
		loss: 0.181400
		loss: 0.173000
		loss: 0.164800
		loss: 0.156900
		loss: 0.149600
		loss: 0.143100
		loss: 0.136600
		loss: 0.130200
		loss: 0.124500
		loss: 0.119100
		loss: 0.114000
		loss: 0.109300
		loss: 0.104700
		loss: 0.100500
		loss: 0.096700
		loss: 0.093100
		loss: 0.089800
		loss: 0.086800
		loss: 0.084100
		loss: 0.081500
		loss: 0.079100
		loss: 0.076900
		loss: 0.074900
		loss: 0.072900
		loss: 0.071200
		loss: 0.069600
		loss: 0.068200
		loss: 0.066900
		loss: 0.065700
		loss: 0.064600
		loss: 0.063600
		loss: 0.062700
		loss: 0.061800
		loss: 0.061100
		loss: 0.060400
		loss: 0.059700
		loss: 0.059100
		loss: 0.058500
		loss: 0.058000
		loss: 0.057500
		loss: 0.057100
		loss: 0.056700
		loss: 0.056300
		loss: 0.056000
		loss: 0.055600
		loss: 0.055300
		loss: 0.055000
		loss: 0.054800
		loss: 0.054500
		loss: 0.054300
		loss: 0.054100
		loss: 0.053900
		loss: 0.053700
		loss: 0.053500
		loss: 0.053300
		loss: 0.053200
		loss: 0.053000
		loss: 0.052900
		loss: 0.052700
		loss: 0.052600
		loss: 0.052500
		loss: 0.052400
		loss: 0.052300
		loss: 0.052100
		loss: 0.052000
		loss: 0.051900
		loss: 0.051800
		loss: 0.051800
		loss: 0.051700
		loss: 0.051600
		loss: 0.051500
		loss: 0.051400
		loss: 0.051400
		loss: 0.051300
		loss: 0.051200
		loss: 0.051200
		loss: 0.051100
		loss: 0.051000
		loss: 0.051000
		loss: 0.050900
		loss: 0.050900
		loss: 0.050800
		loss: 0.050800
		loss: 0.050700
		loss: 0.050700
		loss: 0.050600
		loss: 0.050600
		loss: 0.050500
		loss: 0.050500
		loss: 0.050500
		loss: 0.050400
		loss: 0.050400
		loss: 0.050300
		loss: 0.050300
		loss: 0.050200
		loss: 0.050200
		loss: 0.050200
		loss: 0.050100
		loss: 0.050100
		loss: 0.050100
		loss: 0.050000
		loss: 0.050000
		loss: 0.050000
		loss: 0.049900
		loss: 0.049900
		loss: 0.049900
		loss: 0.049800
		loss: 0.049800
		loss: 0.049800
		loss: 0.049700
		loss: 0.049700
		loss: 0.049700
		loss: 0.049700
		loss: 0.049600
		loss: 0.049600
		loss: 0.049600
		loss: 0.049500
		loss: 0.049500
		loss: 0.049500
		loss: 0.049500
		loss: 0.049400
		loss: 0.049400
		loss: 0.049400
		loss: 0.049400
		loss: 0.049300
		loss: 0.049300
		loss: 0.049300
		loss: 0.049300
		loss: 0.049200
		loss: 0.049200
		loss: 0.049200
		loss: 0.049200
		loss: 0.049100
		loss: 0.049100
		loss: 0.049100
		loss: 0.049100
		loss: 0.049000
		loss: 0.049000
		loss: 0.049000
		loss: 0.049000
		loss: 0.048900
		loss: 0.048900
		loss: 0.048900
		loss: 0.048900
		loss: 0.048900
		loss: 0.048800
		loss: 0.048800
		loss: 0.048800
		loss: 0.048800
		loss: 0.048700
		loss: 0.048700
		loss: 0.048700
		loss: 0.048700
		loss: 0.048700
		loss: 0.048600
		loss: 0.048600
		loss: 0.048600
		loss: 0.048600
		loss: 0.048500
		loss: 0.048500
		loss: 0.048500
		loss: 0.048500
		loss: 0.048500
		loss: 0.048400
		loss: 0.048400
		loss: 0.048400
		loss: 0.048400
		loss: 0.048400
		loss: 0.048300
		loss: 0.048300
		loss: 0.048300
		loss: 0.048300
		loss: 0.048300
		loss: 0.048200
		loss: 0.048200
		loss: 0.048200
		loss: 0.048200
		loss: 0.048200
		loss: 0.048100
		loss: 0.048100
		loss: 0.048100
		loss: 0.048100
		loss: 0.048100
		loss: 0.048000
		loss: 0.048000
		loss: 0.048000
		loss: 0.048000
		loss: 0.048000
		loss: 0.048000
		loss: 0.047900
		loss: 0.047900
		loss: 0.047900
		loss: 0.047900
		loss: 0.047900
		loss: 0.047800
		loss: 0.047800
		loss: 0.047800
		loss: 0.047800
		loss: 0.047800
		loss: 0.047700
		loss: 0.047700
		loss: 0.047700
		loss: 0.047700
		loss: 0.047700
		loss: 0.047700
		loss: 0.047600
		loss: 0.047600
		loss: 0.047600
		loss: 0.047600
	Overall the loss development was 0.856400 -> 0.047600

Training data for problem d-03.pddl in epoch 10:
model creation time: 10.351628065109253s
problem epoch data for epoch 10, problem epoch 1
	sampling search time: 2.5874388217926025s
	during this search the following actions were chosen:
		move d1 d2 peg2 was chosen with probability 0.804817
		move d1 peg2 d2 was chosen with probability 0.872805
	training time: 57.88207197189331s
	during the training the following losses were computed:
		loss: 1.318400
		loss: 1.211300
		loss: 1.109900
		loss: 1.023700
		loss: 0.942000
		loss: 0.867200
		loss: 0.804000
		loss: 0.748700
		loss: 0.699100
		loss: 0.653500
		loss: 0.612400
		loss: 0.576100
		loss: 0.544600
		loss: 0.517500
		loss: 0.495400
		loss: 0.478700
		loss: 0.465800
		loss: 0.456300
		loss: 0.449300
		loss: 0.443500
		loss: 0.438600
		loss: 0.435100
		loss: 0.430700
		loss: 0.425000
		loss: 0.419600
		loss: 0.414200
		loss: 0.408600
		loss: 0.402400
		loss: 0.395800
		loss: 0.389300
		loss: 0.382900
		loss: 0.377100
		loss: 0.371400
		loss: 0.365700
		loss: 0.360100
		loss: 0.354500
		loss: 0.349000
		loss: 0.343600
		loss: 0.338400
		loss: 0.332900
		loss: 0.327700
		loss: 0.322600
		loss: 0.317700
		loss: 0.313100
		loss: 0.308700
		loss: 0.304600
		loss: 0.300300
		loss: 0.295800
		loss: 0.291700
		loss: 0.287600
		loss: 0.283500
		loss: 0.279400
		loss: 0.275200
		loss: 0.271000
		loss: 0.266900
		loss: 0.262800
		loss: 0.258800
		loss: 0.254800
		loss: 0.250800
		loss: 0.247000
		loss: 0.243200
		loss: 0.239700
		loss: 0.236100
		loss: 0.232300
		loss: 0.228400
		loss: 0.224700
		loss: 0.220700
		loss: 0.216600
		loss: 0.212600
		loss: 0.209100
		loss: 0.205800
		loss: 0.202800
		loss: 0.199700
		loss: 0.196700
		loss: 0.193700
		loss: 0.190700
		loss: 0.187700
		loss: 0.184900
		loss: 0.182100
		loss: 0.179300
		loss: 0.176700
		loss: 0.174000
		loss: 0.171400
		loss: 0.168900
		loss: 0.166400
		loss: 0.163700
		loss: 0.161100
		loss: 0.158800
		loss: 0.156400
		loss: 0.154100
		loss: 0.151900
		loss: 0.149700
		loss: 0.147500
		loss: 0.145400
		loss: 0.143200
		loss: 0.141000
		loss: 0.139000
		loss: 0.137000
		loss: 0.135100
		loss: 0.133200
		loss: 0.131400
		loss: 0.129600
		loss: 0.127800
		loss: 0.126100
		loss: 0.124400
		loss: 0.122800
		loss: 0.121200
		loss: 0.119600
		loss: 0.118100
		loss: 0.116700
		loss: 0.115200
		loss: 0.113800
		loss: 0.112400
		loss: 0.111200
		loss: 0.109900
		loss: 0.108600
		loss: 0.107400
		loss: 0.106300
		loss: 0.105200
		loss: 0.104100
		loss: 0.103100
		loss: 0.102100
		loss: 0.101100
		loss: 0.100200
		loss: 0.099300
		loss: 0.098400
		loss: 0.097500
		loss: 0.096700
		loss: 0.095900
		loss: 0.095000
		loss: 0.094200
		loss: 0.093300
		loss: 0.092500
		loss: 0.091700
		loss: 0.090900
		loss: 0.090000
		loss: 0.089200
		loss: 0.088200
		loss: 0.087500
		loss: 0.086800
		loss: 0.086000
		loss: 0.085300
		loss: 0.084600
		loss: 0.083900
		loss: 0.083400
		loss: 0.082900
		loss: 0.082600
		loss: 0.082200
		loss: 0.081900
		loss: 0.081500
		loss: 0.081200
		loss: 0.080900
		loss: 0.080600
		loss: 0.080300
		loss: 0.080000
		loss: 0.079700
		loss: 0.079400
		loss: 0.079200
		loss: 0.078900
		loss: 0.078600
		loss: 0.078400
		loss: 0.078100
		loss: 0.077900
		loss: 0.077700
		loss: 0.077500
		loss: 0.077200
		loss: 0.077000
		loss: 0.076800
		loss: 0.076600
		loss: 0.076400
		loss: 0.076300
		loss: 0.076100
		loss: 0.075900
		loss: 0.075700
		loss: 0.075600
		loss: 0.075400
		loss: 0.075300
		loss: 0.075100
		loss: 0.075000
		loss: 0.074800
		loss: 0.074700
		loss: 0.074500
		loss: 0.074400
		loss: 0.074300
		loss: 0.074200
		loss: 0.074000
		loss: 0.073900
		loss: 0.073800
		loss: 0.073700
		loss: 0.073600
		loss: 0.073400
		loss: 0.073300
		loss: 0.073200
		loss: 0.073100
		loss: 0.073000
		loss: 0.072900
		loss: 0.072800
		loss: 0.072700
		loss: 0.072700
		loss: 0.072600
		loss: 0.072500
		loss: 0.072400
		loss: 0.072300
		loss: 0.072200
		loss: 0.072100
		loss: 0.072100
		loss: 0.072000
		loss: 0.071900
		loss: 0.071800
		loss: 0.071800
		loss: 0.071700
		loss: 0.071600
		loss: 0.071500
		loss: 0.071500
		loss: 0.071400
		loss: 0.071300
		loss: 0.071300
		loss: 0.071200
		loss: 0.071200
		loss: 0.071100
		loss: 0.071100
		loss: 0.071000
		loss: 0.070900
		loss: 0.070900
		loss: 0.070800
		loss: 0.070800
		loss: 0.070700
		loss: 0.070700
		loss: 0.070600
		loss: 0.070600
		loss: 0.070500
		loss: 0.070500
		loss: 0.070400
		loss: 0.070400
		loss: 0.070300
		loss: 0.070300
		loss: 0.070200
		loss: 0.070200
		loss: 0.070200
		loss: 0.070100
		loss: 0.070100
		loss: 0.070000
		loss: 0.070000
		loss: 0.069900
		loss: 0.069900
		loss: 0.069900
		loss: 0.069800
		loss: 0.069800
		loss: 0.069700
		loss: 0.069700
		loss: 0.069700
		loss: 0.069600
		loss: 0.069600
		loss: 0.069500
		loss: 0.069500
		loss: 0.069500
		loss: 0.069400
		loss: 0.069400
		loss: 0.069400
		loss: 0.069300
		loss: 0.069300
		loss: 0.069200
		loss: 0.069200
		loss: 0.069200
		loss: 0.069100
		loss: 0.069100
		loss: 0.069000
		loss: 0.069000
		loss: 0.069000
		loss: 0.068900
		loss: 0.068900
		loss: 0.068800
		loss: 0.068800
		loss: 0.068800
		loss: 0.068700
		loss: 0.068700
		loss: 0.068600
		loss: 0.068600
		loss: 0.068600
		loss: 0.068500
		loss: 0.068500
		loss: 0.068400
		loss: 0.068400
		loss: 0.068400
		loss: 0.068300
		loss: 0.068300
		loss: 0.068300
		loss: 0.068200
		loss: 0.068200
		loss: 0.068200
		loss: 0.068100
		loss: 0.068100
		loss: 0.068100
		loss: 0.068000
		loss: 0.068000
		loss: 0.067900
		loss: 0.067900
		loss: 0.067900
		loss: 0.067800
		loss: 0.067800
	Overall the loss development was 1.318400 -> 0.067800

