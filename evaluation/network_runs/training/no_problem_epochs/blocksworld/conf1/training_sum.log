Training log data for domain blocksworld:
printing the data chronological
Epoch 1:
Training data for problem d-4-0.pddl in epoch 1:
model creation time: 9.088970184326172s
problem epoch data for epoch 1, problem epoch 1
	sampling search time: 2.3219990730285645s
	during this search the following actions were chosen:
		pick-up a was chosen with probability 0.252352
		put-down a was chosen with probability 0.275718
	training time: 59.583070278167725s
	during the training the following losses were computed:
		loss: 1.330400
		loss: 1.301100
		loss: 1.275200
		loss: 1.251100
		loss: 1.230400
		loss: 1.212600
		loss: 1.197000
		loss: 1.182500
		loss: 1.169400
		loss: 1.157700
		loss: 1.146600
		loss: 1.136300
		loss: 1.125700
		loss: 1.115600
		loss: 1.105300
		loss: 1.095400
		loss: 1.085300
		loss: 1.075100
		loss: 1.065000
		loss: 1.054800
		loss: 1.044600
		loss: 1.034700
		loss: 1.025300
		loss: 1.015800
		loss: 1.006200
		loss: 0.996900
		loss: 0.987400
		loss: 0.977700
		loss: 0.967900
		loss: 0.958000
		loss: 0.948200
		loss: 0.938400
		loss: 0.928600
		loss: 0.918600
		loss: 0.908500
		loss: 0.898200
		loss: 0.887800
		loss: 0.877400
		loss: 0.866700
		loss: 0.855800
		loss: 0.845100
		loss: 0.834500
		loss: 0.823900
		loss: 0.813200
		loss: 0.802400
		loss: 0.791800
		loss: 0.781200
		loss: 0.770600
		loss: 0.760200
		loss: 0.750100
		loss: 0.740000
		loss: 0.729800
		loss: 0.719900
		loss: 0.710200
		loss: 0.700400
		loss: 0.690900
		loss: 0.681600
		loss: 0.671900
		loss: 0.662100
		loss: 0.652200
		loss: 0.642800
		loss: 0.633400
		loss: 0.624000
		loss: 0.615200
		loss: 0.606300
		loss: 0.597500
		loss: 0.589000
		loss: 0.580700
		loss: 0.572400
		loss: 0.564600
		loss: 0.556900
		loss: 0.549600
		loss: 0.542500
		loss: 0.535700
		loss: 0.529300
		loss: 0.523100
		loss: 0.517200
		loss: 0.511600
		loss: 0.506400
		loss: 0.501500
		loss: 0.496800
		loss: 0.492400
		loss: 0.488300
		loss: 0.484500
		loss: 0.480900
		loss: 0.477400
		loss: 0.474100
		loss: 0.471000
		loss: 0.468000
		loss: 0.465100
		loss: 0.462300
		loss: 0.459700
		loss: 0.457000
		loss: 0.454500
		loss: 0.452000
		loss: 0.449500
		loss: 0.447100
		loss: 0.444700
		loss: 0.442300
		loss: 0.439900
		loss: 0.437500
		loss: 0.435100
		loss: 0.432800
		loss: 0.430400
		loss: 0.428000
		loss: 0.425600
		loss: 0.423100
		loss: 0.420700
		loss: 0.418200
		loss: 0.415700
		loss: 0.413200
		loss: 0.410800
		loss: 0.408200
		loss: 0.405500
		loss: 0.403000
		loss: 0.400400
		loss: 0.397900
		loss: 0.395300
		loss: 0.392800
		loss: 0.390200
		loss: 0.387600
		loss: 0.384900
		loss: 0.382300
		loss: 0.379700
		loss: 0.377400
		loss: 0.374800
		loss: 0.372300
		loss: 0.369700
		loss: 0.367100
		loss: 0.364600
		loss: 0.362200
		loss: 0.359700
		loss: 0.357400
		loss: 0.355100
		loss: 0.352900
		loss: 0.350800
		loss: 0.348600
		loss: 0.346600
		loss: 0.344700
		loss: 0.342800
		loss: 0.341000
		loss: 0.339300
		loss: 0.337600
		loss: 0.335900
		loss: 0.334400
		loss: 0.332900
		loss: 0.331400
		loss: 0.330000
		loss: 0.328600
		loss: 0.327300
		loss: 0.326000
		loss: 0.324800
		loss: 0.323600
		loss: 0.322500
		loss: 0.321400
		loss: 0.320300
		loss: 0.319300
		loss: 0.318300
		loss: 0.317400
		loss: 0.316400
		loss: 0.315500
		loss: 0.314600
		loss: 0.313800
		loss: 0.312900
		loss: 0.312100
		loss: 0.311300
		loss: 0.310500
		loss: 0.309700
		loss: 0.308900
		loss: 0.308100
		loss: 0.307400
		loss: 0.306600
		loss: 0.305900
		loss: 0.305200
		loss: 0.304500
		loss: 0.303800
		loss: 0.303100
		loss: 0.302400
		loss: 0.301700
		loss: 0.301100
		loss: 0.300400
		loss: 0.299700
		loss: 0.299100
		loss: 0.298500
		loss: 0.297800
		loss: 0.297200
		loss: 0.296600
		loss: 0.295900
		loss: 0.295300
		loss: 0.294700
		loss: 0.294100
		loss: 0.293500
		loss: 0.292900
		loss: 0.292300
		loss: 0.291700
		loss: 0.291100
		loss: 0.290600
		loss: 0.290000
		loss: 0.289400
		loss: 0.288800
		loss: 0.288300
		loss: 0.287700
		loss: 0.287200
		loss: 0.286600
		loss: 0.286000
		loss: 0.285500
		loss: 0.285000
		loss: 0.284400
		loss: 0.283900
		loss: 0.283400
		loss: 0.282800
		loss: 0.282300
		loss: 0.281800
		loss: 0.281300
		loss: 0.280700
		loss: 0.280200
		loss: 0.279700
		loss: 0.279200
		loss: 0.278700
		loss: 0.278200
		loss: 0.277700
		loss: 0.277200
		loss: 0.276700
		loss: 0.276200
		loss: 0.275800
		loss: 0.275300
		loss: 0.274800
		loss: 0.274300
		loss: 0.273800
		loss: 0.273400
		loss: 0.272900
		loss: 0.272400
		loss: 0.272000
		loss: 0.271500
		loss: 0.271100
		loss: 0.270600
		loss: 0.270200
		loss: 0.269700
		loss: 0.269300
		loss: 0.268800
		loss: 0.268400
		loss: 0.267900
		loss: 0.267500
		loss: 0.267100
		loss: 0.266600
		loss: 0.266200
		loss: 0.265800
		loss: 0.265400
		loss: 0.264900
		loss: 0.264500
		loss: 0.264100
		loss: 0.263700
		loss: 0.263300
		loss: 0.262900
		loss: 0.262500
		loss: 0.262000
		loss: 0.261600
		loss: 0.261200
		loss: 0.260800
		loss: 0.260400
		loss: 0.260000
		loss: 0.259600
		loss: 0.259300
		loss: 0.258900
		loss: 0.258500
		loss: 0.258100
		loss: 0.257700
		loss: 0.257300
		loss: 0.257000
		loss: 0.256600
		loss: 0.256200
		loss: 0.255800
		loss: 0.255500
		loss: 0.255100
		loss: 0.254700
		loss: 0.254400
		loss: 0.254000
		loss: 0.253600
		loss: 0.253300
		loss: 0.252900
		loss: 0.252600
		loss: 0.252200
		loss: 0.251900
		loss: 0.251500
		loss: 0.251200
		loss: 0.250800
		loss: 0.250500
		loss: 0.250200
		loss: 0.249800
		loss: 0.249500
		loss: 0.249100
		loss: 0.248800
		loss: 0.248500
		loss: 0.248200
		loss: 0.247800
		loss: 0.247500
		loss: 0.247200
		loss: 0.246900
		loss: 0.246500
		loss: 0.246200
	Overall the loss development was 1.330400 -> 0.246200

Training data for problem d-4-2.pddl in epoch 1:
model creation time: 9.75796103477478s
problem epoch data for epoch 1, problem epoch 1
	sampling search time: 2.3703527450561523s
	during this search the following actions were chosen:
		pick-up a was chosen with probability 0.917648
		stack a c was chosen with probability 0.961057
		pick-up d was chosen with probability 0.999929
		stack d a was chosen with probability 0.953282
	training time: 60.6223087310791s
	during the training the following losses were computed:
		loss: 2.844900
		loss: 2.404200
		loss: 2.002900
		loss: 1.664900
		loss: 1.406000
		loss: 1.220200
		loss: 1.063300
		loss: 0.914000
		loss: 0.765300
		loss: 0.626400
		loss: 0.505600
		loss: 0.411300
		loss: 0.345200
		loss: 0.310000
		loss: 0.302900
		loss: 0.313400
		loss: 0.331500
		loss: 0.350000
		loss: 0.362300
		loss: 0.366400
		loss: 0.361200
		loss: 0.347700
		loss: 0.327700
		loss: 0.304200
		loss: 0.279600
		loss: 0.256900
		loss: 0.237300
		loss: 0.221700
		loss: 0.210400
		loss: 0.203600
		loss: 0.200200
		loss: 0.199300
		loss: 0.200000
		loss: 0.201300
		loss: 0.202700
		loss: 0.203400
		loss: 0.203000
		loss: 0.201600
		loss: 0.199000
		loss: 0.195400
		loss: 0.191100
		loss: 0.186400
		loss: 0.181700
		loss: 0.177100
		loss: 0.173000
		loss: 0.169500
		loss: 0.166600
		loss: 0.164400
		loss: 0.162600
		loss: 0.161300
		loss: 0.160200
		loss: 0.159300
		loss: 0.158400
		loss: 0.157400
		loss: 0.156400
		loss: 0.155200
		loss: 0.153900
		loss: 0.152500
		loss: 0.151100
		loss: 0.149700
		loss: 0.148400
		loss: 0.147200
		loss: 0.146000
		loss: 0.144900
		loss: 0.143900
		loss: 0.142900
		loss: 0.142000
		loss: 0.141200
		loss: 0.140300
		loss: 0.139500
		loss: 0.138700
		loss: 0.137800
		loss: 0.137000
		loss: 0.136200
		loss: 0.135400
		loss: 0.134600
		loss: 0.133900
		loss: 0.133100
		loss: 0.132400
		loss: 0.131700
		loss: 0.131000
		loss: 0.130300
		loss: 0.129700
		loss: 0.129100
		loss: 0.128500
		loss: 0.127900
		loss: 0.127400
		loss: 0.126800
		loss: 0.126300
		loss: 0.125800
		loss: 0.125300
		loss: 0.124800
		loss: 0.124300
		loss: 0.123800
		loss: 0.123400
		loss: 0.122900
		loss: 0.122500
		loss: 0.122100
		loss: 0.121700
		loss: 0.121200
		loss: 0.120900
		loss: 0.120500
		loss: 0.120100
		loss: 0.119700
		loss: 0.119300
		loss: 0.119000
		loss: 0.118600
		loss: 0.118300
		loss: 0.117900
		loss: 0.117600
		loss: 0.117200
		loss: 0.116900
		loss: 0.116600
		loss: 0.116300
		loss: 0.116000
		loss: 0.115700
		loss: 0.115400
		loss: 0.115100
		loss: 0.114900
		loss: 0.114600
		loss: 0.114300
		loss: 0.114100
		loss: 0.113800
		loss: 0.113600
		loss: 0.113300
		loss: 0.113100
		loss: 0.112900
		loss: 0.112700
		loss: 0.112400
		loss: 0.112200
		loss: 0.112000
		loss: 0.111800
		loss: 0.111600
		loss: 0.111400
		loss: 0.111200
		loss: 0.111000
		loss: 0.110900
		loss: 0.110700
		loss: 0.110500
		loss: 0.110300
		loss: 0.110200
		loss: 0.110000
		loss: 0.109800
		loss: 0.109700
		loss: 0.109500
		loss: 0.109400
		loss: 0.109200
		loss: 0.109100
		loss: 0.108900
		loss: 0.108800
		loss: 0.108700
		loss: 0.108500
		loss: 0.108400
		loss: 0.108300
		loss: 0.108100
		loss: 0.108000
		loss: 0.107900
		loss: 0.107800
		loss: 0.107700
		loss: 0.107500
		loss: 0.107400
		loss: 0.107300
		loss: 0.107200
		loss: 0.107100
		loss: 0.107000
		loss: 0.106900
		loss: 0.106800
		loss: 0.106700
		loss: 0.106600
		loss: 0.106500
		loss: 0.106400
		loss: 0.106300
		loss: 0.106200
		loss: 0.106100
		loss: 0.106000
		loss: 0.105900
		loss: 0.105800
		loss: 0.105700
		loss: 0.105600
		loss: 0.105500
		loss: 0.105400
		loss: 0.105300
		loss: 0.105200
		loss: 0.105100
		loss: 0.105100
		loss: 0.105000
		loss: 0.104900
		loss: 0.104800
		loss: 0.104700
		loss: 0.104600
		loss: 0.104600
		loss: 0.104500
		loss: 0.104400
		loss: 0.104300
		loss: 0.104200
		loss: 0.104200
		loss: 0.104100
		loss: 0.104000
		loss: 0.103900
		loss: 0.103900
		loss: 0.103800
		loss: 0.103700
		loss: 0.103600
		loss: 0.103500
		loss: 0.103500
		loss: 0.103400
		loss: 0.103300
		loss: 0.103200
		loss: 0.103200
		loss: 0.103100
		loss: 0.103000
		loss: 0.103000
		loss: 0.102900
		loss: 0.102800
		loss: 0.102700
		loss: 0.102700
		loss: 0.102600
		loss: 0.102500
		loss: 0.102400
		loss: 0.102400
		loss: 0.102300
		loss: 0.102200
		loss: 0.102200
		loss: 0.102100
		loss: 0.102000
		loss: 0.102000
		loss: 0.101900
		loss: 0.101800
		loss: 0.101800
		loss: 0.101700
		loss: 0.101600
		loss: 0.101500
		loss: 0.101500
		loss: 0.101400
		loss: 0.101300
		loss: 0.101300
		loss: 0.101200
		loss: 0.101200
		loss: 0.101100
		loss: 0.101000
		loss: 0.101000
		loss: 0.100900
		loss: 0.100800
		loss: 0.100800
		loss: 0.100700
		loss: 0.100600
		loss: 0.100600
		loss: 0.100500
		loss: 0.100400
		loss: 0.100400
		loss: 0.100300
		loss: 0.100300
		loss: 0.100200
		loss: 0.100100
		loss: 0.100100
		loss: 0.100000
		loss: 0.100000
		loss: 0.099900
		loss: 0.099800
		loss: 0.099800
		loss: 0.099700
		loss: 0.099700
		loss: 0.099600
		loss: 0.099500
		loss: 0.099500
		loss: 0.099400
		loss: 0.099400
		loss: 0.099300
		loss: 0.099200
		loss: 0.099200
		loss: 0.099100
		loss: 0.099100
		loss: 0.099000
		loss: 0.098900
		loss: 0.098900
		loss: 0.098800
		loss: 0.098800
		loss: 0.098700
		loss: 0.098700
		loss: 0.098600
		loss: 0.098500
		loss: 0.098500
		loss: 0.098400
		loss: 0.098400
		loss: 0.098300
		loss: 0.098300
		loss: 0.098200
		loss: 0.098100
		loss: 0.098100
		loss: 0.098000
		loss: 0.098000
		loss: 0.097900
		loss: 0.097900
		loss: 0.097800
		loss: 0.097700
		loss: 0.097700
		loss: 0.097600
		loss: 0.097600
		loss: 0.097500
		loss: 0.097500
	Overall the loss development was 2.844900 -> 0.097500

Training data for problem d-4-1.pddl in epoch 1:
model creation time: 10.085506677627563s
problem epoch data for epoch 1, problem epoch 1
	sampling search time: 2.5465121269226074s
	during this search the following actions were chosen:
	training time: 60.59044575691223s
	during the training the following losses were computed:
		loss: 0.960400
		loss: 0.658500
		loss: 0.413500
		loss: 0.351800
		loss: 0.464300
		loss: 0.495500
		loss: 0.427000
		loss: 0.339600
		loss: 0.291900
		loss: 0.295100
		loss: 0.320800
		loss: 0.338600
		loss: 0.335800
		loss: 0.314100
		loss: 0.283000
		loss: 0.254600
		loss: 0.239600
		loss: 0.240400
		loss: 0.249200
		loss: 0.254300
		loss: 0.249500
		loss: 0.236600
		loss: 0.222300
		loss: 0.212100
		loss: 0.207700
		loss: 0.207700
		loss: 0.208700
		loss: 0.207900
		loss: 0.204400
		loss: 0.198700
		loss: 0.192700
		loss: 0.187800
		loss: 0.184700
		loss: 0.183100
		loss: 0.182100
		loss: 0.180700
		loss: 0.178600
		loss: 0.175900
		loss: 0.172900
		loss: 0.170300
		loss: 0.168100
		loss: 0.166300
		loss: 0.164800
		loss: 0.163300
		loss: 0.161700
		loss: 0.160000
		loss: 0.158300
		loss: 0.156600
		loss: 0.154900
		loss: 0.153400
		loss: 0.152000
		loss: 0.150600
		loss: 0.149300
		loss: 0.148000
		loss: 0.146800
		loss: 0.145600
		loss: 0.144400
		loss: 0.143200
		loss: 0.142000
		loss: 0.141000
		loss: 0.139900
		loss: 0.138900
		loss: 0.137900
		loss: 0.137000
		loss: 0.136000
		loss: 0.135100
		loss: 0.134200
		loss: 0.133300
		loss: 0.132500
		loss: 0.131700
		loss: 0.130900
		loss: 0.130100
		loss: 0.129300
		loss: 0.128600
		loss: 0.127800
		loss: 0.127100
		loss: 0.126400
		loss: 0.125700
		loss: 0.125100
		loss: 0.124400
		loss: 0.123700
		loss: 0.123100
		loss: 0.122500
		loss: 0.121800
		loss: 0.121200
		loss: 0.120700
		loss: 0.120100
		loss: 0.119500
		loss: 0.119000
		loss: 0.118400
		loss: 0.117900
		loss: 0.117400
		loss: 0.116900
		loss: 0.116500
		loss: 0.116000
		loss: 0.115600
		loss: 0.115100
		loss: 0.114700
		loss: 0.114300
		loss: 0.113900
		loss: 0.113500
		loss: 0.113100
		loss: 0.112800
		loss: 0.112400
		loss: 0.112000
		loss: 0.111700
		loss: 0.111400
		loss: 0.111100
		loss: 0.110700
		loss: 0.110400
		loss: 0.110100
		loss: 0.109900
		loss: 0.109600
		loss: 0.109300
		loss: 0.109100
		loss: 0.108800
		loss: 0.108600
		loss: 0.108300
		loss: 0.108100
		loss: 0.107900
		loss: 0.107700
		loss: 0.107500
		loss: 0.107300
		loss: 0.107100
		loss: 0.106900
		loss: 0.106700
		loss: 0.106500
		loss: 0.106400
		loss: 0.106200
		loss: 0.106000
		loss: 0.105900
		loss: 0.105700
		loss: 0.105600
		loss: 0.105400
		loss: 0.105300
		loss: 0.105100
		loss: 0.105000
		loss: 0.104900
		loss: 0.104700
		loss: 0.104600
		loss: 0.104500
		loss: 0.104400
		loss: 0.104300
		loss: 0.104100
		loss: 0.104000
		loss: 0.103900
		loss: 0.103800
		loss: 0.103700
		loss: 0.103600
		loss: 0.103500
		loss: 0.103400
		loss: 0.103300
		loss: 0.103200
		loss: 0.103100
		loss: 0.103000
		loss: 0.102900
		loss: 0.102800
		loss: 0.102700
		loss: 0.102600
		loss: 0.102500
		loss: 0.102400
		loss: 0.102300
		loss: 0.102200
		loss: 0.102100
		loss: 0.102100
		loss: 0.102000
		loss: 0.101900
		loss: 0.101800
		loss: 0.101700
		loss: 0.101600
		loss: 0.101500
		loss: 0.101400
		loss: 0.101400
		loss: 0.101300
		loss: 0.101200
		loss: 0.101100
		loss: 0.101000
		loss: 0.100900
		loss: 0.100900
		loss: 0.100800
		loss: 0.100700
		loss: 0.100600
		loss: 0.100500
		loss: 0.100500
		loss: 0.100400
		loss: 0.100300
		loss: 0.100200
		loss: 0.100200
		loss: 0.100100
		loss: 0.100000
		loss: 0.099900
		loss: 0.099800
		loss: 0.099800
		loss: 0.099700
		loss: 0.099600
		loss: 0.099500
		loss: 0.099500
		loss: 0.099400
		loss: 0.099300
		loss: 0.099200
		loss: 0.099200
		loss: 0.099100
		loss: 0.099000
		loss: 0.098900
		loss: 0.098900
		loss: 0.098800
		loss: 0.098700
		loss: 0.098600
		loss: 0.098600
		loss: 0.098500
		loss: 0.098400
		loss: 0.098300
		loss: 0.098300
		loss: 0.098200
		loss: 0.098100
		loss: 0.098100
		loss: 0.098000
		loss: 0.097900
		loss: 0.097800
		loss: 0.097800
		loss: 0.097700
		loss: 0.097600
		loss: 0.097600
		loss: 0.097500
		loss: 0.097400
		loss: 0.097300
		loss: 0.097300
		loss: 0.097200
		loss: 0.097100
		loss: 0.097100
		loss: 0.097000
		loss: 0.096900
		loss: 0.096900
		loss: 0.096800
		loss: 0.096700
		loss: 0.096600
		loss: 0.096600
		loss: 0.096500
		loss: 0.096400
		loss: 0.096400
		loss: 0.096300
		loss: 0.096200
		loss: 0.096200
		loss: 0.096100
		loss: 0.096000
		loss: 0.096000
		loss: 0.095900
		loss: 0.095800
		loss: 0.095800
		loss: 0.095700
		loss: 0.095600
		loss: 0.095600
		loss: 0.095500
		loss: 0.095400
		loss: 0.095300
		loss: 0.095300
		loss: 0.095200
		loss: 0.095100
		loss: 0.095100
		loss: 0.095000
		loss: 0.094900
		loss: 0.094900
		loss: 0.094800
		loss: 0.094700
		loss: 0.094700
		loss: 0.094600
		loss: 0.094500
		loss: 0.094500
		loss: 0.094400
		loss: 0.094300
		loss: 0.094300
		loss: 0.094200
		loss: 0.094100
		loss: 0.094100
		loss: 0.094000
		loss: 0.093900
		loss: 0.093900
		loss: 0.093800
		loss: 0.093700
		loss: 0.093700
		loss: 0.093600
		loss: 0.093500
		loss: 0.093500
		loss: 0.093400
		loss: 0.093300
		loss: 0.093300
		loss: 0.093200
		loss: 0.093200
		loss: 0.093100
		loss: 0.093000
		loss: 0.093000
		loss: 0.092900
		loss: 0.092800
		loss: 0.092800
		loss: 0.092700
		loss: 0.092600
		loss: 0.092600
		loss: 0.092500
		loss: 0.092400
		loss: 0.092400
	Overall the loss development was 0.960400 -> 0.092400

Training data for problem d-5-2.pddl in epoch 1:
model creation time: 15.12263536453247s
problem epoch data for epoch 1, problem epoch 1
	sampling search time: 4.307020425796509s
	during this search the following actions were chosen:
	training time: 73.5394389629364s
	during the training the following losses were computed:
		loss: 1.945900
		loss: 1.645200
		loss: 1.493400
		loss: 1.442300
		loss: 1.448200
		loss: 1.405800
		loss: 1.318000
		loss: 1.219900
		loss: 1.145700
		loss: 1.109200
		loss: 1.101200
		loss: 1.102000
		loss: 1.097700
		loss: 1.083100
		loss: 1.057200
		loss: 1.022600
		loss: 0.983400
		loss: 0.945300
		loss: 0.913400
		loss: 0.891700
		loss: 0.878900
		loss: 0.869700
		loss: 0.859100
		loss: 0.846100
		loss: 0.831700
		loss: 0.817900
		loss: 0.806400
		loss: 0.795600
		loss: 0.784200
		loss: 0.771900
		loss: 0.758800
		loss: 0.746500
		loss: 0.737600
		loss: 0.731400
		loss: 0.726800
		loss: 0.721800
		loss: 0.715900
		loss: 0.710600
		loss: 0.706000
		loss: 0.702500
		loss: 0.699100
		loss: 0.695300
		loss: 0.691400
		loss: 0.687500
		loss: 0.684100
		loss: 0.681000
		loss: 0.677800
		loss: 0.674200
		loss: 0.670200
		loss: 0.666200
		loss: 0.662500
		loss: 0.659300
		loss: 0.656500
		loss: 0.653600
		loss: 0.650600
		loss: 0.647600
		loss: 0.645000
		loss: 0.642300
		loss: 0.639700
		loss: 0.637100
		loss: 0.634500
		loss: 0.632100
		loss: 0.629700
		loss: 0.627300
		loss: 0.624900
		loss: 0.622400
		loss: 0.619900
		loss: 0.617400
		loss: 0.615000
		loss: 0.612700
		loss: 0.610200
		loss: 0.607800
		loss: 0.605500
		loss: 0.603200
		loss: 0.600900
		loss: 0.598600
		loss: 0.596300
		loss: 0.594000
		loss: 0.591800
		loss: 0.589400
		loss: 0.587100
		loss: 0.584800
		loss: 0.582600
		loss: 0.580400
		loss: 0.578200
		loss: 0.576100
		loss: 0.573900
		loss: 0.571700
		loss: 0.569500
		loss: 0.567300
		loss: 0.565200
		loss: 0.562900
		loss: 0.560700
		loss: 0.558500
		loss: 0.556300
		loss: 0.554200
		loss: 0.552000
		loss: 0.549900
		loss: 0.547800
		loss: 0.545600
		loss: 0.543500
		loss: 0.541300
		loss: 0.539100
		loss: 0.537000
		loss: 0.534800
		loss: 0.532700
		loss: 0.530600
		loss: 0.528500
		loss: 0.526300
		loss: 0.524200
		loss: 0.522100
		loss: 0.520100
		loss: 0.518000
		loss: 0.516000
		loss: 0.514000
		loss: 0.512000
		loss: 0.510000
		loss: 0.508000
		loss: 0.506000
		loss: 0.504000
		loss: 0.502100
		loss: 0.500200
		loss: 0.498300
		loss: 0.496500
		loss: 0.494600
		loss: 0.492800
		loss: 0.490900
		loss: 0.489100
		loss: 0.487200
		loss: 0.485400
		loss: 0.483500
		loss: 0.481700
		loss: 0.480000
		loss: 0.478200
		loss: 0.476400
		loss: 0.474600
		loss: 0.472800
		loss: 0.471100
		loss: 0.469400
		loss: 0.467600
		loss: 0.465900
		loss: 0.464300
		loss: 0.462600
		loss: 0.460900
		loss: 0.459200
		loss: 0.457500
		loss: 0.455900
		loss: 0.454200
		loss: 0.452600
		loss: 0.451000
		loss: 0.449400
		loss: 0.447800
		loss: 0.446300
		loss: 0.444700
		loss: 0.443200
		loss: 0.441600
		loss: 0.440100
		loss: 0.438600
		loss: 0.437200
		loss: 0.435700
		loss: 0.434200
		loss: 0.432900
		loss: 0.431500
		loss: 0.430100
		loss: 0.428700
		loss: 0.427400
		loss: 0.426000
		loss: 0.424700
		loss: 0.423400
		loss: 0.422200
		loss: 0.420900
		loss: 0.419600
		loss: 0.418400
		loss: 0.417300
		loss: 0.416100
		loss: 0.415000
		loss: 0.413900
		loss: 0.412800
		loss: 0.411700
		loss: 0.410700
		loss: 0.409600
		loss: 0.408600
		loss: 0.407700
		loss: 0.406700
		loss: 0.405800
		loss: 0.404800
		loss: 0.403900
		loss: 0.403000
		loss: 0.402200
		loss: 0.401300
		loss: 0.400500
		loss: 0.399700
		loss: 0.398900
		loss: 0.398200
		loss: 0.397400
		loss: 0.396700
		loss: 0.396000
		loss: 0.395300
		loss: 0.394600
		loss: 0.394000
		loss: 0.393400
		loss: 0.392800
		loss: 0.392200
		loss: 0.391600
		loss: 0.391100
		loss: 0.390500
		loss: 0.390000
		loss: 0.389500
		loss: 0.389000
		loss: 0.388600
		loss: 0.388100
		loss: 0.387700
		loss: 0.387300
		loss: 0.386800
		loss: 0.386400
		loss: 0.386000
		loss: 0.385700
		loss: 0.385300
		loss: 0.384900
		loss: 0.384500
		loss: 0.384200
		loss: 0.383900
		loss: 0.383500
		loss: 0.383200
		loss: 0.382900
		loss: 0.382600
		loss: 0.382300
		loss: 0.382000
		loss: 0.381700
		loss: 0.381400
		loss: 0.381200
		loss: 0.380900
		loss: 0.380600
		loss: 0.380400
		loss: 0.380100
		loss: 0.379900
		loss: 0.379700
		loss: 0.379400
		loss: 0.379200
		loss: 0.379000
		loss: 0.378800
		loss: 0.378500
		loss: 0.378300
		loss: 0.378100
		loss: 0.377900
		loss: 0.377700
		loss: 0.377500
		loss: 0.377300
		loss: 0.377200
		loss: 0.377000
		loss: 0.376800
		loss: 0.376600
		loss: 0.376400
		loss: 0.376300
		loss: 0.376100
		loss: 0.375900
		loss: 0.375800
		loss: 0.375600
		loss: 0.375400
		loss: 0.375300
		loss: 0.375100
		loss: 0.375000
		loss: 0.374800
		loss: 0.374600
		loss: 0.374500
		loss: 0.374300
		loss: 0.374200
		loss: 0.374100
		loss: 0.373900
		loss: 0.373800
		loss: 0.373600
		loss: 0.373500
		loss: 0.373400
		loss: 0.373200
		loss: 0.373100
		loss: 0.372900
		loss: 0.372800
		loss: 0.372700
		loss: 0.372500
		loss: 0.372400
		loss: 0.372300
		loss: 0.372200
		loss: 0.372000
		loss: 0.371900
		loss: 0.371800
		loss: 0.371700
		loss: 0.371500
		loss: 0.371400
		loss: 0.371300
		loss: 0.371200
		loss: 0.371100
		loss: 0.370900
		loss: 0.370800
		loss: 0.370700
		loss: 0.370600
		loss: 0.370500
		loss: 0.370400
		loss: 0.370300
		loss: 0.370100
		loss: 0.370000
	Overall the loss development was 1.945900 -> 0.370000

Training data for problem d-5-0.pddl in epoch 1:
model creation time: 15.179116487503052s
problem epoch data for epoch 1, problem epoch 1
	sampling search time: 4.075535297393799s
	during this search the following actions were chosen:
		unstack c e was chosen with probability 0.992792
		put-down c was chosen with probability 0.985033
		pick-up d was chosen with probability 0.990379
		stack d c was chosen with probability 0.993302
		unstack e b was chosen with probability 0.989356
		put-down e was chosen with probability 0.750810
		unstack b a was chosen with probability 0.828487
		stack b d was chosen with probability 0.989684
		pick-up e was chosen with probability 0.985503
		stack e b was chosen with probability 0.993272
		pick-up a was chosen with probability 0.999999
		stack a e was chosen with probability 0.999726
	training time: 74.45842504501343s
	during the training the following losses were computed:
		loss: 0.533100
		loss: 0.273400
		loss: 0.350600
		loss: 0.426000
		loss: 0.380400
		loss: 0.276500
		loss: 0.225700
		loss: 0.279800
		loss: 0.317700
		loss: 0.305400
		loss: 0.261500
		loss: 0.226600
		loss: 0.238300
		loss: 0.266600
		loss: 0.274000
		loss: 0.256600
		loss: 0.231400
		loss: 0.223500
		loss: 0.237000
		loss: 0.249700
		loss: 0.247200
		loss: 0.233300
		loss: 0.222500
		loss: 0.225200
		loss: 0.234500
		loss: 0.237700
		loss: 0.231600
		loss: 0.223300
		loss: 0.221800
		loss: 0.226900
		loss: 0.230700
		loss: 0.228400
		loss: 0.223100
		loss: 0.220900
		loss: 0.223400
		loss: 0.226200
		loss: 0.225300
		loss: 0.222000
		loss: 0.220300
		loss: 0.221700
		loss: 0.223400
		loss: 0.222900
		loss: 0.220800
		loss: 0.219800
		loss: 0.220700
		loss: 0.221700
		loss: 0.221100
		loss: 0.219800
		loss: 0.219300
		loss: 0.220000
		loss: 0.220400
		loss: 0.219800
		loss: 0.219000
		loss: 0.218900
		loss: 0.219400
		loss: 0.219400
		loss: 0.218900
		loss: 0.218500
		loss: 0.218600
		loss: 0.218800
		loss: 0.218600
		loss: 0.218200
		loss: 0.218000
		loss: 0.218100
		loss: 0.218100
		loss: 0.217800
		loss: 0.217600
		loss: 0.217600
		loss: 0.217600
		loss: 0.217500
		loss: 0.217200
		loss: 0.217100
		loss: 0.217100
		loss: 0.217000
		loss: 0.216900
		loss: 0.216700
		loss: 0.216700
		loss: 0.216600
		loss: 0.216500
		loss: 0.216300
		loss: 0.216300
		loss: 0.216200
		loss: 0.216100
		loss: 0.216000
		loss: 0.215900
		loss: 0.215800
		loss: 0.215700
		loss: 0.215600
		loss: 0.215500
		loss: 0.215400
		loss: 0.215300
		loss: 0.215200
		loss: 0.215100
		loss: 0.215000
		loss: 0.214900
		loss: 0.214800
		loss: 0.214700
		loss: 0.214600
		loss: 0.214500
		loss: 0.214400
		loss: 0.214300
		loss: 0.214200
		loss: 0.214100
		loss: 0.214000
		loss: 0.213900
		loss: 0.213800
		loss: 0.213700
		loss: 0.213600
		loss: 0.213500
		loss: 0.213500
		loss: 0.213400
		loss: 0.213300
		loss: 0.213200
		loss: 0.213100
		loss: 0.213000
		loss: 0.212900
		loss: 0.212800
		loss: 0.212700
		loss: 0.212600
		loss: 0.212500
		loss: 0.212400
		loss: 0.212300
		loss: 0.212300
		loss: 0.212200
		loss: 0.212100
		loss: 0.212000
		loss: 0.211900
		loss: 0.211800
		loss: 0.211700
		loss: 0.211600
		loss: 0.211600
		loss: 0.211500
		loss: 0.211400
		loss: 0.211300
		loss: 0.211200
		loss: 0.211100
		loss: 0.211000
		loss: 0.211000
		loss: 0.210900
		loss: 0.210800
		loss: 0.210700
		loss: 0.210600
		loss: 0.210500
		loss: 0.210400
		loss: 0.210400
		loss: 0.210300
		loss: 0.210200
		loss: 0.210100
		loss: 0.210000
		loss: 0.209900
		loss: 0.209900
		loss: 0.209800
		loss: 0.209700
		loss: 0.209600
		loss: 0.209500
		loss: 0.209500
		loss: 0.209400
		loss: 0.209300
		loss: 0.209200
		loss: 0.209100
		loss: 0.209000
		loss: 0.209000
		loss: 0.208900
		loss: 0.208800
		loss: 0.208700
		loss: 0.208600
		loss: 0.208600
		loss: 0.208500
		loss: 0.208400
		loss: 0.208300
		loss: 0.208200
		loss: 0.208200
		loss: 0.208100
		loss: 0.208000
		loss: 0.207900
		loss: 0.207800
		loss: 0.207800
		loss: 0.207700
		loss: 0.207600
		loss: 0.207500
		loss: 0.207400
		loss: 0.207400
		loss: 0.207300
		loss: 0.207200
		loss: 0.207100
		loss: 0.207100
		loss: 0.207000
		loss: 0.206900
		loss: 0.206800
		loss: 0.206700
		loss: 0.206700
		loss: 0.206600
		loss: 0.206500
		loss: 0.206400
		loss: 0.206400
		loss: 0.206300
		loss: 0.206200
		loss: 0.206100
		loss: 0.206100
		loss: 0.206000
		loss: 0.205900
		loss: 0.205800
		loss: 0.205800
		loss: 0.205700
		loss: 0.205600
		loss: 0.205500
		loss: 0.205500
		loss: 0.205400
		loss: 0.205300
		loss: 0.205300
		loss: 0.205200
		loss: 0.205100
		loss: 0.205000
		loss: 0.205000
		loss: 0.204900
		loss: 0.204800
		loss: 0.204700
		loss: 0.204700
		loss: 0.204600
		loss: 0.204500
		loss: 0.204500
		loss: 0.204400
		loss: 0.204300
		loss: 0.204200
		loss: 0.204200
		loss: 0.204100
		loss: 0.204000
		loss: 0.204000
		loss: 0.203900
		loss: 0.203800
		loss: 0.203700
		loss: 0.203700
		loss: 0.203600
		loss: 0.203500
		loss: 0.203500
		loss: 0.203400
		loss: 0.203300
		loss: 0.203300
		loss: 0.203200
		loss: 0.203100
		loss: 0.203000
		loss: 0.203000
		loss: 0.202900
		loss: 0.202800
		loss: 0.202800
		loss: 0.202700
		loss: 0.202600
		loss: 0.202600
		loss: 0.202500
		loss: 0.202400
		loss: 0.202400
		loss: 0.202300
		loss: 0.202200
		loss: 0.202100
		loss: 0.202100
		loss: 0.202000
		loss: 0.201900
		loss: 0.201900
		loss: 0.201800
		loss: 0.201700
		loss: 0.201700
		loss: 0.201600
		loss: 0.201500
		loss: 0.201500
		loss: 0.201400
		loss: 0.201300
		loss: 0.201300
		loss: 0.201200
		loss: 0.201100
		loss: 0.201100
		loss: 0.201000
		loss: 0.200900
		loss: 0.200900
		loss: 0.200800
		loss: 0.200800
		loss: 0.200700
		loss: 0.200600
		loss: 0.200600
		loss: 0.200500
		loss: 0.200400
		loss: 0.200400
		loss: 0.200300
		loss: 0.200200
		loss: 0.200200
		loss: 0.200100
		loss: 0.200000
		loss: 0.200000
		loss: 0.199900
		loss: 0.199800
		loss: 0.199800
		loss: 0.199700
		loss: 0.199700
		loss: 0.199600
		loss: 0.199500
		loss: 0.199500
		loss: 0.199400
		loss: 0.199300
		loss: 0.199300
		loss: 0.199200
		loss: 0.199200
	Overall the loss development was 0.533100 -> 0.199200

Training data for problem d-5-1.pddl in epoch 1:
model creation time: 14.953235626220703s
problem epoch data for epoch 1, problem epoch 1
	sampling search time: 4.316189765930176s
	during this search the following actions were chosen:
		pick-up c was chosen with probability 0.938349
		stack c b was chosen with probability 0.997501
		pick-up e was chosen with probability 0.757150
		put-down e was chosen with probability 0.999340
	training time: 73.72682595252991s
	during the training the following losses were computed:
		loss: 1.282900
		loss: 0.989200
		loss: 0.941600
		loss: 0.954400
		loss: 0.938200
		loss: 0.863000
		loss: 0.787600
		loss: 0.735600
		loss: 0.698200
		loss: 0.669700
		loss: 0.647100
		loss: 0.624300
		loss: 0.594800
		loss: 0.560800
		loss: 0.529100
		loss: 0.504500
		loss: 0.487900
		loss: 0.478700
		loss: 0.475100
		loss: 0.474700
		loss: 0.474500
		loss: 0.472500
		loss: 0.468000
		loss: 0.461900
		loss: 0.455300
		loss: 0.449100
		loss: 0.443100
		loss: 0.437100
		loss: 0.430700
		loss: 0.424000
		loss: 0.416500
		loss: 0.409000
		loss: 0.402200
		loss: 0.396500
		loss: 0.392100
		loss: 0.388800
		loss: 0.386100
		loss: 0.383400
		loss: 0.380500
		loss: 0.377400
		loss: 0.373900
		loss: 0.370300
		loss: 0.366700
		loss: 0.363300
		loss: 0.360000
		loss: 0.356900
		loss: 0.353800
		loss: 0.350700
		loss: 0.347900
		loss: 0.345000
		loss: 0.342000
		loss: 0.339200
		loss: 0.336600
		loss: 0.334000
		loss: 0.331600
		loss: 0.329300
		loss: 0.327100
		loss: 0.324800
		loss: 0.322600
		loss: 0.320300
		loss: 0.318000
		loss: 0.315700
		loss: 0.313400
		loss: 0.311100
		loss: 0.308900
		loss: 0.306700
		loss: 0.304500
		loss: 0.302300
		loss: 0.300100
		loss: 0.297900
		loss: 0.295700
		loss: 0.293500
		loss: 0.291400
		loss: 0.289300
		loss: 0.287200
		loss: 0.285000
		loss: 0.283000
		loss: 0.280900
		loss: 0.278800
		loss: 0.276800
		loss: 0.274900
		loss: 0.272900
		loss: 0.270900
		loss: 0.268900
		loss: 0.266900
		loss: 0.265000
		loss: 0.263100
		loss: 0.261200
		loss: 0.259400
		loss: 0.257600
		loss: 0.255800
		loss: 0.254000
		loss: 0.252300
		loss: 0.250700
		loss: 0.249000
		loss: 0.247400
		loss: 0.245800
		loss: 0.244200
		loss: 0.242700
		loss: 0.241200
		loss: 0.239800
		loss: 0.238400
		loss: 0.237000
		loss: 0.235800
		loss: 0.234500
		loss: 0.233300
		loss: 0.232200
		loss: 0.231100
		loss: 0.230000
		loss: 0.229000
		loss: 0.228100
		loss: 0.227100
		loss: 0.226200
		loss: 0.225400
		loss: 0.224500
		loss: 0.223700
		loss: 0.223000
		loss: 0.222200
		loss: 0.221500
		loss: 0.220900
		loss: 0.220200
		loss: 0.219600
		loss: 0.219100
		loss: 0.218500
		loss: 0.218000
		loss: 0.217500
		loss: 0.217000
		loss: 0.216600
		loss: 0.216100
		loss: 0.215700
		loss: 0.215300
		loss: 0.215000
		loss: 0.214600
		loss: 0.214300
		loss: 0.213900
		loss: 0.213600
		loss: 0.213300
		loss: 0.213000
		loss: 0.212800
		loss: 0.212500
		loss: 0.212200
		loss: 0.212000
		loss: 0.211800
		loss: 0.211500
		loss: 0.211300
		loss: 0.211100
		loss: 0.210900
		loss: 0.210700
		loss: 0.210500
		loss: 0.210300
		loss: 0.210100
		loss: 0.210000
		loss: 0.209800
		loss: 0.209700
		loss: 0.209500
		loss: 0.209300
		loss: 0.209200
		loss: 0.209000
		loss: 0.208900
		loss: 0.208700
		loss: 0.208600
		loss: 0.208500
		loss: 0.208300
		loss: 0.208200
		loss: 0.208100
		loss: 0.207900
		loss: 0.207800
		loss: 0.207700
		loss: 0.207600
		loss: 0.207500
		loss: 0.207300
		loss: 0.207200
		loss: 0.207100
		loss: 0.207000
		loss: 0.206900
		loss: 0.206800
		loss: 0.206700
		loss: 0.206600
		loss: 0.206500
		loss: 0.206400
		loss: 0.206300
		loss: 0.206200
		loss: 0.206100
		loss: 0.206000
		loss: 0.205900
		loss: 0.205800
		loss: 0.205700
		loss: 0.205600
		loss: 0.205500
		loss: 0.205400
		loss: 0.205300
		loss: 0.205300
		loss: 0.205200
		loss: 0.205100
		loss: 0.205000
		loss: 0.204900
		loss: 0.204800
		loss: 0.204700
		loss: 0.204700
		loss: 0.204600
		loss: 0.204500
		loss: 0.204400
		loss: 0.204300
		loss: 0.204300
		loss: 0.204200
		loss: 0.204100
		loss: 0.204000
		loss: 0.203900
		loss: 0.203900
		loss: 0.203800
		loss: 0.203700
		loss: 0.203600
		loss: 0.203600
		loss: 0.203500
		loss: 0.203400
		loss: 0.203300
		loss: 0.203300
		loss: 0.203200
		loss: 0.203100
		loss: 0.203100
		loss: 0.203000
		loss: 0.202900
		loss: 0.202800
		loss: 0.202700
		loss: 0.202700
		loss: 0.202600
		loss: 0.202500
		loss: 0.202500
		loss: 0.202400
		loss: 0.202400
		loss: 0.202300
		loss: 0.202200
		loss: 0.202200
		loss: 0.202100
		loss: 0.202000
		loss: 0.201900
		loss: 0.201800
		loss: 0.201800
		loss: 0.201700
		loss: 0.201700
		loss: 0.201600
		loss: 0.201500
		loss: 0.201400
		loss: 0.201400
		loss: 0.201300
		loss: 0.201200
		loss: 0.201200
		loss: 0.201100
		loss: 0.201100
		loss: 0.201000
		loss: 0.200900
		loss: 0.200800
		loss: 0.200800
		loss: 0.200700
		loss: 0.200700
		loss: 0.200600
		loss: 0.200500
		loss: 0.200500
		loss: 0.200400
		loss: 0.200300
		loss: 0.200300
		loss: 0.200200
		loss: 0.200200
		loss: 0.200100
		loss: 0.200000
		loss: 0.200000
		loss: 0.199900
		loss: 0.199800
		loss: 0.199800
		loss: 0.199700
		loss: 0.199600
		loss: 0.199600
		loss: 0.199500
		loss: 0.199500
		loss: 0.199400
		loss: 0.199400
		loss: 0.199300
		loss: 0.199300
		loss: 0.199200
		loss: 0.199100
		loss: 0.199100
		loss: 0.199000
		loss: 0.198900
		loss: 0.198900
		loss: 0.198800
		loss: 0.198700
		loss: 0.198700
		loss: 0.198600
		loss: 0.198600
		loss: 0.198500
		loss: 0.198500
		loss: 0.198400
		loss: 0.198300
		loss: 0.198300
		loss: 0.198200
		loss: 0.198200
		loss: 0.198100
		loss: 0.198000
		loss: 0.198000
		loss: 0.197900
	Overall the loss development was 1.282900 -> 0.197900

Epoch 2:
Training data for problem d-4-0.pddl in epoch 2:
model creation time: 10.267450094223022s
problem epoch data for epoch 2, problem epoch 1
	sampling search time: 2.4455149173736572s
	during this search the following actions were chosen:
		pick-up b was chosen with probability 0.331194
		stack b a was chosen with probability 0.999696
		pick-up c was chosen with probability 0.996874
		stack c b was chosen with probability 0.981635
		pick-up d was chosen with probability 0.999042
		stack d c was chosen with probability 0.997031
	training time: 60.35950422286987s
	during the training the following losses were computed:
		loss: 0.255500
		loss: 0.252100
		loss: 0.251100
		loss: 0.250400
		loss: 0.249700
		loss: 0.249000
		loss: 0.248300
		loss: 0.247500
		loss: 0.246800
		loss: 0.245900
		loss: 0.245100
		loss: 0.244300
		loss: 0.243400
		loss: 0.242600
		loss: 0.241700
		loss: 0.240900
		loss: 0.240100
		loss: 0.239300
		loss: 0.238500
		loss: 0.237700
		loss: 0.237000
		loss: 0.236200
		loss: 0.235500
		loss: 0.234700
		loss: 0.234000
		loss: 0.233300
		loss: 0.232600
		loss: 0.231900
		loss: 0.231200
		loss: 0.230500
		loss: 0.229900
		loss: 0.229200
		loss: 0.228600
		loss: 0.228000
		loss: 0.227400
		loss: 0.226800
		loss: 0.226200
		loss: 0.225600
		loss: 0.225100
		loss: 0.224500
		loss: 0.223900
		loss: 0.223400
		loss: 0.222900
		loss: 0.222300
		loss: 0.221800
		loss: 0.221300
		loss: 0.220800
		loss: 0.220300
		loss: 0.219800
		loss: 0.219300
		loss: 0.218800
		loss: 0.218300
		loss: 0.217900
		loss: 0.217400
		loss: 0.217000
		loss: 0.216500
		loss: 0.216100
		loss: 0.215700
		loss: 0.215300
		loss: 0.214900
		loss: 0.214500
		loss: 0.214100
		loss: 0.213700
		loss: 0.213300
		loss: 0.212900
		loss: 0.212500
		loss: 0.212200
		loss: 0.211800
		loss: 0.211500
		loss: 0.211100
		loss: 0.210800
		loss: 0.210400
		loss: 0.210100
		loss: 0.209800
		loss: 0.209400
		loss: 0.209100
		loss: 0.208800
		loss: 0.208500
		loss: 0.208200
		loss: 0.207900
		loss: 0.207600
		loss: 0.207300
		loss: 0.207100
		loss: 0.206800
		loss: 0.206500
		loss: 0.206200
		loss: 0.206000
		loss: 0.205700
		loss: 0.205400
		loss: 0.205200
		loss: 0.204900
		loss: 0.204700
		loss: 0.204400
		loss: 0.204200
		loss: 0.203900
		loss: 0.203700
		loss: 0.203500
		loss: 0.203200
		loss: 0.203000
		loss: 0.202800
		loss: 0.202600
		loss: 0.202400
		loss: 0.202100
		loss: 0.201900
		loss: 0.201700
		loss: 0.201500
		loss: 0.201300
		loss: 0.201100
		loss: 0.200900
		loss: 0.200700
		loss: 0.200500
		loss: 0.200300
		loss: 0.200100
		loss: 0.200000
		loss: 0.199800
		loss: 0.199600
		loss: 0.199400
		loss: 0.199200
		loss: 0.199100
		loss: 0.198900
		loss: 0.198700
		loss: 0.198500
		loss: 0.198400
		loss: 0.198200
		loss: 0.198000
		loss: 0.197900
		loss: 0.197700
		loss: 0.197600
		loss: 0.197400
		loss: 0.197200
		loss: 0.197100
		loss: 0.196900
		loss: 0.196800
		loss: 0.196600
		loss: 0.196500
		loss: 0.196400
		loss: 0.196200
		loss: 0.196100
		loss: 0.195900
		loss: 0.195800
		loss: 0.195700
		loss: 0.195500
		loss: 0.195400
		loss: 0.195300
		loss: 0.195100
		loss: 0.195000
		loss: 0.194900
		loss: 0.194700
		loss: 0.194600
		loss: 0.194500
		loss: 0.194400
		loss: 0.194200
		loss: 0.194100
		loss: 0.194000
		loss: 0.193900
		loss: 0.193800
		loss: 0.193700
		loss: 0.193500
		loss: 0.193400
		loss: 0.193300
		loss: 0.193200
		loss: 0.193100
		loss: 0.193000
		loss: 0.192900
		loss: 0.192800
		loss: 0.192700
		loss: 0.192600
		loss: 0.192400
		loss: 0.192300
		loss: 0.192200
		loss: 0.192100
		loss: 0.192000
		loss: 0.191900
		loss: 0.191800
		loss: 0.191700
		loss: 0.191600
		loss: 0.191500
		loss: 0.191500
		loss: 0.191400
		loss: 0.191300
		loss: 0.191200
		loss: 0.191100
		loss: 0.191000
		loss: 0.190900
		loss: 0.190800
		loss: 0.190700
		loss: 0.190600
		loss: 0.190500
		loss: 0.190400
		loss: 0.190400
		loss: 0.190300
		loss: 0.190200
		loss: 0.190100
		loss: 0.190000
		loss: 0.189900
		loss: 0.189900
		loss: 0.189800
		loss: 0.189700
		loss: 0.189600
		loss: 0.189500
		loss: 0.189400
		loss: 0.189400
		loss: 0.189300
		loss: 0.189200
		loss: 0.189100
		loss: 0.189100
		loss: 0.189000
		loss: 0.188900
		loss: 0.188800
		loss: 0.188700
		loss: 0.188700
		loss: 0.188600
		loss: 0.188500
		loss: 0.188400
		loss: 0.188400
		loss: 0.188300
		loss: 0.188200
		loss: 0.188100
		loss: 0.188100
		loss: 0.188000
		loss: 0.187900
		loss: 0.187900
		loss: 0.187800
		loss: 0.187700
		loss: 0.187700
		loss: 0.187600
		loss: 0.187500
		loss: 0.187400
		loss: 0.187400
		loss: 0.187300
		loss: 0.187200
		loss: 0.187200
		loss: 0.187100
		loss: 0.187000
		loss: 0.187000
		loss: 0.186900
		loss: 0.186800
		loss: 0.186800
		loss: 0.186700
		loss: 0.186600
		loss: 0.186600
		loss: 0.186500
		loss: 0.186400
		loss: 0.186400
		loss: 0.186300
		loss: 0.186200
		loss: 0.186200
		loss: 0.186100
		loss: 0.186000
		loss: 0.186000
		loss: 0.185900
		loss: 0.185800
		loss: 0.185800
		loss: 0.185700
		loss: 0.185700
		loss: 0.185600
		loss: 0.185500
		loss: 0.185500
		loss: 0.185400
		loss: 0.185300
		loss: 0.185300
		loss: 0.185200
		loss: 0.185200
		loss: 0.185100
		loss: 0.185000
		loss: 0.185000
		loss: 0.184900
		loss: 0.184900
		loss: 0.184800
		loss: 0.184700
		loss: 0.184700
		loss: 0.184600
		loss: 0.184600
		loss: 0.184500
		loss: 0.184400
		loss: 0.184400
		loss: 0.184300
		loss: 0.184300
		loss: 0.184200
		loss: 0.184100
		loss: 0.184100
		loss: 0.184000
		loss: 0.184000
		loss: 0.183900
		loss: 0.183900
		loss: 0.183800
		loss: 0.183700
		loss: 0.183700
		loss: 0.183600
		loss: 0.183600
		loss: 0.183500
		loss: 0.183500
		loss: 0.183400
		loss: 0.183400
		loss: 0.183300
		loss: 0.183200
		loss: 0.183200
		loss: 0.183100
		loss: 0.183100
		loss: 0.183000
	Overall the loss development was 0.255500 -> 0.183000

Training data for problem d-4-2.pddl in epoch 2:
model creation time: 9.86424970626831s
problem epoch data for epoch 2, problem epoch 1
	sampling search time: 2.5041985511779785s
	during this search the following actions were chosen:
		pick-up a was chosen with probability 0.929257
		stack a c was chosen with probability 0.932951
		pick-up d was chosen with probability 0.995265
		stack d a was chosen with probability 0.980674
	training time: 60.4335196018219s
	during the training the following losses were computed:
		loss: 2.127900
		loss: 1.843400
		loss: 1.565200
		loss: 1.294800
		loss: 1.035500
		loss: 0.794400
		loss: 0.583400
		loss: 0.416500
		loss: 0.301100
		loss: 0.232400
		loss: 0.200700
		loss: 0.199900
		loss: 0.228100
		loss: 0.271600
		loss: 0.310800
		loss: 0.334200
		loss: 0.339700
		loss: 0.329100
		loss: 0.306500
		loss: 0.276800
		loss: 0.245200
		loss: 0.216200
		loss: 0.192500
		loss: 0.176100
		loss: 0.165900
		loss: 0.160600
		loss: 0.158800
		loss: 0.159200
		loss: 0.160600
		loss: 0.162200
		loss: 0.163300
		loss: 0.163400
		loss: 0.162400
		loss: 0.160300
		loss: 0.157100
		loss: 0.153000
		loss: 0.148200
		loss: 0.143000
		loss: 0.137600
		loss: 0.132200
		loss: 0.127100
		loss: 0.122500
		loss: 0.118500
		loss: 0.115100
		loss: 0.112400
		loss: 0.110200
		loss: 0.108400
		loss: 0.106700
		loss: 0.105000
		loss: 0.103200
		loss: 0.101100
		loss: 0.098800
		loss: 0.096400
		loss: 0.093900
		loss: 0.091400
		loss: 0.089100
		loss: 0.087100
		loss: 0.085200
		loss: 0.083700
		loss: 0.082300
		loss: 0.081100
		loss: 0.080000
		loss: 0.078800
		loss: 0.077700
		loss: 0.076500
		loss: 0.075300
		loss: 0.074100
		loss: 0.072800
		loss: 0.071600
		loss: 0.070400
		loss: 0.069300
		loss: 0.068200
		loss: 0.067200
		loss: 0.066300
		loss: 0.065400
		loss: 0.064600
		loss: 0.063700
		loss: 0.062900
		loss: 0.062100
		loss: 0.061300
		loss: 0.060500
		loss: 0.059700
		loss: 0.059000
		loss: 0.058300
		loss: 0.057600
		loss: 0.057000
		loss: 0.056500
		loss: 0.055900
		loss: 0.055400
		loss: 0.054900
		loss: 0.054400
		loss: 0.054000
		loss: 0.053500
		loss: 0.053100
		loss: 0.052600
		loss: 0.052300
		loss: 0.051900
		loss: 0.051500
		loss: 0.051200
		loss: 0.050800
		loss: 0.050500
		loss: 0.050100
		loss: 0.049800
		loss: 0.049500
		loss: 0.049200
		loss: 0.049000
		loss: 0.048700
		loss: 0.048400
		loss: 0.048200
		loss: 0.047900
		loss: 0.047700
		loss: 0.047400
		loss: 0.047200
		loss: 0.047000
		loss: 0.046700
		loss: 0.046500
		loss: 0.046300
		loss: 0.046100
		loss: 0.045900
		loss: 0.045700
		loss: 0.045500
		loss: 0.045300
		loss: 0.045200
		loss: 0.045000
		loss: 0.044800
		loss: 0.044700
		loss: 0.044500
		loss: 0.044400
		loss: 0.044200
		loss: 0.044100
		loss: 0.043900
		loss: 0.043800
		loss: 0.043700
		loss: 0.043600
		loss: 0.043400
		loss: 0.043300
		loss: 0.043200
		loss: 0.043100
		loss: 0.043000
		loss: 0.042900
		loss: 0.042700
		loss: 0.042600
		loss: 0.042500
		loss: 0.042400
		loss: 0.042300
		loss: 0.042200
		loss: 0.042200
		loss: 0.042100
		loss: 0.042000
		loss: 0.041900
		loss: 0.041800
		loss: 0.041700
		loss: 0.041600
		loss: 0.041600
		loss: 0.041500
		loss: 0.041400
		loss: 0.041300
		loss: 0.041300
		loss: 0.041200
		loss: 0.041100
		loss: 0.041000
		loss: 0.041000
		loss: 0.040900
		loss: 0.040800
		loss: 0.040800
		loss: 0.040700
		loss: 0.040700
		loss: 0.040600
		loss: 0.040500
		loss: 0.040500
		loss: 0.040400
		loss: 0.040400
		loss: 0.040300
		loss: 0.040300
		loss: 0.040200
		loss: 0.040100
		loss: 0.040100
		loss: 0.040000
		loss: 0.040000
		loss: 0.040000
		loss: 0.039900
		loss: 0.039900
		loss: 0.039800
		loss: 0.039800
		loss: 0.039700
		loss: 0.039700
		loss: 0.039600
		loss: 0.039600
		loss: 0.039600
		loss: 0.039500
		loss: 0.039500
		loss: 0.039400
		loss: 0.039400
		loss: 0.039400
		loss: 0.039300
		loss: 0.039300
		loss: 0.039200
		loss: 0.039200
		loss: 0.039200
		loss: 0.039100
		loss: 0.039100
		loss: 0.039000
		loss: 0.039000
		loss: 0.039000
		loss: 0.038900
		loss: 0.038900
		loss: 0.038900
		loss: 0.038800
		loss: 0.038800
		loss: 0.038800
		loss: 0.038700
		loss: 0.038700
		loss: 0.038700
		loss: 0.038600
		loss: 0.038600
		loss: 0.038600
		loss: 0.038500
		loss: 0.038500
		loss: 0.038500
		loss: 0.038400
		loss: 0.038400
		loss: 0.038400
		loss: 0.038300
		loss: 0.038300
		loss: 0.038300
		loss: 0.038300
		loss: 0.038200
		loss: 0.038200
		loss: 0.038200
		loss: 0.038100
		loss: 0.038100
		loss: 0.038100
		loss: 0.038100
		loss: 0.038000
		loss: 0.038000
		loss: 0.038000
		loss: 0.038000
		loss: 0.037900
		loss: 0.037900
		loss: 0.037900
		loss: 0.037900
		loss: 0.037800
		loss: 0.037800
		loss: 0.037800
		loss: 0.037800
		loss: 0.037800
		loss: 0.037700
		loss: 0.037700
		loss: 0.037700
		loss: 0.037700
		loss: 0.037600
		loss: 0.037600
		loss: 0.037600
		loss: 0.037600
		loss: 0.037600
		loss: 0.037500
		loss: 0.037500
		loss: 0.037500
		loss: 0.037500
		loss: 0.037500
		loss: 0.037400
		loss: 0.037400
		loss: 0.037400
		loss: 0.037400
		loss: 0.037400
		loss: 0.037400
		loss: 0.037300
		loss: 0.037300
		loss: 0.037300
		loss: 0.037300
		loss: 0.037300
		loss: 0.037200
		loss: 0.037200
		loss: 0.037200
		loss: 0.037200
		loss: 0.037200
		loss: 0.037200
		loss: 0.037100
		loss: 0.037100
		loss: 0.037100
		loss: 0.037100
		loss: 0.037100
		loss: 0.037100
		loss: 0.037100
		loss: 0.037000
		loss: 0.037000
		loss: 0.037000
		loss: 0.037000
		loss: 0.037000
		loss: 0.037000
		loss: 0.036900
		loss: 0.036900
		loss: 0.036900
		loss: 0.036900
		loss: 0.036900
		loss: 0.036900
		loss: 0.036900
		loss: 0.036800
		loss: 0.036800
		loss: 0.036800
	Overall the loss development was 2.127900 -> 0.036800

Training data for problem d-4-1.pddl in epoch 2:
model creation time: 9.868896245956421s
problem epoch data for epoch 2, problem epoch 1
	sampling search time: 2.3948757648468018s
	during this search the following actions were chosen:
	training time: 60.11737823486328s
	during the training the following losses were computed:
		loss: 0.540000
		loss: 0.325800
		loss: 0.175500
		loss: 0.219700
		loss: 0.298600
		loss: 0.277100
		loss: 0.207600
		loss: 0.152800
		loss: 0.136800
		loss: 0.150200
		loss: 0.171200
		loss: 0.181700
		loss: 0.175700
		loss: 0.157700
		loss: 0.138200
		loss: 0.126200
		loss: 0.124900
		loss: 0.130500
		loss: 0.136500
		loss: 0.137500
		loss: 0.132300
		loss: 0.123100
		loss: 0.113900
		loss: 0.107600
		loss: 0.105300
		loss: 0.106000
		loss: 0.107400
		loss: 0.107500
		loss: 0.105400
		loss: 0.101600
		loss: 0.097300
		loss: 0.093900
		loss: 0.091900
		loss: 0.091200
		loss: 0.091200
		loss: 0.090900
		loss: 0.089700
		loss: 0.087700
		loss: 0.085200
		loss: 0.082900
		loss: 0.081000
		loss: 0.079800
		loss: 0.079000
		loss: 0.078300
		loss: 0.077400
		loss: 0.076300
		loss: 0.074900
		loss: 0.073400
		loss: 0.072100
		loss: 0.071000
		loss: 0.070100
		loss: 0.069300
		loss: 0.068600
		loss: 0.067800
		loss: 0.066900
		loss: 0.066000
		loss: 0.065100
		loss: 0.064300
		loss: 0.063500
		loss: 0.062900
		loss: 0.062300
		loss: 0.061700
		loss: 0.061100
		loss: 0.060500
		loss: 0.059900
		loss: 0.059300
		loss: 0.058700
		loss: 0.058200
		loss: 0.057700
		loss: 0.057300
		loss: 0.056900
		loss: 0.056400
		loss: 0.056000
		loss: 0.055700
		loss: 0.055300
		loss: 0.054900
		loss: 0.054600
		loss: 0.054200
		loss: 0.054000
		loss: 0.053700
		loss: 0.053400
		loss: 0.053100
		loss: 0.052900
		loss: 0.052600
		loss: 0.052400
		loss: 0.052200
		loss: 0.052000
		loss: 0.051800
		loss: 0.051600
		loss: 0.051400
		loss: 0.051200
		loss: 0.051000
		loss: 0.050900
		loss: 0.050700
		loss: 0.050500
		loss: 0.050400
		loss: 0.050200
		loss: 0.050100
		loss: 0.050000
		loss: 0.049800
		loss: 0.049700
		loss: 0.049600
		loss: 0.049500
		loss: 0.049300
		loss: 0.049200
		loss: 0.049100
		loss: 0.049000
		loss: 0.048900
		loss: 0.048800
		loss: 0.048700
		loss: 0.048600
		loss: 0.048500
		loss: 0.048400
		loss: 0.048300
		loss: 0.048200
		loss: 0.048200
		loss: 0.048100
		loss: 0.048000
		loss: 0.047900
		loss: 0.047800
		loss: 0.047800
		loss: 0.047700
		loss: 0.047600
		loss: 0.047600
		loss: 0.047500
		loss: 0.047400
		loss: 0.047400
		loss: 0.047300
		loss: 0.047200
		loss: 0.047200
		loss: 0.047100
		loss: 0.047000
		loss: 0.047000
		loss: 0.046900
		loss: 0.046900
		loss: 0.046800
		loss: 0.046800
		loss: 0.046700
		loss: 0.046700
		loss: 0.046600
		loss: 0.046600
		loss: 0.046500
		loss: 0.046500
		loss: 0.046400
		loss: 0.046400
		loss: 0.046300
		loss: 0.046300
		loss: 0.046200
		loss: 0.046200
		loss: 0.046100
		loss: 0.046100
		loss: 0.046000
		loss: 0.046000
		loss: 0.046000
		loss: 0.045900
		loss: 0.045900
		loss: 0.045800
		loss: 0.045800
		loss: 0.045800
		loss: 0.045700
		loss: 0.045700
		loss: 0.045700
		loss: 0.045600
		loss: 0.045600
		loss: 0.045500
		loss: 0.045500
		loss: 0.045500
		loss: 0.045400
		loss: 0.045400
		loss: 0.045400
		loss: 0.045400
		loss: 0.045300
		loss: 0.045300
		loss: 0.045300
		loss: 0.045200
		loss: 0.045200
		loss: 0.045200
		loss: 0.045100
		loss: 0.045100
		loss: 0.045100
		loss: 0.045100
		loss: 0.045000
		loss: 0.045000
		loss: 0.045000
		loss: 0.045000
		loss: 0.044900
		loss: 0.044900
		loss: 0.044900
		loss: 0.044900
		loss: 0.044800
		loss: 0.044800
		loss: 0.044800
		loss: 0.044800
		loss: 0.044700
		loss: 0.044700
		loss: 0.044700
		loss: 0.044700
		loss: 0.044600
		loss: 0.044600
		loss: 0.044600
		loss: 0.044600
		loss: 0.044600
		loss: 0.044500
		loss: 0.044500
		loss: 0.044500
		loss: 0.044500
		loss: 0.044400
		loss: 0.044400
		loss: 0.044400
		loss: 0.044400
		loss: 0.044400
		loss: 0.044300
		loss: 0.044300
		loss: 0.044300
		loss: 0.044300
		loss: 0.044300
		loss: 0.044200
		loss: 0.044200
		loss: 0.044200
		loss: 0.044200
		loss: 0.044200
		loss: 0.044100
		loss: 0.044100
		loss: 0.044100
		loss: 0.044100
		loss: 0.044100
		loss: 0.044000
		loss: 0.044000
		loss: 0.044000
		loss: 0.044000
		loss: 0.044000
		loss: 0.043900
		loss: 0.043900
		loss: 0.043900
		loss: 0.043900
		loss: 0.043900
		loss: 0.043800
		loss: 0.043800
		loss: 0.043800
		loss: 0.043800
		loss: 0.043800
		loss: 0.043700
		loss: 0.043700
		loss: 0.043700
		loss: 0.043700
		loss: 0.043700
		loss: 0.043700
		loss: 0.043600
		loss: 0.043600
		loss: 0.043600
		loss: 0.043600
		loss: 0.043600
		loss: 0.043500
		loss: 0.043500
		loss: 0.043500
		loss: 0.043500
		loss: 0.043500
		loss: 0.043500
		loss: 0.043400
		loss: 0.043400
		loss: 0.043400
		loss: 0.043400
		loss: 0.043400
		loss: 0.043300
		loss: 0.043300
		loss: 0.043300
		loss: 0.043300
		loss: 0.043300
		loss: 0.043300
		loss: 0.043200
		loss: 0.043200
		loss: 0.043200
		loss: 0.043200
		loss: 0.043200
		loss: 0.043200
		loss: 0.043100
		loss: 0.043100
		loss: 0.043100
		loss: 0.043100
		loss: 0.043100
		loss: 0.043100
		loss: 0.043000
		loss: 0.043000
		loss: 0.043000
		loss: 0.043000
		loss: 0.043000
		loss: 0.043000
		loss: 0.042900
		loss: 0.042900
		loss: 0.042900
		loss: 0.042900
		loss: 0.042900
		loss: 0.042900
		loss: 0.042800
		loss: 0.042800
		loss: 0.042800
		loss: 0.042800
		loss: 0.042800
		loss: 0.042800
		loss: 0.042700
	Overall the loss development was 0.540000 -> 0.042700

Training data for problem d-5-2.pddl in epoch 2:
model creation time: 14.891949653625488s
problem epoch data for epoch 2, problem epoch 1
	sampling search time: 4.228124380111694s
	during this search the following actions were chosen:
	training time: 74.70290660858154s
	during the training the following losses were computed:
		loss: 1.793400
		loss: 1.549400
		loss: 1.409800
		loss: 1.343700
		loss: 1.337900
		loss: 1.328300
		loss: 1.270500
		loss: 1.190000
		loss: 1.116600
		loss: 1.064600
		loss: 1.034400
		loss: 1.011400
		loss: 0.988100
		loss: 0.959300
		loss: 0.925100
		loss: 0.887900
		loss: 0.852400
		loss: 0.822500
		loss: 0.801000
		loss: 0.787000
		loss: 0.774900
		loss: 0.760200
		loss: 0.741500
		loss: 0.720900
		loss: 0.702000
		loss: 0.687200
		loss: 0.676900
		loss: 0.669200
		loss: 0.662500
		loss: 0.655300
		loss: 0.647600
		loss: 0.639700
		loss: 0.632500
		loss: 0.626900
		loss: 0.623000
		loss: 0.620400
		loss: 0.618100
		loss: 0.615300
		loss: 0.611700
		loss: 0.607900
		loss: 0.604400
		loss: 0.601700
		loss: 0.599600
		loss: 0.597600
		loss: 0.595300
		loss: 0.592500
		loss: 0.589400
		loss: 0.586400
		loss: 0.583600
		loss: 0.581300
		loss: 0.578900
		loss: 0.576400
		loss: 0.573500
		loss: 0.570500
		loss: 0.567500
		loss: 0.564800
		loss: 0.562200
		loss: 0.559500
		loss: 0.556800
		loss: 0.554000
		loss: 0.551300
		loss: 0.548700
		loss: 0.546200
		loss: 0.543700
		loss: 0.541200
		loss: 0.538600
		loss: 0.536100
		loss: 0.533700
		loss: 0.531200
		loss: 0.528800
		loss: 0.526300
		loss: 0.523700
		loss: 0.521100
		loss: 0.518700
		loss: 0.516200
		loss: 0.513700
		loss: 0.511200
		loss: 0.508600
		loss: 0.506100
		loss: 0.503600
		loss: 0.501200
		loss: 0.498800
		loss: 0.496600
		loss: 0.494500
		loss: 0.492400
		loss: 0.490200
		loss: 0.488100
		loss: 0.486000
		loss: 0.483800
		loss: 0.481600
		loss: 0.479400
		loss: 0.477100
		loss: 0.474800
		loss: 0.472600
		loss: 0.470500
		loss: 0.468500
		loss: 0.466500
		loss: 0.464400
		loss: 0.462400
		loss: 0.460300
		loss: 0.458200
		loss: 0.456200
		loss: 0.454200
		loss: 0.452200
		loss: 0.450300
		loss: 0.448300
		loss: 0.446400
		loss: 0.444500
		loss: 0.442600
		loss: 0.440800
		loss: 0.438900
		loss: 0.437100
		loss: 0.435300
		loss: 0.433400
		loss: 0.431600
		loss: 0.429800
		loss: 0.427900
		loss: 0.426200
		loss: 0.424500
		loss: 0.422800
		loss: 0.421200
		loss: 0.419700
		loss: 0.418100
		loss: 0.416600
		loss: 0.415100
		loss: 0.413700
		loss: 0.412300
		loss: 0.410900
		loss: 0.409600
		loss: 0.408300
		loss: 0.407100
		loss: 0.405900
		loss: 0.404800
		loss: 0.403600
		loss: 0.402600
		loss: 0.401500
		loss: 0.400500
		loss: 0.399500
		loss: 0.398500
		loss: 0.397500
		loss: 0.396600
		loss: 0.395700
		loss: 0.394800
		loss: 0.394000
		loss: 0.393100
		loss: 0.392300
		loss: 0.391600
		loss: 0.390800
		loss: 0.390100
		loss: 0.389400
		loss: 0.388700
		loss: 0.388000
		loss: 0.387400
		loss: 0.386700
		loss: 0.386100
		loss: 0.385400
		loss: 0.384800
		loss: 0.384200
		loss: 0.383600
		loss: 0.383000
		loss: 0.382500
		loss: 0.381900
		loss: 0.381300
		loss: 0.380800
		loss: 0.380200
		loss: 0.379700
		loss: 0.379200
		loss: 0.378600
		loss: 0.378100
		loss: 0.377600
		loss: 0.377100
		loss: 0.376600
		loss: 0.376100
		loss: 0.375600
		loss: 0.375200
		loss: 0.374700
		loss: 0.374200
		loss: 0.373800
		loss: 0.373300
		loss: 0.372800
		loss: 0.372400
		loss: 0.371900
		loss: 0.371500
		loss: 0.371000
		loss: 0.370500
		loss: 0.370100
		loss: 0.369700
		loss: 0.369300
		loss: 0.368800
		loss: 0.368300
		loss: 0.367900
		loss: 0.367600
		loss: 0.367100
		loss: 0.366600
		loss: 0.366200
		loss: 0.365800
		loss: 0.365400
		loss: 0.365000
		loss: 0.364600
		loss: 0.364200
		loss: 0.363800
		loss: 0.363400
		loss: 0.362900
		loss: 0.362500
		loss: 0.362100
		loss: 0.361700
		loss: 0.361300
		loss: 0.360900
		loss: 0.360400
		loss: 0.360000
		loss: 0.359700
		loss: 0.359300
		loss: 0.358800
		loss: 0.358400
		loss: 0.358000
		loss: 0.357600
		loss: 0.357100
		loss: 0.356800
		loss: 0.356400
		loss: 0.355900
		loss: 0.355500
		loss: 0.355100
		loss: 0.354700
		loss: 0.354200
		loss: 0.353800
		loss: 0.353400
		loss: 0.353000
		loss: 0.352600
		loss: 0.352200
		loss: 0.351800
		loss: 0.351400
		loss: 0.351000
		loss: 0.350500
		loss: 0.350200
		loss: 0.349800
		loss: 0.349400
		loss: 0.349100
		loss: 0.348700
		loss: 0.348200
		loss: 0.347900
		loss: 0.347500
		loss: 0.347200
		loss: 0.346900
		loss: 0.346500
		loss: 0.346100
		loss: 0.345700
		loss: 0.345300
		loss: 0.345000
		loss: 0.344700
		loss: 0.344300
		loss: 0.344000
		loss: 0.343600
		loss: 0.343200
		loss: 0.342900
		loss: 0.342700
		loss: 0.342400
		loss: 0.342000
		loss: 0.341700
		loss: 0.341400
		loss: 0.341100
		loss: 0.340800
		loss: 0.340600
		loss: 0.340300
		loss: 0.340000
		loss: 0.339700
		loss: 0.339500
		loss: 0.339200
		loss: 0.338900
		loss: 0.338700
		loss: 0.338500
		loss: 0.338200
		loss: 0.338000
		loss: 0.337800
		loss: 0.337600
		loss: 0.337300
		loss: 0.337100
		loss: 0.336900
		loss: 0.336700
		loss: 0.336500
		loss: 0.336300
		loss: 0.336100
		loss: 0.335900
		loss: 0.335700
		loss: 0.335500
		loss: 0.335300
		loss: 0.335100
		loss: 0.334900
		loss: 0.334800
		loss: 0.334600
		loss: 0.334400
		loss: 0.334200
		loss: 0.334100
		loss: 0.333900
		loss: 0.333700
		loss: 0.333600
		loss: 0.333400
		loss: 0.333300
		loss: 0.333100
		loss: 0.333000
		loss: 0.332800
	Overall the loss development was 1.793400 -> 0.332800

Training data for problem d-5-0.pddl in epoch 2:
model creation time: 25.911085844039917s
problem epoch data for epoch 2, problem epoch 1
	sampling search time: 7.216188669204712s
	during this search the following actions were chosen:
		unstack c e was chosen with probability 0.999826
		put-down c was chosen with probability 0.994813
		unstack e b was chosen with probability 0.595840
		put-down e was chosen with probability 0.944837
		unstack b a was chosen with probability 0.581573
		stack b e was chosen with probability 0.331506
		pick-up d was chosen with probability 0.905438
		stack d c was chosen with probability 0.997147
		unstack b e was chosen with probability 0.989940
		stack b d was chosen with probability 0.998488
		pick-up e was chosen with probability 0.995946
		stack e b was chosen with probability 0.987688
	training time: 76.26140141487122s
	during the training the following losses were computed:
		loss: 0.368200
		loss: 0.624700
		loss: 0.392100
		loss: 0.410700
		loss: 0.473100
		loss: 0.382700
		loss: 0.341500
		loss: 0.381300
		loss: 0.404400
		loss: 0.383100
		loss: 0.343800
		loss: 0.331700
		loss: 0.354900
		loss: 0.367700
		loss: 0.351000
		loss: 0.330300
		loss: 0.330300
		loss: 0.343000
		loss: 0.348300
		loss: 0.339700
		loss: 0.327400
		loss: 0.325000
		loss: 0.332500
		loss: 0.336500
		loss: 0.330900
		loss: 0.323500
		loss: 0.323000
		loss: 0.327500
		loss: 0.329300
		loss: 0.325800
		loss: 0.321300
		loss: 0.321000
		loss: 0.323800
		loss: 0.324600
		loss: 0.322000
		loss: 0.319500
		loss: 0.320100
		loss: 0.321800
		loss: 0.321600
		loss: 0.319600
		loss: 0.318500
		loss: 0.319300
		loss: 0.320100
		loss: 0.319300
		loss: 0.318000
		loss: 0.317900
		loss: 0.318500
		loss: 0.318600
		loss: 0.317700
		loss: 0.317100
		loss: 0.317400
		loss: 0.317700
		loss: 0.317300
		loss: 0.316700
		loss: 0.316600
		loss: 0.316900
		loss: 0.316700
		loss: 0.316300
		loss: 0.316100
		loss: 0.316200
		loss: 0.316100
		loss: 0.315800
		loss: 0.315600
		loss: 0.315600
		loss: 0.315600
		loss: 0.315400
		loss: 0.315200
		loss: 0.315200
		loss: 0.315100
		loss: 0.315000
		loss: 0.314800
		loss: 0.314800
		loss: 0.314700
		loss: 0.314600
		loss: 0.314500
		loss: 0.314400
		loss: 0.314400
		loss: 0.314200
		loss: 0.314100
		loss: 0.314100
		loss: 0.314000
		loss: 0.313900
		loss: 0.313800
		loss: 0.313800
		loss: 0.313700
		loss: 0.313600
		loss: 0.313500
		loss: 0.313400
		loss: 0.313400
		loss: 0.313300
		loss: 0.313200
		loss: 0.313100
		loss: 0.313100
		loss: 0.313000
		loss: 0.312900
		loss: 0.312900
		loss: 0.312800
		loss: 0.312700
		loss: 0.312700
		loss: 0.312600
		loss: 0.312500
		loss: 0.312500
		loss: 0.312400
		loss: 0.312300
		loss: 0.312300
		loss: 0.312200
		loss: 0.312100
		loss: 0.312100
		loss: 0.312000
		loss: 0.312000
		loss: 0.311900
		loss: 0.311800
		loss: 0.311800
		loss: 0.311700
		loss: 0.311700
		loss: 0.311600
		loss: 0.311600
		loss: 0.311500
		loss: 0.311500
		loss: 0.311400
		loss: 0.311400
		loss: 0.311300
		loss: 0.311200
		loss: 0.311200
		loss: 0.311100
		loss: 0.311100
		loss: 0.311000
		loss: 0.311000
		loss: 0.310900
		loss: 0.310900
		loss: 0.310800
		loss: 0.310800
		loss: 0.310700
		loss: 0.310700
		loss: 0.310600
		loss: 0.310600
		loss: 0.310500
		loss: 0.310400
		loss: 0.310400
		loss: 0.310300
		loss: 0.310300
		loss: 0.310200
		loss: 0.310200
		loss: 0.310100
		loss: 0.310000
		loss: 0.310000
		loss: 0.309900
		loss: 0.309800
		loss: 0.309800
		loss: 0.309700
		loss: 0.309600
		loss: 0.309600
		loss: 0.309500
		loss: 0.309400
		loss: 0.309400
		loss: 0.309300
		loss: 0.309200
		loss: 0.309200
		loss: 0.309100
		loss: 0.309000
		loss: 0.309000
		loss: 0.308900
		loss: 0.308800
		loss: 0.308800
		loss: 0.308700
		loss: 0.308600
		loss: 0.308600
		loss: 0.308500
		loss: 0.308500
		loss: 0.308400
		loss: 0.308400
		loss: 0.308300
		loss: 0.308300
		loss: 0.308200
		loss: 0.308200
		loss: 0.308100
		loss: 0.308100
		loss: 0.308100
		loss: 0.308000
		loss: 0.308000
		loss: 0.308000
		loss: 0.307900
		loss: 0.307900
		loss: 0.307800
		loss: 0.307800
		loss: 0.307800
		loss: 0.307700
		loss: 0.307700
		loss: 0.307600
		loss: 0.307600
		loss: 0.307600
		loss: 0.307500
		loss: 0.307500
		loss: 0.307500
		loss: 0.307400
		loss: 0.307400
		loss: 0.307400
		loss: 0.307300
		loss: 0.307300
		loss: 0.307300
		loss: 0.307200
		loss: 0.307200
		loss: 0.307100
		loss: 0.307100
		loss: 0.307100
		loss: 0.307000
		loss: 0.307000
		loss: 0.307000
		loss: 0.306900
		loss: 0.306900
		loss: 0.306900
		loss: 0.306800
		loss: 0.306800
		loss: 0.306800
		loss: 0.306700
		loss: 0.306700
		loss: 0.306700
		loss: 0.306600
		loss: 0.306600
		loss: 0.306600
		loss: 0.306500
		loss: 0.306500
		loss: 0.306500
		loss: 0.306400
		loss: 0.306400
		loss: 0.306400
		loss: 0.306300
		loss: 0.306300
		loss: 0.306300
		loss: 0.306200
		loss: 0.306200
		loss: 0.306200
		loss: 0.306100
		loss: 0.306100
		loss: 0.306100
		loss: 0.306100
		loss: 0.306000
		loss: 0.306000
		loss: 0.306000
		loss: 0.305900
		loss: 0.305900
		loss: 0.305900
		loss: 0.305800
		loss: 0.305800
		loss: 0.305800
		loss: 0.305700
		loss: 0.305700
		loss: 0.305700
		loss: 0.305700
		loss: 0.305600
		loss: 0.305600
		loss: 0.305600
		loss: 0.305500
		loss: 0.305500
		loss: 0.305500
		loss: 0.305400
		loss: 0.305400
		loss: 0.305400
		loss: 0.305400
		loss: 0.305300
		loss: 0.305300
		loss: 0.305300
		loss: 0.305200
		loss: 0.305200
		loss: 0.305200
		loss: 0.305100
		loss: 0.305100
		loss: 0.305100
		loss: 0.305100
		loss: 0.305000
		loss: 0.305000
		loss: 0.305000
		loss: 0.304900
		loss: 0.304900
		loss: 0.304900
		loss: 0.304900
		loss: 0.304800
		loss: 0.304800
		loss: 0.304800
		loss: 0.304700
		loss: 0.304700
		loss: 0.304700
		loss: 0.304700
		loss: 0.304600
		loss: 0.304600
		loss: 0.304600
		loss: 0.304500
		loss: 0.304500
		loss: 0.304500
		loss: 0.304500
		loss: 0.304400
		loss: 0.304400
		loss: 0.304400
		loss: 0.304400
		loss: 0.304300
		loss: 0.304300
		loss: 0.304300
		loss: 0.304200
		loss: 0.304200
		loss: 0.304200
	Overall the loss development was 0.368200 -> 0.304200

Training data for problem d-5-1.pddl in epoch 2:
model creation time: 14.814599990844727s
problem epoch data for epoch 2, problem epoch 1
	sampling search time: 4.313058376312256s
	during this search the following actions were chosen:
		pick-up c was chosen with probability 0.998466
		stack c b was chosen with probability 0.998697
		unstack c b was chosen with probability 0.767360
	training time: 73.71883273124695s
	during the training the following losses were computed:
		loss: 1.660200
		loss: 1.212000
		loss: 1.037700
		loss: 1.074500
		loss: 1.104200
		loss: 1.018400
		loss: 0.903100
		loss: 0.822900
		loss: 0.773400
		loss: 0.735300
		loss: 0.709800
		loss: 0.694200
		loss: 0.678800
		loss: 0.652400
		loss: 0.615300
		loss: 0.580600
		loss: 0.558100
		loss: 0.549800
		loss: 0.550200
		loss: 0.546700
		loss: 0.530700
		loss: 0.504400
		loss: 0.479200
		loss: 0.462700
		loss: 0.453500
		loss: 0.445800
		loss: 0.435400
		loss: 0.422200
		loss: 0.409300
		loss: 0.399900
		loss: 0.394900
		loss: 0.391400
		loss: 0.386300
		loss: 0.378700
		loss: 0.369400
		loss: 0.360900
		loss: 0.354600
		loss: 0.350000
		loss: 0.345300
		loss: 0.339600
		loss: 0.333200
		loss: 0.327800
		loss: 0.324000
		loss: 0.321400
		loss: 0.318300
		loss: 0.314200
		loss: 0.309600
		loss: 0.305600
		loss: 0.302400
		loss: 0.299600
		loss: 0.296500
		loss: 0.292900
		loss: 0.289600
		loss: 0.286700
		loss: 0.284300
		loss: 0.281800
		loss: 0.279100
		loss: 0.276300
		loss: 0.273800
		loss: 0.271600
		loss: 0.269600
		loss: 0.267500
		loss: 0.265400
		loss: 0.263300
		loss: 0.261400
		loss: 0.259600
		loss: 0.257900
		loss: 0.256100
		loss: 0.254300
		loss: 0.252500
		loss: 0.250900
		loss: 0.249400
		loss: 0.247800
		loss: 0.246200
		loss: 0.244700
		loss: 0.243200
		loss: 0.241700
		loss: 0.240300
		loss: 0.238900
		loss: 0.237500
		loss: 0.236200
		loss: 0.235000
		loss: 0.233800
		loss: 0.232700
		loss: 0.231600
		loss: 0.230500
		loss: 0.229500
		loss: 0.228500
		loss: 0.227500
		loss: 0.226500
		loss: 0.225600
		loss: 0.224700
		loss: 0.223900
		loss: 0.223000
		loss: 0.222200
		loss: 0.221400
		loss: 0.220600
		loss: 0.219800
		loss: 0.219100
		loss: 0.218300
		loss: 0.217600
		loss: 0.216900
		loss: 0.216200
		loss: 0.215600
		loss: 0.214900
		loss: 0.214300
		loss: 0.213700
		loss: 0.213100
		loss: 0.212500
		loss: 0.211900
		loss: 0.211300
		loss: 0.210700
		loss: 0.210100
		loss: 0.209600
		loss: 0.209000
		loss: 0.208500
		loss: 0.208000
		loss: 0.207500
		loss: 0.207000
		loss: 0.206500
		loss: 0.206000
		loss: 0.205600
		loss: 0.205100
		loss: 0.204700
		loss: 0.204200
		loss: 0.203800
		loss: 0.203400
		loss: 0.202900
		loss: 0.202500
		loss: 0.202100
		loss: 0.201700
		loss: 0.201300
		loss: 0.201000
		loss: 0.200600
		loss: 0.200200
		loss: 0.199900
		loss: 0.199500
		loss: 0.199200
		loss: 0.198900
		loss: 0.198600
		loss: 0.198200
		loss: 0.197900
		loss: 0.197600
		loss: 0.197300
		loss: 0.197100
		loss: 0.196800
		loss: 0.196500
		loss: 0.196200
		loss: 0.196000
		loss: 0.195700
		loss: 0.195500
		loss: 0.195200
		loss: 0.195000
		loss: 0.194700
		loss: 0.194500
		loss: 0.194300
		loss: 0.194100
		loss: 0.193800
		loss: 0.193600
		loss: 0.193400
		loss: 0.193200
		loss: 0.193000
		loss: 0.192800
		loss: 0.192600
		loss: 0.192400
		loss: 0.192200
		loss: 0.192000
		loss: 0.191800
		loss: 0.191700
		loss: 0.191500
		loss: 0.191300
		loss: 0.191200
		loss: 0.191000
		loss: 0.190800
		loss: 0.190700
		loss: 0.190500
		loss: 0.190400
		loss: 0.190200
		loss: 0.190100
		loss: 0.189900
		loss: 0.189800
		loss: 0.189600
		loss: 0.189500
		loss: 0.189400
		loss: 0.189200
		loss: 0.189100
		loss: 0.189000
		loss: 0.188900
		loss: 0.188700
		loss: 0.188600
		loss: 0.188500
		loss: 0.188400
		loss: 0.188200
		loss: 0.188100
		loss: 0.188000
		loss: 0.187900
		loss: 0.187800
		loss: 0.187700
		loss: 0.187600
		loss: 0.187500
		loss: 0.187400
		loss: 0.187300
		loss: 0.187200
		loss: 0.187100
		loss: 0.187000
		loss: 0.186900
		loss: 0.186800
		loss: 0.186700
		loss: 0.186600
		loss: 0.186500
		loss: 0.186400
		loss: 0.186300
		loss: 0.186200
		loss: 0.186100
		loss: 0.186000
		loss: 0.185900
		loss: 0.185900
		loss: 0.185800
		loss: 0.185700
		loss: 0.185600
		loss: 0.185500
		loss: 0.185400
		loss: 0.185300
		loss: 0.185200
		loss: 0.185200
		loss: 0.185100
		loss: 0.185000
		loss: 0.184900
		loss: 0.184800
		loss: 0.184800
		loss: 0.184700
		loss: 0.184600
		loss: 0.184500
		loss: 0.184400
		loss: 0.184400
		loss: 0.184300
		loss: 0.184200
		loss: 0.184200
		loss: 0.184100
		loss: 0.184000
		loss: 0.183900
		loss: 0.183900
		loss: 0.183800
		loss: 0.183700
		loss: 0.183700
		loss: 0.183600
		loss: 0.183500
		loss: 0.183500
		loss: 0.183400
		loss: 0.183400
		loss: 0.183300
		loss: 0.183200
		loss: 0.183200
		loss: 0.183100
		loss: 0.183100
		loss: 0.183000
		loss: 0.182900
		loss: 0.182900
		loss: 0.182800
		loss: 0.182800
		loss: 0.182700
		loss: 0.182700
		loss: 0.182600
		loss: 0.182600
		loss: 0.182500
		loss: 0.182500
		loss: 0.182400
		loss: 0.182400
		loss: 0.182300
		loss: 0.182300
		loss: 0.182200
		loss: 0.182200
		loss: 0.182100
		loss: 0.182100
		loss: 0.182000
		loss: 0.182000
		loss: 0.181900
		loss: 0.181900
		loss: 0.181800
		loss: 0.181800
		loss: 0.181700
		loss: 0.181700
		loss: 0.181600
		loss: 0.181600
		loss: 0.181500
		loss: 0.181500
		loss: 0.181500
		loss: 0.181400
		loss: 0.181400
		loss: 0.181300
		loss: 0.181300
		loss: 0.181200
		loss: 0.181200
		loss: 0.181200
		loss: 0.181100
		loss: 0.181100
		loss: 0.181000
		loss: 0.181000
		loss: 0.180900
		loss: 0.180900
	Overall the loss development was 1.660200 -> 0.180900

Epoch 3:
Training data for problem d-4-0.pddl in epoch 3:
model creation time: 9.825657606124878s
problem epoch data for epoch 3, problem epoch 1
	sampling search time: 2.3676881790161133s
	during this search the following actions were chosen:
		pick-up b was chosen with probability 0.333333
		stack b a was chosen with probability 0.998954
		pick-up c was chosen with probability 0.997233
		stack c b was chosen with probability 0.969543
		pick-up d was chosen with probability 0.999937
		stack d c was chosen with probability 0.998193
	training time: 60.08746600151062s
	during the training the following losses were computed:
		loss: 0.232000
		loss: 0.227800
		loss: 0.226600
		loss: 0.225900
		loss: 0.225300
		loss: 0.224700
		loss: 0.224100
		loss: 0.223500
		loss: 0.222900
		loss: 0.222300
		loss: 0.221700
		loss: 0.221100
		loss: 0.220400
		loss: 0.219800
		loss: 0.219200
		loss: 0.218600
		loss: 0.217900
		loss: 0.217300
		loss: 0.216700
		loss: 0.216100
		loss: 0.215500
		loss: 0.214900
		loss: 0.214300
		loss: 0.213700
		loss: 0.213100
		loss: 0.212500
		loss: 0.212000
		loss: 0.211400
		loss: 0.210900
		loss: 0.210300
		loss: 0.209800
		loss: 0.209200
		loss: 0.208700
		loss: 0.208200
		loss: 0.207700
		loss: 0.207200
		loss: 0.206700
		loss: 0.206300
		loss: 0.205800
		loss: 0.205300
		loss: 0.204900
		loss: 0.204500
		loss: 0.204000
		loss: 0.203600
		loss: 0.203200
		loss: 0.202800
		loss: 0.202400
		loss: 0.202000
		loss: 0.201600
		loss: 0.201200
		loss: 0.200900
		loss: 0.200500
		loss: 0.200200
		loss: 0.199800
		loss: 0.199500
		loss: 0.199100
		loss: 0.198800
		loss: 0.198500
		loss: 0.198200
		loss: 0.197900
		loss: 0.197600
		loss: 0.197300
		loss: 0.197000
		loss: 0.196700
		loss: 0.196400
		loss: 0.196200
		loss: 0.195900
		loss: 0.195700
		loss: 0.195400
		loss: 0.195200
		loss: 0.194900
		loss: 0.194700
		loss: 0.194500
		loss: 0.194200
		loss: 0.194000
		loss: 0.193800
		loss: 0.193600
		loss: 0.193400
		loss: 0.193200
		loss: 0.193000
		loss: 0.192800
		loss: 0.192600
		loss: 0.192400
		loss: 0.192300
		loss: 0.192100
		loss: 0.191900
		loss: 0.191700
		loss: 0.191600
		loss: 0.191400
		loss: 0.191200
		loss: 0.191100
		loss: 0.190900
		loss: 0.190800
		loss: 0.190600
		loss: 0.190500
		loss: 0.190300
		loss: 0.190200
		loss: 0.190000
		loss: 0.189900
		loss: 0.189700
		loss: 0.189600
		loss: 0.189500
		loss: 0.189300
		loss: 0.189200
		loss: 0.189100
		loss: 0.189000
		loss: 0.188800
		loss: 0.188700
		loss: 0.188600
		loss: 0.188500
		loss: 0.188400
		loss: 0.188200
		loss: 0.188100
		loss: 0.188000
		loss: 0.187900
		loss: 0.187800
		loss: 0.187700
		loss: 0.187600
		loss: 0.187500
		loss: 0.187400
		loss: 0.187300
		loss: 0.187200
		loss: 0.187100
		loss: 0.187000
		loss: 0.186900
		loss: 0.186800
		loss: 0.186700
		loss: 0.186600
		loss: 0.186500
		loss: 0.186400
		loss: 0.186300
		loss: 0.186200
		loss: 0.186100
		loss: 0.186000
		loss: 0.185900
		loss: 0.185900
		loss: 0.185800
		loss: 0.185700
		loss: 0.185600
		loss: 0.185500
		loss: 0.185400
		loss: 0.185400
		loss: 0.185300
		loss: 0.185200
		loss: 0.185100
		loss: 0.185100
		loss: 0.185000
		loss: 0.184900
		loss: 0.184800
		loss: 0.184800
		loss: 0.184700
		loss: 0.184600
		loss: 0.184500
		loss: 0.184500
		loss: 0.184400
		loss: 0.184300
		loss: 0.184300
		loss: 0.184200
		loss: 0.184100
		loss: 0.184100
		loss: 0.184000
		loss: 0.183900
		loss: 0.183900
		loss: 0.183800
		loss: 0.183800
		loss: 0.183700
		loss: 0.183600
		loss: 0.183600
		loss: 0.183500
		loss: 0.183500
		loss: 0.183400
		loss: 0.183300
		loss: 0.183300
		loss: 0.183200
		loss: 0.183200
		loss: 0.183100
		loss: 0.183100
		loss: 0.183000
		loss: 0.182900
		loss: 0.182900
		loss: 0.182800
		loss: 0.182800
		loss: 0.182700
		loss: 0.182700
		loss: 0.182600
		loss: 0.182600
		loss: 0.182500
		loss: 0.182500
		loss: 0.182400
		loss: 0.182400
		loss: 0.182300
		loss: 0.182300
		loss: 0.182200
		loss: 0.182200
		loss: 0.182100
		loss: 0.182100
		loss: 0.182100
		loss: 0.182000
		loss: 0.182000
		loss: 0.181900
		loss: 0.181900
		loss: 0.181800
		loss: 0.181800
		loss: 0.181700
		loss: 0.181700
		loss: 0.181700
		loss: 0.181600
		loss: 0.181600
		loss: 0.181500
		loss: 0.181500
		loss: 0.181500
		loss: 0.181400
		loss: 0.181400
		loss: 0.181300
		loss: 0.181300
		loss: 0.181300
		loss: 0.181200
		loss: 0.181200
		loss: 0.181100
		loss: 0.181100
		loss: 0.181100
		loss: 0.181000
		loss: 0.181000
		loss: 0.181000
		loss: 0.180900
		loss: 0.180900
		loss: 0.180900
		loss: 0.180800
		loss: 0.180800
		loss: 0.180800
		loss: 0.180700
		loss: 0.180700
		loss: 0.180700
		loss: 0.180600
		loss: 0.180600
		loss: 0.180600
		loss: 0.180500
		loss: 0.180500
		loss: 0.180500
		loss: 0.180400
		loss: 0.180400
		loss: 0.180400
		loss: 0.180300
		loss: 0.180300
		loss: 0.180300
		loss: 0.180200
		loss: 0.180200
		loss: 0.180200
		loss: 0.180200
		loss: 0.180100
		loss: 0.180100
		loss: 0.180100
		loss: 0.180100
		loss: 0.180000
		loss: 0.180000
		loss: 0.180000
		loss: 0.179900
		loss: 0.179900
		loss: 0.179900
		loss: 0.179900
		loss: 0.179800
		loss: 0.179800
		loss: 0.179800
		loss: 0.179800
		loss: 0.179800
		loss: 0.179700
		loss: 0.179700
		loss: 0.179700
		loss: 0.179700
		loss: 0.179600
		loss: 0.179600
		loss: 0.179600
		loss: 0.179600
		loss: 0.179500
		loss: 0.179500
		loss: 0.179500
		loss: 0.179500
		loss: 0.179500
		loss: 0.179400
		loss: 0.179400
		loss: 0.179400
		loss: 0.179400
		loss: 0.179400
		loss: 0.179300
		loss: 0.179300
		loss: 0.179300
		loss: 0.179300
		loss: 0.179300
		loss: 0.179200
		loss: 0.179200
		loss: 0.179200
		loss: 0.179200
		loss: 0.179200
		loss: 0.179100
		loss: 0.179100
		loss: 0.179100
		loss: 0.179100
		loss: 0.179100
		loss: 0.179100
		loss: 0.179000
	Overall the loss development was 0.232000 -> 0.179000

Training data for problem d-4-2.pddl in epoch 3:
model creation time: 10.038668870925903s
problem epoch data for epoch 3, problem epoch 1
	sampling search time: 2.5026586055755615s
	during this search the following actions were chosen:
		pick-up a was chosen with probability 0.986995
		stack a c was chosen with probability 0.853423
		pick-up d was chosen with probability 0.996176
		stack d a was chosen with probability 0.977561
	training time: 60.79971194267273s
	during the training the following losses were computed:
		loss: 2.176800
		loss: 2.032500
		loss: 1.845200
		loss: 1.664700
		loss: 1.491600
		loss: 1.325400
		loss: 1.166000
		loss: 1.014300
		loss: 0.872600
		loss: 0.746900
		loss: 0.639600
		loss: 0.551600
		loss: 0.493200
		loss: 0.444000
		loss: 0.404000
		loss: 0.372700
		loss: 0.350400
		loss: 0.339300
		loss: 0.341500
		loss: 0.352300
		loss: 0.369300
		loss: 0.385900
		loss: 0.396100
		loss: 0.397600
		loss: 0.390100
		loss: 0.375400
		loss: 0.355600
		loss: 0.333800
		loss: 0.313400
		loss: 0.295300
		loss: 0.279700
		loss: 0.266700
		loss: 0.256100
		loss: 0.247300
		loss: 0.239300
		loss: 0.231700
		loss: 0.223600
		loss: 0.214900
		loss: 0.205500
		loss: 0.195600
		loss: 0.185100
		loss: 0.174400
		loss: 0.164000
		loss: 0.154300
		loss: 0.145600
		loss: 0.138100
		loss: 0.132000
		loss: 0.127000
		loss: 0.122600
		loss: 0.118400
		loss: 0.114100
		loss: 0.109300
		loss: 0.104400
		loss: 0.099700
		loss: 0.095500
		loss: 0.092000
		loss: 0.089300
		loss: 0.087000
		loss: 0.085100
		loss: 0.083100
		loss: 0.081100
		loss: 0.079000
		loss: 0.076800
		loss: 0.074600
		loss: 0.072600
		loss: 0.070800
		loss: 0.069300
		loss: 0.067900
		loss: 0.066700
		loss: 0.065500
		loss: 0.064200
		loss: 0.062900
		loss: 0.061600
		loss: 0.060400
		loss: 0.059200
		loss: 0.058200
		loss: 0.057200
		loss: 0.056400
		loss: 0.055500
		loss: 0.054800
		loss: 0.054000
		loss: 0.053200
		loss: 0.052400
		loss: 0.051700
		loss: 0.051000
		loss: 0.050400
		loss: 0.049800
		loss: 0.049300
		loss: 0.048800
		loss: 0.048300
		loss: 0.047800
		loss: 0.047300
		loss: 0.046800
		loss: 0.046400
		loss: 0.046000
		loss: 0.045600
		loss: 0.045200
		loss: 0.044900
		loss: 0.044500
		loss: 0.044200
		loss: 0.043900
		loss: 0.043600
		loss: 0.043400
		loss: 0.043100
		loss: 0.042800
		loss: 0.042600
		loss: 0.042400
		loss: 0.042200
		loss: 0.042000
		loss: 0.041800
		loss: 0.041600
		loss: 0.041400
		loss: 0.041200
		loss: 0.041000
		loss: 0.040900
		loss: 0.040700
		loss: 0.040600
		loss: 0.040400
		loss: 0.040300
		loss: 0.040200
		loss: 0.040100
		loss: 0.039900
		loss: 0.039800
		loss: 0.039700
		loss: 0.039600
		loss: 0.039500
		loss: 0.039400
		loss: 0.039300
		loss: 0.039200
		loss: 0.039100
		loss: 0.039000
		loss: 0.038900
		loss: 0.038900
		loss: 0.038800
		loss: 0.038700
		loss: 0.038600
		loss: 0.038600
		loss: 0.038500
		loss: 0.038400
		loss: 0.038400
		loss: 0.038300
		loss: 0.038200
		loss: 0.038200
		loss: 0.038100
		loss: 0.038100
		loss: 0.038000
		loss: 0.037900
		loss: 0.037900
		loss: 0.037800
		loss: 0.037800
		loss: 0.037700
		loss: 0.037700
		loss: 0.037600
		loss: 0.037600
		loss: 0.037500
		loss: 0.037500
		loss: 0.037400
		loss: 0.037400
		loss: 0.037400
		loss: 0.037300
		loss: 0.037300
		loss: 0.037200
		loss: 0.037200
		loss: 0.037200
		loss: 0.037100
		loss: 0.037100
		loss: 0.037000
		loss: 0.037000
		loss: 0.037000
		loss: 0.036900
		loss: 0.036900
		loss: 0.036800
		loss: 0.036800
		loss: 0.036800
		loss: 0.036700
		loss: 0.036700
		loss: 0.036700
		loss: 0.036600
		loss: 0.036600
		loss: 0.036600
		loss: 0.036500
		loss: 0.036500
		loss: 0.036500
		loss: 0.036400
		loss: 0.036400
		loss: 0.036400
		loss: 0.036400
		loss: 0.036300
		loss: 0.036300
		loss: 0.036300
		loss: 0.036200
		loss: 0.036200
		loss: 0.036200
		loss: 0.036100
		loss: 0.036100
		loss: 0.036100
		loss: 0.036100
		loss: 0.036000
		loss: 0.036000
		loss: 0.036000
		loss: 0.036000
		loss: 0.035900
		loss: 0.035900
		loss: 0.035900
		loss: 0.035900
		loss: 0.035800
		loss: 0.035800
		loss: 0.035800
		loss: 0.035700
		loss: 0.035700
		loss: 0.035700
		loss: 0.035700
		loss: 0.035700
		loss: 0.035600
		loss: 0.035600
		loss: 0.035600
		loss: 0.035600
		loss: 0.035500
		loss: 0.035500
		loss: 0.035500
		loss: 0.035500
		loss: 0.035400
		loss: 0.035400
		loss: 0.035400
		loss: 0.035400
		loss: 0.035400
		loss: 0.035300
		loss: 0.035300
		loss: 0.035300
		loss: 0.035300
		loss: 0.035200
		loss: 0.035200
		loss: 0.035200
		loss: 0.035200
		loss: 0.035200
		loss: 0.035100
		loss: 0.035100
		loss: 0.035100
		loss: 0.035100
		loss: 0.035100
		loss: 0.035000
		loss: 0.035000
		loss: 0.035000
		loss: 0.035000
		loss: 0.035000
		loss: 0.034900
		loss: 0.034900
		loss: 0.034900
		loss: 0.034900
		loss: 0.034900
		loss: 0.034900
		loss: 0.034800
		loss: 0.034800
		loss: 0.034800
		loss: 0.034800
		loss: 0.034800
		loss: 0.034700
		loss: 0.034700
		loss: 0.034700
		loss: 0.034700
		loss: 0.034700
		loss: 0.034700
		loss: 0.034600
		loss: 0.034600
		loss: 0.034600
		loss: 0.034600
		loss: 0.034600
		loss: 0.034600
		loss: 0.034500
		loss: 0.034500
		loss: 0.034500
		loss: 0.034500
		loss: 0.034500
		loss: 0.034500
		loss: 0.034400
		loss: 0.034400
		loss: 0.034400
		loss: 0.034400
		loss: 0.034400
		loss: 0.034400
		loss: 0.034400
		loss: 0.034300
		loss: 0.034300
		loss: 0.034300
		loss: 0.034300
		loss: 0.034300
		loss: 0.034300
		loss: 0.034300
		loss: 0.034200
		loss: 0.034200
		loss: 0.034200
		loss: 0.034200
		loss: 0.034200
		loss: 0.034200
		loss: 0.034200
		loss: 0.034100
		loss: 0.034100
		loss: 0.034100
		loss: 0.034100
		loss: 0.034100
	Overall the loss development was 2.176800 -> 0.034100

Training data for problem d-4-1.pddl in epoch 3:
model creation time: 9.940695524215698s
problem epoch data for epoch 3, problem epoch 1
	sampling search time: 2.463519811630249s
	during this search the following actions were chosen:
	training time: 60.430602073669434s
	during the training the following losses were computed:
		loss: 0.383500
		loss: 0.188900
		loss: 0.113200
		loss: 0.146200
		loss: 0.181500
		loss: 0.161500
		loss: 0.122600
		loss: 0.094100
		loss: 0.083900
		loss: 0.087000
		loss: 0.095600
		loss: 0.102200
		loss: 0.102600
		loss: 0.096800
		loss: 0.088000
		loss: 0.079900
		loss: 0.074900
		loss: 0.073500
		loss: 0.074700
		loss: 0.076600
		loss: 0.077400
		loss: 0.076200
		loss: 0.073200
		loss: 0.069400
		loss: 0.065700
		loss: 0.063000
		loss: 0.061300
		loss: 0.060600
		loss: 0.060400
		loss: 0.060300
		loss: 0.059900
		loss: 0.059000
		loss: 0.057800
		loss: 0.056500
		loss: 0.055200
		loss: 0.054200
		loss: 0.053500
		loss: 0.053100
		loss: 0.052800
		loss: 0.052600
		loss: 0.052300
		loss: 0.051900
		loss: 0.051400
		loss: 0.050800
		loss: 0.050200
		loss: 0.049600
		loss: 0.049200
		loss: 0.048800
		loss: 0.048500
		loss: 0.048200
		loss: 0.047900
		loss: 0.047700
		loss: 0.047400
		loss: 0.047100
		loss: 0.046700
		loss: 0.046400
		loss: 0.046100
		loss: 0.045800
		loss: 0.045600
		loss: 0.045400
		loss: 0.045200
		loss: 0.045000
		loss: 0.044800
		loss: 0.044600
		loss: 0.044400
		loss: 0.044200
		loss: 0.044000
		loss: 0.043800
		loss: 0.043700
		loss: 0.043500
		loss: 0.043400
		loss: 0.043200
		loss: 0.043100
		loss: 0.043000
		loss: 0.042800
		loss: 0.042700
		loss: 0.042600
		loss: 0.042400
		loss: 0.042300
		loss: 0.042200
		loss: 0.042100
		loss: 0.042000
		loss: 0.041900
		loss: 0.041800
		loss: 0.041700
		loss: 0.041600
		loss: 0.041500
		loss: 0.041400
		loss: 0.041300
		loss: 0.041200
		loss: 0.041200
		loss: 0.041100
		loss: 0.041000
		loss: 0.040900
		loss: 0.040900
		loss: 0.040800
		loss: 0.040700
		loss: 0.040700
		loss: 0.040600
		loss: 0.040600
		loss: 0.040500
		loss: 0.040500
		loss: 0.040400
		loss: 0.040400
		loss: 0.040300
		loss: 0.040300
		loss: 0.040200
		loss: 0.040200
		loss: 0.040100
		loss: 0.040100
		loss: 0.040100
		loss: 0.040000
		loss: 0.040000
		loss: 0.040000
		loss: 0.039900
		loss: 0.039900
		loss: 0.039900
		loss: 0.039800
		loss: 0.039800
		loss: 0.039800
		loss: 0.039800
		loss: 0.039700
		loss: 0.039700
		loss: 0.039700
		loss: 0.039600
		loss: 0.039600
		loss: 0.039600
		loss: 0.039600
		loss: 0.039600
		loss: 0.039500
		loss: 0.039500
		loss: 0.039500
		loss: 0.039500
		loss: 0.039400
		loss: 0.039400
		loss: 0.039400
		loss: 0.039400
		loss: 0.039400
		loss: 0.039300
		loss: 0.039300
		loss: 0.039300
		loss: 0.039300
		loss: 0.039300
		loss: 0.039200
		loss: 0.039200
		loss: 0.039200
		loss: 0.039200
		loss: 0.039200
		loss: 0.039200
		loss: 0.039100
		loss: 0.039100
		loss: 0.039100
		loss: 0.039100
		loss: 0.039100
		loss: 0.039000
		loss: 0.039000
		loss: 0.039000
		loss: 0.039000
		loss: 0.039000
		loss: 0.039000
		loss: 0.038900
		loss: 0.038900
		loss: 0.038900
		loss: 0.038900
		loss: 0.038900
		loss: 0.038900
		loss: 0.038900
		loss: 0.038800
		loss: 0.038800
		loss: 0.038800
		loss: 0.038800
		loss: 0.038800
		loss: 0.038800
		loss: 0.038700
		loss: 0.038700
		loss: 0.038700
		loss: 0.038700
		loss: 0.038700
		loss: 0.038700
		loss: 0.038600
		loss: 0.038600
		loss: 0.038600
		loss: 0.038600
		loss: 0.038600
		loss: 0.038600
		loss: 0.038600
		loss: 0.038500
		loss: 0.038500
		loss: 0.038500
		loss: 0.038500
		loss: 0.038500
		loss: 0.038500
		loss: 0.038500
		loss: 0.038400
		loss: 0.038400
		loss: 0.038400
		loss: 0.038400
		loss: 0.038400
		loss: 0.038400
		loss: 0.038300
		loss: 0.038300
		loss: 0.038300
		loss: 0.038300
		loss: 0.038300
		loss: 0.038300
		loss: 0.038300
		loss: 0.038200
		loss: 0.038200
		loss: 0.038200
		loss: 0.038200
		loss: 0.038200
		loss: 0.038200
		loss: 0.038200
		loss: 0.038100
		loss: 0.038100
		loss: 0.038100
		loss: 0.038100
		loss: 0.038100
		loss: 0.038100
		loss: 0.038100
		loss: 0.038000
		loss: 0.038000
		loss: 0.038000
		loss: 0.038000
		loss: 0.038000
		loss: 0.038000
		loss: 0.038000
		loss: 0.037900
		loss: 0.037900
		loss: 0.037900
		loss: 0.037900
		loss: 0.037900
		loss: 0.037900
		loss: 0.037900
		loss: 0.037800
		loss: 0.037800
		loss: 0.037800
		loss: 0.037800
		loss: 0.037800
		loss: 0.037800
		loss: 0.037800
		loss: 0.037800
		loss: 0.037700
		loss: 0.037700
		loss: 0.037700
		loss: 0.037700
		loss: 0.037700
		loss: 0.037700
		loss: 0.037700
		loss: 0.037600
		loss: 0.037600
		loss: 0.037600
		loss: 0.037600
		loss: 0.037600
		loss: 0.037600
		loss: 0.037600
		loss: 0.037500
		loss: 0.037500
		loss: 0.037500
		loss: 0.037500
		loss: 0.037500
		loss: 0.037500
		loss: 0.037500
		loss: 0.037500
		loss: 0.037400
		loss: 0.037400
		loss: 0.037400
		loss: 0.037400
		loss: 0.037400
		loss: 0.037400
		loss: 0.037400
		loss: 0.037400
		loss: 0.037300
		loss: 0.037300
		loss: 0.037300
		loss: 0.037300
		loss: 0.037300
		loss: 0.037300
		loss: 0.037300
		loss: 0.037200
		loss: 0.037200
		loss: 0.037200
		loss: 0.037200
		loss: 0.037200
		loss: 0.037200
		loss: 0.037200
		loss: 0.037200
		loss: 0.037100
		loss: 0.037100
		loss: 0.037100
		loss: 0.037100
		loss: 0.037100
		loss: 0.037100
		loss: 0.037100
		loss: 0.037100
		loss: 0.037000
		loss: 0.037000
		loss: 0.037000
		loss: 0.037000
		loss: 0.037000
	Overall the loss development was 0.383500 -> 0.037000

Training data for problem d-5-2.pddl in epoch 3:
model creation time: 15.057137727737427s
problem epoch data for epoch 3, problem epoch 1
	sampling search time: 4.8663530349731445s
	during this search the following actions were chosen:
	training time: 73.83082056045532s
	during the training the following losses were computed:
		loss: 2.609700
		loss: 2.442200
		loss: 2.288600
		loss: 2.145400
		loss: 2.011000
		loss: 1.885500
		loss: 1.769200
		loss: 1.662200
		loss: 1.564500
		loss: 1.476900
		loss: 1.397900
		loss: 1.327600
		loss: 1.265400
		loss: 1.210800
		loss: 1.163500
		loss: 1.123800
		loss: 1.090700
		loss: 1.063600
		loss: 1.041300
		loss: 1.023900
		loss: 1.010400
		loss: 1.000100
		loss: 0.992900
		loss: 0.988400
		loss: 0.986100
		loss: 0.985100
		loss: 0.984600
		loss: 0.984200
		loss: 0.983500
		loss: 0.982300
		loss: 0.980500
		loss: 0.978200
		loss: 0.975300
		loss: 0.972000
		loss: 0.968200
		loss: 0.964200
		loss: 0.960000
		loss: 0.955600
		loss: 0.951300
		loss: 0.947000
		loss: 0.942700
		loss: 0.938700
		loss: 0.934800
		loss: 0.931000
		loss: 0.927400
		loss: 0.923800
		loss: 0.920400
		loss: 0.917200
		loss: 0.914100
		loss: 0.911100
		loss: 0.908100
		loss: 0.905100
		loss: 0.902100
		loss: 0.899000
		loss: 0.895800
		loss: 0.892500
		loss: 0.889200
		loss: 0.886100
		loss: 0.882900
		loss: 0.879800
		loss: 0.876600
		loss: 0.873500
		loss: 0.870400
		loss: 0.867300
		loss: 0.864100
		loss: 0.861000
		loss: 0.857800
		loss: 0.854600
		loss: 0.851400
		loss: 0.848200
		loss: 0.845000
		loss: 0.841700
		loss: 0.838500
		loss: 0.835200
		loss: 0.831900
		loss: 0.828700
		loss: 0.825400
		loss: 0.822100
		loss: 0.818800
		loss: 0.815400
		loss: 0.812000
		loss: 0.808400
		loss: 0.804800
		loss: 0.801300
		loss: 0.797800
		loss: 0.794400
		loss: 0.791000
		loss: 0.787600
		loss: 0.784000
		loss: 0.780400
		loss: 0.776700
		loss: 0.773100
		loss: 0.769400
		loss: 0.765800
		loss: 0.762100
		loss: 0.758500
		loss: 0.754900
		loss: 0.751200
		loss: 0.747500
		loss: 0.743800
		loss: 0.740000
		loss: 0.736200
		loss: 0.732400
		loss: 0.728600
		loss: 0.724800
		loss: 0.721000
		loss: 0.717200
		loss: 0.713500
		loss: 0.709700
		loss: 0.706000
		loss: 0.702200
		loss: 0.698400
		loss: 0.694700
		loss: 0.691000
		loss: 0.687300
		loss: 0.683600
		loss: 0.679900
		loss: 0.676300
		loss: 0.672600
		loss: 0.668900
		loss: 0.665200
		loss: 0.661600
		loss: 0.657900
		loss: 0.654300
		loss: 0.650600
		loss: 0.646900
		loss: 0.643200
		loss: 0.639600
		loss: 0.635800
		loss: 0.632100
		loss: 0.628400
		loss: 0.624800
		loss: 0.621100
		loss: 0.617400
		loss: 0.613700
		loss: 0.610100
		loss: 0.606500
		loss: 0.603100
		loss: 0.600100
		loss: 0.597600
		loss: 0.594700
		loss: 0.590300
		loss: 0.586400
		loss: 0.584900
		loss: 0.582600
		loss: 0.578300
		loss: 0.575800
		loss: 0.574100
		loss: 0.571100
		loss: 0.568000
		loss: 0.566100
		loss: 0.564300
		loss: 0.561800
		loss: 0.558400
		loss: 0.555900
		loss: 0.553900
		loss: 0.552000
		loss: 0.549900
		loss: 0.547300
		loss: 0.544800
		loss: 0.542000
		loss: 0.539500
		loss: 0.537400
		loss: 0.535200
		loss: 0.532800
		loss: 0.530300
		loss: 0.528300
		loss: 0.527000
		loss: 0.527500
		loss: 0.531900
		loss: 0.538200
		loss: 0.520400
		loss: 0.521000
		loss: 0.528100
		loss: 0.513700
		loss: 0.521800
		loss: 0.518000
		loss: 0.511600
		loss: 0.517700
		loss: 0.506400
		loss: 0.512100
		loss: 0.504200
		loss: 0.506500
		loss: 0.504300
		loss: 0.501300
		loss: 0.502600
		loss: 0.496700
		loss: 0.499000
		loss: 0.494300
		loss: 0.495400
		loss: 0.493000
		loss: 0.491100
		loss: 0.490800
		loss: 0.487700
		loss: 0.488100
		loss: 0.485800
		loss: 0.484200
		loss: 0.483700
		loss: 0.481400
		loss: 0.480800
		loss: 0.479700
		loss: 0.477700
		loss: 0.476800
		loss: 0.475900
		loss: 0.474200
		loss: 0.473300
		loss: 0.472300
		loss: 0.470800
		loss: 0.469600
		loss: 0.468800
		loss: 0.467500
		loss: 0.466100
		loss: 0.465100
		loss: 0.464200
		loss: 0.462900
		loss: 0.461700
		loss: 0.460800
		loss: 0.460000
		loss: 0.458900
		loss: 0.457700
		loss: 0.456600
		loss: 0.455600
		loss: 0.454700
		loss: 0.453600
		loss: 0.452600
		loss: 0.451500
		loss: 0.450300
		loss: 0.449300
		loss: 0.448500
		loss: 0.447600
		loss: 0.446600
		loss: 0.445600
		loss: 0.444700
		loss: 0.444000
		loss: 0.443400
		loss: 0.443100
		loss: 0.443800
		loss: 0.444900
		loss: 0.447400
		loss: 0.445200
		loss: 0.441900
		loss: 0.437300
		loss: 0.437200
		loss: 0.439900
		loss: 0.439300
		loss: 0.436400
		loss: 0.433100
		loss: 0.433100
		loss: 0.434600
		loss: 0.433500
		loss: 0.431000
		loss: 0.429100
		loss: 0.429100
		loss: 0.429700
		loss: 0.429000
		loss: 0.427600
		loss: 0.425900
		loss: 0.425000
		loss: 0.425000
		loss: 0.425000
		loss: 0.424600
		loss: 0.423500
		loss: 0.422100
		loss: 0.420900
		loss: 0.420200
		loss: 0.419900
		loss: 0.419700
		loss: 0.419600
		loss: 0.419100
		loss: 0.418600
		loss: 0.417800
		loss: 0.416900
		loss: 0.415800
		loss: 0.414800
		loss: 0.414000
		loss: 0.413400
		loss: 0.412700
		loss: 0.412100
		loss: 0.411500
		loss: 0.411100
		loss: 0.410700
		loss: 0.410700
		loss: 0.411800
		loss: 0.414800
		loss: 0.421200
		loss: 0.420600
		loss: 0.416100
		loss: 0.407100
		loss: 0.410500
		loss: 0.417500
		loss: 0.409600
		loss: 0.404500
		loss: 0.408700
		loss: 0.410400
		loss: 0.405700
		loss: 0.402800
		loss: 0.406300
		loss: 0.406300
		loss: 0.401500
		loss: 0.402500
	Overall the loss development was 2.609700 -> 0.402500

Training data for problem d-5-0.pddl in epoch 3:
model creation time: 15.49332880973816s
problem epoch data for epoch 3, problem epoch 1
	sampling search time: 4.0024683475494385s
	during this search the following actions were chosen:
		unstack c e was chosen with probability 0.998882
		put-down c was chosen with probability 0.999720
		unstack e b was chosen with probability 0.999169
		put-down e was chosen with probability 0.965399
		pick-up d was chosen with probability 0.659274
		stack d c was chosen with probability 0.999946
		unstack b a was chosen with probability 0.825147
		stack b d was chosen with probability 0.944348
		pick-up e was chosen with probability 0.856843
		stack e b was chosen with probability 0.837500
		pick-up a was chosen with probability 0.956426
		stack a e was chosen with probability 0.900900
	training time: 74.77235746383667s
	during the training the following losses were computed:
		loss: 0.591700
		loss: 0.614300
		loss: 0.469800
		loss: 0.418300
		loss: 0.442200
		loss: 0.430900
		loss: 0.377300
		loss: 0.336500
		loss: 0.342100
		loss: 0.346100
		loss: 0.306300
		loss: 0.275600
		loss: 0.277900
		loss: 0.278200
		loss: 0.256100
		loss: 0.229700
		loss: 0.227500
		loss: 0.231700
		loss: 0.212600
		loss: 0.197700
		loss: 0.201100
		loss: 0.199500
		loss: 0.187200
		loss: 0.182100
		loss: 0.187600
		loss: 0.184400
		loss: 0.176400
		loss: 0.177300
		loss: 0.180600
		loss: 0.176700
		loss: 0.173100
		loss: 0.175500
		loss: 0.176400
		loss: 0.172900
		loss: 0.171700
		loss: 0.173700
		loss: 0.172600
		loss: 0.170200
		loss: 0.170800
		loss: 0.171400
		loss: 0.169400
		loss: 0.168800
		loss: 0.169700
		loss: 0.168500
		loss: 0.167500
		loss: 0.168100
		loss: 0.167500
		loss: 0.166500
		loss: 0.166800
		loss: 0.166500
		loss: 0.165600
		loss: 0.165800
		loss: 0.165600
		loss: 0.164900
		loss: 0.165000
		loss: 0.164800
		loss: 0.164300
		loss: 0.164300
		loss: 0.164200
		loss: 0.163800
		loss: 0.163800
		loss: 0.163700
		loss: 0.163400
		loss: 0.163400
		loss: 0.163200
		loss: 0.163000
		loss: 0.163000
		loss: 0.162900
		loss: 0.162700
		loss: 0.162700
		loss: 0.162500
		loss: 0.162400
		loss: 0.162400
		loss: 0.162300
		loss: 0.162200
		loss: 0.162100
		loss: 0.162000
		loss: 0.162000
		loss: 0.161900
		loss: 0.161800
		loss: 0.161800
		loss: 0.161700
		loss: 0.161600
		loss: 0.161600
		loss: 0.161500
		loss: 0.161400
		loss: 0.161400
		loss: 0.161300
		loss: 0.161300
		loss: 0.161200
		loss: 0.161100
		loss: 0.161100
		loss: 0.161000
		loss: 0.161000
		loss: 0.160900
		loss: 0.160800
		loss: 0.160800
		loss: 0.160700
		loss: 0.160700
		loss: 0.160600
		loss: 0.160600
		loss: 0.160500
		loss: 0.160500
		loss: 0.160400
		loss: 0.160300
		loss: 0.160300
		loss: 0.160200
		loss: 0.160200
		loss: 0.160100
		loss: 0.160100
		loss: 0.160000
		loss: 0.160000
		loss: 0.159900
		loss: 0.159900
		loss: 0.159800
		loss: 0.159800
		loss: 0.159700
		loss: 0.159700
		loss: 0.159600
		loss: 0.159600
		loss: 0.159500
		loss: 0.159400
		loss: 0.159400
		loss: 0.159300
		loss: 0.159300
		loss: 0.159200
		loss: 0.159200
		loss: 0.159100
		loss: 0.159100
		loss: 0.159000
		loss: 0.159000
		loss: 0.158900
		loss: 0.158900
		loss: 0.158800
		loss: 0.158800
		loss: 0.158700
		loss: 0.158700
		loss: 0.158600
		loss: 0.158600
		loss: 0.158500
		loss: 0.158500
		loss: 0.158400
		loss: 0.158400
		loss: 0.158300
		loss: 0.158300
		loss: 0.158200
		loss: 0.158200
		loss: 0.158100
		loss: 0.158100
		loss: 0.158000
		loss: 0.158000
		loss: 0.157900
		loss: 0.157900
		loss: 0.157800
		loss: 0.157800
		loss: 0.157700
		loss: 0.157700
		loss: 0.157600
		loss: 0.157600
		loss: 0.157500
		loss: 0.157500
		loss: 0.157400
		loss: 0.157400
		loss: 0.157300
		loss: 0.157300
		loss: 0.157200
		loss: 0.157200
		loss: 0.157100
		loss: 0.157100
		loss: 0.157000
		loss: 0.157000
		loss: 0.156900
		loss: 0.156900
		loss: 0.156800
		loss: 0.156800
		loss: 0.156700
		loss: 0.156700
		loss: 0.156600
		loss: 0.156600
		loss: 0.156600
		loss: 0.156500
		loss: 0.156500
		loss: 0.156400
		loss: 0.156400
		loss: 0.156300
		loss: 0.156300
		loss: 0.156200
		loss: 0.156200
		loss: 0.156100
		loss: 0.156100
		loss: 0.156000
		loss: 0.156000
		loss: 0.155900
		loss: 0.155900
		loss: 0.155800
		loss: 0.155800
		loss: 0.155700
		loss: 0.155700
		loss: 0.155600
		loss: 0.155600
		loss: 0.155500
		loss: 0.155500
		loss: 0.155400
		loss: 0.155400
		loss: 0.155300
		loss: 0.155300
		loss: 0.155200
		loss: 0.155200
		loss: 0.155200
		loss: 0.155100
		loss: 0.155100
		loss: 0.155000
		loss: 0.155000
		loss: 0.154900
		loss: 0.154900
		loss: 0.154800
		loss: 0.154800
		loss: 0.154700
		loss: 0.154700
		loss: 0.154600
		loss: 0.154600
		loss: 0.154500
		loss: 0.154500
		loss: 0.154400
		loss: 0.154400
		loss: 0.154300
		loss: 0.154300
		loss: 0.154300
		loss: 0.154200
		loss: 0.154200
		loss: 0.154100
		loss: 0.154100
		loss: 0.154000
		loss: 0.154000
		loss: 0.153900
		loss: 0.153900
		loss: 0.153800
		loss: 0.153800
		loss: 0.153700
		loss: 0.153700
		loss: 0.153600
		loss: 0.153600
		loss: 0.153600
		loss: 0.153500
		loss: 0.153500
		loss: 0.153400
		loss: 0.153400
		loss: 0.153300
		loss: 0.153300
		loss: 0.153200
		loss: 0.153200
		loss: 0.153100
		loss: 0.153100
		loss: 0.153000
		loss: 0.153000
		loss: 0.152900
		loss: 0.152900
		loss: 0.152900
		loss: 0.152800
		loss: 0.152800
		loss: 0.152700
		loss: 0.152700
		loss: 0.152600
		loss: 0.152600
		loss: 0.152500
		loss: 0.152500
		loss: 0.152400
		loss: 0.152400
		loss: 0.152400
		loss: 0.152300
		loss: 0.152300
		loss: 0.152200
		loss: 0.152200
		loss: 0.152100
		loss: 0.152100
		loss: 0.152000
		loss: 0.152000
		loss: 0.151900
		loss: 0.151900
		loss: 0.151900
		loss: 0.151800
		loss: 0.151800
		loss: 0.151700
		loss: 0.151700
		loss: 0.151600
		loss: 0.151600
		loss: 0.151500
		loss: 0.151500
		loss: 0.151500
		loss: 0.151400
		loss: 0.151400
		loss: 0.151300
		loss: 0.151300
		loss: 0.151200
		loss: 0.151200
		loss: 0.151100
		loss: 0.151100
		loss: 0.151100
		loss: 0.151000
		loss: 0.151000
	Overall the loss development was 0.591700 -> 0.151000

Training data for problem d-5-1.pddl in epoch 3:
model creation time: 15.171477556228638s
problem epoch data for epoch 3, problem epoch 1
	sampling search time: 3.993574619293213s
	during this search the following actions were chosen:
		pick-up c was chosen with probability 0.996136
		stack c b was chosen with probability 0.987178
		unstack c b was chosen with probability 0.945235
	training time: 75.12412929534912s
	during the training the following losses were computed:
		loss: 1.529800
		loss: 1.121000
		loss: 1.194300
		loss: 1.146700
		loss: 1.007100
		loss: 0.896200
		loss: 0.844700
		loss: 0.819600
		loss: 0.766900
		loss: 0.680700
		loss: 0.606800
		loss: 0.558300
		loss: 0.512800
		loss: 0.469000
		loss: 0.432000
		loss: 0.406200
		loss: 0.396200
		loss: 0.395400
		loss: 0.389800
		loss: 0.376900
		loss: 0.365100
		loss: 0.359400
		loss: 0.353000
		loss: 0.344600
		loss: 0.338900
		loss: 0.336200
		loss: 0.331900
		loss: 0.324700
		loss: 0.317800
		loss: 0.312300
		loss: 0.305900
		loss: 0.297700
		loss: 0.289500
		loss: 0.282900
		loss: 0.277300
		loss: 0.271400
		loss: 0.265900
		loss: 0.262200
		loss: 0.259600
		loss: 0.257400
		loss: 0.255600
		loss: 0.254000
		loss: 0.251800
		loss: 0.248900
		loss: 0.245800
		loss: 0.244200
		loss: 0.242900
		loss: 0.241400
		loss: 0.239800
		loss: 0.237900
		loss: 0.236000
		loss: 0.234000
		loss: 0.232300
		loss: 0.231000
		loss: 0.229700
		loss: 0.228300
		loss: 0.226900
		loss: 0.225700
		loss: 0.224800
		loss: 0.223900
		loss: 0.222800
		loss: 0.221900
		loss: 0.221000
		loss: 0.219900
		loss: 0.218900
		loss: 0.218000
		loss: 0.217100
		loss: 0.216200
		loss: 0.215200
		loss: 0.214400
		loss: 0.213600
		loss: 0.212800
		loss: 0.212000
		loss: 0.211200
		loss: 0.210500
		loss: 0.209800
		loss: 0.209200
		loss: 0.208600
		loss: 0.207900
		loss: 0.207300
		loss: 0.206700
		loss: 0.206100
		loss: 0.205500
		loss: 0.204900
		loss: 0.204400
		loss: 0.203800
		loss: 0.203300
		loss: 0.202700
		loss: 0.202200
		loss: 0.201800
		loss: 0.201300
		loss: 0.200800
		loss: 0.200400
		loss: 0.199900
		loss: 0.199500
		loss: 0.199100
		loss: 0.198600
		loss: 0.198300
		loss: 0.197900
		loss: 0.197500
		loss: 0.197100
		loss: 0.196700
		loss: 0.196400
		loss: 0.196000
		loss: 0.195700
		loss: 0.195300
		loss: 0.195000
		loss: 0.194700
		loss: 0.194400
		loss: 0.194100
		loss: 0.193800
		loss: 0.193500
		loss: 0.193200
		loss: 0.192900
		loss: 0.192700
		loss: 0.192400
		loss: 0.192100
		loss: 0.191900
		loss: 0.191600
		loss: 0.191400
		loss: 0.191200
		loss: 0.190900
		loss: 0.190700
		loss: 0.190400
		loss: 0.190200
		loss: 0.190000
		loss: 0.189800
		loss: 0.189500
		loss: 0.189300
		loss: 0.189100
		loss: 0.188900
		loss: 0.188700
		loss: 0.188500
		loss: 0.188300
		loss: 0.188100
		loss: 0.187900
		loss: 0.187800
		loss: 0.187600
		loss: 0.187400
		loss: 0.187200
		loss: 0.187000
		loss: 0.186900
		loss: 0.186700
		loss: 0.186500
		loss: 0.186400
		loss: 0.186200
		loss: 0.186000
		loss: 0.185900
		loss: 0.185700
		loss: 0.185600
		loss: 0.185400
		loss: 0.185300
		loss: 0.185100
		loss: 0.185000
		loss: 0.184800
		loss: 0.184700
		loss: 0.184600
		loss: 0.184400
		loss: 0.184300
		loss: 0.184200
		loss: 0.184000
		loss: 0.183900
		loss: 0.183800
		loss: 0.183600
		loss: 0.183500
		loss: 0.183400
		loss: 0.183300
		loss: 0.183200
		loss: 0.183000
		loss: 0.182900
		loss: 0.182800
		loss: 0.182700
		loss: 0.182600
		loss: 0.182500
		loss: 0.182400
		loss: 0.182300
		loss: 0.182200
		loss: 0.182100
		loss: 0.182000
		loss: 0.181900
		loss: 0.181800
		loss: 0.181700
		loss: 0.181600
		loss: 0.181500
		loss: 0.181400
		loss: 0.181300
		loss: 0.181200
		loss: 0.181100
		loss: 0.181000
		loss: 0.180900
		loss: 0.180900
		loss: 0.180800
		loss: 0.180700
		loss: 0.180600
		loss: 0.180500
		loss: 0.180400
		loss: 0.180400
		loss: 0.180300
		loss: 0.180200
		loss: 0.180100
		loss: 0.180000
		loss: 0.180000
		loss: 0.179900
		loss: 0.179800
		loss: 0.179700
		loss: 0.179700
		loss: 0.179600
		loss: 0.179500
		loss: 0.179500
		loss: 0.179400
		loss: 0.179300
		loss: 0.179200
		loss: 0.179200
		loss: 0.179100
		loss: 0.179000
		loss: 0.179000
		loss: 0.178900
		loss: 0.178800
		loss: 0.178800
		loss: 0.178700
		loss: 0.178600
		loss: 0.178600
		loss: 0.178500
		loss: 0.178400
		loss: 0.178400
		loss: 0.178300
		loss: 0.178200
		loss: 0.178200
		loss: 0.178100
		loss: 0.178000
		loss: 0.178000
		loss: 0.177900
		loss: 0.177900
		loss: 0.177800
		loss: 0.177700
		loss: 0.177700
		loss: 0.177600
		loss: 0.177600
		loss: 0.177500
		loss: 0.177500
		loss: 0.177400
		loss: 0.177300
		loss: 0.177300
		loss: 0.177200
		loss: 0.177200
		loss: 0.177100
		loss: 0.177100
		loss: 0.177000
		loss: 0.176900
		loss: 0.176900
		loss: 0.176800
		loss: 0.176800
		loss: 0.176700
		loss: 0.176700
		loss: 0.176600
		loss: 0.176600
		loss: 0.176500
		loss: 0.176500
		loss: 0.176400
		loss: 0.176300
		loss: 0.176300
		loss: 0.176200
		loss: 0.176200
		loss: 0.176100
		loss: 0.176100
		loss: 0.176000
		loss: 0.176000
		loss: 0.175900
		loss: 0.175900
		loss: 0.175800
		loss: 0.175800
		loss: 0.175700
		loss: 0.175700
		loss: 0.175600
		loss: 0.175600
		loss: 0.175500
		loss: 0.175500
		loss: 0.175400
		loss: 0.175400
		loss: 0.175300
		loss: 0.175300
		loss: 0.175300
		loss: 0.175200
		loss: 0.175200
		loss: 0.175100
		loss: 0.175100
		loss: 0.175000
		loss: 0.175000
		loss: 0.174900
		loss: 0.174900
		loss: 0.174800
		loss: 0.174800
		loss: 0.174700
		loss: 0.174700
		loss: 0.174700
		loss: 0.174600
		loss: 0.174600
		loss: 0.174500
		loss: 0.174500
		loss: 0.174400
	Overall the loss development was 1.529800 -> 0.174400

Epoch 4:
Training data for problem d-4-0.pddl in epoch 4:
model creation time: 10.392372846603394s
problem epoch data for epoch 4, problem epoch 1
	sampling search time: 2.520367383956909s
	during this search the following actions were chosen:
		pick-up b was chosen with probability 0.333327
		stack b a was chosen with probability 0.998600
		pick-up c was chosen with probability 0.997965
		stack c b was chosen with probability 0.974756
		pick-up d was chosen with probability 0.999773
		stack d c was chosen with probability 0.998980
	training time: 61.31767797470093s
	during the training the following losses were computed:
		loss: 0.224800
		loss: 0.221400
		loss: 0.220300
		loss: 0.219700
		loss: 0.219000
		loss: 0.218400
		loss: 0.217800
		loss: 0.217200
		loss: 0.216500
		loss: 0.215900
		loss: 0.215300
		loss: 0.214600
		loss: 0.214000
		loss: 0.213300
		loss: 0.212700
		loss: 0.212100
		loss: 0.211500
		loss: 0.210800
		loss: 0.210200
		loss: 0.209600
		loss: 0.209000
		loss: 0.208400
		loss: 0.207800
		loss: 0.207200
		loss: 0.206600
		loss: 0.206000
		loss: 0.205400
		loss: 0.204900
		loss: 0.204300
		loss: 0.203800
		loss: 0.203200
		loss: 0.202700
		loss: 0.202200
		loss: 0.201700
		loss: 0.201200
		loss: 0.200700
		loss: 0.200300
		loss: 0.199800
		loss: 0.199300
		loss: 0.198900
		loss: 0.198500
		loss: 0.198100
		loss: 0.197700
		loss: 0.197300
		loss: 0.196900
		loss: 0.196600
		loss: 0.196200
		loss: 0.195900
		loss: 0.195500
		loss: 0.195200
		loss: 0.194900
		loss: 0.194600
		loss: 0.194300
		loss: 0.194000
		loss: 0.193700
		loss: 0.193400
		loss: 0.193100
		loss: 0.192800
		loss: 0.192500
		loss: 0.192300
		loss: 0.192000
		loss: 0.191800
		loss: 0.191500
		loss: 0.191300
		loss: 0.191100
		loss: 0.190800
		loss: 0.190600
		loss: 0.190400
		loss: 0.190200
		loss: 0.189900
		loss: 0.189700
		loss: 0.189500
		loss: 0.189300
		loss: 0.189100
		loss: 0.189000
		loss: 0.188800
		loss: 0.188600
		loss: 0.188400
		loss: 0.188200
		loss: 0.188100
		loss: 0.187900
		loss: 0.187700
		loss: 0.187600
		loss: 0.187400
		loss: 0.187300
		loss: 0.187100
		loss: 0.187000
		loss: 0.186800
		loss: 0.186700
		loss: 0.186500
		loss: 0.186400
		loss: 0.186300
		loss: 0.186100
		loss: 0.186000
		loss: 0.185900
		loss: 0.185800
		loss: 0.185600
		loss: 0.185500
		loss: 0.185400
		loss: 0.185300
		loss: 0.185200
		loss: 0.185000
		loss: 0.184900
		loss: 0.184800
		loss: 0.184700
		loss: 0.184600
		loss: 0.184500
		loss: 0.184400
		loss: 0.184300
		loss: 0.184200
		loss: 0.184100
		loss: 0.184000
		loss: 0.183900
		loss: 0.183800
		loss: 0.183700
		loss: 0.183700
		loss: 0.183600
		loss: 0.183500
		loss: 0.183400
		loss: 0.183300
		loss: 0.183200
		loss: 0.183200
		loss: 0.183100
		loss: 0.183000
		loss: 0.182900
		loss: 0.182800
		loss: 0.182800
		loss: 0.182700
		loss: 0.182600
		loss: 0.182600
		loss: 0.182500
		loss: 0.182400
		loss: 0.182300
		loss: 0.182300
		loss: 0.182200
		loss: 0.182100
		loss: 0.182100
		loss: 0.182000
		loss: 0.182000
		loss: 0.181900
		loss: 0.181800
		loss: 0.181800
		loss: 0.181700
		loss: 0.181700
		loss: 0.181600
		loss: 0.181500
		loss: 0.181500
		loss: 0.181400
		loss: 0.181400
		loss: 0.181300
		loss: 0.181300
		loss: 0.181200
		loss: 0.181200
		loss: 0.181100
		loss: 0.181100
		loss: 0.181000
		loss: 0.181000
		loss: 0.180900
		loss: 0.180900
		loss: 0.180800
		loss: 0.180800
		loss: 0.180700
		loss: 0.180700
		loss: 0.180600
		loss: 0.180600
		loss: 0.180600
		loss: 0.180500
		loss: 0.180500
		loss: 0.180400
		loss: 0.180400
		loss: 0.180300
		loss: 0.180300
		loss: 0.180300
		loss: 0.180200
		loss: 0.180200
		loss: 0.180100
		loss: 0.180100
		loss: 0.180100
		loss: 0.180000
		loss: 0.180000
		loss: 0.180000
		loss: 0.179900
		loss: 0.179900
		loss: 0.179900
		loss: 0.179800
		loss: 0.179800
		loss: 0.179800
		loss: 0.179700
		loss: 0.179700
		loss: 0.179700
		loss: 0.179600
		loss: 0.179600
		loss: 0.179600
		loss: 0.179500
		loss: 0.179500
		loss: 0.179500
		loss: 0.179500
		loss: 0.179400
		loss: 0.179400
		loss: 0.179400
		loss: 0.179300
		loss: 0.179300
		loss: 0.179300
		loss: 0.179300
		loss: 0.179200
		loss: 0.179200
		loss: 0.179200
		loss: 0.179200
		loss: 0.179100
		loss: 0.179100
		loss: 0.179100
		loss: 0.179100
		loss: 0.179000
		loss: 0.179000
		loss: 0.179000
		loss: 0.179000
		loss: 0.179000
		loss: 0.178900
		loss: 0.178900
		loss: 0.178900
		loss: 0.178900
		loss: 0.178900
		loss: 0.178800
		loss: 0.178800
		loss: 0.178800
		loss: 0.178800
		loss: 0.178800
		loss: 0.178700
		loss: 0.178700
		loss: 0.178700
		loss: 0.178700
		loss: 0.178700
		loss: 0.178600
		loss: 0.178600
		loss: 0.178600
		loss: 0.178600
		loss: 0.178600
		loss: 0.178600
		loss: 0.178500
		loss: 0.178500
		loss: 0.178500
		loss: 0.178500
		loss: 0.178500
		loss: 0.178500
		loss: 0.178400
		loss: 0.178400
		loss: 0.178400
		loss: 0.178400
		loss: 0.178400
		loss: 0.178400
		loss: 0.178400
		loss: 0.178300
		loss: 0.178300
		loss: 0.178300
		loss: 0.178300
		loss: 0.178300
		loss: 0.178300
		loss: 0.178300
		loss: 0.178200
		loss: 0.178200
		loss: 0.178200
		loss: 0.178200
		loss: 0.178200
		loss: 0.178200
		loss: 0.178200
		loss: 0.178200
		loss: 0.178100
		loss: 0.178100
		loss: 0.178100
		loss: 0.178100
		loss: 0.178100
		loss: 0.178100
		loss: 0.178100
		loss: 0.178100
		loss: 0.178000
		loss: 0.178000
		loss: 0.178000
		loss: 0.178000
		loss: 0.178000
		loss: 0.178000
		loss: 0.178000
		loss: 0.178000
		loss: 0.178000
		loss: 0.177900
		loss: 0.177900
		loss: 0.177900
		loss: 0.177900
		loss: 0.177900
		loss: 0.177900
		loss: 0.177900
		loss: 0.177900
		loss: 0.177900
		loss: 0.177900
		loss: 0.177800
		loss: 0.177800
		loss: 0.177800
		loss: 0.177800
		loss: 0.177800
		loss: 0.177800
		loss: 0.177800
	Overall the loss development was 0.224800 -> 0.177800

Training data for problem d-4-2.pddl in epoch 4:
model creation time: 9.929033279418945s
problem epoch data for epoch 4, problem epoch 1
	sampling search time: 3.037736177444458s
	during this search the following actions were chosen:
		pick-up a was chosen with probability 0.993517
		stack a c was chosen with probability 0.738081
		pick-up d was chosen with probability 0.996334
		stack d a was chosen with probability 0.982519
	training time: 60.13322424888611s
	during the training the following losses were computed:
		loss: 2.262100
		loss: 2.075900
		loss: 1.896300
		loss: 1.723400
		loss: 1.557500
		loss: 1.398600
		loss: 1.247400
		loss: 1.107300
		loss: 0.979800
		loss: 0.862400
		loss: 0.757300
		loss: 0.671800
		loss: 0.600700
		loss: 0.539500
		loss: 0.489800
		loss: 0.453300
		loss: 0.424200
		loss: 0.402900
		loss: 0.390500
		loss: 0.387300
		loss: 0.393400
		loss: 0.404300
		loss: 0.415600
		loss: 0.423800
		loss: 0.427100
		loss: 0.424300
		loss: 0.415400
		loss: 0.401800
		loss: 0.385200
		loss: 0.367000
		loss: 0.348200
		loss: 0.329900
		loss: 0.313300
		loss: 0.299000
		loss: 0.286600
		loss: 0.275800
		loss: 0.266000
		loss: 0.256800
		loss: 0.247800
		loss: 0.238400
		loss: 0.228600
		loss: 0.218300
		loss: 0.207700
		loss: 0.196900
		loss: 0.186300
		loss: 0.176400
		loss: 0.167300
		loss: 0.159500
		loss: 0.152800
		loss: 0.147000
		loss: 0.141500
		loss: 0.135800
		loss: 0.129700
		loss: 0.123100
		loss: 0.116500
		loss: 0.110500
		loss: 0.105500
		loss: 0.101400
		loss: 0.098200
		loss: 0.095300
		loss: 0.092300
		loss: 0.089200
		loss: 0.086000
		loss: 0.082700
		loss: 0.079700
		loss: 0.077000
		loss: 0.074700
		loss: 0.072700
		loss: 0.070800
		loss: 0.069100
		loss: 0.067300
		loss: 0.065500
		loss: 0.063700
		loss: 0.062000
		loss: 0.060600
		loss: 0.059200
		loss: 0.058100
		loss: 0.057000
		loss: 0.055900
		loss: 0.054900
		loss: 0.054000
		loss: 0.053000
		loss: 0.052100
		loss: 0.051300
		loss: 0.050600
		loss: 0.049900
		loss: 0.049300
		loss: 0.048700
		loss: 0.048200
		loss: 0.047700
		loss: 0.047200
		loss: 0.046700
		loss: 0.046200
		loss: 0.045800
		loss: 0.045400
		loss: 0.045000
		loss: 0.044600
		loss: 0.044300
		loss: 0.044000
		loss: 0.043700
		loss: 0.043400
		loss: 0.043100
		loss: 0.042800
		loss: 0.042600
		loss: 0.042300
		loss: 0.042100
		loss: 0.041900
		loss: 0.041700
		loss: 0.041500
		loss: 0.041300
		loss: 0.041100
		loss: 0.040900
		loss: 0.040800
		loss: 0.040600
		loss: 0.040400
		loss: 0.040300
		loss: 0.040100
		loss: 0.040000
		loss: 0.039900
		loss: 0.039700
		loss: 0.039600
		loss: 0.039500
		loss: 0.039400
		loss: 0.039300
		loss: 0.039200
		loss: 0.039100
		loss: 0.039000
		loss: 0.038900
		loss: 0.038800
		loss: 0.038700
		loss: 0.038600
		loss: 0.038500
		loss: 0.038400
		loss: 0.038300
		loss: 0.038200
		loss: 0.038200
		loss: 0.038100
		loss: 0.038000
		loss: 0.037900
		loss: 0.037900
		loss: 0.037800
		loss: 0.037700
		loss: 0.037700
		loss: 0.037600
		loss: 0.037600
		loss: 0.037500
		loss: 0.037400
		loss: 0.037400
		loss: 0.037300
		loss: 0.037300
		loss: 0.037200
		loss: 0.037200
		loss: 0.037100
		loss: 0.037100
		loss: 0.037000
		loss: 0.037000
		loss: 0.036900
		loss: 0.036900
		loss: 0.036900
		loss: 0.036800
		loss: 0.036800
		loss: 0.036700
		loss: 0.036700
		loss: 0.036600
		loss: 0.036600
		loss: 0.036600
		loss: 0.036500
		loss: 0.036500
		loss: 0.036500
		loss: 0.036400
		loss: 0.036400
		loss: 0.036300
		loss: 0.036300
		loss: 0.036300
		loss: 0.036200
		loss: 0.036200
		loss: 0.036200
		loss: 0.036100
		loss: 0.036100
		loss: 0.036100
		loss: 0.036000
		loss: 0.036000
		loss: 0.036000
		loss: 0.036000
		loss: 0.035900
		loss: 0.035900
		loss: 0.035900
		loss: 0.035800
		loss: 0.035800
		loss: 0.035800
		loss: 0.035800
		loss: 0.035700
		loss: 0.035700
		loss: 0.035700
		loss: 0.035600
		loss: 0.035600
		loss: 0.035600
		loss: 0.035600
		loss: 0.035500
		loss: 0.035500
		loss: 0.035500
		loss: 0.035500
		loss: 0.035400
		loss: 0.035400
		loss: 0.035400
		loss: 0.035400
		loss: 0.035300
		loss: 0.035300
		loss: 0.035300
		loss: 0.035300
		loss: 0.035300
		loss: 0.035200
		loss: 0.035200
		loss: 0.035200
		loss: 0.035200
		loss: 0.035100
		loss: 0.035100
		loss: 0.035100
		loss: 0.035100
		loss: 0.035100
		loss: 0.035000
		loss: 0.035000
		loss: 0.035000
		loss: 0.035000
		loss: 0.035000
		loss: 0.034900
		loss: 0.034900
		loss: 0.034900
		loss: 0.034900
		loss: 0.034900
		loss: 0.034800
		loss: 0.034800
		loss: 0.034800
		loss: 0.034800
		loss: 0.034800
		loss: 0.034700
		loss: 0.034700
		loss: 0.034700
		loss: 0.034700
		loss: 0.034700
		loss: 0.034700
		loss: 0.034600
		loss: 0.034600
		loss: 0.034600
		loss: 0.034600
		loss: 0.034600
		loss: 0.034600
		loss: 0.034500
		loss: 0.034500
		loss: 0.034500
		loss: 0.034500
		loss: 0.034500
		loss: 0.034400
		loss: 0.034400
		loss: 0.034400
		loss: 0.034400
		loss: 0.034400
		loss: 0.034400
		loss: 0.034400
		loss: 0.034300
		loss: 0.034300
		loss: 0.034300
		loss: 0.034300
		loss: 0.034300
		loss: 0.034300
		loss: 0.034200
		loss: 0.034200
		loss: 0.034200
		loss: 0.034200
		loss: 0.034200
		loss: 0.034200
		loss: 0.034100
		loss: 0.034100
		loss: 0.034100
		loss: 0.034100
		loss: 0.034100
		loss: 0.034100
		loss: 0.034100
		loss: 0.034000
		loss: 0.034000
		loss: 0.034000
		loss: 0.034000
		loss: 0.034000
		loss: 0.034000
		loss: 0.034000
		loss: 0.033900
		loss: 0.033900
		loss: 0.033900
		loss: 0.033900
		loss: 0.033900
		loss: 0.033900
		loss: 0.033900
		loss: 0.033800
		loss: 0.033800
		loss: 0.033800
		loss: 0.033800
		loss: 0.033800
		loss: 0.033800
		loss: 0.033800
		loss: 0.033800
	Overall the loss development was 2.262100 -> 0.033800

Training data for problem d-4-1.pddl in epoch 4:
model creation time: 10.344893217086792s
problem epoch data for epoch 4, problem epoch 1
	sampling search time: 3.642488479614258s
	during this search the following actions were chosen:
	training time: 60.49001717567444s
	during the training the following losses were computed:
		loss: 0.437000
		loss: 0.211600
		loss: 0.119500
		loss: 0.150300
		loss: 0.196600
		loss: 0.182400
		loss: 0.138800
		loss: 0.103800
		loss: 0.088800
		loss: 0.089000
		loss: 0.097400
		loss: 0.106200
		loss: 0.109600
		loss: 0.105900
		loss: 0.097300
		loss: 0.087800
		loss: 0.080500
		loss: 0.076900
		loss: 0.076600
		loss: 0.078100
		loss: 0.079500
		loss: 0.079600
		loss: 0.077800
		loss: 0.074400
		loss: 0.070300
		loss: 0.066700
		loss: 0.063900
		loss: 0.062300
		loss: 0.061600
		loss: 0.061400
		loss: 0.061200
		loss: 0.060800
		loss: 0.059900
		loss: 0.058700
		loss: 0.057300
		loss: 0.056000
		loss: 0.054900
		loss: 0.054100
		loss: 0.053600
		loss: 0.053300
		loss: 0.053000
		loss: 0.052800
		loss: 0.052400
		loss: 0.051900
		loss: 0.051400
		loss: 0.050800
		loss: 0.050200
		loss: 0.049700
		loss: 0.049200
		loss: 0.048800
		loss: 0.048500
		loss: 0.048300
		loss: 0.048000
		loss: 0.047700
		loss: 0.047400
		loss: 0.047100
		loss: 0.046800
		loss: 0.046500
		loss: 0.046200
		loss: 0.045900
		loss: 0.045700
		loss: 0.045500
		loss: 0.045300
		loss: 0.045100
		loss: 0.044900
		loss: 0.044700
		loss: 0.044500
		loss: 0.044300
		loss: 0.044100
		loss: 0.044000
		loss: 0.043800
		loss: 0.043600
		loss: 0.043500
		loss: 0.043300
		loss: 0.043200
		loss: 0.043100
		loss: 0.042900
		loss: 0.042800
		loss: 0.042700
		loss: 0.042500
		loss: 0.042400
		loss: 0.042300
		loss: 0.042200
		loss: 0.042100
		loss: 0.042000
		loss: 0.041900
		loss: 0.041800
		loss: 0.041700
		loss: 0.041600
		loss: 0.041500
		loss: 0.041500
		loss: 0.041400
		loss: 0.041300
		loss: 0.041200
		loss: 0.041200
		loss: 0.041100
		loss: 0.041000
		loss: 0.041000
		loss: 0.040900
		loss: 0.040800
		loss: 0.040800
		loss: 0.040700
		loss: 0.040700
		loss: 0.040600
		loss: 0.040600
		loss: 0.040500
		loss: 0.040500
		loss: 0.040500
		loss: 0.040400
		loss: 0.040400
		loss: 0.040300
		loss: 0.040300
		loss: 0.040300
		loss: 0.040200
		loss: 0.040200
		loss: 0.040200
		loss: 0.040100
		loss: 0.040100
		loss: 0.040100
		loss: 0.040100
		loss: 0.040000
		loss: 0.040000
		loss: 0.040000
		loss: 0.039900
		loss: 0.039900
		loss: 0.039900
		loss: 0.039900
		loss: 0.039900
		loss: 0.039800
		loss: 0.039800
		loss: 0.039800
		loss: 0.039800
		loss: 0.039700
		loss: 0.039700
		loss: 0.039700
		loss: 0.039700
		loss: 0.039700
		loss: 0.039600
		loss: 0.039600
		loss: 0.039600
		loss: 0.039600
		loss: 0.039600
		loss: 0.039600
		loss: 0.039500
		loss: 0.039500
		loss: 0.039500
		loss: 0.039500
		loss: 0.039500
		loss: 0.039500
		loss: 0.039400
		loss: 0.039400
		loss: 0.039400
		loss: 0.039400
		loss: 0.039400
		loss: 0.039400
		loss: 0.039400
		loss: 0.039300
		loss: 0.039300
		loss: 0.039300
		loss: 0.039300
		loss: 0.039300
		loss: 0.039300
		loss: 0.039200
		loss: 0.039200
		loss: 0.039200
		loss: 0.039200
		loss: 0.039200
		loss: 0.039200
		loss: 0.039200
		loss: 0.039100
		loss: 0.039100
		loss: 0.039100
		loss: 0.039100
		loss: 0.039100
		loss: 0.039100
		loss: 0.039100
		loss: 0.039000
		loss: 0.039000
		loss: 0.039000
		loss: 0.039000
		loss: 0.039000
		loss: 0.039000
		loss: 0.039000
		loss: 0.038900
		loss: 0.038900
		loss: 0.038900
		loss: 0.038900
		loss: 0.038900
		loss: 0.038900
		loss: 0.038900
		loss: 0.038900
		loss: 0.038800
		loss: 0.038800
		loss: 0.038800
		loss: 0.038800
		loss: 0.038800
		loss: 0.038800
		loss: 0.038800
		loss: 0.038700
		loss: 0.038700
		loss: 0.038700
		loss: 0.038700
		loss: 0.038700
		loss: 0.038700
		loss: 0.038700
		loss: 0.038700
		loss: 0.038600
		loss: 0.038600
		loss: 0.038600
		loss: 0.038600
		loss: 0.038600
		loss: 0.038600
		loss: 0.038600
		loss: 0.038600
		loss: 0.038500
		loss: 0.038500
		loss: 0.038500
		loss: 0.038500
		loss: 0.038500
		loss: 0.038500
		loss: 0.038500
		loss: 0.038500
		loss: 0.038400
		loss: 0.038400
		loss: 0.038400
		loss: 0.038400
		loss: 0.038400
		loss: 0.038400
		loss: 0.038400
		loss: 0.038300
		loss: 0.038300
		loss: 0.038300
		loss: 0.038300
		loss: 0.038300
		loss: 0.038300
		loss: 0.038300
		loss: 0.038300
		loss: 0.038200
		loss: 0.038200
		loss: 0.038200
		loss: 0.038200
		loss: 0.038200
		loss: 0.038200
		loss: 0.038200
		loss: 0.038200
		loss: 0.038100
		loss: 0.038100
		loss: 0.038100
		loss: 0.038100
		loss: 0.038100
		loss: 0.038100
		loss: 0.038100
		loss: 0.038100
		loss: 0.038000
		loss: 0.038000
		loss: 0.038000
		loss: 0.038000
		loss: 0.038000
		loss: 0.038000
		loss: 0.038000
		loss: 0.038000
		loss: 0.037900
		loss: 0.037900
		loss: 0.037900
		loss: 0.037900
		loss: 0.037900
		loss: 0.037900
		loss: 0.037900
		loss: 0.037900
		loss: 0.037900
		loss: 0.037800
		loss: 0.037800
		loss: 0.037800
		loss: 0.037800
		loss: 0.037800
		loss: 0.037800
		loss: 0.037800
		loss: 0.037800
		loss: 0.037700
		loss: 0.037700
		loss: 0.037700
		loss: 0.037700
		loss: 0.037700
		loss: 0.037700
		loss: 0.037700
		loss: 0.037700
		loss: 0.037600
		loss: 0.037600
		loss: 0.037600
		loss: 0.037600
		loss: 0.037600
		loss: 0.037600
		loss: 0.037600
		loss: 0.037600
		loss: 0.037600
		loss: 0.037500
		loss: 0.037500
		loss: 0.037500
		loss: 0.037500
		loss: 0.037500
	Overall the loss development was 0.437000 -> 0.037500

Training data for problem d-5-2.pddl in epoch 4:
model creation time: 14.869159460067749s
problem epoch data for epoch 4, problem epoch 1
	sampling search time: 5.5975470542907715s
	during this search the following actions were chosen:
	training time: 73.7006459236145s
	during the training the following losses were computed:
		loss: 2.585900
		loss: 2.407000
		loss: 2.240300
		loss: 2.085800
		loss: 1.942500
		loss: 1.809000
		loss: 1.684500
		loss: 1.573100
		loss: 1.469900
		loss: 1.377600
		loss: 1.297900
		loss: 1.229900
		loss: 1.171700
		loss: 1.122600
		loss: 1.080700
		loss: 1.045100
		loss: 1.016400
		loss: 0.994100
		loss: 0.977700
		loss: 0.965500
		loss: 0.957200
		loss: 0.952000
		loss: 0.949500
		loss: 0.949000
		loss: 0.949500
		loss: 0.950500
		loss: 0.951600
		loss: 0.952300
		loss: 0.952300
		loss: 0.951400
		loss: 0.949500
		loss: 0.946700
		loss: 0.943400
		loss: 0.939600
		loss: 0.935500
		loss: 0.931000
		loss: 0.926300
		loss: 0.921600
		loss: 0.916800
		loss: 0.912200
		loss: 0.907700
		loss: 0.903500
		loss: 0.899500
		loss: 0.895700
		loss: 0.892100
		loss: 0.888800
		loss: 0.885500
		loss: 0.882500
		loss: 0.879600
		loss: 0.876900
		loss: 0.874200
		loss: 0.871700
		loss: 0.869100
		loss: 0.866600
		loss: 0.864000
		loss: 0.861500
		loss: 0.858800
		loss: 0.856000
		loss: 0.853200
		loss: 0.850400
		loss: 0.847500
		loss: 0.844500
		loss: 0.841600
		loss: 0.838600
		loss: 0.835600
		loss: 0.832600
		loss: 0.829500
		loss: 0.826500
		loss: 0.823400
		loss: 0.820300
		loss: 0.817200
		loss: 0.814100
		loss: 0.811000
		loss: 0.807900
		loss: 0.804800
		loss: 0.801700
		loss: 0.798500
		loss: 0.795400
		loss: 0.792200
		loss: 0.789000
		loss: 0.785700
		loss: 0.782500
		loss: 0.779100
		loss: 0.775700
		loss: 0.772300
		loss: 0.768900
		loss: 0.765400
		loss: 0.761800
		loss: 0.758200
		loss: 0.754600
		loss: 0.751100
		loss: 0.747400
		loss: 0.743800
		loss: 0.740200
		loss: 0.736600
		loss: 0.733000
		loss: 0.729300
		loss: 0.725900
		loss: 0.722500
		loss: 0.719100
		loss: 0.715700
		loss: 0.712300
		loss: 0.709000
		loss: 0.705600
		loss: 0.702200
		loss: 0.698900
		loss: 0.695500
		loss: 0.692200
		loss: 0.688800
		loss: 0.685500
		loss: 0.682100
		loss: 0.678800
		loss: 0.675400
		loss: 0.671900
		loss: 0.668400
		loss: 0.665000
		loss: 0.661600
		loss: 0.658400
		loss: 0.655100
		loss: 0.651800
		loss: 0.648600
		loss: 0.645500
		loss: 0.642300
		loss: 0.639100
		loss: 0.635800
		loss: 0.632700
		loss: 0.629700
		loss: 0.626500
		loss: 0.623400
		loss: 0.620300
		loss: 0.617200
		loss: 0.614300
		loss: 0.611200
		loss: 0.608300
		loss: 0.605300
		loss: 0.602500
		loss: 0.599700
		loss: 0.597000
		loss: 0.594700
		loss: 0.593400
		loss: 0.592400
		loss: 0.589900
		loss: 0.584400
		loss: 0.583100
		loss: 0.583000
		loss: 0.578100
		loss: 0.576000
		loss: 0.575500
		loss: 0.571500
		loss: 0.569600
		loss: 0.569100
		loss: 0.565600
		loss: 0.563300
		loss: 0.562400
		loss: 0.559700
		loss: 0.557300
		loss: 0.555900
		loss: 0.554000
		loss: 0.551700
		loss: 0.549900
		loss: 0.548400
		loss: 0.546300
		loss: 0.544200
		loss: 0.542600
		loss: 0.541100
		loss: 0.539200
		loss: 0.537400
		loss: 0.535700
		loss: 0.534100
		loss: 0.532400
		loss: 0.530400
		loss: 0.528300
		loss: 0.526300
		loss: 0.524400
		loss: 0.522600
		loss: 0.520900
		loss: 0.519400
		loss: 0.517600
		loss: 0.515600
		loss: 0.513100
		loss: 0.510800
		loss: 0.508700
		loss: 0.506700
		loss: 0.505000
		loss: 0.503400
		loss: 0.502100
		loss: 0.500700
		loss: 0.499100
		loss: 0.496500
		loss: 0.493900
		loss: 0.491700
		loss: 0.490100
		loss: 0.489000
		loss: 0.487700
		loss: 0.486500
		loss: 0.484100
		loss: 0.481500
		loss: 0.479300
		loss: 0.478000
		loss: 0.477400
		loss: 0.476600
		loss: 0.475800
		loss: 0.472800
		loss: 0.469800
		loss: 0.467700
		loss: 0.466700
		loss: 0.466100
		loss: 0.464300
		loss: 0.462300
		loss: 0.460100
		loss: 0.458600
		loss: 0.457600
		loss: 0.456700
		loss: 0.455700
		loss: 0.454100
		loss: 0.452200
		loss: 0.450400
		loss: 0.449000
		loss: 0.447800
		loss: 0.446800
		loss: 0.445900
		loss: 0.444800
		loss: 0.443800
		loss: 0.442400
		loss: 0.441100
		loss: 0.439500
		loss: 0.438100
		loss: 0.436700
		loss: 0.435400
		loss: 0.434200
		loss: 0.433100
		loss: 0.432000
		loss: 0.431000
		loss: 0.430100
		loss: 0.429600
		loss: 0.430300
		loss: 0.431900
		loss: 0.437500
		loss: 0.433100
		loss: 0.427700
		loss: 0.423000
		loss: 0.425900
		loss: 0.429100
		loss: 0.422400
		loss: 0.419700
		loss: 0.422700
		loss: 0.421300
		loss: 0.417500
		loss: 0.416800
		loss: 0.418000
		loss: 0.416700
		loss: 0.413800
		loss: 0.414200
		loss: 0.414900
		loss: 0.412400
		loss: 0.410900
		loss: 0.411400
		loss: 0.410800
		loss: 0.409100
		loss: 0.408100
		loss: 0.408300
		loss: 0.407800
		loss: 0.406300
		loss: 0.405500
		loss: 0.405500
		loss: 0.404900
		loss: 0.403800
		loss: 0.403000
		loss: 0.402800
		loss: 0.402500
		loss: 0.401600
		loss: 0.400800
		loss: 0.400300
		loss: 0.400000
		loss: 0.399500
		loss: 0.398800
		loss: 0.398100
		loss: 0.397600
		loss: 0.397200
		loss: 0.396800
		loss: 0.396300
		loss: 0.395700
		loss: 0.395100
		loss: 0.394700
		loss: 0.394300
		loss: 0.394000
		loss: 0.393500
		loss: 0.393000
		loss: 0.392500
		loss: 0.392000
		loss: 0.391600
		loss: 0.391100
		loss: 0.390700
		loss: 0.390300
		loss: 0.389900
		loss: 0.389600
		loss: 0.389300
		loss: 0.389000
		loss: 0.388700
		loss: 0.388600
	Overall the loss development was 2.585900 -> 0.388600

Training data for problem d-5-0.pddl in epoch 4:
model creation time: 15.973206520080566s
problem epoch data for epoch 4, problem epoch 1
	sampling search time: 7.293948650360107s
	during this search the following actions were chosen:
		unstack c e was chosen with probability 0.999983
		put-down c was chosen with probability 0.998689
		unstack e b was chosen with probability 0.999213
		put-down e was chosen with probability 0.945675
		pick-up d was chosen with probability 0.468449
		stack d c was chosen with probability 0.999741
		unstack b a was chosen with probability 0.665090
		stack b d was chosen with probability 0.959345
		pick-up e was chosen with probability 0.897988
		stack e b was chosen with probability 0.913471
		pick-up a was chosen with probability 0.973414
		stack a e was chosen with probability 0.920999
	training time: 77.41274571418762s
	during the training the following losses were computed:
		loss: 0.638400
		loss: 0.725900
		loss: 0.586600
		loss: 0.478900
		loss: 0.524800
		loss: 0.490000
		loss: 0.401800
		loss: 0.382200
		loss: 0.409500
		loss: 0.382300
		loss: 0.324000
		loss: 0.309200
		loss: 0.324200
		loss: 0.313900
		loss: 0.277000
		loss: 0.256000
		loss: 0.268300
		loss: 0.264100
		loss: 0.235300
		loss: 0.227600
		loss: 0.237400
		loss: 0.233200
		loss: 0.215400
		loss: 0.210300
		loss: 0.218100
		loss: 0.213400
		loss: 0.201100
		loss: 0.200700
		loss: 0.204800
		loss: 0.199700
		loss: 0.192200
		loss: 0.193200
		loss: 0.195400
		loss: 0.190600
		loss: 0.186600
		loss: 0.188400
		loss: 0.188800
		loss: 0.184900
		loss: 0.183100
		loss: 0.184900
		loss: 0.184000
		loss: 0.180700
		loss: 0.180400
		loss: 0.181300
		loss: 0.179500
		loss: 0.177500
		loss: 0.177900
		loss: 0.177700
		loss: 0.175800
		loss: 0.175000
		loss: 0.175200
		loss: 0.174300
		loss: 0.172900
		loss: 0.172700
		loss: 0.172600
		loss: 0.171600
		loss: 0.170900
		loss: 0.170900
		loss: 0.170400
		loss: 0.169600
		loss: 0.169400
		loss: 0.169200
		loss: 0.168500
		loss: 0.168100
		loss: 0.168000
		loss: 0.167500
		loss: 0.167000
		loss: 0.166900
		loss: 0.166600
		loss: 0.166200
		loss: 0.166100
		loss: 0.165900
		loss: 0.165600
		loss: 0.165300
		loss: 0.165200
		loss: 0.165000
		loss: 0.164800
		loss: 0.164600
		loss: 0.164400
		loss: 0.164200
		loss: 0.164100
		loss: 0.163900
		loss: 0.163700
		loss: 0.163500
		loss: 0.163400
		loss: 0.163200
		loss: 0.163000
		loss: 0.162900
		loss: 0.162700
		loss: 0.162500
		loss: 0.162300
		loss: 0.162200
		loss: 0.162000
		loss: 0.161900
		loss: 0.161700
		loss: 0.161500
		loss: 0.161400
		loss: 0.161300
		loss: 0.161100
		loss: 0.161000
		loss: 0.160800
		loss: 0.160700
		loss: 0.160600
		loss: 0.160500
		loss: 0.160400
		loss: 0.160200
		loss: 0.160100
		loss: 0.160000
		loss: 0.159900
		loss: 0.159800
		loss: 0.159700
		loss: 0.159600
		loss: 0.159500
		loss: 0.159400
		loss: 0.159300
		loss: 0.159300
		loss: 0.159200
		loss: 0.159100
		loss: 0.159000
		loss: 0.158900
		loss: 0.158800
		loss: 0.158700
		loss: 0.158600
		loss: 0.158500
		loss: 0.158500
		loss: 0.158400
		loss: 0.158300
		loss: 0.158200
		loss: 0.158100
		loss: 0.158000
		loss: 0.157900
		loss: 0.157900
		loss: 0.157800
		loss: 0.157700
		loss: 0.157600
		loss: 0.157500
		loss: 0.157500
		loss: 0.157400
		loss: 0.157300
		loss: 0.157300
		loss: 0.157200
		loss: 0.157100
		loss: 0.157100
		loss: 0.157000
		loss: 0.156900
		loss: 0.156900
		loss: 0.156800
		loss: 0.156800
		loss: 0.156700
		loss: 0.156600
		loss: 0.156600
		loss: 0.156500
		loss: 0.156400
		loss: 0.156400
		loss: 0.156300
		loss: 0.156300
		loss: 0.156200
		loss: 0.156100
		loss: 0.156100
		loss: 0.156000
		loss: 0.156000
		loss: 0.155900
		loss: 0.155900
		loss: 0.155800
		loss: 0.155700
		loss: 0.155700
		loss: 0.155600
		loss: 0.155600
		loss: 0.155500
		loss: 0.155500
		loss: 0.155400
		loss: 0.155400
		loss: 0.155300
		loss: 0.155300
		loss: 0.155200
		loss: 0.155200
		loss: 0.155100
		loss: 0.155100
		loss: 0.155000
		loss: 0.155000
		loss: 0.154900
		loss: 0.154900
		loss: 0.154900
		loss: 0.154800
		loss: 0.154800
		loss: 0.154700
		loss: 0.154700
		loss: 0.154600
		loss: 0.154600
		loss: 0.154500
		loss: 0.154500
		loss: 0.154400
		loss: 0.154400
		loss: 0.154400
		loss: 0.154300
		loss: 0.154300
		loss: 0.154200
		loss: 0.154200
		loss: 0.154100
		loss: 0.154100
		loss: 0.154100
		loss: 0.154000
		loss: 0.154000
		loss: 0.153900
		loss: 0.153900
		loss: 0.153800
		loss: 0.153800
		loss: 0.153800
		loss: 0.153700
		loss: 0.153700
		loss: 0.153600
		loss: 0.153600
		loss: 0.153500
		loss: 0.153500
		loss: 0.153500
		loss: 0.153400
		loss: 0.153400
		loss: 0.153300
		loss: 0.153300
		loss: 0.153300
		loss: 0.153200
		loss: 0.153200
		loss: 0.153100
		loss: 0.153100
		loss: 0.153100
		loss: 0.153000
		loss: 0.153000
		loss: 0.152900
		loss: 0.152900
		loss: 0.152900
		loss: 0.152800
		loss: 0.152800
		loss: 0.152700
		loss: 0.152700
		loss: 0.152700
		loss: 0.152600
		loss: 0.152600
		loss: 0.152500
		loss: 0.152500
		loss: 0.152500
		loss: 0.152400
		loss: 0.152400
		loss: 0.152300
		loss: 0.152300
		loss: 0.152300
		loss: 0.152200
		loss: 0.152200
		loss: 0.152100
		loss: 0.152100
		loss: 0.152100
		loss: 0.152000
		loss: 0.152000
		loss: 0.152000
		loss: 0.151900
		loss: 0.151900
		loss: 0.151900
		loss: 0.151800
		loss: 0.151800
		loss: 0.151700
		loss: 0.151700
		loss: 0.151700
		loss: 0.151600
		loss: 0.151600
		loss: 0.151600
		loss: 0.151500
		loss: 0.151500
		loss: 0.151400
		loss: 0.151400
		loss: 0.151400
		loss: 0.151300
		loss: 0.151300
		loss: 0.151300
		loss: 0.151200
		loss: 0.151200
		loss: 0.151200
		loss: 0.151100
		loss: 0.151100
		loss: 0.151100
		loss: 0.151100
		loss: 0.151000
		loss: 0.151000
		loss: 0.150900
		loss: 0.150900
		loss: 0.150900
		loss: 0.150800
		loss: 0.150800
		loss: 0.150700
		loss: 0.150700
		loss: 0.150700
		loss: 0.150600
		loss: 0.150600
		loss: 0.150600
		loss: 0.150500
		loss: 0.150500
		loss: 0.150500
		loss: 0.150400
		loss: 0.150400
		loss: 0.150400
		loss: 0.150300
		loss: 0.150300
	Overall the loss development was 0.638400 -> 0.150300

Training data for problem d-5-1.pddl in epoch 4:
model creation time: 19.329127073287964s
problem epoch data for epoch 4, problem epoch 1
	sampling search time: 6.40545916557312s
	during this search the following actions were chosen:
		pick-up c was chosen with probability 0.992288
		stack c b was chosen with probability 0.524132
		unstack c b was chosen with probability 0.999284
	training time: 74.31950831413269s
	during the training the following losses were computed:
		loss: 1.597300
		loss: 1.435800
		loss: 1.355400
		loss: 1.199500
		loss: 1.098500
		loss: 1.033800
		loss: 0.930700
		loss: 0.836200
		loss: 0.777100
		loss: 0.722300
		loss: 0.662000
		loss: 0.605000
		loss: 0.560000
		loss: 0.536300
		loss: 0.519600
		loss: 0.491100
		loss: 0.460700
		loss: 0.442500
		loss: 0.426500
		loss: 0.400100
		loss: 0.375300
		loss: 0.359700
		loss: 0.344100
		loss: 0.324900
		loss: 0.309100
		loss: 0.300000
		loss: 0.292000
		loss: 0.282100
		loss: 0.273500
		loss: 0.268200
		loss: 0.263900
		loss: 0.258200
		loss: 0.252400
		loss: 0.248100
		loss: 0.244700
		loss: 0.241000
		loss: 0.236700
		loss: 0.232900
		loss: 0.230100
		loss: 0.227600
		loss: 0.224600
		loss: 0.221700
		loss: 0.219200
		loss: 0.217400
		loss: 0.215600
		loss: 0.213600
		loss: 0.211600
		loss: 0.210100
		loss: 0.208800
		loss: 0.207500
		loss: 0.206100
		loss: 0.204700
		loss: 0.203500
		loss: 0.202500
		loss: 0.201400
		loss: 0.200300
		loss: 0.199300
		loss: 0.198400
		loss: 0.197600
		loss: 0.196800
		loss: 0.196100
		loss: 0.195400
		loss: 0.194700
		loss: 0.194100
		loss: 0.193500
		loss: 0.192900
		loss: 0.192400
		loss: 0.191900
		loss: 0.191400
		loss: 0.190900
		loss: 0.190500
		loss: 0.190000
		loss: 0.189600
		loss: 0.189200
		loss: 0.188800
		loss: 0.188400
		loss: 0.188100
		loss: 0.187700
		loss: 0.187400
		loss: 0.187100
		loss: 0.186700
		loss: 0.186400
		loss: 0.186100
		loss: 0.185800
		loss: 0.185500
		loss: 0.185200
		loss: 0.185000
		loss: 0.184700
		loss: 0.184500
		loss: 0.184200
		loss: 0.184000
		loss: 0.183700
		loss: 0.183500
		loss: 0.183300
		loss: 0.183000
		loss: 0.182800
		loss: 0.182600
		loss: 0.182400
		loss: 0.182200
		loss: 0.182000
		loss: 0.181800
		loss: 0.181600
		loss: 0.181400
		loss: 0.181300
		loss: 0.181100
		loss: 0.180900
		loss: 0.180700
		loss: 0.180600
		loss: 0.180400
		loss: 0.180200
		loss: 0.180100
		loss: 0.179900
		loss: 0.179800
		loss: 0.179600
		loss: 0.179500
		loss: 0.179400
		loss: 0.179200
		loss: 0.179100
		loss: 0.179000
		loss: 0.178900
		loss: 0.178700
		loss: 0.178600
		loss: 0.178500
		loss: 0.178400
		loss: 0.178300
		loss: 0.178200
		loss: 0.178100
		loss: 0.178000
		loss: 0.177900
		loss: 0.177800
		loss: 0.177700
		loss: 0.177600
		loss: 0.177500
		loss: 0.177400
		loss: 0.177300
		loss: 0.177200
		loss: 0.177200
		loss: 0.177100
		loss: 0.177000
		loss: 0.176900
		loss: 0.176800
		loss: 0.176800
		loss: 0.176700
		loss: 0.176600
		loss: 0.176600
		loss: 0.176500
		loss: 0.176400
		loss: 0.176400
		loss: 0.176300
		loss: 0.176200
		loss: 0.176200
		loss: 0.176100
		loss: 0.176100
		loss: 0.176000
		loss: 0.175900
		loss: 0.175900
		loss: 0.175800
		loss: 0.175700
		loss: 0.175700
		loss: 0.175600
		loss: 0.175500
		loss: 0.175500
		loss: 0.175400
		loss: 0.175400
		loss: 0.175300
		loss: 0.175200
		loss: 0.175200
		loss: 0.175100
		loss: 0.175100
		loss: 0.175000
		loss: 0.175000
		loss: 0.174900
		loss: 0.174900
		loss: 0.174800
		loss: 0.174700
		loss: 0.174700
		loss: 0.174600
		loss: 0.174600
		loss: 0.174500
		loss: 0.174500
		loss: 0.174400
		loss: 0.174400
		loss: 0.174300
		loss: 0.174300
		loss: 0.174200
		loss: 0.174200
		loss: 0.174200
		loss: 0.174100
		loss: 0.174100
		loss: 0.174000
		loss: 0.174000
		loss: 0.173900
		loss: 0.173900
		loss: 0.173900
		loss: 0.173800
		loss: 0.173800
		loss: 0.173700
		loss: 0.173700
		loss: 0.173700
		loss: 0.173600
		loss: 0.173600
		loss: 0.173500
		loss: 0.173500
		loss: 0.173500
		loss: 0.173400
		loss: 0.173400
		loss: 0.173300
		loss: 0.173300
		loss: 0.173300
		loss: 0.173200
		loss: 0.173200
		loss: 0.173200
		loss: 0.173100
		loss: 0.173100
		loss: 0.173000
		loss: 0.173000
		loss: 0.173000
		loss: 0.172900
		loss: 0.172900
		loss: 0.172900
		loss: 0.172800
		loss: 0.172800
		loss: 0.172800
		loss: 0.172700
		loss: 0.172700
		loss: 0.172700
		loss: 0.172600
		loss: 0.172600
		loss: 0.172600
		loss: 0.172500
		loss: 0.172500
		loss: 0.172500
		loss: 0.172400
		loss: 0.172400
		loss: 0.172400
		loss: 0.172300
		loss: 0.172300
		loss: 0.172300
		loss: 0.172200
		loss: 0.172200
		loss: 0.172200
		loss: 0.172100
		loss: 0.172100
		loss: 0.172100
		loss: 0.172000
		loss: 0.172000
		loss: 0.172000
		loss: 0.171900
		loss: 0.171900
		loss: 0.171900
		loss: 0.171800
		loss: 0.171800
		loss: 0.171800
		loss: 0.171700
		loss: 0.171700
		loss: 0.171700
		loss: 0.171600
		loss: 0.171600
		loss: 0.171600
		loss: 0.171500
		loss: 0.171500
		loss: 0.171500
		loss: 0.171500
		loss: 0.171400
		loss: 0.171400
		loss: 0.171400
		loss: 0.171300
		loss: 0.171300
		loss: 0.171300
		loss: 0.171200
		loss: 0.171200
		loss: 0.171200
		loss: 0.171100
		loss: 0.171100
		loss: 0.171100
		loss: 0.171100
		loss: 0.171000
		loss: 0.171000
		loss: 0.171000
		loss: 0.170900
		loss: 0.170900
		loss: 0.170900
		loss: 0.170800
		loss: 0.170800
		loss: 0.170800
		loss: 0.170800
		loss: 0.170700
		loss: 0.170700
		loss: 0.170700
		loss: 0.170600
		loss: 0.170600
		loss: 0.170600
		loss: 0.170600
		loss: 0.170500
		loss: 0.170500
		loss: 0.170500
		loss: 0.170400
		loss: 0.170400
		loss: 0.170400
		loss: 0.170300
	Overall the loss development was 1.597300 -> 0.170300

Epoch 5:
Training data for problem d-4-0.pddl in epoch 5:
model creation time: 10.067615747451782s
problem epoch data for epoch 5, problem epoch 1
	sampling search time: 2.5594937801361084s
	during this search the following actions were chosen:
		pick-up b was chosen with probability 0.333329
		stack b a was chosen with probability 0.994381
		pick-up c was chosen with probability 0.999045
		stack c b was chosen with probability 0.995495
		pick-up d was chosen with probability 0.999677
		stack d c was chosen with probability 0.999070
	training time: 60.634541034698486s
	during the training the following losses were computed:
		loss: 0.218900
		loss: 0.218000
		loss: 0.217300
		loss: 0.216500
		loss: 0.215800
		loss: 0.215100
		loss: 0.214400
		loss: 0.213700
		loss: 0.213100
		loss: 0.212400
		loss: 0.211700
		loss: 0.211000
		loss: 0.210300
		loss: 0.209600
		loss: 0.209000
		loss: 0.208300
		loss: 0.207600
		loss: 0.207000
		loss: 0.206300
		loss: 0.205700
		loss: 0.205000
		loss: 0.204400
		loss: 0.203800
		loss: 0.203200
		loss: 0.202700
		loss: 0.202100
		loss: 0.201600
		loss: 0.201000
		loss: 0.200500
		loss: 0.200000
		loss: 0.199500
		loss: 0.199000
		loss: 0.198500
		loss: 0.198100
		loss: 0.197600
		loss: 0.197100
		loss: 0.196700
		loss: 0.196300
		loss: 0.195800
		loss: 0.195400
		loss: 0.195000
		loss: 0.194600
		loss: 0.194200
		loss: 0.193900
		loss: 0.193500
		loss: 0.193200
		loss: 0.192800
		loss: 0.192500
		loss: 0.192100
		loss: 0.191800
		loss: 0.191500
		loss: 0.191200
		loss: 0.190900
		loss: 0.190600
		loss: 0.190400
		loss: 0.190100
		loss: 0.189900
		loss: 0.189600
		loss: 0.189300
		loss: 0.189100
		loss: 0.188900
		loss: 0.188700
		loss: 0.188400
		loss: 0.188200
		loss: 0.188000
		loss: 0.187800
		loss: 0.187600
		loss: 0.187400
		loss: 0.187200
		loss: 0.187000
		loss: 0.186800
		loss: 0.186700
		loss: 0.186500
		loss: 0.186300
		loss: 0.186100
		loss: 0.186000
		loss: 0.185800
		loss: 0.185600
		loss: 0.185500
		loss: 0.185300
		loss: 0.185200
		loss: 0.185000
		loss: 0.184900
		loss: 0.184800
		loss: 0.184600
		loss: 0.184500
		loss: 0.184400
		loss: 0.184200
		loss: 0.184100
		loss: 0.184000
		loss: 0.183900
		loss: 0.183700
		loss: 0.183600
		loss: 0.183500
		loss: 0.183400
		loss: 0.183300
		loss: 0.183200
		loss: 0.183100
		loss: 0.183000
		loss: 0.182900
		loss: 0.182800
		loss: 0.182700
		loss: 0.182600
		loss: 0.182500
		loss: 0.182400
		loss: 0.182300
		loss: 0.182200
		loss: 0.182100
		loss: 0.182000
		loss: 0.181900
		loss: 0.181900
		loss: 0.181800
		loss: 0.181700
		loss: 0.181600
		loss: 0.181500
		loss: 0.181500
		loss: 0.181400
		loss: 0.181300
		loss: 0.181200
		loss: 0.181200
		loss: 0.181100
		loss: 0.181000
		loss: 0.181000
		loss: 0.180900
		loss: 0.180800
		loss: 0.180800
		loss: 0.180700
		loss: 0.180600
		loss: 0.180600
		loss: 0.180500
		loss: 0.180400
		loss: 0.180400
		loss: 0.180300
		loss: 0.180300
		loss: 0.180200
		loss: 0.180200
		loss: 0.180100
		loss: 0.180000
		loss: 0.180000
		loss: 0.179900
		loss: 0.179900
		loss: 0.179800
		loss: 0.179800
		loss: 0.179700
		loss: 0.179700
		loss: 0.179600
		loss: 0.179600
		loss: 0.179600
		loss: 0.179500
		loss: 0.179500
		loss: 0.179400
		loss: 0.179400
		loss: 0.179300
		loss: 0.179300
		loss: 0.179300
		loss: 0.179200
		loss: 0.179200
		loss: 0.179100
		loss: 0.179100
		loss: 0.179100
		loss: 0.179000
		loss: 0.179000
		loss: 0.179000
		loss: 0.178900
		loss: 0.178900
		loss: 0.178900
		loss: 0.178800
		loss: 0.178800
		loss: 0.178800
		loss: 0.178700
		loss: 0.178700
		loss: 0.178700
		loss: 0.178600
		loss: 0.178600
		loss: 0.178600
		loss: 0.178600
		loss: 0.178500
		loss: 0.178500
		loss: 0.178500
		loss: 0.178500
		loss: 0.178400
		loss: 0.178400
		loss: 0.178400
		loss: 0.178400
		loss: 0.178300
		loss: 0.178300
		loss: 0.178300
		loss: 0.178300
		loss: 0.178300
		loss: 0.178200
		loss: 0.178200
		loss: 0.178200
		loss: 0.178200
		loss: 0.178200
		loss: 0.178100
		loss: 0.178100
		loss: 0.178100
		loss: 0.178100
		loss: 0.178100
		loss: 0.178000
		loss: 0.178000
		loss: 0.178000
		loss: 0.178000
		loss: 0.178000
		loss: 0.178000
		loss: 0.177900
		loss: 0.177900
		loss: 0.177900
		loss: 0.177900
		loss: 0.177900
		loss: 0.177900
		loss: 0.177900
		loss: 0.177800
		loss: 0.177800
		loss: 0.177800
		loss: 0.177800
		loss: 0.177800
		loss: 0.177800
		loss: 0.177800
		loss: 0.177800
		loss: 0.177700
		loss: 0.177700
		loss: 0.177700
		loss: 0.177700
		loss: 0.177700
		loss: 0.177700
		loss: 0.177700
		loss: 0.177700
		loss: 0.177600
		loss: 0.177600
		loss: 0.177600
		loss: 0.177600
		loss: 0.177600
		loss: 0.177600
		loss: 0.177600
		loss: 0.177600
		loss: 0.177600
		loss: 0.177600
		loss: 0.177500
		loss: 0.177500
		loss: 0.177500
		loss: 0.177500
		loss: 0.177500
		loss: 0.177500
		loss: 0.177500
		loss: 0.177500
		loss: 0.177500
		loss: 0.177500
		loss: 0.177500
		loss: 0.177400
		loss: 0.177400
		loss: 0.177400
		loss: 0.177400
		loss: 0.177400
		loss: 0.177400
		loss: 0.177400
		loss: 0.177400
		loss: 0.177400
		loss: 0.177400
		loss: 0.177400
		loss: 0.177400
		loss: 0.177300
		loss: 0.177300
		loss: 0.177300
		loss: 0.177300
		loss: 0.177300
		loss: 0.177300
		loss: 0.177300
		loss: 0.177300
		loss: 0.177300
		loss: 0.177300
		loss: 0.177300
		loss: 0.177300
		loss: 0.177300
		loss: 0.177300
		loss: 0.177300
		loss: 0.177200
		loss: 0.177200
		loss: 0.177200
		loss: 0.177200
		loss: 0.177200
		loss: 0.177200
		loss: 0.177200
		loss: 0.177200
		loss: 0.177200
		loss: 0.177200
		loss: 0.177200
		loss: 0.177200
		loss: 0.177200
		loss: 0.177200
		loss: 0.177200
		loss: 0.177200
		loss: 0.177100
		loss: 0.177100
		loss: 0.177100
		loss: 0.177100
		loss: 0.177100
		loss: 0.177100
		loss: 0.177100
		loss: 0.177100
	Overall the loss development was 0.218900 -> 0.177100

Training data for problem d-4-2.pddl in epoch 5:
model creation time: 9.985124826431274s
problem epoch data for epoch 5, problem epoch 1
	sampling search time: 5.535609483718872s
	during this search the following actions were chosen:
		pick-up a was chosen with probability 0.994578
		stack a c was chosen with probability 0.763422
		pick-up d was chosen with probability 0.998734
		stack d a was chosen with probability 0.987016
	training time: 60.091878175735474s
	during the training the following losses were computed:
		loss: 2.545900
		loss: 2.365300
		loss: 2.193000
		loss: 2.028600
		loss: 1.871000
		loss: 1.719500
		loss: 1.578200
		loss: 1.438400
		loss: 1.304900
		loss: 1.177700
		loss: 1.059700
		loss: 0.952100
		loss: 0.852600
		loss: 0.761500
		loss: 0.682000
		loss: 0.614900
		loss: 0.561300
		loss: 0.515500
		loss: 0.480400
		loss: 0.456600
		loss: 0.442500
		loss: 0.435500
		loss: 0.435900
		loss: 0.441900
		loss: 0.451800
		loss: 0.462200
		loss: 0.468900
		loss: 0.469400
		loss: 0.463200
		loss: 0.451300
		loss: 0.435800
		loss: 0.418800
		loss: 0.401300
		loss: 0.384700
		loss: 0.369500
		loss: 0.355800
		loss: 0.343300
		loss: 0.331800
		loss: 0.320900
		loss: 0.310400
		loss: 0.299700
		loss: 0.288700
		loss: 0.277400
		loss: 0.265600
		loss: 0.253700
		loss: 0.241800
		loss: 0.230500
		loss: 0.220500
		loss: 0.212400
		loss: 0.206400
		loss: 0.201800
		loss: 0.197400
		loss: 0.192000
		loss: 0.185500
		loss: 0.179100
		loss: 0.173500
		loss: 0.169100
		loss: 0.165300
		loss: 0.161300
		loss: 0.156500
		loss: 0.151100
		loss: 0.145900
		loss: 0.141300
		loss: 0.137400
		loss: 0.133600
		loss: 0.129300
		loss: 0.124600
		loss: 0.120200
		loss: 0.116300
		loss: 0.112800
		loss: 0.109500
		loss: 0.105900
		loss: 0.102300
		loss: 0.098800
		loss: 0.095700
		loss: 0.092800
		loss: 0.090000
		loss: 0.087200
		loss: 0.084400
		loss: 0.081700
		loss: 0.079300
		loss: 0.077100
		loss: 0.074900
		loss: 0.072800
		loss: 0.070800
		loss: 0.068900
		loss: 0.067200
		loss: 0.065600
		loss: 0.064000
		loss: 0.062600
		loss: 0.061200
		loss: 0.060000
		loss: 0.058800
		loss: 0.057700
		loss: 0.056700
		loss: 0.055800
		loss: 0.054900
		loss: 0.054000
		loss: 0.053200
		loss: 0.052500
		loss: 0.051800
		loss: 0.051200
		loss: 0.050600
		loss: 0.050000
		loss: 0.049500
		loss: 0.049000
		loss: 0.048500
		loss: 0.048100
		loss: 0.047700
		loss: 0.047300
		loss: 0.047000
		loss: 0.046600
		loss: 0.046300
		loss: 0.046000
		loss: 0.045800
		loss: 0.045500
		loss: 0.045300
		loss: 0.045000
		loss: 0.044800
		loss: 0.044600
		loss: 0.044400
		loss: 0.044200
		loss: 0.044000
		loss: 0.043800
		loss: 0.043700
		loss: 0.043500
		loss: 0.043400
		loss: 0.043200
		loss: 0.043100
		loss: 0.042900
		loss: 0.042800
		loss: 0.042700
		loss: 0.042600
		loss: 0.042400
		loss: 0.042300
		loss: 0.042200
		loss: 0.042100
		loss: 0.042000
		loss: 0.041900
		loss: 0.041800
		loss: 0.041700
		loss: 0.041600
		loss: 0.041500
		loss: 0.041400
		loss: 0.041400
		loss: 0.041300
		loss: 0.041200
		loss: 0.041100
		loss: 0.041000
		loss: 0.040900
		loss: 0.040900
		loss: 0.040800
		loss: 0.040700
		loss: 0.040600
		loss: 0.040600
		loss: 0.040500
		loss: 0.040400
		loss: 0.040400
		loss: 0.040300
		loss: 0.040200
		loss: 0.040200
		loss: 0.040100
		loss: 0.040000
		loss: 0.040000
		loss: 0.039900
		loss: 0.039800
		loss: 0.039800
		loss: 0.039700
		loss: 0.039700
		loss: 0.039600
		loss: 0.039500
		loss: 0.039500
		loss: 0.039400
		loss: 0.039400
		loss: 0.039300
		loss: 0.039300
		loss: 0.039200
		loss: 0.039200
		loss: 0.039100
		loss: 0.039000
		loss: 0.039000
		loss: 0.038900
		loss: 0.038900
		loss: 0.038800
		loss: 0.038800
		loss: 0.038700
		loss: 0.038700
		loss: 0.038700
		loss: 0.038600
		loss: 0.038600
		loss: 0.038500
		loss: 0.038500
		loss: 0.038400
		loss: 0.038400
		loss: 0.038300
		loss: 0.038300
		loss: 0.038300
		loss: 0.038200
		loss: 0.038200
		loss: 0.038100
		loss: 0.038100
		loss: 0.038000
		loss: 0.038000
		loss: 0.038000
		loss: 0.037900
		loss: 0.037900
		loss: 0.037800
		loss: 0.037800
		loss: 0.037800
		loss: 0.037700
		loss: 0.037700
		loss: 0.037700
		loss: 0.037600
		loss: 0.037600
		loss: 0.037600
		loss: 0.037500
		loss: 0.037500
		loss: 0.037500
		loss: 0.037400
		loss: 0.037400
		loss: 0.037400
		loss: 0.037300
		loss: 0.037300
		loss: 0.037300
		loss: 0.037200
		loss: 0.037200
		loss: 0.037200
		loss: 0.037100
		loss: 0.037100
		loss: 0.037100
		loss: 0.037100
		loss: 0.037000
		loss: 0.037000
		loss: 0.037000
		loss: 0.036900
		loss: 0.036900
		loss: 0.036900
		loss: 0.036900
		loss: 0.036800
		loss: 0.036800
		loss: 0.036800
		loss: 0.036700
		loss: 0.036700
		loss: 0.036700
		loss: 0.036700
		loss: 0.036600
		loss: 0.036600
		loss: 0.036600
		loss: 0.036600
		loss: 0.036500
		loss: 0.036500
		loss: 0.036500
		loss: 0.036500
		loss: 0.036400
		loss: 0.036400
		loss: 0.036400
		loss: 0.036400
		loss: 0.036300
		loss: 0.036300
		loss: 0.036300
		loss: 0.036300
		loss: 0.036200
		loss: 0.036200
		loss: 0.036200
		loss: 0.036200
		loss: 0.036200
		loss: 0.036100
		loss: 0.036100
		loss: 0.036100
		loss: 0.036100
		loss: 0.036000
		loss: 0.036000
		loss: 0.036000
		loss: 0.036000
		loss: 0.036000
		loss: 0.035900
		loss: 0.035900
		loss: 0.035900
		loss: 0.035900
		loss: 0.035900
		loss: 0.035800
		loss: 0.035800
		loss: 0.035800
		loss: 0.035800
		loss: 0.035800
		loss: 0.035700
		loss: 0.035700
		loss: 0.035700
		loss: 0.035700
		loss: 0.035700
		loss: 0.035600
		loss: 0.035600
		loss: 0.035600
		loss: 0.035600
		loss: 0.035600
		loss: 0.035500
		loss: 0.035500
		loss: 0.035500
		loss: 0.035500
		loss: 0.035500
	Overall the loss development was 2.545900 -> 0.035500

Training data for problem d-4-1.pddl in epoch 5:
model creation time: 10.03242015838623s
problem epoch data for epoch 5, problem epoch 1
	sampling search time: 15.274964094161987s
	during this search the following actions were chosen:
	training time: 65.946861743927s
	during the training the following losses were computed:
		loss: 0.341000
		loss: 0.172600
		loss: 0.107200
		loss: 0.136300
		loss: 0.156400
		loss: 0.133500
		loss: 0.101500
		loss: 0.082200
		loss: 0.076300
		loss: 0.079200
		loss: 0.085500
		loss: 0.089800
		loss: 0.089500
		loss: 0.085000
		loss: 0.078700
		loss: 0.073200
		loss: 0.070000
		loss: 0.069200
		loss: 0.069800
		loss: 0.070800
		loss: 0.070800
		loss: 0.069400
		loss: 0.066900
		loss: 0.063900
		loss: 0.061100
		loss: 0.059000
		loss: 0.057600
		loss: 0.056900
		loss: 0.056600
		loss: 0.056300
		loss: 0.055900
		loss: 0.055200
		loss: 0.054300
		loss: 0.053300
		loss: 0.052300
		loss: 0.051400
		loss: 0.050800
		loss: 0.050400
		loss: 0.050200
		loss: 0.050000
		loss: 0.049800
		loss: 0.049500
		loss: 0.049100
		loss: 0.048700
		loss: 0.048200
		loss: 0.047800
		loss: 0.047400
		loss: 0.047100
		loss: 0.046800
		loss: 0.046600
		loss: 0.046400
		loss: 0.046200
		loss: 0.046000
		loss: 0.045800
		loss: 0.045500
		loss: 0.045300
		loss: 0.045100
		loss: 0.044900
		loss: 0.044700
		loss: 0.044500
		loss: 0.044400
		loss: 0.044200
		loss: 0.044100
		loss: 0.044000
		loss: 0.043800
		loss: 0.043700
		loss: 0.043600
		loss: 0.043500
		loss: 0.043300
		loss: 0.043200
		loss: 0.043100
		loss: 0.043000
		loss: 0.042900
		loss: 0.042800
		loss: 0.042800
		loss: 0.042700
		loss: 0.042600
		loss: 0.042500
		loss: 0.042400
		loss: 0.042400
		loss: 0.042300
		loss: 0.042200
		loss: 0.042200
		loss: 0.042100
		loss: 0.042000
		loss: 0.042000
		loss: 0.041900
		loss: 0.041900
		loss: 0.041800
		loss: 0.041800
		loss: 0.041700
		loss: 0.041600
		loss: 0.041600
		loss: 0.041600
		loss: 0.041500
		loss: 0.041500
		loss: 0.041400
		loss: 0.041400
		loss: 0.041300
		loss: 0.041300
		loss: 0.041200
		loss: 0.041200
		loss: 0.041200
		loss: 0.041100
		loss: 0.041100
		loss: 0.041100
		loss: 0.041000
		loss: 0.041000
		loss: 0.041000
		loss: 0.040900
		loss: 0.040900
		loss: 0.040900
		loss: 0.040800
		loss: 0.040800
		loss: 0.040800
		loss: 0.040800
		loss: 0.040700
		loss: 0.040700
		loss: 0.040700
		loss: 0.040600
		loss: 0.040600
		loss: 0.040600
		loss: 0.040600
		loss: 0.040500
		loss: 0.040500
		loss: 0.040500
		loss: 0.040500
		loss: 0.040400
		loss: 0.040400
		loss: 0.040400
		loss: 0.040400
		loss: 0.040300
		loss: 0.040300
		loss: 0.040300
		loss: 0.040300
		loss: 0.040300
		loss: 0.040200
		loss: 0.040200
		loss: 0.040200
		loss: 0.040200
		loss: 0.040100
		loss: 0.040100
		loss: 0.040100
		loss: 0.040100
		loss: 0.040100
		loss: 0.040000
		loss: 0.040000
		loss: 0.040000
		loss: 0.040000
		loss: 0.040000
		loss: 0.039900
		loss: 0.039900
		loss: 0.039900
		loss: 0.039900
		loss: 0.039900
		loss: 0.039800
		loss: 0.039800
		loss: 0.039800
		loss: 0.039800
		loss: 0.039800
		loss: 0.039800
		loss: 0.039700
		loss: 0.039700
		loss: 0.039700
		loss: 0.039700
		loss: 0.039700
		loss: 0.039600
		loss: 0.039600
		loss: 0.039600
		loss: 0.039600
		loss: 0.039600
		loss: 0.039600
		loss: 0.039500
		loss: 0.039500
		loss: 0.039500
		loss: 0.039500
		loss: 0.039500
		loss: 0.039400
		loss: 0.039400
		loss: 0.039400
		loss: 0.039400
		loss: 0.039400
		loss: 0.039400
		loss: 0.039300
		loss: 0.039300
		loss: 0.039300
		loss: 0.039300
		loss: 0.039300
		loss: 0.039300
		loss: 0.039200
		loss: 0.039200
		loss: 0.039200
		loss: 0.039200
		loss: 0.039200
		loss: 0.039100
		loss: 0.039100
		loss: 0.039100
		loss: 0.039100
		loss: 0.039100
		loss: 0.039100
		loss: 0.039000
		loss: 0.039000
		loss: 0.039000
		loss: 0.039000
		loss: 0.039000
		loss: 0.039000
		loss: 0.038900
		loss: 0.038900
		loss: 0.038900
		loss: 0.038900
		loss: 0.038900
		loss: 0.038900
		loss: 0.038800
		loss: 0.038800
		loss: 0.038800
		loss: 0.038800
		loss: 0.038800
		loss: 0.038800
		loss: 0.038700
		loss: 0.038700
		loss: 0.038700
		loss: 0.038700
		loss: 0.038700
		loss: 0.038700
		loss: 0.038700
		loss: 0.038600
		loss: 0.038600
		loss: 0.038600
		loss: 0.038600
		loss: 0.038600
		loss: 0.038600
		loss: 0.038500
		loss: 0.038500
		loss: 0.038500
		loss: 0.038500
		loss: 0.038500
		loss: 0.038500
		loss: 0.038400
		loss: 0.038400
		loss: 0.038400
		loss: 0.038400
		loss: 0.038400
		loss: 0.038400
		loss: 0.038300
		loss: 0.038300
		loss: 0.038300
		loss: 0.038300
		loss: 0.038300
		loss: 0.038300
		loss: 0.038200
		loss: 0.038200
		loss: 0.038200
		loss: 0.038200
		loss: 0.038200
		loss: 0.038200
		loss: 0.038200
		loss: 0.038100
		loss: 0.038100
		loss: 0.038100
		loss: 0.038100
		loss: 0.038100
		loss: 0.038100
		loss: 0.038000
		loss: 0.038000
		loss: 0.038000
		loss: 0.038000
		loss: 0.038000
		loss: 0.038000
		loss: 0.038000
		loss: 0.037900
		loss: 0.037900
		loss: 0.037900
		loss: 0.037900
		loss: 0.037900
		loss: 0.037900
		loss: 0.037800
		loss: 0.037800
		loss: 0.037800
		loss: 0.037800
		loss: 0.037800
		loss: 0.037800
		loss: 0.037800
		loss: 0.037700
		loss: 0.037700
		loss: 0.037700
		loss: 0.037700
		loss: 0.037700
		loss: 0.037700
		loss: 0.037600
		loss: 0.037600
		loss: 0.037600
		loss: 0.037600
		loss: 0.037600
		loss: 0.037600
		loss: 0.037600
		loss: 0.037500
		loss: 0.037500
		loss: 0.037500
		loss: 0.037500
		loss: 0.037500
	Overall the loss development was 0.341000 -> 0.037500

Training data for problem d-5-2.pddl in epoch 5:
model creation time: 16.355899333953857s
problem epoch data for epoch 5, problem epoch 1
	sampling search time: 11.897910594940186s
	during this search the following actions were chosen:
	training time: 76.88462042808533s
	during the training the following losses were computed:
		loss: 2.916400
		loss: 2.739500
		loss: 2.581500
		loss: 2.438100
		loss: 2.303700
		loss: 2.174200
		loss: 2.051400
		loss: 1.935200
		loss: 1.828200
		loss: 1.728300
		loss: 1.635900
		loss: 1.550800
		loss: 1.472800
		loss: 1.401600
		loss: 1.336700
		loss: 1.278300
		loss: 1.226300
		loss: 1.180600
		loss: 1.141200
		loss: 1.108200
		loss: 1.081400
		loss: 1.060500
		loss: 1.045400
		loss: 1.035600
		loss: 1.029500
		loss: 1.026000
		loss: 1.025400
		loss: 1.025900
		loss: 1.027400
		loss: 1.028900
		loss: 1.029800
		loss: 1.029500
		loss: 1.028100
		loss: 1.025800
		loss: 1.022700
		loss: 1.019000
		loss: 1.015100
		loss: 1.010700
		loss: 1.006000
		loss: 1.001800
		loss: 0.998100
		loss: 0.994800
		loss: 0.991900
		loss: 0.989000
		loss: 0.986100
		loss: 0.983500
		loss: 0.981000
		loss: 0.978800
		loss: 0.976700
		loss: 0.974800
		loss: 0.972900
		loss: 0.971000
		loss: 0.969000
		loss: 0.966900
		loss: 0.964700
		loss: 0.962700
		loss: 0.960700
		loss: 0.958700
		loss: 0.956700
		loss: 0.954600
		loss: 0.952300
		loss: 0.950100
		loss: 0.947700
		loss: 0.945400
		loss: 0.943100
		loss: 0.940800
		loss: 0.938500
		loss: 0.936100
		loss: 0.933600
		loss: 0.931100
		loss: 0.928700
		loss: 0.926200
		loss: 0.923800
		loss: 0.921300
		loss: 0.918700
		loss: 0.916200
		loss: 0.913600
		loss: 0.911000
		loss: 0.908400
		loss: 0.905800
		loss: 0.903100
		loss: 0.900300
		loss: 0.897600
		loss: 0.894800
		loss: 0.892000
		loss: 0.889100
		loss: 0.886200
		loss: 0.883300
		loss: 0.880300
		loss: 0.877300
		loss: 0.874300
		loss: 0.871300
		loss: 0.868200
		loss: 0.865000
		loss: 0.861900
		loss: 0.858700
		loss: 0.855400
		loss: 0.852100
		loss: 0.848800
		loss: 0.845400
		loss: 0.842000
		loss: 0.838500
		loss: 0.835000
		loss: 0.831400
		loss: 0.827600
		loss: 0.823900
		loss: 0.820100
		loss: 0.816200
		loss: 0.812300
		loss: 0.808300
		loss: 0.804300
		loss: 0.800200
		loss: 0.796200
		loss: 0.792100
		loss: 0.788000
		loss: 0.784000
		loss: 0.779800
		loss: 0.775700
		loss: 0.771500
		loss: 0.767500
		loss: 0.763400
		loss: 0.759400
		loss: 0.755400
		loss: 0.751400
		loss: 0.747500
		loss: 0.743600
		loss: 0.739700
		loss: 0.735800
		loss: 0.731900
		loss: 0.728100
		loss: 0.724300
		loss: 0.720500
		loss: 0.716900
		loss: 0.713200
		loss: 0.709600
		loss: 0.706000
		loss: 0.702400
		loss: 0.698900
		loss: 0.695500
		loss: 0.692100
		loss: 0.688800
		loss: 0.685600
		loss: 0.682400
		loss: 0.679100
		loss: 0.675900
		loss: 0.672700
		loss: 0.669400
		loss: 0.666100
		loss: 0.662800
		loss: 0.659600
		loss: 0.656600
		loss: 0.653400
		loss: 0.650400
		loss: 0.647500
		loss: 0.644800
		loss: 0.641300
		loss: 0.637300
		loss: 0.633500
		loss: 0.630600
		loss: 0.628500
		loss: 0.626300
		loss: 0.622800
		loss: 0.617400
		loss: 0.613700
		loss: 0.612000
		loss: 0.610200
		loss: 0.607000
		loss: 0.603100
		loss: 0.600300
		loss: 0.598600
		loss: 0.596700
		loss: 0.593800
		loss: 0.590200
		loss: 0.587300
		loss: 0.585200
		loss: 0.583300
		loss: 0.581100
		loss: 0.577800
		loss: 0.574500
		loss: 0.571400
		loss: 0.568900
		loss: 0.566900
		loss: 0.564800
		loss: 0.562500
		loss: 0.559600
		loss: 0.556500
		loss: 0.553400
		loss: 0.550700
		loss: 0.548400
		loss: 0.546300
		loss: 0.544600
		loss: 0.542800
		loss: 0.541200
		loss: 0.538800
		loss: 0.536000
		loss: 0.532100
		loss: 0.528700
		loss: 0.526200
		loss: 0.524600
		loss: 0.523700
		loss: 0.522500
		loss: 0.521100
		loss: 0.517600
		loss: 0.513700
		loss: 0.510600
		loss: 0.509100
		loss: 0.508500
		loss: 0.507200
		loss: 0.505200
		loss: 0.501800
		loss: 0.498900
		loss: 0.497100
		loss: 0.496000
		loss: 0.495100
		loss: 0.493400
		loss: 0.491300
		loss: 0.488500
		loss: 0.486200
		loss: 0.484300
		loss: 0.482900
		loss: 0.482100
		loss: 0.481400
		loss: 0.481100
		loss: 0.479700
		loss: 0.478400
		loss: 0.475400
		loss: 0.472600
		loss: 0.470300
		loss: 0.468800
		loss: 0.468100
		loss: 0.467700
		loss: 0.467800
		loss: 0.466900
		loss: 0.466000
		loss: 0.462900
		loss: 0.460100
		loss: 0.457700
		loss: 0.456700
		loss: 0.456700
		loss: 0.457400
		loss: 0.459900
		loss: 0.459800
		loss: 0.458600
		loss: 0.451400
		loss: 0.448300
		loss: 0.450300
		loss: 0.451900
		loss: 0.451300
		loss: 0.445900
		loss: 0.443000
		loss: 0.443700
		loss: 0.444600
		loss: 0.443600
		loss: 0.440000
		loss: 0.438100
		loss: 0.438500
		loss: 0.438800
		loss: 0.438000
		loss: 0.435400
		loss: 0.433500
		loss: 0.433100
		loss: 0.433200
		loss: 0.433300
		loss: 0.432500
		loss: 0.431400
		loss: 0.429700
		loss: 0.428200
		loss: 0.426900
		loss: 0.425900
		loss: 0.425200
		loss: 0.424800
		loss: 0.424700
		loss: 0.424900
		loss: 0.426000
		loss: 0.427200
		loss: 0.429300
		loss: 0.427200
		loss: 0.424200
		loss: 0.419900
		loss: 0.418500
		loss: 0.419800
		loss: 0.421200
		loss: 0.422300
		loss: 0.419800
		loss: 0.416900
		loss: 0.414800
		loss: 0.414800
		loss: 0.416000
		loss: 0.416500
		loss: 0.416000
		loss: 0.413700
		loss: 0.411700
		loss: 0.410700
		loss: 0.410800
		loss: 0.411300
		loss: 0.411400
		loss: 0.411100
		loss: 0.409700
		loss: 0.408300
		loss: 0.407400
	Overall the loss development was 2.916400 -> 0.407400

Training data for problem d-5-0.pddl in epoch 5:
model creation time: 14.606566190719604s
problem epoch data for epoch 5, problem epoch 1
	sampling search time: 15.289350986480713s
	during this search the following actions were chosen:
		unstack c e was chosen with probability 0.999970
		put-down c was chosen with probability 0.999456
		unstack e b was chosen with probability 0.999830
		put-down e was chosen with probability 0.963440
		pick-up d was chosen with probability 0.793824
		stack d c was chosen with probability 0.997180
		unstack b a was chosen with probability 0.867374
		stack b d was chosen with probability 0.964659
		pick-up e was chosen with probability 0.948023
		stack e b was chosen with probability 0.895454
		pick-up a was chosen with probability 0.854007
		stack a e was chosen with probability 0.921845
	training time: 76.9088065624237s
	during the training the following losses were computed:
		loss: 0.736000
		loss: 0.711300
		loss: 0.635500
		loss: 0.514500
		loss: 0.493400
		loss: 0.492100
		loss: 0.420500
		loss: 0.386400
		loss: 0.400800
		loss: 0.376600
		loss: 0.330100
		loss: 0.318500
		loss: 0.322800
		loss: 0.301600
		loss: 0.269900
		loss: 0.259300
		loss: 0.261400
		loss: 0.241300
		loss: 0.220800
		loss: 0.219300
		loss: 0.215000
		loss: 0.198900
		loss: 0.189200
		loss: 0.192700
		loss: 0.187500
		loss: 0.177600
		loss: 0.178000
		loss: 0.179700
		loss: 0.174700
		loss: 0.170700
		loss: 0.172900
		loss: 0.172900
		loss: 0.169000
		loss: 0.168200
		loss: 0.169900
		loss: 0.168500
		loss: 0.166100
		loss: 0.166800
		loss: 0.167300
		loss: 0.165500
		loss: 0.164700
		loss: 0.165600
		loss: 0.165000
		loss: 0.163700
		loss: 0.164000
		loss: 0.164200
		loss: 0.163100
		loss: 0.162800
		loss: 0.163100
		loss: 0.162500
		loss: 0.162000
		loss: 0.162200
		loss: 0.162000
		loss: 0.161500
		loss: 0.161600
		loss: 0.161400
		loss: 0.161000
		loss: 0.161100
		loss: 0.160900
		loss: 0.160600
		loss: 0.160600
		loss: 0.160500
		loss: 0.160300
		loss: 0.160300
		loss: 0.160100
		loss: 0.159900
		loss: 0.159900
		loss: 0.159800
		loss: 0.159600
		loss: 0.159600
		loss: 0.159400
		loss: 0.159300
		loss: 0.159300
		loss: 0.159100
		loss: 0.159100
		loss: 0.158900
		loss: 0.158800
		loss: 0.158800
		loss: 0.158600
		loss: 0.158600
		loss: 0.158500
		loss: 0.158400
		loss: 0.158300
		loss: 0.158200
		loss: 0.158200
		loss: 0.158100
		loss: 0.158000
		loss: 0.157900
		loss: 0.157800
		loss: 0.157800
		loss: 0.157700
		loss: 0.157600
		loss: 0.157500
		loss: 0.157500
		loss: 0.157400
		loss: 0.157300
		loss: 0.157300
		loss: 0.157200
		loss: 0.157100
		loss: 0.157100
		loss: 0.157000
		loss: 0.156900
		loss: 0.156900
		loss: 0.156800
		loss: 0.156700
		loss: 0.156700
		loss: 0.156600
		loss: 0.156500
		loss: 0.156500
		loss: 0.156400
		loss: 0.156300
		loss: 0.156300
		loss: 0.156200
		loss: 0.156200
		loss: 0.156100
		loss: 0.156000
		loss: 0.156000
		loss: 0.155900
		loss: 0.155900
		loss: 0.155800
		loss: 0.155700
		loss: 0.155700
		loss: 0.155600
		loss: 0.155500
		loss: 0.155500
		loss: 0.155400
		loss: 0.155400
		loss: 0.155300
		loss: 0.155200
		loss: 0.155200
		loss: 0.155100
		loss: 0.155100
		loss: 0.155000
		loss: 0.154900
		loss: 0.154900
		loss: 0.154800
		loss: 0.154800
		loss: 0.154700
		loss: 0.154600
		loss: 0.154600
		loss: 0.154500
		loss: 0.154500
		loss: 0.154400
		loss: 0.154400
		loss: 0.154300
		loss: 0.154200
		loss: 0.154200
		loss: 0.154100
		loss: 0.154100
		loss: 0.154000
		loss: 0.154000
		loss: 0.153900
		loss: 0.153900
		loss: 0.153800
		loss: 0.153800
		loss: 0.153700
		loss: 0.153700
		loss: 0.153600
		loss: 0.153500
		loss: 0.153500
		loss: 0.153400
		loss: 0.153400
		loss: 0.153300
		loss: 0.153300
		loss: 0.153200
		loss: 0.153200
		loss: 0.153100
		loss: 0.153100
		loss: 0.153000
		loss: 0.153000
		loss: 0.152900
		loss: 0.152900
		loss: 0.152800
		loss: 0.152800
		loss: 0.152700
		loss: 0.152700
		loss: 0.152600
		loss: 0.152600
		loss: 0.152500
		loss: 0.152500
		loss: 0.152400
		loss: 0.152400
		loss: 0.152300
		loss: 0.152300
		loss: 0.152300
		loss: 0.152200
		loss: 0.152200
		loss: 0.152100
		loss: 0.152100
		loss: 0.152000
		loss: 0.152000
		loss: 0.151900
		loss: 0.151900
		loss: 0.151900
		loss: 0.151800
		loss: 0.151800
		loss: 0.151700
		loss: 0.151700
		loss: 0.151600
		loss: 0.151600
		loss: 0.151500
		loss: 0.151500
		loss: 0.151400
		loss: 0.151400
		loss: 0.151400
		loss: 0.151300
		loss: 0.151300
		loss: 0.151200
		loss: 0.151200
		loss: 0.151100
		loss: 0.151100
		loss: 0.151100
		loss: 0.151000
		loss: 0.151000
		loss: 0.150900
		loss: 0.150900
		loss: 0.150800
		loss: 0.150800
		loss: 0.150700
		loss: 0.150700
		loss: 0.150700
		loss: 0.150600
		loss: 0.150600
		loss: 0.150500
		loss: 0.150500
		loss: 0.150400
		loss: 0.150400
		loss: 0.150400
		loss: 0.150300
		loss: 0.150300
		loss: 0.150200
		loss: 0.150200
		loss: 0.150100
		loss: 0.150100
		loss: 0.150100
		loss: 0.150000
		loss: 0.150000
		loss: 0.149900
		loss: 0.149900
		loss: 0.149900
		loss: 0.149800
		loss: 0.149800
		loss: 0.149700
		loss: 0.149700
		loss: 0.149700
		loss: 0.149600
		loss: 0.149600
		loss: 0.149500
		loss: 0.149500
		loss: 0.149500
		loss: 0.149400
		loss: 0.149400
		loss: 0.149300
		loss: 0.149300
		loss: 0.149300
		loss: 0.149200
		loss: 0.149200
		loss: 0.149100
		loss: 0.149100
		loss: 0.149100
		loss: 0.149000
		loss: 0.149000
		loss: 0.149000
		loss: 0.148900
		loss: 0.148900
		loss: 0.148800
		loss: 0.148800
		loss: 0.148800
		loss: 0.148700
		loss: 0.148700
		loss: 0.148600
		loss: 0.148600
		loss: 0.148600
		loss: 0.148500
		loss: 0.148500
		loss: 0.148500
		loss: 0.148400
		loss: 0.148400
		loss: 0.148300
		loss: 0.148300
		loss: 0.148300
		loss: 0.148200
		loss: 0.148200
		loss: 0.148200
		loss: 0.148100
		loss: 0.148100
		loss: 0.148000
		loss: 0.148000
		loss: 0.148000
		loss: 0.147900
		loss: 0.147900
		loss: 0.147900
		loss: 0.147800
		loss: 0.147800
		loss: 0.147700
		loss: 0.147700
		loss: 0.147700
		loss: 0.147600
		loss: 0.147600
		loss: 0.147600
	Overall the loss development was 0.736000 -> 0.147600

Training data for problem d-5-1.pddl in epoch 5:
model creation time: 15.403298377990723s
problem epoch data for epoch 5, problem epoch 1
	sampling search time: 13.681588172912598s
	during this search the following actions were chosen:
		pick-up c was chosen with probability 0.994585
		stack c b was chosen with probability 0.960398
		unstack c b was chosen with probability 0.995337
	training time: 73.34662818908691s
	during the training the following losses were computed:
		loss: 1.717700
		loss: 1.399400
		loss: 1.603700
		loss: 1.403100
		loss: 1.246300
		loss: 1.237900
		loss: 1.239600
		loss: 1.180300
		loss: 1.085100
		loss: 0.996100
		loss: 0.939200
		loss: 0.905300
		loss: 0.870200
		loss: 0.812900
		loss: 0.738900
		loss: 0.669700
		loss: 0.610700
		loss: 0.569400
		loss: 0.546900
		loss: 0.519700
		loss: 0.481200
		loss: 0.443500
		loss: 0.422900
		loss: 0.422300
		loss: 0.426500
		loss: 0.420300
		loss: 0.406000
		loss: 0.396100
		loss: 0.393400
		loss: 0.389300
		loss: 0.377800
		loss: 0.363600
		loss: 0.353500
		loss: 0.349800
		loss: 0.347400
		loss: 0.341900
		loss: 0.334500
		loss: 0.329400
		loss: 0.327600
		loss: 0.326200
		loss: 0.322500
		loss: 0.317100
		loss: 0.312400
		loss: 0.309300
		loss: 0.306200
		loss: 0.301800
		loss: 0.296300
		loss: 0.291500
		loss: 0.287800
		loss: 0.284300
		loss: 0.280000
		loss: 0.275500
		loss: 0.271700
		loss: 0.268800
		loss: 0.266200
		loss: 0.263200
		loss: 0.260100
		loss: 0.257500
		loss: 0.255400
		loss: 0.253300
		loss: 0.250800
		loss: 0.248400
		loss: 0.246400
		loss: 0.244600
		loss: 0.242600
		loss: 0.240400
		loss: 0.238400
		loss: 0.236600
		loss: 0.234800
		loss: 0.232900
		loss: 0.231000
		loss: 0.229400
		loss: 0.227800
		loss: 0.226300
		loss: 0.224700
		loss: 0.223300
		loss: 0.221900
		loss: 0.220600
		loss: 0.219100
		loss: 0.217800
		loss: 0.216600
		loss: 0.215400
		loss: 0.214100
		loss: 0.213000
		loss: 0.211900
		loss: 0.210800
		loss: 0.209700
		loss: 0.208700
		loss: 0.207800
		loss: 0.206800
		loss: 0.205900
		loss: 0.205000
		loss: 0.204200
		loss: 0.203300
		loss: 0.202500
		loss: 0.201800
		loss: 0.201000
		loss: 0.200300
		loss: 0.199600
		loss: 0.198900
		loss: 0.198200
		loss: 0.197600
		loss: 0.197000
		loss: 0.196400
		loss: 0.195800
		loss: 0.195200
		loss: 0.194700
		loss: 0.194200
		loss: 0.193700
		loss: 0.193200
		loss: 0.192700
		loss: 0.192200
		loss: 0.191800
		loss: 0.191400
		loss: 0.190900
		loss: 0.190500
		loss: 0.190100
		loss: 0.189700
		loss: 0.189300
		loss: 0.189000
		loss: 0.188600
		loss: 0.188300
		loss: 0.187900
		loss: 0.187600
		loss: 0.187300
		loss: 0.187000
		loss: 0.186700
		loss: 0.186400
		loss: 0.186100
		loss: 0.185900
		loss: 0.185600
		loss: 0.185300
		loss: 0.185100
		loss: 0.184800
		loss: 0.184600
		loss: 0.184400
		loss: 0.184200
		loss: 0.183900
		loss: 0.183700
		loss: 0.183500
		loss: 0.183300
		loss: 0.183100
		loss: 0.182900
		loss: 0.182700
		loss: 0.182600
		loss: 0.182400
		loss: 0.182200
		loss: 0.182000
		loss: 0.181900
		loss: 0.181700
		loss: 0.181500
		loss: 0.181400
		loss: 0.181200
		loss: 0.181100
		loss: 0.180900
		loss: 0.180800
		loss: 0.180700
		loss: 0.180500
		loss: 0.180400
		loss: 0.180300
		loss: 0.180100
		loss: 0.180000
		loss: 0.179900
		loss: 0.179800
		loss: 0.179600
		loss: 0.179500
		loss: 0.179400
		loss: 0.179300
		loss: 0.179200
		loss: 0.179100
		loss: 0.179000
		loss: 0.178900
		loss: 0.178800
		loss: 0.178700
		loss: 0.178600
		loss: 0.178500
		loss: 0.178400
		loss: 0.178300
		loss: 0.178200
		loss: 0.178100
		loss: 0.178000
		loss: 0.177900
		loss: 0.177800
		loss: 0.177700
		loss: 0.177600
		loss: 0.177500
		loss: 0.177400
		loss: 0.177300
		loss: 0.177200
		loss: 0.177100
		loss: 0.177000
		loss: 0.176900
		loss: 0.176800
		loss: 0.176700
		loss: 0.176700
		loss: 0.176600
		loss: 0.176500
		loss: 0.176400
		loss: 0.176400
		loss: 0.176300
		loss: 0.176200
		loss: 0.176200
		loss: 0.176100
		loss: 0.176000
		loss: 0.176000
		loss: 0.175900
		loss: 0.175800
		loss: 0.175800
		loss: 0.175700
		loss: 0.175600
		loss: 0.175600
		loss: 0.175500
		loss: 0.175500
		loss: 0.175400
		loss: 0.175400
		loss: 0.175300
		loss: 0.175300
		loss: 0.175200
		loss: 0.175100
		loss: 0.175100
		loss: 0.175000
		loss: 0.175000
		loss: 0.174900
		loss: 0.174900
		loss: 0.174900
		loss: 0.174800
		loss: 0.174800
		loss: 0.174700
		loss: 0.174700
		loss: 0.174600
		loss: 0.174600
		loss: 0.174500
		loss: 0.174500
		loss: 0.174400
		loss: 0.174400
		loss: 0.174400
		loss: 0.174300
		loss: 0.174300
		loss: 0.174200
		loss: 0.174200
		loss: 0.174100
		loss: 0.174100
		loss: 0.174100
		loss: 0.174000
		loss: 0.174000
		loss: 0.174000
		loss: 0.173900
		loss: 0.173900
		loss: 0.173800
		loss: 0.173800
		loss: 0.173800
		loss: 0.173700
		loss: 0.173700
		loss: 0.173700
		loss: 0.173600
		loss: 0.173600
		loss: 0.173500
		loss: 0.173500
		loss: 0.173500
		loss: 0.173400
		loss: 0.173400
		loss: 0.173400
		loss: 0.173300
		loss: 0.173300
		loss: 0.173300
		loss: 0.173200
		loss: 0.173200
		loss: 0.173200
		loss: 0.173100
		loss: 0.173100
		loss: 0.173100
		loss: 0.173000
		loss: 0.173000
		loss: 0.173000
		loss: 0.173000
		loss: 0.172900
		loss: 0.172900
		loss: 0.172900
		loss: 0.172800
		loss: 0.172800
		loss: 0.172800
		loss: 0.172700
		loss: 0.172700
		loss: 0.172700
		loss: 0.172700
		loss: 0.172600
		loss: 0.172600
		loss: 0.172600
		loss: 0.172500
		loss: 0.172500
		loss: 0.172500
		loss: 0.172400
		loss: 0.172400
		loss: 0.172400
		loss: 0.172400
		loss: 0.172300
		loss: 0.172300
		loss: 0.172300
		loss: 0.172200
		loss: 0.172200
	Overall the loss development was 1.717700 -> 0.172200

Epoch 6:
Training data for problem d-4-0.pddl in epoch 6:
model creation time: 9.809083938598633s
problem epoch data for epoch 6, problem epoch 1
	sampling search time: 8.938125848770142s
	during this search the following actions were chosen:
		pick-up b was chosen with probability 0.330492
		stack b a was chosen with probability 0.953723
		pick-up c was chosen with probability 0.996731
		stack c b was chosen with probability 0.997836
		pick-up d was chosen with probability 0.999282
		stack d c was chosen with probability 0.998099
	training time: 60.5531587600708s
	during the training the following losses were computed:
		loss: 0.227200
		loss: 0.220700
		loss: 0.219100
		loss: 0.218300
		loss: 0.217700
		loss: 0.217100
		loss: 0.216600
		loss: 0.216100
		loss: 0.215600
		loss: 0.215100
		loss: 0.214500
		loss: 0.214000
		loss: 0.213400
		loss: 0.212900
		loss: 0.212300
		loss: 0.211700
		loss: 0.211100
		loss: 0.210600
		loss: 0.210000
		loss: 0.209400
		loss: 0.208900
		loss: 0.208300
		loss: 0.207800
		loss: 0.207300
		loss: 0.206800
		loss: 0.206300
		loss: 0.205800
		loss: 0.205300
		loss: 0.204800
		loss: 0.204400
		loss: 0.203900
		loss: 0.203500
		loss: 0.203100
		loss: 0.202700
		loss: 0.202200
		loss: 0.201800
		loss: 0.201400
		loss: 0.201000
		loss: 0.200600
		loss: 0.200200
		loss: 0.199800
		loss: 0.199500
		loss: 0.199100
		loss: 0.198700
		loss: 0.198400
		loss: 0.198000
		loss: 0.197700
		loss: 0.197400
		loss: 0.197000
		loss: 0.196700
		loss: 0.196400
		loss: 0.196100
		loss: 0.195800
		loss: 0.195500
		loss: 0.195200
		loss: 0.194900
		loss: 0.194700
		loss: 0.194400
		loss: 0.194100
		loss: 0.193800
		loss: 0.193600
		loss: 0.193300
		loss: 0.193100
		loss: 0.192800
		loss: 0.192600
		loss: 0.192300
		loss: 0.192100
		loss: 0.191900
		loss: 0.191700
		loss: 0.191400
		loss: 0.191200
		loss: 0.191000
		loss: 0.190800
		loss: 0.190600
		loss: 0.190400
		loss: 0.190200
		loss: 0.190000
		loss: 0.189800
		loss: 0.189700
		loss: 0.189500
		loss: 0.189300
		loss: 0.189100
		loss: 0.189000
		loss: 0.188800
		loss: 0.188600
		loss: 0.188500
		loss: 0.188300
		loss: 0.188200
		loss: 0.188000
		loss: 0.187900
		loss: 0.187700
		loss: 0.187600
		loss: 0.187400
		loss: 0.187300
		loss: 0.187200
		loss: 0.187000
		loss: 0.186900
		loss: 0.186800
		loss: 0.186600
		loss: 0.186500
		loss: 0.186400
		loss: 0.186300
		loss: 0.186100
		loss: 0.186000
		loss: 0.185900
		loss: 0.185800
		loss: 0.185700
		loss: 0.185600
		loss: 0.185400
		loss: 0.185300
		loss: 0.185200
		loss: 0.185100
		loss: 0.185000
		loss: 0.184900
		loss: 0.184800
		loss: 0.184700
		loss: 0.184600
		loss: 0.184500
		loss: 0.184400
		loss: 0.184300
		loss: 0.184200
		loss: 0.184100
		loss: 0.184000
		loss: 0.183900
		loss: 0.183800
		loss: 0.183700
		loss: 0.183600
		loss: 0.183500
		loss: 0.183400
		loss: 0.183400
		loss: 0.183300
		loss: 0.183200
		loss: 0.183100
		loss: 0.183000
		loss: 0.182900
		loss: 0.182900
		loss: 0.182800
		loss: 0.182700
		loss: 0.182600
		loss: 0.182500
		loss: 0.182500
		loss: 0.182400
		loss: 0.182300
		loss: 0.182300
		loss: 0.182200
		loss: 0.182100
		loss: 0.182000
		loss: 0.182000
		loss: 0.181900
		loss: 0.181800
		loss: 0.181800
		loss: 0.181700
		loss: 0.181600
		loss: 0.181600
		loss: 0.181500
		loss: 0.181500
		loss: 0.181400
		loss: 0.181300
		loss: 0.181300
		loss: 0.181200
		loss: 0.181200
		loss: 0.181100
		loss: 0.181100
		loss: 0.181000
		loss: 0.181000
		loss: 0.180900
		loss: 0.180800
		loss: 0.180800
		loss: 0.180700
		loss: 0.180700
		loss: 0.180600
		loss: 0.180600
		loss: 0.180600
		loss: 0.180500
		loss: 0.180500
		loss: 0.180400
		loss: 0.180400
		loss: 0.180300
		loss: 0.180300
		loss: 0.180200
		loss: 0.180200
		loss: 0.180200
		loss: 0.180100
		loss: 0.180100
		loss: 0.180000
		loss: 0.180000
		loss: 0.180000
		loss: 0.179900
		loss: 0.179900
		loss: 0.179800
		loss: 0.179800
		loss: 0.179800
		loss: 0.179700
		loss: 0.179700
		loss: 0.179700
		loss: 0.179600
		loss: 0.179600
		loss: 0.179600
		loss: 0.179500
		loss: 0.179500
		loss: 0.179500
		loss: 0.179400
		loss: 0.179400
		loss: 0.179400
		loss: 0.179300
		loss: 0.179300
		loss: 0.179300
		loss: 0.179200
		loss: 0.179200
		loss: 0.179200
		loss: 0.179200
		loss: 0.179100
		loss: 0.179100
		loss: 0.179100
		loss: 0.179000
		loss: 0.179000
		loss: 0.179000
		loss: 0.179000
		loss: 0.178900
		loss: 0.178900
		loss: 0.178900
		loss: 0.178900
		loss: 0.178800
		loss: 0.178800
		loss: 0.178800
		loss: 0.178800
		loss: 0.178700
		loss: 0.178700
		loss: 0.178700
		loss: 0.178700
		loss: 0.178700
		loss: 0.178600
		loss: 0.178600
		loss: 0.178600
		loss: 0.178600
		loss: 0.178600
		loss: 0.178500
		loss: 0.178500
		loss: 0.178500
		loss: 0.178500
		loss: 0.178500
		loss: 0.178400
		loss: 0.178400
		loss: 0.178400
		loss: 0.178400
		loss: 0.178400
		loss: 0.178400
		loss: 0.178300
		loss: 0.178300
		loss: 0.178300
		loss: 0.178300
		loss: 0.178300
		loss: 0.178300
		loss: 0.178200
		loss: 0.178200
		loss: 0.178200
		loss: 0.178200
		loss: 0.178200
		loss: 0.178200
		loss: 0.178100
		loss: 0.178100
		loss: 0.178100
		loss: 0.178100
		loss: 0.178100
		loss: 0.178100
		loss: 0.178100
		loss: 0.178000
		loss: 0.178000
		loss: 0.178000
		loss: 0.178000
		loss: 0.178000
		loss: 0.178000
		loss: 0.178000
		loss: 0.178000
		loss: 0.177900
		loss: 0.177900
		loss: 0.177900
		loss: 0.177900
		loss: 0.177900
		loss: 0.177900
		loss: 0.177900
		loss: 0.177900
		loss: 0.177900
		loss: 0.177800
		loss: 0.177800
		loss: 0.177800
		loss: 0.177800
		loss: 0.177800
		loss: 0.177800
		loss: 0.177800
		loss: 0.177800
		loss: 0.177800
		loss: 0.177800
		loss: 0.177700
		loss: 0.177700
		loss: 0.177700
		loss: 0.177700
		loss: 0.177700
		loss: 0.177700
		loss: 0.177700
	Overall the loss development was 0.227200 -> 0.177700

Training data for problem d-4-2.pddl in epoch 6:
model creation time: 11.218352317810059s
problem epoch data for epoch 6, problem epoch 1
	sampling search time: 10.172227382659912s
	during this search the following actions were chosen:
		pick-up a was chosen with probability 0.992448
		stack a c was chosen with probability 0.761293
		pick-up d was chosen with probability 0.997527
		stack d a was chosen with probability 0.978812
	training time: 59.72901701927185s
	during the training the following losses were computed:
		loss: 2.266300
		loss: 2.071600
		loss: 1.887700
		loss: 1.713100
		loss: 1.558200
		loss: 1.402500
		loss: 1.256900
		loss: 1.124600
		loss: 1.004300
		loss: 0.894800
		loss: 0.799200
		loss: 0.716800
		loss: 0.647100
		loss: 0.588200
		loss: 0.537000
		loss: 0.493900
		loss: 0.461700
		loss: 0.443300
		loss: 0.434400
		loss: 0.432300
		loss: 0.436200
		loss: 0.444200
		loss: 0.453800
		loss: 0.461500
		loss: 0.465000
		loss: 0.462600
		loss: 0.454400
		loss: 0.441900
		loss: 0.426500
		loss: 0.410300
		loss: 0.394000
		loss: 0.378700
		loss: 0.364600
		loss: 0.351800
		loss: 0.340100
		loss: 0.329400
		loss: 0.319400
		loss: 0.309800
		loss: 0.300300
		loss: 0.291000
		loss: 0.281400
		loss: 0.271500
		loss: 0.261100
		loss: 0.250600
		loss: 0.240100
		loss: 0.229700
		loss: 0.219800
		loss: 0.210700
		loss: 0.202700
		loss: 0.196000
		loss: 0.190600
		loss: 0.186000
		loss: 0.181500
		loss: 0.176300
		loss: 0.170300
		loss: 0.163700
		loss: 0.157500
		loss: 0.152200
		loss: 0.147700
		loss: 0.143700
		loss: 0.139900
		loss: 0.135700
		loss: 0.131200
		loss: 0.126500
		loss: 0.121900
		loss: 0.117800
		loss: 0.114200
		loss: 0.111000
		loss: 0.107800
		loss: 0.104400
		loss: 0.100800
		loss: 0.097200
		loss: 0.094000
		loss: 0.091200
		loss: 0.088700
		loss: 0.086100
		loss: 0.083600
		loss: 0.081000
		loss: 0.078500
		loss: 0.076200
		loss: 0.074100
		loss: 0.072200
		loss: 0.070300
		loss: 0.068500
		loss: 0.066700
		loss: 0.065100
		loss: 0.063600
		loss: 0.062200
		loss: 0.060900
		loss: 0.059600
		loss: 0.058400
		loss: 0.057300
		loss: 0.056200
		loss: 0.055200
		loss: 0.054300
		loss: 0.053400
		loss: 0.052700
		loss: 0.051900
		loss: 0.051200
		loss: 0.050500
		loss: 0.049900
		loss: 0.049400
		loss: 0.048800
		loss: 0.048300
		loss: 0.047800
		loss: 0.047400
		loss: 0.046900
		loss: 0.046600
		loss: 0.046200
		loss: 0.045900
		loss: 0.045600
		loss: 0.045200
		loss: 0.044900
		loss: 0.044700
		loss: 0.044500
		loss: 0.044200
		loss: 0.044000
		loss: 0.043800
		loss: 0.043600
		loss: 0.043400
		loss: 0.043200
		loss: 0.043000
		loss: 0.042900
		loss: 0.042700
		loss: 0.042600
		loss: 0.042500
		loss: 0.042300
		loss: 0.042200
		loss: 0.042100
		loss: 0.042000
		loss: 0.041800
		loss: 0.041700
		loss: 0.041600
		loss: 0.041500
		loss: 0.041400
		loss: 0.041300
		loss: 0.041200
		loss: 0.041200
		loss: 0.041100
		loss: 0.041000
		loss: 0.040900
		loss: 0.040800
		loss: 0.040800
		loss: 0.040700
		loss: 0.040600
		loss: 0.040500
		loss: 0.040500
		loss: 0.040400
		loss: 0.040300
		loss: 0.040300
		loss: 0.040200
		loss: 0.040100
		loss: 0.040100
		loss: 0.040000
		loss: 0.039900
		loss: 0.039900
		loss: 0.039800
		loss: 0.039800
		loss: 0.039700
		loss: 0.039600
		loss: 0.039600
		loss: 0.039500
		loss: 0.039500
		loss: 0.039400
		loss: 0.039400
		loss: 0.039300
		loss: 0.039300
		loss: 0.039200
		loss: 0.039200
		loss: 0.039100
		loss: 0.039100
		loss: 0.039000
		loss: 0.039000
		loss: 0.038900
		loss: 0.038900
		loss: 0.038900
		loss: 0.038800
		loss: 0.038800
		loss: 0.038700
		loss: 0.038700
		loss: 0.038600
		loss: 0.038600
		loss: 0.038600
		loss: 0.038500
		loss: 0.038500
		loss: 0.038400
		loss: 0.038400
		loss: 0.038400
		loss: 0.038300
		loss: 0.038300
		loss: 0.038200
		loss: 0.038200
		loss: 0.038200
		loss: 0.038100
		loss: 0.038100
		loss: 0.038100
		loss: 0.038000
		loss: 0.038000
		loss: 0.038000
		loss: 0.037900
		loss: 0.037900
		loss: 0.037900
		loss: 0.037800
		loss: 0.037800
		loss: 0.037800
		loss: 0.037700
		loss: 0.037700
		loss: 0.037700
		loss: 0.037600
		loss: 0.037600
		loss: 0.037600
		loss: 0.037500
		loss: 0.037500
		loss: 0.037500
		loss: 0.037500
		loss: 0.037400
		loss: 0.037400
		loss: 0.037400
		loss: 0.037300
		loss: 0.037300
		loss: 0.037300
		loss: 0.037300
		loss: 0.037200
		loss: 0.037200
		loss: 0.037200
		loss: 0.037100
		loss: 0.037100
		loss: 0.037100
		loss: 0.037100
		loss: 0.037000
		loss: 0.037000
		loss: 0.037000
		loss: 0.037000
		loss: 0.036900
		loss: 0.036900
		loss: 0.036900
		loss: 0.036900
		loss: 0.036800
		loss: 0.036800
		loss: 0.036800
		loss: 0.036800
		loss: 0.036700
		loss: 0.036700
		loss: 0.036700
		loss: 0.036700
		loss: 0.036700
		loss: 0.036600
		loss: 0.036600
		loss: 0.036600
		loss: 0.036600
		loss: 0.036500
		loss: 0.036500
		loss: 0.036500
		loss: 0.036500
		loss: 0.036500
		loss: 0.036400
		loss: 0.036400
		loss: 0.036400
		loss: 0.036400
		loss: 0.036400
		loss: 0.036300
		loss: 0.036300
		loss: 0.036300
		loss: 0.036300
		loss: 0.036300
		loss: 0.036200
		loss: 0.036200
		loss: 0.036200
		loss: 0.036200
		loss: 0.036200
		loss: 0.036100
		loss: 0.036100
		loss: 0.036100
		loss: 0.036100
		loss: 0.036100
		loss: 0.036000
		loss: 0.036000
		loss: 0.036000
		loss: 0.036000
		loss: 0.036000
		loss: 0.036000
		loss: 0.035900
		loss: 0.035900
		loss: 0.035900
		loss: 0.035900
		loss: 0.035900
		loss: 0.035900
		loss: 0.035800
		loss: 0.035800
		loss: 0.035800
		loss: 0.035800
		loss: 0.035800
		loss: 0.035800
		loss: 0.035700
		loss: 0.035700
		loss: 0.035700
		loss: 0.035700
		loss: 0.035700
		loss: 0.035700
		loss: 0.035600
	Overall the loss development was 2.266300 -> 0.035600

Training data for problem d-4-1.pddl in epoch 6:
model creation time: 9.889890909194946s
problem epoch data for epoch 6, problem epoch 1
	sampling search time: 3.7818572521209717s
	during this search the following actions were chosen:
	training time: 59.67515468597412s
	during the training the following losses were computed:
		loss: 0.395400
		loss: 0.256600
		loss: 0.145200
		loss: 0.148500
		loss: 0.191400
		loss: 0.176500
		loss: 0.134400
		loss: 0.103600
		loss: 0.091100
		loss: 0.092100
		loss: 0.099600
		loss: 0.106700
		loss: 0.109000
		loss: 0.105100
		loss: 0.097400
		loss: 0.089700
		loss: 0.084800
		loss: 0.083500
		loss: 0.084900
		loss: 0.086700
		loss: 0.087100
		loss: 0.085200
		loss: 0.081500
		loss: 0.077100
		loss: 0.073100
		loss: 0.070400
		loss: 0.068900
		loss: 0.068300
		loss: 0.068000
		loss: 0.067400
		loss: 0.066300
		loss: 0.064800
		loss: 0.063000
		loss: 0.061300
		loss: 0.060000
		loss: 0.059100
		loss: 0.058600
		loss: 0.058400
		loss: 0.058100
		loss: 0.057800
		loss: 0.057200
		loss: 0.056400
		loss: 0.055600
		loss: 0.054800
		loss: 0.054200
		loss: 0.053700
		loss: 0.053300
		loss: 0.052900
		loss: 0.052600
		loss: 0.052200
		loss: 0.051800
		loss: 0.051300
		loss: 0.050800
		loss: 0.050400
		loss: 0.049900
		loss: 0.049600
		loss: 0.049300
		loss: 0.049100
		loss: 0.048800
		loss: 0.048400
		loss: 0.048100
		loss: 0.047800
		loss: 0.047500
		loss: 0.047200
		loss: 0.047000
		loss: 0.046700
		loss: 0.046500
		loss: 0.046200
		loss: 0.046000
		loss: 0.045700
		loss: 0.045500
		loss: 0.045300
		loss: 0.045100
		loss: 0.044900
		loss: 0.044700
		loss: 0.044500
		loss: 0.044300
		loss: 0.044100
		loss: 0.044000
		loss: 0.043800
		loss: 0.043700
		loss: 0.043500
		loss: 0.043400
		loss: 0.043300
		loss: 0.043200
		loss: 0.043100
		loss: 0.043000
		loss: 0.042900
		loss: 0.042900
		loss: 0.042800
		loss: 0.042700
		loss: 0.042700
		loss: 0.042600
		loss: 0.042600
		loss: 0.042500
		loss: 0.042500
		loss: 0.042500
		loss: 0.042400
		loss: 0.042400
		loss: 0.042400
		loss: 0.042300
		loss: 0.042300
		loss: 0.042300
		loss: 0.042300
		loss: 0.042200
		loss: 0.042200
		loss: 0.042200
		loss: 0.042200
		loss: 0.042100
		loss: 0.042100
		loss: 0.042100
		loss: 0.042100
		loss: 0.042000
		loss: 0.042000
		loss: 0.042000
		loss: 0.042000
		loss: 0.041900
		loss: 0.041900
		loss: 0.041900
		loss: 0.041900
		loss: 0.041900
		loss: 0.041800
		loss: 0.041800
		loss: 0.041800
		loss: 0.041800
		loss: 0.041800
		loss: 0.041700
		loss: 0.041700
		loss: 0.041700
		loss: 0.041700
		loss: 0.041700
		loss: 0.041600
		loss: 0.041600
		loss: 0.041600
		loss: 0.041600
		loss: 0.041600
		loss: 0.041600
		loss: 0.041500
		loss: 0.041500
		loss: 0.041500
		loss: 0.041500
		loss: 0.041500
		loss: 0.041400
		loss: 0.041400
		loss: 0.041400
		loss: 0.041400
		loss: 0.041400
		loss: 0.041400
		loss: 0.041300
		loss: 0.041300
		loss: 0.041300
		loss: 0.041300
		loss: 0.041300
		loss: 0.041300
		loss: 0.041200
		loss: 0.041200
		loss: 0.041200
		loss: 0.041200
		loss: 0.041200
		loss: 0.041100
		loss: 0.041100
		loss: 0.041100
		loss: 0.041100
		loss: 0.041100
		loss: 0.041100
		loss: 0.041000
		loss: 0.041000
		loss: 0.041000
		loss: 0.041000
		loss: 0.041000
		loss: 0.041000
		loss: 0.040900
		loss: 0.040900
		loss: 0.040900
		loss: 0.040900
		loss: 0.040900
		loss: 0.040900
		loss: 0.040800
		loss: 0.040800
		loss: 0.040800
		loss: 0.040800
		loss: 0.040800
		loss: 0.040800
		loss: 0.040700
		loss: 0.040700
		loss: 0.040700
		loss: 0.040700
		loss: 0.040700
		loss: 0.040700
		loss: 0.040600
		loss: 0.040600
		loss: 0.040600
		loss: 0.040600
		loss: 0.040600
		loss: 0.040600
		loss: 0.040500
		loss: 0.040500
		loss: 0.040500
		loss: 0.040500
		loss: 0.040500
		loss: 0.040500
		loss: 0.040400
		loss: 0.040400
		loss: 0.040400
		loss: 0.040400
		loss: 0.040400
		loss: 0.040400
		loss: 0.040300
		loss: 0.040300
		loss: 0.040300
		loss: 0.040300
		loss: 0.040300
		loss: 0.040300
		loss: 0.040200
		loss: 0.040200
		loss: 0.040200
		loss: 0.040200
		loss: 0.040200
		loss: 0.040200
		loss: 0.040100
		loss: 0.040100
		loss: 0.040100
		loss: 0.040100
		loss: 0.040100
		loss: 0.040100
		loss: 0.040000
		loss: 0.040000
		loss: 0.040000
		loss: 0.040000
		loss: 0.040000
		loss: 0.040000
		loss: 0.040000
		loss: 0.039900
		loss: 0.039900
		loss: 0.039900
		loss: 0.039900
		loss: 0.039900
		loss: 0.039900
		loss: 0.039800
		loss: 0.039800
		loss: 0.039800
		loss: 0.039800
		loss: 0.039800
		loss: 0.039800
		loss: 0.039700
		loss: 0.039700
		loss: 0.039700
		loss: 0.039700
		loss: 0.039700
		loss: 0.039700
		loss: 0.039700
		loss: 0.039600
		loss: 0.039600
		loss: 0.039600
		loss: 0.039600
		loss: 0.039600
		loss: 0.039600
		loss: 0.039500
		loss: 0.039500
		loss: 0.039500
		loss: 0.039500
		loss: 0.039500
		loss: 0.039500
		loss: 0.039500
		loss: 0.039400
		loss: 0.039400
		loss: 0.039400
		loss: 0.039400
		loss: 0.039400
		loss: 0.039400
		loss: 0.039300
		loss: 0.039300
		loss: 0.039300
		loss: 0.039300
		loss: 0.039300
		loss: 0.039300
		loss: 0.039300
		loss: 0.039200
		loss: 0.039200
		loss: 0.039200
		loss: 0.039200
		loss: 0.039200
		loss: 0.039200
		loss: 0.039200
		loss: 0.039100
		loss: 0.039100
		loss: 0.039100
		loss: 0.039100
		loss: 0.039100
		loss: 0.039100
		loss: 0.039100
		loss: 0.039000
		loss: 0.039000
		loss: 0.039000
		loss: 0.039000
		loss: 0.039000
		loss: 0.039000
		loss: 0.039000
		loss: 0.038900
		loss: 0.038900
	Overall the loss development was 0.395400 -> 0.038900

Training data for problem d-5-2.pddl in epoch 6:
model creation time: 14.912246704101562s
problem epoch data for epoch 6, problem epoch 1
	sampling search time: 5.1637444496154785s
	during this search the following actions were chosen:
	training time: 74.02757954597473s
	during the training the following losses were computed:
		loss: 2.545000
		loss: 2.379900
		loss: 2.228400
		loss: 2.085000
		loss: 1.949900
		loss: 1.828600
		loss: 1.711000
		loss: 1.602400
		loss: 1.502300
		loss: 1.410700
		loss: 1.328000
		loss: 1.253700
		loss: 1.188700
		loss: 1.132900
		loss: 1.086600
		loss: 1.049700
		loss: 1.021600
		loss: 1.001000
		loss: 0.987200
		loss: 0.979100
		loss: 0.975000
		loss: 0.973500
		loss: 0.973700
		loss: 0.974800
		loss: 0.975800
		loss: 0.976300
		loss: 0.975900
		loss: 0.974600
		loss: 0.972400
		loss: 0.969300
		loss: 0.965300
		loss: 0.960900
		loss: 0.956200
		loss: 0.951200
		loss: 0.946000
		loss: 0.940700
		loss: 0.935300
		loss: 0.929800
		loss: 0.924500
		loss: 0.919400
		loss: 0.914500
		loss: 0.909900
		loss: 0.905500
		loss: 0.901400
		loss: 0.897500
		loss: 0.893700
		loss: 0.890100
		loss: 0.886500
		loss: 0.883000
		loss: 0.879400
		loss: 0.875800
		loss: 0.872000
		loss: 0.868100
		loss: 0.864000
		loss: 0.859700
		loss: 0.855300
		loss: 0.850800
		loss: 0.846300
		loss: 0.841700
		loss: 0.837000
		loss: 0.832400
		loss: 0.827700
		loss: 0.822900
		loss: 0.818000
		loss: 0.813100
		loss: 0.808100
		loss: 0.803100
		loss: 0.798000
		loss: 0.792800
		loss: 0.787800
		loss: 0.782900
		loss: 0.778000
		loss: 0.773200
		loss: 0.768400
		loss: 0.763600
		loss: 0.758800
		loss: 0.753900
		loss: 0.749000
		loss: 0.744000
		loss: 0.739000
		loss: 0.733900
		loss: 0.728700
		loss: 0.723500
		loss: 0.718300
		loss: 0.713300
		loss: 0.708200
		loss: 0.703200
		loss: 0.698300
		loss: 0.693600
		loss: 0.688800
		loss: 0.684000
		loss: 0.679300
		loss: 0.674600
		loss: 0.669900
		loss: 0.665200
		loss: 0.660600
		loss: 0.656200
		loss: 0.652300
		loss: 0.649500
		loss: 0.646200
		loss: 0.639700
		loss: 0.634800
		loss: 0.632600
		loss: 0.628100
		loss: 0.622700
		loss: 0.619700
		loss: 0.616700
		loss: 0.611900
		loss: 0.607300
		loss: 0.604700
		loss: 0.601400
		loss: 0.596200
		loss: 0.592600
		loss: 0.590000
		loss: 0.585800
		loss: 0.581100
		loss: 0.577600
		loss: 0.574800
		loss: 0.571600
		loss: 0.567300
		loss: 0.563100
		loss: 0.559700
		loss: 0.557000
		loss: 0.554700
		loss: 0.551700
		loss: 0.547800
		loss: 0.543600
		loss: 0.540700
		loss: 0.538500
		loss: 0.536200
		loss: 0.533200
		loss: 0.529400
		loss: 0.525900
		loss: 0.523200
		loss: 0.520900
		loss: 0.518800
		loss: 0.516700
		loss: 0.514800
		loss: 0.512100
		loss: 0.509100
		loss: 0.505100
		loss: 0.501700
		loss: 0.499700
		loss: 0.498300
		loss: 0.496800
		loss: 0.494200
		loss: 0.491200
		loss: 0.488200
		loss: 0.485900
		loss: 0.484200
		loss: 0.482700
		loss: 0.481500
		loss: 0.480400
		loss: 0.479600
		loss: 0.477600
		loss: 0.474900
		loss: 0.471600
		loss: 0.468900
		loss: 0.467600
		loss: 0.466900
		loss: 0.466400
		loss: 0.465200
		loss: 0.463400
		loss: 0.460600
		loss: 0.457800
		loss: 0.455800
		loss: 0.454600
		loss: 0.454000
		loss: 0.453500
		loss: 0.452900
		loss: 0.451700
		loss: 0.449900
		loss: 0.447500
		loss: 0.445200
		loss: 0.443700
		loss: 0.442800
		loss: 0.442300
		loss: 0.442100
		loss: 0.441900
		loss: 0.441100
		loss: 0.439600
		loss: 0.437200
		loss: 0.435100
		loss: 0.433500
		loss: 0.432600
		loss: 0.432000
		loss: 0.432000
		loss: 0.432100
		loss: 0.431800
		loss: 0.431000
		loss: 0.429000
		loss: 0.426700
		loss: 0.424900
		loss: 0.423900
		loss: 0.423600
		loss: 0.423500
		loss: 0.423500
		loss: 0.423200
		loss: 0.422500
		loss: 0.421100
		loss: 0.419400
		loss: 0.417800
		loss: 0.416500
		loss: 0.415700
		loss: 0.415300
		loss: 0.415000
		loss: 0.414900
		loss: 0.415000
		loss: 0.415000
		loss: 0.414900
		loss: 0.414100
		loss: 0.412700
		loss: 0.410800
		loss: 0.409100
		loss: 0.407900
		loss: 0.407300
		loss: 0.407100
		loss: 0.407100
		loss: 0.407300
		loss: 0.407200
		loss: 0.407000
		loss: 0.406300
		loss: 0.405500
		loss: 0.404200
		loss: 0.402800
		loss: 0.401600
		loss: 0.400700
		loss: 0.400300
		loss: 0.400200
		loss: 0.400200
		loss: 0.400400
		loss: 0.400800
		loss: 0.401300
		loss: 0.402000
		loss: 0.401700
		loss: 0.400900
		loss: 0.398600
		loss: 0.396500
		loss: 0.395100
		loss: 0.394800
		loss: 0.395300
		loss: 0.396000
		loss: 0.396700
		loss: 0.396400
		loss: 0.395800
		loss: 0.394100
		loss: 0.392600
		loss: 0.391500
		loss: 0.391000
		loss: 0.391100
		loss: 0.391400
		loss: 0.392000
		loss: 0.392500
		loss: 0.393100
		loss: 0.392600
		loss: 0.392000
		loss: 0.390500
		loss: 0.389000
		loss: 0.387800
		loss: 0.387100
		loss: 0.386800
		loss: 0.387000
		loss: 0.387400
		loss: 0.387800
		loss: 0.388500
		loss: 0.388800
		loss: 0.389200
		loss: 0.388200
		loss: 0.387100
		loss: 0.385200
		loss: 0.384000
		loss: 0.383300
		loss: 0.383000
		loss: 0.383200
		loss: 0.383500
		loss: 0.384100
		loss: 0.384300
		loss: 0.384700
		loss: 0.384300
		loss: 0.383900
		loss: 0.382900
		loss: 0.381900
		loss: 0.380900
		loss: 0.380100
		loss: 0.379600
		loss: 0.379200
		loss: 0.379000
		loss: 0.378900
		loss: 0.378900
		loss: 0.379100
		loss: 0.379800
		loss: 0.380700
		loss: 0.382600
		loss: 0.384000
		loss: 0.386300
		loss: 0.385500
		loss: 0.384100
		loss: 0.379500
		loss: 0.376300
		loss: 0.375800
	Overall the loss development was 2.545000 -> 0.375800

Training data for problem d-5-0.pddl in epoch 6:
model creation time: 14.86710810661316s
problem epoch data for epoch 6, problem epoch 1
	sampling search time: 6.418503046035767s
	during this search the following actions were chosen:
	training time: 75.23553013801575s
	during the training the following losses were computed:
		loss: 0.959600
		loss: 0.906300
		loss: 0.834000
		loss: 0.707800
		loss: 0.628000
		loss: 0.638900
		loss: 0.556900
		loss: 0.496900
		loss: 0.499300
		loss: 0.506300
		loss: 0.442100
		loss: 0.413900
		loss: 0.428900
		loss: 0.390900
		loss: 0.348700
		loss: 0.344700
		loss: 0.332000
		loss: 0.295500
		loss: 0.286500
		loss: 0.282300
		loss: 0.256000
		loss: 0.237300
		loss: 0.237700
		loss: 0.223600
		loss: 0.209000
		loss: 0.209200
		loss: 0.201800
		loss: 0.189800
		loss: 0.189400
		loss: 0.188600
		loss: 0.180300
		loss: 0.180100
		loss: 0.181200
		loss: 0.176500
		loss: 0.174700
		loss: 0.177000
		loss: 0.175000
		loss: 0.172400
		loss: 0.173800
		loss: 0.173700
		loss: 0.171300
		loss: 0.171500
		loss: 0.172200
		loss: 0.170500
		loss: 0.169900
		loss: 0.170600
		loss: 0.169500
		loss: 0.168700
		loss: 0.169200
		loss: 0.168500
		loss: 0.167600
		loss: 0.167800
		loss: 0.167400
		loss: 0.166600
		loss: 0.166700
		loss: 0.166400
		loss: 0.165700
		loss: 0.165700
		loss: 0.165500
		loss: 0.164900
		loss: 0.164900
		loss: 0.164700
		loss: 0.164300
		loss: 0.164200
		loss: 0.164000
		loss: 0.163600
		loss: 0.163600
		loss: 0.163400
		loss: 0.163200
		loss: 0.163100
		loss: 0.162900
		loss: 0.162800
		loss: 0.162700
		loss: 0.162500
		loss: 0.162400
		loss: 0.162300
		loss: 0.162200
		loss: 0.162100
		loss: 0.162000
		loss: 0.161900
		loss: 0.161800
		loss: 0.161700
		loss: 0.161600
		loss: 0.161500
		loss: 0.161400
		loss: 0.161300
		loss: 0.161200
		loss: 0.161100
		loss: 0.161000
		loss: 0.160900
		loss: 0.160800
		loss: 0.160700
		loss: 0.160700
		loss: 0.160600
		loss: 0.160500
		loss: 0.160400
		loss: 0.160300
		loss: 0.160300
		loss: 0.160200
		loss: 0.160100
		loss: 0.160000
		loss: 0.160000
		loss: 0.159900
		loss: 0.159800
		loss: 0.159700
		loss: 0.159700
		loss: 0.159600
		loss: 0.159500
		loss: 0.159400
		loss: 0.159400
		loss: 0.159300
		loss: 0.159200
		loss: 0.159100
		loss: 0.159100
		loss: 0.159000
		loss: 0.158900
		loss: 0.158900
		loss: 0.158800
		loss: 0.158700
		loss: 0.158700
		loss: 0.158600
		loss: 0.158600
		loss: 0.158500
		loss: 0.158400
		loss: 0.158400
		loss: 0.158300
		loss: 0.158200
		loss: 0.158200
		loss: 0.158100
		loss: 0.158000
		loss: 0.158000
		loss: 0.157900
		loss: 0.157900
		loss: 0.157800
		loss: 0.157700
		loss: 0.157700
		loss: 0.157600
		loss: 0.157500
		loss: 0.157500
		loss: 0.157400
		loss: 0.157400
		loss: 0.157300
		loss: 0.157200
		loss: 0.157200
		loss: 0.157100
		loss: 0.157100
		loss: 0.157000
		loss: 0.156900
		loss: 0.156900
		loss: 0.156800
		loss: 0.156800
		loss: 0.156700
		loss: 0.156600
		loss: 0.156600
		loss: 0.156500
		loss: 0.156500
		loss: 0.156400
		loss: 0.156300
		loss: 0.156300
		loss: 0.156200
		loss: 0.156200
		loss: 0.156100
		loss: 0.156000
		loss: 0.156000
		loss: 0.155900
		loss: 0.155900
		loss: 0.155800
		loss: 0.155800
		loss: 0.155700
		loss: 0.155600
		loss: 0.155600
		loss: 0.155500
		loss: 0.155500
		loss: 0.155400
		loss: 0.155400
		loss: 0.155300
		loss: 0.155200
		loss: 0.155200
		loss: 0.155100
		loss: 0.155100
		loss: 0.155000
		loss: 0.155000
		loss: 0.154900
		loss: 0.154900
		loss: 0.154800
		loss: 0.154800
		loss: 0.154700
		loss: 0.154600
		loss: 0.154600
		loss: 0.154500
		loss: 0.154500
		loss: 0.154400
		loss: 0.154400
		loss: 0.154300
		loss: 0.154300
		loss: 0.154200
		loss: 0.154100
		loss: 0.154100
		loss: 0.154000
		loss: 0.154000
		loss: 0.153900
		loss: 0.153900
		loss: 0.153800
		loss: 0.153800
		loss: 0.153700
		loss: 0.153700
		loss: 0.153600
		loss: 0.153600
		loss: 0.153500
		loss: 0.153500
		loss: 0.153400
		loss: 0.153400
		loss: 0.153300
		loss: 0.153300
		loss: 0.153200
		loss: 0.153100
		loss: 0.153100
		loss: 0.153000
		loss: 0.153000
		loss: 0.152900
		loss: 0.152900
		loss: 0.152800
		loss: 0.152800
		loss: 0.152700
		loss: 0.152700
		loss: 0.152700
		loss: 0.152600
		loss: 0.152600
		loss: 0.152500
		loss: 0.152500
		loss: 0.152400
		loss: 0.152400
		loss: 0.152300
		loss: 0.152300
		loss: 0.152200
		loss: 0.152200
		loss: 0.152100
		loss: 0.152100
		loss: 0.152000
		loss: 0.152000
		loss: 0.151900
		loss: 0.151900
		loss: 0.151800
		loss: 0.151800
		loss: 0.151700
		loss: 0.151700
		loss: 0.151700
		loss: 0.151600
		loss: 0.151600
		loss: 0.151500
		loss: 0.151500
		loss: 0.151400
		loss: 0.151400
		loss: 0.151300
		loss: 0.151300
		loss: 0.151200
		loss: 0.151200
		loss: 0.151200
		loss: 0.151100
		loss: 0.151100
		loss: 0.151000
		loss: 0.151000
		loss: 0.150900
		loss: 0.150900
		loss: 0.150800
		loss: 0.150800
		loss: 0.150700
		loss: 0.150700
		loss: 0.150700
		loss: 0.150600
		loss: 0.150600
		loss: 0.150500
		loss: 0.150500
		loss: 0.150400
		loss: 0.150400
		loss: 0.150300
		loss: 0.150300
		loss: 0.150300
		loss: 0.150200
		loss: 0.150200
		loss: 0.150100
		loss: 0.150100
		loss: 0.150000
		loss: 0.150000
		loss: 0.149900
		loss: 0.149900
		loss: 0.149900
		loss: 0.149800
		loss: 0.149800
		loss: 0.149700
		loss: 0.149700
		loss: 0.149600
		loss: 0.149600
		loss: 0.149500
		loss: 0.149500
		loss: 0.149500
		loss: 0.149400
		loss: 0.149400
		loss: 0.149300
		loss: 0.149300
	Overall the loss development was 0.959600 -> 0.149300

Training data for problem d-5-1.pddl in epoch 6:
model creation time: 14.891790866851807s
problem epoch data for epoch 6, problem epoch 1
	sampling search time: 7.532016277313232s
	during this search the following actions were chosen:
		pick-up c was chosen with probability 0.946052
		stack c b was chosen with probability 0.869830
		unstack c b was chosen with probability 0.987059
	training time: 73.86562848091125s
	during the training the following losses were computed:
		loss: 1.496300
		loss: 1.384600
		loss: 1.385500
		loss: 1.223600
		loss: 1.120800
		loss: 1.125500
		loss: 1.095600
		loss: 1.003000
		loss: 0.938500
		loss: 0.908400
		loss: 0.888000
		loss: 0.857000
		loss: 0.811300
		loss: 0.758800
		loss: 0.714900
		loss: 0.696700
		loss: 0.681500
		loss: 0.647700
		loss: 0.606500
		loss: 0.581500
		loss: 0.568500
		loss: 0.552600
		loss: 0.529600
		loss: 0.505100
		loss: 0.486500
		loss: 0.475900
		loss: 0.466700
		loss: 0.451200
		loss: 0.434800
		loss: 0.424800
		loss: 0.420500
		loss: 0.415000
		loss: 0.406100
		loss: 0.397800
		loss: 0.393000
		loss: 0.389200
		loss: 0.382700
		loss: 0.374900
		loss: 0.368600
		loss: 0.364100
		loss: 0.359200
		loss: 0.352800
		loss: 0.346100
		loss: 0.340600
		loss: 0.335900
		loss: 0.330700
		loss: 0.324700
		loss: 0.319100
		loss: 0.314800
		loss: 0.310800
		loss: 0.306300
		loss: 0.301900
		loss: 0.298300
		loss: 0.295100
		loss: 0.291600
		loss: 0.287800
		loss: 0.284100
		loss: 0.280900
		loss: 0.277800
		loss: 0.274400
		loss: 0.270900
		loss: 0.267600
		loss: 0.264600
		loss: 0.261700
		loss: 0.258700
		loss: 0.256300
		loss: 0.253900
		loss: 0.251600
		loss: 0.249200
		loss: 0.246700
		loss: 0.244300
		loss: 0.242000
		loss: 0.239900
		loss: 0.237900
		loss: 0.235900
		loss: 0.234000
		loss: 0.232300
		loss: 0.230500
		loss: 0.228700
		loss: 0.227000
		loss: 0.225500
		loss: 0.223900
		loss: 0.222500
		loss: 0.221000
		loss: 0.219600
		loss: 0.218200
		loss: 0.216900
		loss: 0.215600
		loss: 0.214400
		loss: 0.213200
		loss: 0.212000
		loss: 0.210900
		loss: 0.209800
		loss: 0.208700
		loss: 0.207700
		loss: 0.206700
		loss: 0.205700
		loss: 0.204800
		loss: 0.203900
		loss: 0.203000
		loss: 0.202200
		loss: 0.201300
		loss: 0.200500
		loss: 0.199800
		loss: 0.199000
		loss: 0.198300
		loss: 0.197600
		loss: 0.196900
		loss: 0.196300
		loss: 0.195700
		loss: 0.195100
		loss: 0.194500
		loss: 0.194000
		loss: 0.193400
		loss: 0.192900
		loss: 0.192400
		loss: 0.191900
		loss: 0.191400
		loss: 0.191000
		loss: 0.190500
		loss: 0.190100
		loss: 0.189700
		loss: 0.189300
		loss: 0.188900
		loss: 0.188500
		loss: 0.188100
		loss: 0.187700
		loss: 0.187400
		loss: 0.187000
		loss: 0.186700
		loss: 0.186300
		loss: 0.185800
		loss: 0.185400
		loss: 0.184800
		loss: 0.184300
		loss: 0.183800
		loss: 0.183200
		loss: 0.182700
		loss: 0.182200
		loss: 0.181700
		loss: 0.181200
		loss: 0.180700
		loss: 0.180300
		loss: 0.179900
		loss: 0.179600
		loss: 0.179200
		loss: 0.178900
		loss: 0.178600
		loss: 0.178400
		loss: 0.178100
		loss: 0.177900
		loss: 0.177700
		loss: 0.177400
		loss: 0.177200
		loss: 0.177100
		loss: 0.176900
		loss: 0.176700
		loss: 0.176500
		loss: 0.176400
		loss: 0.176200
		loss: 0.176100
		loss: 0.176000
		loss: 0.175800
		loss: 0.175700
		loss: 0.175600
		loss: 0.175500
		loss: 0.175400
		loss: 0.175300
		loss: 0.175200
		loss: 0.175100
		loss: 0.175000
		loss: 0.174900
		loss: 0.174800
		loss: 0.174700
		loss: 0.174600
		loss: 0.174500
		loss: 0.174500
		loss: 0.174400
		loss: 0.174300
		loss: 0.174200
		loss: 0.174200
		loss: 0.174100
		loss: 0.174000
		loss: 0.174000
		loss: 0.173900
		loss: 0.173800
		loss: 0.173800
		loss: 0.173700
		loss: 0.173700
		loss: 0.173600
		loss: 0.173500
		loss: 0.173500
		loss: 0.173400
		loss: 0.173400
		loss: 0.173300
		loss: 0.173300
		loss: 0.173200
		loss: 0.173200
		loss: 0.173100
		loss: 0.173100
		loss: 0.173000
		loss: 0.173000
		loss: 0.172900
		loss: 0.172900
		loss: 0.172800
		loss: 0.172800
		loss: 0.172700
		loss: 0.172700
		loss: 0.172600
		loss: 0.172600
		loss: 0.172500
		loss: 0.172500
		loss: 0.172500
		loss: 0.172400
		loss: 0.172400
		loss: 0.172300
		loss: 0.172300
		loss: 0.172200
		loss: 0.172200
		loss: 0.172200
		loss: 0.172100
		loss: 0.172100
		loss: 0.172000
		loss: 0.172000
		loss: 0.172000
		loss: 0.171900
		loss: 0.171900
		loss: 0.171800
		loss: 0.171800
		loss: 0.171800
		loss: 0.171700
		loss: 0.171700
		loss: 0.171600
		loss: 0.171600
		loss: 0.171600
		loss: 0.171500
		loss: 0.171500
		loss: 0.171500
		loss: 0.171400
		loss: 0.171400
		loss: 0.171400
		loss: 0.171300
		loss: 0.171300
		loss: 0.171200
		loss: 0.171200
		loss: 0.171200
		loss: 0.171100
		loss: 0.171100
		loss: 0.171100
		loss: 0.171000
		loss: 0.171000
		loss: 0.171000
		loss: 0.170900
		loss: 0.170900
		loss: 0.170900
		loss: 0.170800
		loss: 0.170800
		loss: 0.170800
		loss: 0.170700
		loss: 0.170700
		loss: 0.170700
		loss: 0.170600
		loss: 0.170600
		loss: 0.170600
		loss: 0.170500
		loss: 0.170500
		loss: 0.170500
		loss: 0.170400
		loss: 0.170400
		loss: 0.170400
		loss: 0.170300
		loss: 0.170300
		loss: 0.170300
		loss: 0.170200
		loss: 0.170200
		loss: 0.170200
		loss: 0.170200
		loss: 0.170100
		loss: 0.170100
		loss: 0.170100
		loss: 0.170000
		loss: 0.170000
		loss: 0.170000
		loss: 0.169900
		loss: 0.169900
		loss: 0.169900
		loss: 0.169800
		loss: 0.169800
		loss: 0.169800
		loss: 0.169800
		loss: 0.169700
		loss: 0.169700
		loss: 0.169700
		loss: 0.169600
		loss: 0.169600
		loss: 0.169600
		loss: 0.169500
		loss: 0.169500
		loss: 0.169500
		loss: 0.169500
	Overall the loss development was 1.496300 -> 0.169500

Epoch 7:
Training data for problem d-4-0.pddl in epoch 7:
model creation time: 9.912044048309326s
problem epoch data for epoch 7, problem epoch 1
	sampling search time: 3.6281721591949463s
	during this search the following actions were chosen:
		pick-up b was chosen with probability 0.329377
		stack b a was chosen with probability 0.993014
		pick-up c was chosen with probability 0.999189
		stack c b was chosen with probability 0.999464
		pick-up d was chosen with probability 0.999717
		stack d c was chosen with probability 0.999269
	training time: 60.17219257354736s
	during the training the following losses were computed:
		loss: 0.219700
		loss: 0.217400
		loss: 0.216600
		loss: 0.215900
		loss: 0.215200
		loss: 0.214500
		loss: 0.213800
		loss: 0.213000
		loss: 0.212300
		loss: 0.211600
		loss: 0.210900
		loss: 0.210100
		loss: 0.209400
		loss: 0.208700
		loss: 0.208000
		loss: 0.207300
		loss: 0.206600
		loss: 0.205900
		loss: 0.205200
		loss: 0.204500
		loss: 0.203900
		loss: 0.203200
		loss: 0.202600
		loss: 0.202000
		loss: 0.201400
		loss: 0.200800
		loss: 0.200200
		loss: 0.199700
		loss: 0.199100
		loss: 0.198600
		loss: 0.198100
		loss: 0.197600
		loss: 0.197100
		loss: 0.196600
		loss: 0.196100
		loss: 0.195600
		loss: 0.195200
		loss: 0.194800
		loss: 0.194300
		loss: 0.193900
		loss: 0.193500
		loss: 0.193100
		loss: 0.192700
		loss: 0.192400
		loss: 0.192000
		loss: 0.191600
		loss: 0.191300
		loss: 0.191000
		loss: 0.190700
		loss: 0.190300
		loss: 0.190100
		loss: 0.189800
		loss: 0.189500
		loss: 0.189200
		loss: 0.188900
		loss: 0.188700
		loss: 0.188400
		loss: 0.188200
		loss: 0.187900
		loss: 0.187700
		loss: 0.187500
		loss: 0.187200
		loss: 0.187000
		loss: 0.186800
		loss: 0.186600
		loss: 0.186400
		loss: 0.186200
		loss: 0.186000
		loss: 0.185800
		loss: 0.185600
		loss: 0.185500
		loss: 0.185300
		loss: 0.185100
		loss: 0.184900
		loss: 0.184800
		loss: 0.184600
		loss: 0.184500
		loss: 0.184300
		loss: 0.184200
		loss: 0.184000
		loss: 0.183900
		loss: 0.183700
		loss: 0.183600
		loss: 0.183500
		loss: 0.183300
		loss: 0.183200
		loss: 0.183100
		loss: 0.183000
		loss: 0.182900
		loss: 0.182700
		loss: 0.182600
		loss: 0.182500
		loss: 0.182400
		loss: 0.182300
		loss: 0.182200
		loss: 0.182100
		loss: 0.182000
		loss: 0.181900
		loss: 0.181800
		loss: 0.181700
		loss: 0.181600
		loss: 0.181500
		loss: 0.181500
		loss: 0.181400
		loss: 0.181300
		loss: 0.181200
		loss: 0.181100
		loss: 0.181100
		loss: 0.181000
		loss: 0.180900
		loss: 0.180800
		loss: 0.180800
		loss: 0.180700
		loss: 0.180600
		loss: 0.180600
		loss: 0.180500
		loss: 0.180400
		loss: 0.180400
		loss: 0.180300
		loss: 0.180300
		loss: 0.180200
		loss: 0.180100
		loss: 0.180100
		loss: 0.180000
		loss: 0.180000
		loss: 0.179900
		loss: 0.179900
		loss: 0.179800
		loss: 0.179800
		loss: 0.179700
		loss: 0.179700
		loss: 0.179600
		loss: 0.179600
		loss: 0.179500
		loss: 0.179500
		loss: 0.179500
		loss: 0.179400
		loss: 0.179400
		loss: 0.179300
		loss: 0.179300
		loss: 0.179300
		loss: 0.179200
		loss: 0.179200
		loss: 0.179100
		loss: 0.179100
		loss: 0.179100
		loss: 0.179000
		loss: 0.179000
		loss: 0.179000
		loss: 0.178900
		loss: 0.178900
		loss: 0.178900
		loss: 0.178800
		loss: 0.178800
		loss: 0.178800
		loss: 0.178800
		loss: 0.178700
		loss: 0.178700
		loss: 0.178700
		loss: 0.178600
		loss: 0.178600
		loss: 0.178600
		loss: 0.178600
		loss: 0.178500
		loss: 0.178500
		loss: 0.178500
		loss: 0.178500
		loss: 0.178400
		loss: 0.178400
		loss: 0.178400
		loss: 0.178400
		loss: 0.178300
		loss: 0.178300
		loss: 0.178300
		loss: 0.178300
		loss: 0.178300
		loss: 0.178200
		loss: 0.178200
		loss: 0.178200
		loss: 0.178200
		loss: 0.178200
		loss: 0.178100
		loss: 0.178100
		loss: 0.178100
		loss: 0.178100
		loss: 0.178100
		loss: 0.178000
		loss: 0.178000
		loss: 0.178000
		loss: 0.178000
		loss: 0.178000
		loss: 0.178000
		loss: 0.177900
		loss: 0.177900
		loss: 0.177900
		loss: 0.177900
		loss: 0.177900
		loss: 0.177900
		loss: 0.177900
		loss: 0.177800
		loss: 0.177800
		loss: 0.177800
		loss: 0.177800
		loss: 0.177800
		loss: 0.177800
		loss: 0.177700
		loss: 0.177700
		loss: 0.177700
		loss: 0.177700
		loss: 0.177700
		loss: 0.177700
		loss: 0.177700
		loss: 0.177700
		loss: 0.177600
		loss: 0.177600
		loss: 0.177600
		loss: 0.177600
		loss: 0.177600
		loss: 0.177600
		loss: 0.177600
		loss: 0.177600
		loss: 0.177600
		loss: 0.177500
		loss: 0.177500
		loss: 0.177500
		loss: 0.177500
		loss: 0.177500
		loss: 0.177500
		loss: 0.177500
		loss: 0.177500
		loss: 0.177500
		loss: 0.177400
		loss: 0.177400
		loss: 0.177400
		loss: 0.177400
		loss: 0.177400
		loss: 0.177400
		loss: 0.177400
		loss: 0.177400
		loss: 0.177400
		loss: 0.177400
		loss: 0.177300
		loss: 0.177300
		loss: 0.177300
		loss: 0.177300
		loss: 0.177300
		loss: 0.177300
		loss: 0.177300
		loss: 0.177300
		loss: 0.177300
		loss: 0.177300
		loss: 0.177300
		loss: 0.177300
		loss: 0.177200
		loss: 0.177200
		loss: 0.177200
		loss: 0.177200
		loss: 0.177200
		loss: 0.177200
		loss: 0.177200
		loss: 0.177200
		loss: 0.177200
		loss: 0.177200
		loss: 0.177200
		loss: 0.177200
		loss: 0.177200
		loss: 0.177200
		loss: 0.177100
		loss: 0.177100
		loss: 0.177100
		loss: 0.177100
		loss: 0.177100
		loss: 0.177100
		loss: 0.177100
		loss: 0.177100
		loss: 0.177100
		loss: 0.177100
		loss: 0.177100
		loss: 0.177100
		loss: 0.177100
		loss: 0.177100
		loss: 0.177100
		loss: 0.177100
		loss: 0.177100
		loss: 0.177000
		loss: 0.177000
		loss: 0.177000
		loss: 0.177000
		loss: 0.177000
		loss: 0.177000
		loss: 0.177000
		loss: 0.177000
		loss: 0.177000
		loss: 0.177000
		loss: 0.177000
		loss: 0.177000
		loss: 0.177000
		loss: 0.177000
		loss: 0.177000
		loss: 0.177000
	Overall the loss development was 0.219700 -> 0.177000

Training data for problem d-4-2.pddl in epoch 7:
model creation time: 11.906351089477539s
problem epoch data for epoch 7, problem epoch 1
	sampling search time: 13.613121509552002s
	during this search the following actions were chosen:
		pick-up a was chosen with probability 0.994181
		stack a c was chosen with probability 0.759424
		pick-up d was chosen with probability 0.998961
		stack d a was chosen with probability 0.988845
	training time: 64.65035605430603s
	during the training the following losses were computed:
		loss: 2.609700
		loss: 2.411800
		loss: 2.224000
		loss: 2.042500
		loss: 1.879100
		loss: 1.712700
		loss: 1.558800
		loss: 1.408200
		loss: 1.266100
		loss: 1.132500
		loss: 1.008100
		loss: 0.896400
		loss: 0.795800
		loss: 0.705800
		loss: 0.627700
		loss: 0.565600
		loss: 0.518200
		loss: 0.480100
		loss: 0.454400
		loss: 0.446800
		loss: 0.448100
		loss: 0.456600
		loss: 0.469700
		loss: 0.484000
		loss: 0.495100
		loss: 0.499900
		loss: 0.497400
		loss: 0.488200
		loss: 0.473400
		loss: 0.455200
		loss: 0.435900
		loss: 0.416800
		loss: 0.399200
		loss: 0.383700
		loss: 0.370300
		loss: 0.358900
		loss: 0.349000
		loss: 0.340100
		loss: 0.331900
		loss: 0.324500
		loss: 0.317300
		loss: 0.309400
		loss: 0.300900
		loss: 0.292000
		loss: 0.282800
		loss: 0.273500
		loss: 0.264700
		loss: 0.256900
		loss: 0.250600
		loss: 0.245900
		loss: 0.242500
		loss: 0.239600
		loss: 0.236300
		loss: 0.231800
		loss: 0.225900
		loss: 0.219200
		loss: 0.212700
		loss: 0.207000
		loss: 0.202100
		loss: 0.198100
		loss: 0.194300
		loss: 0.190300
		loss: 0.185900
		loss: 0.181000
		loss: 0.175800
		loss: 0.170700
		loss: 0.166000
		loss: 0.161900
		loss: 0.158200
		loss: 0.154600
		loss: 0.150700
		loss: 0.146500
		loss: 0.142100
		loss: 0.137800
		loss: 0.133900
		loss: 0.130300
		loss: 0.126800
		loss: 0.123300
		loss: 0.119700
		loss: 0.116100
		loss: 0.112500
		loss: 0.109100
		loss: 0.106000
		loss: 0.103100
		loss: 0.100100
		loss: 0.097200
		loss: 0.094200
		loss: 0.091400
		loss: 0.088800
		loss: 0.086300
		loss: 0.084000
		loss: 0.081700
		loss: 0.079500
		loss: 0.077300
		loss: 0.075300
		loss: 0.073400
		loss: 0.071600
		loss: 0.069900
		loss: 0.068200
		loss: 0.066600
		loss: 0.065200
		loss: 0.063800
		loss: 0.062400
		loss: 0.061200
		loss: 0.060000
		loss: 0.058800
		loss: 0.057700
		loss: 0.056800
		loss: 0.055800
		loss: 0.054900
		loss: 0.054100
		loss: 0.053300
		loss: 0.052600
		loss: 0.051900
		loss: 0.051200
		loss: 0.050600
		loss: 0.050000
		loss: 0.049500
		loss: 0.049000
		loss: 0.048500
		loss: 0.048100
		loss: 0.047700
		loss: 0.047300
		loss: 0.046900
		loss: 0.046600
		loss: 0.046300
		loss: 0.046000
		loss: 0.045700
		loss: 0.045400
		loss: 0.045200
		loss: 0.045000
		loss: 0.044800
		loss: 0.044600
		loss: 0.044400
		loss: 0.044200
		loss: 0.044000
		loss: 0.043800
		loss: 0.043700
		loss: 0.043500
		loss: 0.043400
		loss: 0.043200
		loss: 0.043100
		loss: 0.043000
		loss: 0.042900
		loss: 0.042700
		loss: 0.042600
		loss: 0.042500
		loss: 0.042400
		loss: 0.042300
		loss: 0.042200
		loss: 0.042100
		loss: 0.042000
		loss: 0.041900
		loss: 0.041900
		loss: 0.041800
		loss: 0.041700
		loss: 0.041600
		loss: 0.041500
		loss: 0.041500
		loss: 0.041400
		loss: 0.041300
		loss: 0.041200
		loss: 0.041200
		loss: 0.041100
		loss: 0.041000
		loss: 0.041000
		loss: 0.040900
		loss: 0.040800
		loss: 0.040800
		loss: 0.040700
		loss: 0.040700
		loss: 0.040600
		loss: 0.040500
		loss: 0.040500
		loss: 0.040400
		loss: 0.040400
		loss: 0.040300
		loss: 0.040300
		loss: 0.040200
		loss: 0.040200
		loss: 0.040100
		loss: 0.040100
		loss: 0.040000
		loss: 0.040000
		loss: 0.039900
		loss: 0.039900
		loss: 0.039800
		loss: 0.039800
		loss: 0.039700
		loss: 0.039700
		loss: 0.039700
		loss: 0.039600
		loss: 0.039600
		loss: 0.039500
		loss: 0.039500
		loss: 0.039400
		loss: 0.039400
		loss: 0.039400
		loss: 0.039300
		loss: 0.039300
		loss: 0.039200
		loss: 0.039200
		loss: 0.039200
		loss: 0.039100
		loss: 0.039100
		loss: 0.039000
		loss: 0.039000
		loss: 0.039000
		loss: 0.038900
		loss: 0.038900
		loss: 0.038900
		loss: 0.038800
		loss: 0.038800
		loss: 0.038800
		loss: 0.038700
		loss: 0.038700
		loss: 0.038700
		loss: 0.038600
		loss: 0.038600
		loss: 0.038600
		loss: 0.038500
		loss: 0.038500
		loss: 0.038500
		loss: 0.038400
		loss: 0.038400
		loss: 0.038400
		loss: 0.038400
		loss: 0.038300
		loss: 0.038300
		loss: 0.038300
		loss: 0.038200
		loss: 0.038200
		loss: 0.038200
		loss: 0.038200
		loss: 0.038100
		loss: 0.038100
		loss: 0.038100
		loss: 0.038000
		loss: 0.038000
		loss: 0.038000
		loss: 0.038000
		loss: 0.037900
		loss: 0.037900
		loss: 0.037900
		loss: 0.037900
		loss: 0.037800
		loss: 0.037800
		loss: 0.037800
		loss: 0.037800
		loss: 0.037700
		loss: 0.037700
		loss: 0.037700
		loss: 0.037700
		loss: 0.037600
		loss: 0.037600
		loss: 0.037600
		loss: 0.037600
		loss: 0.037600
		loss: 0.037500
		loss: 0.037500
		loss: 0.037500
		loss: 0.037500
		loss: 0.037400
		loss: 0.037400
		loss: 0.037400
		loss: 0.037400
		loss: 0.037400
		loss: 0.037300
		loss: 0.037300
		loss: 0.037300
		loss: 0.037300
		loss: 0.037200
		loss: 0.037200
		loss: 0.037200
		loss: 0.037200
		loss: 0.037200
		loss: 0.037100
		loss: 0.037100
		loss: 0.037100
		loss: 0.037100
		loss: 0.037100
		loss: 0.037000
		loss: 0.037000
		loss: 0.037000
		loss: 0.037000
		loss: 0.037000
		loss: 0.036900
		loss: 0.036900
		loss: 0.036900
		loss: 0.036900
		loss: 0.036900
		loss: 0.036800
		loss: 0.036800
		loss: 0.036800
		loss: 0.036800
		loss: 0.036800
		loss: 0.036800
		loss: 0.036700
		loss: 0.036700
		loss: 0.036700
	Overall the loss development was 2.609700 -> 0.036700

Training data for problem d-4-1.pddl in epoch 7:
model creation time: 13.334911584854126s
problem epoch data for epoch 7, problem epoch 1
	sampling search time: 12.005791187286377s
	during this search the following actions were chosen:
	training time: 65.82992434501648s
	during the training the following losses were computed:
		loss: 0.457200
		loss: 0.276300
		loss: 0.176200
		loss: 0.190000
		loss: 0.209600
		loss: 0.175200
		loss: 0.134900
		loss: 0.113800
		loss: 0.109600
		loss: 0.114600
		loss: 0.121000
		loss: 0.123500
		loss: 0.120200
		loss: 0.113100
		loss: 0.105900
		loss: 0.101800
		loss: 0.101400
		loss: 0.103000
		loss: 0.104000
		loss: 0.102500
		loss: 0.098500
		loss: 0.093300
		loss: 0.088400
		loss: 0.084900
		loss: 0.082900
		loss: 0.081800
		loss: 0.080800
		loss: 0.079300
		loss: 0.077100
		loss: 0.074500
		loss: 0.072000
		loss: 0.069900
		loss: 0.068500
		loss: 0.067600
		loss: 0.066900
		loss: 0.066300
		loss: 0.065400
		loss: 0.064300
		loss: 0.063100
		loss: 0.061900
		loss: 0.060900
		loss: 0.060000
		loss: 0.059400
		loss: 0.058800
		loss: 0.058200
		loss: 0.057500
		loss: 0.056800
		loss: 0.056100
		loss: 0.055300
		loss: 0.054600
		loss: 0.054000
		loss: 0.053500
		loss: 0.053000
		loss: 0.052600
		loss: 0.052100
		loss: 0.051700
		loss: 0.051200
		loss: 0.050800
		loss: 0.050300
		loss: 0.049900
		loss: 0.049600
		loss: 0.049300
		loss: 0.049000
		loss: 0.048700
		loss: 0.048400
		loss: 0.048100
		loss: 0.047900
		loss: 0.047600
		loss: 0.047400
		loss: 0.047100
		loss: 0.046900
		loss: 0.046700
		loss: 0.046600
		loss: 0.046400
		loss: 0.046200
		loss: 0.046000
		loss: 0.045900
		loss: 0.045700
		loss: 0.045600
		loss: 0.045400
		loss: 0.045300
		loss: 0.045100
		loss: 0.045000
		loss: 0.044900
		loss: 0.044800
		loss: 0.044700
		loss: 0.044600
		loss: 0.044500
		loss: 0.044400
		loss: 0.044300
		loss: 0.044200
		loss: 0.044100
		loss: 0.044000
		loss: 0.044000
		loss: 0.043900
		loss: 0.043800
		loss: 0.043700
		loss: 0.043700
		loss: 0.043600
		loss: 0.043600
		loss: 0.043500
		loss: 0.043500
		loss: 0.043400
		loss: 0.043400
		loss: 0.043300
		loss: 0.043300
		loss: 0.043200
		loss: 0.043200
		loss: 0.043100
		loss: 0.043100
		loss: 0.043100
		loss: 0.043000
		loss: 0.043000
		loss: 0.043000
		loss: 0.042900
		loss: 0.042900
		loss: 0.042900
		loss: 0.042800
		loss: 0.042800
		loss: 0.042800
		loss: 0.042700
		loss: 0.042700
		loss: 0.042700
		loss: 0.042600
		loss: 0.042600
		loss: 0.042600
		loss: 0.042600
		loss: 0.042500
		loss: 0.042500
		loss: 0.042500
		loss: 0.042400
		loss: 0.042400
		loss: 0.042400
		loss: 0.042400
		loss: 0.042300
		loss: 0.042300
		loss: 0.042300
		loss: 0.042300
		loss: 0.042200
		loss: 0.042200
		loss: 0.042200
		loss: 0.042200
		loss: 0.042100
		loss: 0.042100
		loss: 0.042100
		loss: 0.042100
		loss: 0.042000
		loss: 0.042000
		loss: 0.042000
		loss: 0.042000
		loss: 0.041900
		loss: 0.041900
		loss: 0.041900
		loss: 0.041900
		loss: 0.041900
		loss: 0.041800
		loss: 0.041800
		loss: 0.041800
		loss: 0.041800
		loss: 0.041700
		loss: 0.041700
		loss: 0.041700
		loss: 0.041700
		loss: 0.041700
		loss: 0.041600
		loss: 0.041600
		loss: 0.041600
		loss: 0.041600
		loss: 0.041500
		loss: 0.041500
		loss: 0.041500
		loss: 0.041500
		loss: 0.041500
		loss: 0.041400
		loss: 0.041400
		loss: 0.041400
		loss: 0.041400
		loss: 0.041300
		loss: 0.041300
		loss: 0.041300
		loss: 0.041300
		loss: 0.041300
		loss: 0.041200
		loss: 0.041200
		loss: 0.041200
		loss: 0.041200
		loss: 0.041100
		loss: 0.041100
		loss: 0.041100
		loss: 0.041100
		loss: 0.041100
		loss: 0.041000
		loss: 0.041000
		loss: 0.041000
		loss: 0.041000
		loss: 0.041000
		loss: 0.040900
		loss: 0.040900
		loss: 0.040900
		loss: 0.040900
		loss: 0.040900
		loss: 0.040800
		loss: 0.040800
		loss: 0.040800
		loss: 0.040800
		loss: 0.040800
		loss: 0.040700
		loss: 0.040700
		loss: 0.040700
		loss: 0.040700
		loss: 0.040700
		loss: 0.040600
		loss: 0.040600
		loss: 0.040600
		loss: 0.040600
		loss: 0.040600
		loss: 0.040500
		loss: 0.040500
		loss: 0.040500
		loss: 0.040500
		loss: 0.040500
		loss: 0.040400
		loss: 0.040400
		loss: 0.040400
		loss: 0.040400
		loss: 0.040400
		loss: 0.040300
		loss: 0.040300
		loss: 0.040300
		loss: 0.040300
		loss: 0.040300
		loss: 0.040200
		loss: 0.040200
		loss: 0.040200
		loss: 0.040200
		loss: 0.040200
		loss: 0.040100
		loss: 0.040100
		loss: 0.040100
		loss: 0.040100
		loss: 0.040100
		loss: 0.040100
		loss: 0.040000
		loss: 0.040000
		loss: 0.040000
		loss: 0.040000
		loss: 0.040000
		loss: 0.039900
		loss: 0.039900
		loss: 0.039900
		loss: 0.039900
		loss: 0.039900
		loss: 0.039800
		loss: 0.039800
		loss: 0.039800
		loss: 0.039800
		loss: 0.039800
		loss: 0.039800
		loss: 0.039700
		loss: 0.039700
		loss: 0.039700
		loss: 0.039700
		loss: 0.039700
		loss: 0.039600
		loss: 0.039600
		loss: 0.039600
		loss: 0.039600
		loss: 0.039600
		loss: 0.039600
		loss: 0.039500
		loss: 0.039500
		loss: 0.039500
		loss: 0.039500
		loss: 0.039500
		loss: 0.039500
		loss: 0.039400
		loss: 0.039400
		loss: 0.039400
		loss: 0.039400
		loss: 0.039400
		loss: 0.039300
		loss: 0.039300
		loss: 0.039300
		loss: 0.039300
		loss: 0.039300
		loss: 0.039300
		loss: 0.039200
		loss: 0.039200
		loss: 0.039200
		loss: 0.039200
		loss: 0.039200
		loss: 0.039200
		loss: 0.039100
		loss: 0.039100
		loss: 0.039100
		loss: 0.039100
		loss: 0.039100
		loss: 0.039100
		loss: 0.039000
		loss: 0.039000
	Overall the loss development was 0.457200 -> 0.039000

Training data for problem d-5-2.pddl in epoch 7:
model creation time: 19.479147911071777s
problem epoch data for epoch 7, problem epoch 1
	sampling search time: 16.05973720550537s
	during this search the following actions were chosen:
	training time: 73.74034690856934s
	during the training the following losses were computed:
		loss: 2.724300
		loss: 2.530400
		loss: 2.357200
		loss: 2.201500
		loss: 2.059100
		loss: 1.927300
		loss: 1.804500
		loss: 1.691000
		loss: 1.588800
		loss: 1.495200
		loss: 1.411600
		loss: 1.338800
		loss: 1.276300
		loss: 1.223200
		loss: 1.178300
		loss: 1.141400
		loss: 1.111300
		loss: 1.088000
		loss: 1.070800
		loss: 1.058600
		loss: 1.049900
		loss: 1.043700
		loss: 1.039700
		loss: 1.037100
		loss: 1.035600
		loss: 1.035000
		loss: 1.034500
		loss: 1.034300
		loss: 1.033800
		loss: 1.033000
		loss: 1.032000
		loss: 1.030400
		loss: 1.028500
		loss: 1.026200
		loss: 1.023700
		loss: 1.021000
		loss: 1.017900
		loss: 1.014600
		loss: 1.011200
		loss: 1.007600
		loss: 1.003900
		loss: 1.000200
		loss: 0.996400
		loss: 0.992600
		loss: 0.988900
		loss: 0.985300
		loss: 0.981800
		loss: 0.978500
		loss: 0.975400
		loss: 0.972400
		loss: 0.969600
		loss: 0.966800
		loss: 0.964200
		loss: 0.961500
		loss: 0.958800
		loss: 0.956100
		loss: 0.953300
		loss: 0.950500
		loss: 0.947600
		loss: 0.944600
		loss: 0.941700
		loss: 0.938600
		loss: 0.935400
		loss: 0.932100
		loss: 0.928700
		loss: 0.925300
		loss: 0.921700
		loss: 0.918000
		loss: 0.914300
		loss: 0.910700
		loss: 0.907000
		loss: 0.903500
		loss: 0.899800
		loss: 0.893900
		loss: 0.884900
		loss: 0.879000
		loss: 0.872700
		loss: 0.864200
		loss: 0.857500
		loss: 0.853900
		loss: 0.849200
		loss: 0.843100
		loss: 0.839000
		loss: 0.834300
		loss: 0.826900
		loss: 0.821000
		loss: 0.816000
		loss: 0.809500
		loss: 0.804100
		loss: 0.799800
		loss: 0.794600
		loss: 0.789900
		loss: 0.785900
		loss: 0.780800
		loss: 0.776100
		loss: 0.771400
		loss: 0.766300
		loss: 0.762200
		loss: 0.757900
		loss: 0.753800
		loss: 0.750000
		loss: 0.745900
		loss: 0.741900
		loss: 0.738100
		loss: 0.733800
		loss: 0.730100
		loss: 0.726000
		loss: 0.722500
		loss: 0.718700
		loss: 0.715000
		loss: 0.711200
		loss: 0.707500
		loss: 0.704000
		loss: 0.700700
		loss: 0.697100
		loss: 0.693600
		loss: 0.690200
		loss: 0.686800
		loss: 0.683400
		loss: 0.679700
		loss: 0.675900
		loss: 0.672200
		loss: 0.668700
		loss: 0.665000
		loss: 0.661400
		loss: 0.657500
		loss: 0.653800
		loss: 0.650100
		loss: 0.646500
		loss: 0.642800
		loss: 0.639200
		loss: 0.635400
		loss: 0.632000
		loss: 0.629100
		loss: 0.626300
		loss: 0.623000
		loss: 0.618200
		loss: 0.613800
		loss: 0.611200
		loss: 0.608700
		loss: 0.604500
		loss: 0.599900
		loss: 0.596000
		loss: 0.592900
		loss: 0.590700
		loss: 0.589400
		loss: 0.587100
		loss: 0.580800
		loss: 0.575300
		loss: 0.573700
		loss: 0.574200
		loss: 0.570100
		loss: 0.562900
		loss: 0.560600
		loss: 0.560200
		loss: 0.555500
		loss: 0.550000
		loss: 0.547700
		loss: 0.546000
		loss: 0.542000
		loss: 0.538000
		loss: 0.534900
		loss: 0.532800
		loss: 0.530500
		loss: 0.526700
		loss: 0.523100
		loss: 0.520300
		loss: 0.518100
		loss: 0.515900
		loss: 0.513100
		loss: 0.509800
		loss: 0.506800
		loss: 0.504300
		loss: 0.502400
		loss: 0.500600
		loss: 0.499100
		loss: 0.497800
		loss: 0.495500
		loss: 0.492900
		loss: 0.488600
		loss: 0.484700
		loss: 0.482300
		loss: 0.480900
		loss: 0.480000
		loss: 0.479000
		loss: 0.477600
		loss: 0.474200
		loss: 0.470400
		loss: 0.467700
		loss: 0.466200
		loss: 0.465200
		loss: 0.464400
		loss: 0.463500
		loss: 0.461500
		loss: 0.458500
		loss: 0.455400
		loss: 0.453100
		loss: 0.452000
		loss: 0.451300
		loss: 0.450500
		loss: 0.449500
		loss: 0.448000
		loss: 0.446100
		loss: 0.443800
		loss: 0.441600
		loss: 0.439800
		loss: 0.438400
		loss: 0.437500
		loss: 0.436700
		loss: 0.436900
		loss: 0.437900
		loss: 0.438400
		loss: 0.438200
		loss: 0.434200
		loss: 0.430000
		loss: 0.427600
		loss: 0.426900
		loss: 0.427400
		loss: 0.428200
		loss: 0.428000
		loss: 0.426300
		loss: 0.423500
		loss: 0.420900
		loss: 0.419800
		loss: 0.420000
		loss: 0.420400
		loss: 0.420100
		loss: 0.419200
		loss: 0.417200
		loss: 0.415300
		loss: 0.413900
		loss: 0.413300
		loss: 0.413200
		loss: 0.413300
		loss: 0.414000
		loss: 0.414500
		loss: 0.414000
		loss: 0.412700
		loss: 0.410500
		loss: 0.408200
		loss: 0.406700
		loss: 0.406600
		loss: 0.407000
		loss: 0.407300
		loss: 0.407100
		loss: 0.406500
		loss: 0.405300
		loss: 0.403900
		loss: 0.402500
		loss: 0.401400
		loss: 0.400900
		loss: 0.400900
		loss: 0.401200
		loss: 0.401800
		loss: 0.403000
		loss: 0.404700
		loss: 0.404300
		loss: 0.402900
		loss: 0.399600
		loss: 0.397000
		loss: 0.395900
		loss: 0.396300
		loss: 0.397300
		loss: 0.398400
		loss: 0.399000
		loss: 0.397900
		loss: 0.395900
		loss: 0.393600
		loss: 0.392400
		loss: 0.392500
		loss: 0.393200
		loss: 0.394000
		loss: 0.394200
		loss: 0.393700
		loss: 0.392700
		loss: 0.391200
		loss: 0.389800
		loss: 0.388900
		loss: 0.388500
		loss: 0.388600
		loss: 0.388800
		loss: 0.388800
		loss: 0.388700
		loss: 0.388800
		loss: 0.389100
		loss: 0.389700
		loss: 0.390300
		loss: 0.390300
		loss: 0.389700
		loss: 0.387900
		loss: 0.385900
		loss: 0.384200
		loss: 0.383600
		loss: 0.383900
		loss: 0.384500
		loss: 0.384900
		loss: 0.385100
		loss: 0.385100
		loss: 0.384900
		loss: 0.384400
	Overall the loss development was 2.724300 -> 0.384400

Training data for problem d-5-0.pddl in epoch 7:
model creation time: 19.563757181167603s
problem epoch data for epoch 7, problem epoch 1
	sampling search time: 15.199893712997437s
	during this search the following actions were chosen:
		unstack c e was chosen with probability 0.999999
		put-down c was chosen with probability 0.999869
		unstack e b was chosen with probability 0.999992
		put-down e was chosen with probability 0.987983
		pick-up d was chosen with probability 0.897251
		stack d c was chosen with probability 0.998430
		unstack b a was chosen with probability 0.942817
		stack b d was chosen with probability 0.978064
		pick-up e was chosen with probability 0.970116
		stack e b was chosen with probability 0.942115
		pick-up a was chosen with probability 0.911153
		stack a e was chosen with probability 0.943678
	training time: 87.32642269134521s
	during the training the following losses were computed:
		loss: 0.864400
		loss: 0.694800
		loss: 0.679100
		loss: 0.538600
		loss: 0.492800
		loss: 0.495000
		loss: 0.449600
		loss: 0.413700
		loss: 0.416200
		loss: 0.413700
		loss: 0.379000
		loss: 0.348300
		loss: 0.343400
		loss: 0.333400
		loss: 0.300900
		loss: 0.270800
		loss: 0.273000
		loss: 0.255900
		loss: 0.227700
		loss: 0.226400
		loss: 0.220500
		loss: 0.200700
		loss: 0.194200
		loss: 0.197200
		loss: 0.185500
		loss: 0.179500
		loss: 0.182700
		loss: 0.179200
		loss: 0.172900
		loss: 0.174500
		loss: 0.175600
		loss: 0.170900
		loss: 0.170000
		loss: 0.172200
		loss: 0.169900
		loss: 0.167900
		loss: 0.169800
		loss: 0.169200
		loss: 0.166800
		loss: 0.168100
		loss: 0.167900
		loss: 0.166000
		loss: 0.167100
		loss: 0.166700
		loss: 0.165400
		loss: 0.166300
		loss: 0.165600
		loss: 0.165000
		loss: 0.165500
		loss: 0.164900
		loss: 0.164500
		loss: 0.164800
		loss: 0.164200
		loss: 0.164200
		loss: 0.164200
		loss: 0.163800
		loss: 0.163900
		loss: 0.163700
		loss: 0.163500
		loss: 0.163600
		loss: 0.163300
		loss: 0.163200
		loss: 0.163200
		loss: 0.163000
		loss: 0.162900
		loss: 0.162900
		loss: 0.162700
		loss: 0.162600
		loss: 0.162500
		loss: 0.162400
		loss: 0.162400
		loss: 0.162200
		loss: 0.162200
		loss: 0.162100
		loss: 0.162000
		loss: 0.161900
		loss: 0.161800
		loss: 0.161800
		loss: 0.161600
		loss: 0.161600
		loss: 0.161500
		loss: 0.161400
		loss: 0.161300
		loss: 0.161300
		loss: 0.161200
		loss: 0.161100
		loss: 0.161000
		loss: 0.161000
		loss: 0.160900
		loss: 0.160800
		loss: 0.160800
		loss: 0.160700
		loss: 0.160600
		loss: 0.160500
		loss: 0.160500
		loss: 0.160400
		loss: 0.160300
		loss: 0.160300
		loss: 0.160200
		loss: 0.160100
		loss: 0.160100
		loss: 0.160000
		loss: 0.160000
		loss: 0.159900
		loss: 0.159800
		loss: 0.159800
		loss: 0.159700
		loss: 0.159600
		loss: 0.159600
		loss: 0.159500
		loss: 0.159500
		loss: 0.159400
		loss: 0.159300
		loss: 0.159300
		loss: 0.159200
		loss: 0.159200
		loss: 0.159100
		loss: 0.159000
		loss: 0.159000
		loss: 0.158900
		loss: 0.158900
		loss: 0.158800
		loss: 0.158700
		loss: 0.158700
		loss: 0.158600
		loss: 0.158600
		loss: 0.158500
		loss: 0.158500
		loss: 0.158400
		loss: 0.158300
		loss: 0.158300
		loss: 0.158200
		loss: 0.158200
		loss: 0.158100
		loss: 0.158100
		loss: 0.158000
		loss: 0.157900
		loss: 0.157900
		loss: 0.157800
		loss: 0.157800
		loss: 0.157700
		loss: 0.157700
		loss: 0.157600
		loss: 0.157500
		loss: 0.157500
		loss: 0.157400
		loss: 0.157400
		loss: 0.157300
		loss: 0.157300
		loss: 0.157200
		loss: 0.157200
		loss: 0.157100
		loss: 0.157100
		loss: 0.157000
		loss: 0.156900
		loss: 0.156900
		loss: 0.156800
		loss: 0.156800
		loss: 0.156700
		loss: 0.156700
		loss: 0.156600
		loss: 0.156600
		loss: 0.156500
		loss: 0.156500
		loss: 0.156400
		loss: 0.156400
		loss: 0.156300
		loss: 0.156300
		loss: 0.156200
		loss: 0.156200
		loss: 0.156100
		loss: 0.156100
		loss: 0.156000
		loss: 0.156000
		loss: 0.155900
		loss: 0.155900
		loss: 0.155800
		loss: 0.155700
		loss: 0.155700
		loss: 0.155600
		loss: 0.155600
		loss: 0.155500
		loss: 0.155500
		loss: 0.155400
		loss: 0.155400
		loss: 0.155300
		loss: 0.155300
		loss: 0.155200
		loss: 0.155200
		loss: 0.155100
		loss: 0.155100
		loss: 0.155000
		loss: 0.155000
		loss: 0.154900
		loss: 0.154900
		loss: 0.154800
		loss: 0.154800
		loss: 0.154700
		loss: 0.154700
		loss: 0.154600
		loss: 0.154600
		loss: 0.154500
		loss: 0.154500
		loss: 0.154400
		loss: 0.154400
		loss: 0.154300
		loss: 0.154300
		loss: 0.154200
		loss: 0.154200
		loss: 0.154100
		loss: 0.154100
		loss: 0.154000
		loss: 0.154000
		loss: 0.153900
		loss: 0.153900
		loss: 0.153800
		loss: 0.153800
		loss: 0.153700
		loss: 0.153700
		loss: 0.153600
		loss: 0.153600
		loss: 0.153500
		loss: 0.153500
		loss: 0.153400
		loss: 0.153400
		loss: 0.153300
		loss: 0.153300
		loss: 0.153300
		loss: 0.153200
		loss: 0.153200
		loss: 0.153100
		loss: 0.153000
		loss: 0.153000
		loss: 0.152900
		loss: 0.152900
		loss: 0.152800
		loss: 0.152800
		loss: 0.152700
		loss: 0.152700
		loss: 0.152600
		loss: 0.152600
		loss: 0.152500
		loss: 0.152500
		loss: 0.152400
		loss: 0.152400
		loss: 0.152300
		loss: 0.152300
		loss: 0.152200
		loss: 0.152200
		loss: 0.152100
		loss: 0.152000
		loss: 0.152000
		loss: 0.151900
		loss: 0.151900
		loss: 0.151800
		loss: 0.151800
		loss: 0.151700
		loss: 0.151700
		loss: 0.151600
		loss: 0.151600
		loss: 0.151500
		loss: 0.151500
		loss: 0.151400
		loss: 0.151400
		loss: 0.151300
		loss: 0.151200
		loss: 0.151200
		loss: 0.151100
		loss: 0.151100
		loss: 0.151000
		loss: 0.151000
		loss: 0.150900
		loss: 0.150900
		loss: 0.150800
		loss: 0.150800
		loss: 0.150700
		loss: 0.150700
		loss: 0.150600
		loss: 0.150600
		loss: 0.150500
		loss: 0.150500
		loss: 0.150400
		loss: 0.150400
		loss: 0.150300
		loss: 0.150300
		loss: 0.150200
		loss: 0.150200
		loss: 0.150100
		loss: 0.150100
		loss: 0.150000
		loss: 0.150000
		loss: 0.149900
		loss: 0.149900
		loss: 0.149800
		loss: 0.149800
		loss: 0.149800
		loss: 0.149700
		loss: 0.149700
		loss: 0.149600
		loss: 0.149600
	Overall the loss development was 0.864400 -> 0.149600

Training data for problem d-5-1.pddl in epoch 7:
model creation time: 16.652926683425903s
problem epoch data for epoch 7, problem epoch 1
	sampling search time: 26.43438482284546s
	during this search the following actions were chosen:
		pick-up c was chosen with probability 0.996447
		stack c b was chosen with probability 0.933432
		unstack c b was chosen with probability 0.997747
	training time: 72.7463972568512s
	during the training the following losses were computed:
		loss: 1.606000
		loss: 1.300900
		loss: 1.275500
		loss: 1.126100
		loss: 1.087600
		loss: 1.046500
		loss: 0.954100
		loss: 0.886900
		loss: 0.848800
		loss: 0.799700
		loss: 0.735800
		loss: 0.670700
		loss: 0.617200
		loss: 0.572400
		loss: 0.526400
		loss: 0.474500
		loss: 0.424800
		loss: 0.387400
		loss: 0.361300
		loss: 0.342600
		loss: 0.330100
		loss: 0.328600
		loss: 0.332800
		loss: 0.333600
		loss: 0.333800
		loss: 0.336400
		loss: 0.336700
		loss: 0.331800
		loss: 0.325200
		loss: 0.319600
		loss: 0.312900
		loss: 0.304300
		loss: 0.295700
		loss: 0.288300
		loss: 0.281700
		loss: 0.274500
		loss: 0.267700
		loss: 0.262100
		loss: 0.258200
		loss: 0.254400
		loss: 0.250600
		loss: 0.247800
		loss: 0.246000
		loss: 0.243900
		loss: 0.241200
		loss: 0.238700
		loss: 0.236600
		loss: 0.234300
		loss: 0.231700
		loss: 0.229600
		loss: 0.228000
		loss: 0.226500
		loss: 0.224500
		loss: 0.222600
		loss: 0.221300
		loss: 0.219800
		loss: 0.218200
		loss: 0.216900
		loss: 0.215900
		loss: 0.214800
		loss: 0.213600
		loss: 0.212500
		loss: 0.211500
		loss: 0.210500
		loss: 0.209300
		loss: 0.208300
		loss: 0.207300
		loss: 0.206400
		loss: 0.205600
		loss: 0.204800
		loss: 0.204100
		loss: 0.203300
		loss: 0.202500
		loss: 0.201800
		loss: 0.201200
		loss: 0.200600
		loss: 0.200000
		loss: 0.199400
		loss: 0.198800
		loss: 0.198200
		loss: 0.197600
		loss: 0.197000
		loss: 0.196500
		loss: 0.196000
		loss: 0.195500
		loss: 0.195000
		loss: 0.194500
		loss: 0.194000
		loss: 0.193600
		loss: 0.193100
		loss: 0.192700
		loss: 0.192300
		loss: 0.191900
		loss: 0.191400
		loss: 0.191000
		loss: 0.190700
		loss: 0.190300
		loss: 0.189900
		loss: 0.189600
		loss: 0.189200
		loss: 0.188800
		loss: 0.188500
		loss: 0.188200
		loss: 0.187900
		loss: 0.187600
		loss: 0.187300
		loss: 0.187000
		loss: 0.186700
		loss: 0.186400
		loss: 0.186200
		loss: 0.185900
		loss: 0.185700
		loss: 0.185400
		loss: 0.185200
		loss: 0.184900
		loss: 0.184700
		loss: 0.184500
		loss: 0.184200
		loss: 0.184000
		loss: 0.183800
		loss: 0.183600
		loss: 0.183400
		loss: 0.183200
		loss: 0.183000
		loss: 0.182900
		loss: 0.182700
		loss: 0.182500
		loss: 0.182400
		loss: 0.182200
		loss: 0.182000
		loss: 0.181900
		loss: 0.181700
		loss: 0.181600
		loss: 0.181500
		loss: 0.181300
		loss: 0.181200
		loss: 0.181000
		loss: 0.180900
		loss: 0.180800
		loss: 0.180600
		loss: 0.180500
		loss: 0.180400
		loss: 0.180300
		loss: 0.180200
		loss: 0.180100
		loss: 0.180000
		loss: 0.179800
		loss: 0.179700
		loss: 0.179600
		loss: 0.179500
		loss: 0.179400
		loss: 0.179300
		loss: 0.179200
		loss: 0.179200
		loss: 0.179100
		loss: 0.179000
		loss: 0.178900
		loss: 0.178800
		loss: 0.178700
		loss: 0.178600
		loss: 0.178500
		loss: 0.178500
		loss: 0.178400
		loss: 0.178300
		loss: 0.178200
		loss: 0.178100
		loss: 0.178100
		loss: 0.178000
		loss: 0.177900
		loss: 0.177800
		loss: 0.177800
		loss: 0.177700
		loss: 0.177600
		loss: 0.177600
		loss: 0.177500
		loss: 0.177400
		loss: 0.177400
		loss: 0.177300
		loss: 0.177200
		loss: 0.177200
		loss: 0.177100
		loss: 0.177000
		loss: 0.177000
		loss: 0.176900
		loss: 0.176900
		loss: 0.176800
		loss: 0.176700
		loss: 0.176700
		loss: 0.176600
		loss: 0.176600
		loss: 0.176500
		loss: 0.176500
		loss: 0.176400
		loss: 0.176400
		loss: 0.176300
		loss: 0.176300
		loss: 0.176200
		loss: 0.176200
		loss: 0.176100
		loss: 0.176100
		loss: 0.176000
		loss: 0.176000
		loss: 0.175900
		loss: 0.175900
		loss: 0.175800
		loss: 0.175800
		loss: 0.175700
		loss: 0.175700
		loss: 0.175600
		loss: 0.175600
		loss: 0.175500
		loss: 0.175500
		loss: 0.175500
		loss: 0.175400
		loss: 0.175400
		loss: 0.175300
		loss: 0.175300
		loss: 0.175200
		loss: 0.175200
		loss: 0.175200
		loss: 0.175100
		loss: 0.175100
		loss: 0.175000
		loss: 0.175000
		loss: 0.175000
		loss: 0.174900
		loss: 0.174900
		loss: 0.174800
		loss: 0.174800
		loss: 0.174800
		loss: 0.174700
		loss: 0.174700
		loss: 0.174600
		loss: 0.174600
		loss: 0.174600
		loss: 0.174500
		loss: 0.174500
		loss: 0.174500
		loss: 0.174400
		loss: 0.174400
		loss: 0.174300
		loss: 0.174300
		loss: 0.174300
		loss: 0.174200
		loss: 0.174200
		loss: 0.174200
		loss: 0.174100
		loss: 0.174100
		loss: 0.174100
		loss: 0.174000
		loss: 0.174000
		loss: 0.174000
		loss: 0.173900
		loss: 0.173900
		loss: 0.173900
		loss: 0.173800
		loss: 0.173800
		loss: 0.173800
		loss: 0.173700
		loss: 0.173700
		loss: 0.173700
		loss: 0.173600
		loss: 0.173600
		loss: 0.173600
		loss: 0.173500
		loss: 0.173500
		loss: 0.173500
		loss: 0.173400
		loss: 0.173400
		loss: 0.173400
		loss: 0.173300
		loss: 0.173300
		loss: 0.173300
		loss: 0.173200
		loss: 0.173200
		loss: 0.173200
		loss: 0.173100
		loss: 0.173100
		loss: 0.173100
		loss: 0.173100
		loss: 0.173000
		loss: 0.173000
		loss: 0.173000
		loss: 0.172900
		loss: 0.172900
		loss: 0.172900
		loss: 0.172800
		loss: 0.172800
		loss: 0.172800
		loss: 0.172800
		loss: 0.172700
		loss: 0.172700
		loss: 0.172700
		loss: 0.172600
		loss: 0.172600
		loss: 0.172600
		loss: 0.172500
		loss: 0.172500
		loss: 0.172500
		loss: 0.172500
	Overall the loss development was 1.606000 -> 0.172500

Epoch 8:
Training data for problem d-4-0.pddl in epoch 8:
model creation time: 9.800984621047974s
problem epoch data for epoch 8, problem epoch 1
	sampling search time: 11.132999420166016s
	during this search the following actions were chosen:
		pick-up b was chosen with probability 0.332908
		stack b a was chosen with probability 0.951813
		pick-up c was chosen with probability 0.996687
		stack c b was chosen with probability 0.995736
		pick-up d was chosen with probability 0.999288
		stack d c was chosen with probability 0.999222
	training time: 59.799341917037964s
	during the training the following losses were computed:
		loss: 0.227100
		loss: 0.221000
		loss: 0.219200
		loss: 0.218400
		loss: 0.217700
		loss: 0.217200
		loss: 0.216600
		loss: 0.216100
		loss: 0.215500
		loss: 0.214900
		loss: 0.214300
		loss: 0.213700
		loss: 0.213100
		loss: 0.212500
		loss: 0.211900
		loss: 0.211300
		loss: 0.210700
		loss: 0.210100
		loss: 0.209500
		loss: 0.208900
		loss: 0.208300
		loss: 0.207800
		loss: 0.207200
		loss: 0.206600
		loss: 0.206000
		loss: 0.205500
		loss: 0.204900
		loss: 0.204400
		loss: 0.203800
		loss: 0.203300
		loss: 0.202800
		loss: 0.202300
		loss: 0.201800
		loss: 0.201300
		loss: 0.200900
		loss: 0.200400
		loss: 0.200000
		loss: 0.199500
		loss: 0.199100
		loss: 0.198700
		loss: 0.198300
		loss: 0.197900
		loss: 0.197500
		loss: 0.197100
		loss: 0.196800
		loss: 0.196400
		loss: 0.196000
		loss: 0.195700
		loss: 0.195400
		loss: 0.195000
		loss: 0.194700
		loss: 0.194400
		loss: 0.194100
		loss: 0.193800
		loss: 0.193500
		loss: 0.193200
		loss: 0.192900
		loss: 0.192600
		loss: 0.192300
		loss: 0.192100
		loss: 0.191800
		loss: 0.191500
		loss: 0.191300
		loss: 0.191000
		loss: 0.190800
		loss: 0.190600
		loss: 0.190300
		loss: 0.190100
		loss: 0.189900
		loss: 0.189700
		loss: 0.189400
		loss: 0.189200
		loss: 0.189000
		loss: 0.188800
		loss: 0.188600
		loss: 0.188400
		loss: 0.188300
		loss: 0.188100
		loss: 0.187900
		loss: 0.187700
		loss: 0.187500
		loss: 0.187400
		loss: 0.187200
		loss: 0.187000
		loss: 0.186900
		loss: 0.186700
		loss: 0.186600
		loss: 0.186400
		loss: 0.186300
		loss: 0.186100
		loss: 0.186000
		loss: 0.185800
		loss: 0.185700
		loss: 0.185600
		loss: 0.185400
		loss: 0.185300
		loss: 0.185200
		loss: 0.185000
		loss: 0.184900
		loss: 0.184800
		loss: 0.184700
		loss: 0.184500
		loss: 0.184400
		loss: 0.184300
		loss: 0.184200
		loss: 0.184100
		loss: 0.184000
		loss: 0.183900
		loss: 0.183800
		loss: 0.183700
		loss: 0.183600
		loss: 0.183500
		loss: 0.183400
		loss: 0.183300
		loss: 0.183200
		loss: 0.183100
		loss: 0.183000
		loss: 0.182900
		loss: 0.182800
		loss: 0.182700
		loss: 0.182600
		loss: 0.182600
		loss: 0.182500
		loss: 0.182400
		loss: 0.182300
		loss: 0.182200
		loss: 0.182200
		loss: 0.182100
		loss: 0.182000
		loss: 0.181900
		loss: 0.181900
		loss: 0.181800
		loss: 0.181700
		loss: 0.181600
		loss: 0.181600
		loss: 0.181500
		loss: 0.181400
		loss: 0.181400
		loss: 0.181300
		loss: 0.181200
		loss: 0.181200
		loss: 0.181100
		loss: 0.181100
		loss: 0.181000
		loss: 0.180900
		loss: 0.180900
		loss: 0.180800
		loss: 0.180800
		loss: 0.180700
		loss: 0.180700
		loss: 0.180600
		loss: 0.180600
		loss: 0.180500
		loss: 0.180500
		loss: 0.180400
		loss: 0.180400
		loss: 0.180300
		loss: 0.180300
		loss: 0.180200
		loss: 0.180200
		loss: 0.180100
		loss: 0.180100
		loss: 0.180100
		loss: 0.180000
		loss: 0.180000
		loss: 0.179900
		loss: 0.179900
		loss: 0.179800
		loss: 0.179800
		loss: 0.179800
		loss: 0.179700
		loss: 0.179700
		loss: 0.179700
		loss: 0.179600
		loss: 0.179600
		loss: 0.179600
		loss: 0.179500
		loss: 0.179500
		loss: 0.179400
		loss: 0.179400
		loss: 0.179400
		loss: 0.179300
		loss: 0.179300
		loss: 0.179300
		loss: 0.179300
		loss: 0.179200
		loss: 0.179200
		loss: 0.179200
		loss: 0.179100
		loss: 0.179100
		loss: 0.179100
		loss: 0.179100
		loss: 0.179000
		loss: 0.179000
		loss: 0.179000
		loss: 0.178900
		loss: 0.178900
		loss: 0.178900
		loss: 0.178900
		loss: 0.178800
		loss: 0.178800
		loss: 0.178800
		loss: 0.178800
		loss: 0.178700
		loss: 0.178700
		loss: 0.178700
		loss: 0.178700
		loss: 0.178700
		loss: 0.178600
		loss: 0.178600
		loss: 0.178600
		loss: 0.178600
		loss: 0.178500
		loss: 0.178500
		loss: 0.178500
		loss: 0.178500
		loss: 0.178500
		loss: 0.178400
		loss: 0.178400
		loss: 0.178400
		loss: 0.178400
		loss: 0.178400
		loss: 0.178300
		loss: 0.178300
		loss: 0.178300
		loss: 0.178300
		loss: 0.178300
		loss: 0.178300
		loss: 0.178200
		loss: 0.178200
		loss: 0.178200
		loss: 0.178200
		loss: 0.178200
		loss: 0.178200
		loss: 0.178100
		loss: 0.178100
		loss: 0.178100
		loss: 0.178100
		loss: 0.178100
		loss: 0.178100
		loss: 0.178000
		loss: 0.178000
		loss: 0.178000
		loss: 0.178000
		loss: 0.178000
		loss: 0.178000
		loss: 0.178000
		loss: 0.178000
		loss: 0.177900
		loss: 0.177900
		loss: 0.177900
		loss: 0.177900
		loss: 0.177900
		loss: 0.177900
		loss: 0.177900
		loss: 0.177900
		loss: 0.177800
		loss: 0.177800
		loss: 0.177800
		loss: 0.177800
		loss: 0.177800
		loss: 0.177800
		loss: 0.177800
		loss: 0.177800
		loss: 0.177800
		loss: 0.177700
		loss: 0.177700
		loss: 0.177700
		loss: 0.177700
		loss: 0.177700
		loss: 0.177700
		loss: 0.177700
		loss: 0.177700
		loss: 0.177700
		loss: 0.177700
		loss: 0.177600
		loss: 0.177600
		loss: 0.177600
		loss: 0.177600
		loss: 0.177600
		loss: 0.177600
		loss: 0.177600
		loss: 0.177600
		loss: 0.177600
		loss: 0.177600
		loss: 0.177600
		loss: 0.177500
		loss: 0.177500
		loss: 0.177500
		loss: 0.177500
		loss: 0.177500
		loss: 0.177500
		loss: 0.177500
		loss: 0.177500
		loss: 0.177500
		loss: 0.177500
		loss: 0.177500
		loss: 0.177500
		loss: 0.177500
		loss: 0.177400
	Overall the loss development was 0.227100 -> 0.177400

Training data for problem d-4-2.pddl in epoch 8:
model creation time: 9.796400308609009s
problem epoch data for epoch 8, problem epoch 1
	sampling search time: 14.857536792755127s
	during this search the following actions were chosen:
		pick-up a was chosen with probability 0.989951
		stack a c was chosen with probability 0.795422
		pick-up d was chosen with probability 0.998908
		stack d a was chosen with probability 0.988718
	training time: 59.691009283065796s
	during the training the following losses were computed:
		loss: 2.525500
		loss: 2.318000
		loss: 2.121600
		loss: 1.934200
		loss: 1.756500
		loss: 1.588000
		loss: 1.428600
		loss: 1.278700
		loss: 1.138400
		loss: 1.010500
		loss: 0.893900
		loss: 0.788300
		loss: 0.693800
		loss: 0.614900
		loss: 0.551200
		loss: 0.500400
		loss: 0.466200
		loss: 0.450000
		loss: 0.443700
		loss: 0.448200
		loss: 0.462900
		loss: 0.482000
		loss: 0.499200
		loss: 0.508900
		loss: 0.507700
		loss: 0.496600
		loss: 0.478300
		loss: 0.456900
		loss: 0.435000
		loss: 0.414100
		loss: 0.396300
		loss: 0.381100
		loss: 0.368100
		loss: 0.356600
		loss: 0.346100
		loss: 0.336100
		loss: 0.326200
		loss: 0.316000
		loss: 0.305300
		loss: 0.294200
		loss: 0.282800
		loss: 0.271500
		loss: 0.260300
		loss: 0.249600
		loss: 0.239400
		loss: 0.230300
		loss: 0.222800
		loss: 0.217000
		loss: 0.212300
		loss: 0.208100
		loss: 0.203300
		loss: 0.197400
		loss: 0.190400
		loss: 0.183000
		loss: 0.176000
		loss: 0.169800
		loss: 0.164600
		loss: 0.159800
		loss: 0.155100
		loss: 0.150100
		loss: 0.144800
		loss: 0.139200
		loss: 0.133700
		loss: 0.128600
		loss: 0.124200
		loss: 0.120400
		loss: 0.117000
		loss: 0.113500
		loss: 0.109900
		loss: 0.106100
		loss: 0.102400
		loss: 0.099000
		loss: 0.096000
		loss: 0.093200
		loss: 0.090600
		loss: 0.088000
		loss: 0.085400
		loss: 0.082900
		loss: 0.080400
		loss: 0.078100
		loss: 0.076100
		loss: 0.074200
		loss: 0.072400
		loss: 0.070600
		loss: 0.068800
		loss: 0.067200
		loss: 0.065600
		loss: 0.064200
		loss: 0.062900
		loss: 0.061700
		loss: 0.060600
		loss: 0.059500
		loss: 0.058400
		loss: 0.057500
		loss: 0.056600
		loss: 0.055800
		loss: 0.055000
		loss: 0.054200
		loss: 0.053500
		loss: 0.052900
		loss: 0.052200
		loss: 0.051600
		loss: 0.051100
		loss: 0.050500
		loss: 0.050000
		loss: 0.049600
		loss: 0.049100
		loss: 0.048700
		loss: 0.048300
		loss: 0.047900
		loss: 0.047600
		loss: 0.047200
		loss: 0.046900
		loss: 0.046600
		loss: 0.046300
		loss: 0.046100
		loss: 0.045800
		loss: 0.045600
		loss: 0.045300
		loss: 0.045100
		loss: 0.044900
		loss: 0.044700
		loss: 0.044500
		loss: 0.044300
		loss: 0.044200
		loss: 0.044000
		loss: 0.043900
		loss: 0.043700
		loss: 0.043600
		loss: 0.043400
		loss: 0.043300
		loss: 0.043200
		loss: 0.043000
		loss: 0.042900
		loss: 0.042800
		loss: 0.042700
		loss: 0.042600
		loss: 0.042500
		loss: 0.042400
		loss: 0.042300
		loss: 0.042200
		loss: 0.042100
		loss: 0.042000
		loss: 0.041900
		loss: 0.041800
		loss: 0.041700
		loss: 0.041600
		loss: 0.041500
		loss: 0.041400
		loss: 0.041400
		loss: 0.041300
		loss: 0.041200
		loss: 0.041100
		loss: 0.041100
		loss: 0.041000
		loss: 0.040900
		loss: 0.040800
		loss: 0.040800
		loss: 0.040700
		loss: 0.040600
		loss: 0.040500
		loss: 0.040500
		loss: 0.040400
		loss: 0.040300
		loss: 0.040300
		loss: 0.040200
		loss: 0.040100
		loss: 0.040100
		loss: 0.040000
		loss: 0.039900
		loss: 0.039900
		loss: 0.039800
		loss: 0.039700
		loss: 0.039700
		loss: 0.039600
		loss: 0.039600
		loss: 0.039500
		loss: 0.039400
		loss: 0.039400
		loss: 0.039300
		loss: 0.039300
		loss: 0.039200
		loss: 0.039200
		loss: 0.039100
		loss: 0.039100
		loss: 0.039000
		loss: 0.039000
		loss: 0.038900
		loss: 0.038900
		loss: 0.038800
		loss: 0.038800
		loss: 0.038700
		loss: 0.038700
		loss: 0.038600
		loss: 0.038600
		loss: 0.038500
		loss: 0.038500
		loss: 0.038400
		loss: 0.038400
		loss: 0.038300
		loss: 0.038300
		loss: 0.038200
		loss: 0.038200
		loss: 0.038200
		loss: 0.038100
		loss: 0.038100
		loss: 0.038000
		loss: 0.038000
		loss: 0.037900
		loss: 0.037900
		loss: 0.037900
		loss: 0.037800
		loss: 0.037800
		loss: 0.037800
		loss: 0.037700
		loss: 0.037700
		loss: 0.037600
		loss: 0.037600
		loss: 0.037600
		loss: 0.037500
		loss: 0.037500
		loss: 0.037500
		loss: 0.037400
		loss: 0.037400
		loss: 0.037400
		loss: 0.037300
		loss: 0.037300
		loss: 0.037300
		loss: 0.037200
		loss: 0.037200
		loss: 0.037200
		loss: 0.037200
		loss: 0.037100
		loss: 0.037100
		loss: 0.037100
		loss: 0.037000
		loss: 0.037000
		loss: 0.037000
		loss: 0.037000
		loss: 0.036900
		loss: 0.036900
		loss: 0.036900
		loss: 0.036900
		loss: 0.036800
		loss: 0.036800
		loss: 0.036800
		loss: 0.036800
		loss: 0.036700
		loss: 0.036700
		loss: 0.036700
		loss: 0.036700
		loss: 0.036600
		loss: 0.036600
		loss: 0.036600
		loss: 0.036600
		loss: 0.036600
		loss: 0.036500
		loss: 0.036500
		loss: 0.036500
		loss: 0.036500
		loss: 0.036500
		loss: 0.036400
		loss: 0.036400
		loss: 0.036400
		loss: 0.036400
		loss: 0.036400
		loss: 0.036300
		loss: 0.036300
		loss: 0.036300
		loss: 0.036300
		loss: 0.036300
		loss: 0.036200
		loss: 0.036200
		loss: 0.036200
		loss: 0.036200
		loss: 0.036200
		loss: 0.036200
		loss: 0.036100
		loss: 0.036100
		loss: 0.036100
		loss: 0.036100
		loss: 0.036100
		loss: 0.036100
		loss: 0.036000
		loss: 0.036000
		loss: 0.036000
		loss: 0.036000
		loss: 0.036000
		loss: 0.036000
		loss: 0.036000
		loss: 0.035900
		loss: 0.035900
		loss: 0.035900
		loss: 0.035900
		loss: 0.035900
		loss: 0.035900
		loss: 0.035800
		loss: 0.035800
		loss: 0.035800
		loss: 0.035800
	Overall the loss development was 2.525500 -> 0.035800

Training data for problem d-4-1.pddl in epoch 8:
model creation time: 9.641920328140259s
problem epoch data for epoch 8, problem epoch 1
	sampling search time: 2.7564210891723633s
	during this search the following actions were chosen:
	training time: 60.71728491783142s
	during the training the following losses were computed:
		loss: 0.498700
		loss: 0.312000
		loss: 0.197800
		loss: 0.205500
		loss: 0.236300
		loss: 0.199300
		loss: 0.151800
		loss: 0.127000
		loss: 0.123700
		loss: 0.130700
		loss: 0.137900
		loss: 0.139100
		loss: 0.133400
		loss: 0.124000
		loss: 0.115800
		loss: 0.112400
		loss: 0.113800
		loss: 0.116600
		loss: 0.117200
		loss: 0.114100
		loss: 0.108000
		loss: 0.101600
		loss: 0.096600
		loss: 0.094000
		loss: 0.092800
		loss: 0.091700
		loss: 0.089600
		loss: 0.086500
		loss: 0.082800
		loss: 0.079400
		loss: 0.076800
		loss: 0.075100
		loss: 0.074000
		loss: 0.073100
		loss: 0.071900
		loss: 0.070300
		loss: 0.068600
		loss: 0.066800
		loss: 0.065400
		loss: 0.064200
		loss: 0.063400
		loss: 0.062600
		loss: 0.061900
		loss: 0.061000
		loss: 0.060000
		loss: 0.059100
		loss: 0.058100
		loss: 0.057300
		loss: 0.056600
		loss: 0.055900
		loss: 0.055400
		loss: 0.054800
		loss: 0.054200
		loss: 0.053600
		loss: 0.053000
		loss: 0.052400
		loss: 0.051900
		loss: 0.051400
		loss: 0.051000
		loss: 0.050600
		loss: 0.050200
		loss: 0.049800
		loss: 0.049400
		loss: 0.049100
		loss: 0.048700
		loss: 0.048400
		loss: 0.048100
		loss: 0.047800
		loss: 0.047600
		loss: 0.047300
		loss: 0.047100
		loss: 0.046800
		loss: 0.046600
		loss: 0.046400
		loss: 0.046200
		loss: 0.046000
		loss: 0.045800
		loss: 0.045600
		loss: 0.045500
		loss: 0.045300
		loss: 0.045200
		loss: 0.045000
		loss: 0.044900
		loss: 0.044700
		loss: 0.044600
		loss: 0.044500
		loss: 0.044400
		loss: 0.044300
		loss: 0.044200
		loss: 0.044100
		loss: 0.044000
		loss: 0.043900
		loss: 0.043900
		loss: 0.043800
		loss: 0.043700
		loss: 0.043600
		loss: 0.043600
		loss: 0.043500
		loss: 0.043500
		loss: 0.043400
		loss: 0.043400
		loss: 0.043300
		loss: 0.043300
		loss: 0.043200
		loss: 0.043200
		loss: 0.043100
		loss: 0.043100
		loss: 0.043100
		loss: 0.043000
		loss: 0.043000
		loss: 0.043000
		loss: 0.042900
		loss: 0.042900
		loss: 0.042900
		loss: 0.042800
		loss: 0.042800
		loss: 0.042800
		loss: 0.042800
		loss: 0.042700
		loss: 0.042700
		loss: 0.042700
		loss: 0.042600
		loss: 0.042600
		loss: 0.042600
		loss: 0.042600
		loss: 0.042600
		loss: 0.042500
		loss: 0.042500
		loss: 0.042500
		loss: 0.042500
		loss: 0.042400
		loss: 0.042400
		loss: 0.042400
		loss: 0.042400
		loss: 0.042400
		loss: 0.042300
		loss: 0.042300
		loss: 0.042300
		loss: 0.042300
		loss: 0.042200
		loss: 0.042200
		loss: 0.042200
		loss: 0.042200
		loss: 0.042200
		loss: 0.042200
		loss: 0.042100
		loss: 0.042100
		loss: 0.042100
		loss: 0.042100
		loss: 0.042100
		loss: 0.042000
		loss: 0.042000
		loss: 0.042000
		loss: 0.042000
		loss: 0.042000
		loss: 0.041900
		loss: 0.041900
		loss: 0.041900
		loss: 0.041900
		loss: 0.041900
		loss: 0.041900
		loss: 0.041800
		loss: 0.041800
		loss: 0.041800
		loss: 0.041800
		loss: 0.041800
		loss: 0.041700
		loss: 0.041700
		loss: 0.041700
		loss: 0.041700
		loss: 0.041700
		loss: 0.041700
		loss: 0.041600
		loss: 0.041600
		loss: 0.041600
		loss: 0.041600
		loss: 0.041600
		loss: 0.041600
		loss: 0.041500
		loss: 0.041500
		loss: 0.041500
		loss: 0.041500
		loss: 0.041500
		loss: 0.041400
		loss: 0.041400
		loss: 0.041400
		loss: 0.041400
		loss: 0.041400
		loss: 0.041400
		loss: 0.041300
		loss: 0.041300
		loss: 0.041300
		loss: 0.041300
		loss: 0.041300
		loss: 0.041300
		loss: 0.041200
		loss: 0.041200
		loss: 0.041200
		loss: 0.041200
		loss: 0.041200
		loss: 0.041200
		loss: 0.041100
		loss: 0.041100
		loss: 0.041100
		loss: 0.041100
		loss: 0.041100
		loss: 0.041100
		loss: 0.041000
		loss: 0.041000
		loss: 0.041000
		loss: 0.041000
		loss: 0.041000
		loss: 0.041000
		loss: 0.040900
		loss: 0.040900
		loss: 0.040900
		loss: 0.040900
		loss: 0.040900
		loss: 0.040900
		loss: 0.040800
		loss: 0.040800
		loss: 0.040800
		loss: 0.040800
		loss: 0.040800
		loss: 0.040800
		loss: 0.040700
		loss: 0.040700
		loss: 0.040700
		loss: 0.040700
		loss: 0.040700
		loss: 0.040700
		loss: 0.040700
		loss: 0.040600
		loss: 0.040600
		loss: 0.040600
		loss: 0.040600
		loss: 0.040600
		loss: 0.040600
		loss: 0.040500
		loss: 0.040500
		loss: 0.040500
		loss: 0.040500
		loss: 0.040500
		loss: 0.040500
		loss: 0.040400
		loss: 0.040400
		loss: 0.040400
		loss: 0.040400
		loss: 0.040400
		loss: 0.040400
		loss: 0.040300
		loss: 0.040300
		loss: 0.040300
		loss: 0.040300
		loss: 0.040300
		loss: 0.040300
		loss: 0.040300
		loss: 0.040200
		loss: 0.040200
		loss: 0.040200
		loss: 0.040200
		loss: 0.040200
		loss: 0.040200
		loss: 0.040100
		loss: 0.040100
		loss: 0.040100
		loss: 0.040100
		loss: 0.040100
		loss: 0.040100
		loss: 0.040100
		loss: 0.040000
		loss: 0.040000
		loss: 0.040000
		loss: 0.040000
		loss: 0.040000
		loss: 0.040000
		loss: 0.039900
		loss: 0.039900
		loss: 0.039900
		loss: 0.039900
		loss: 0.039900
		loss: 0.039900
		loss: 0.039900
		loss: 0.039800
		loss: 0.039800
		loss: 0.039800
		loss: 0.039800
		loss: 0.039800
		loss: 0.039800
		loss: 0.039800
		loss: 0.039700
		loss: 0.039700
		loss: 0.039700
		loss: 0.039700
		loss: 0.039700
		loss: 0.039700
		loss: 0.039700
		loss: 0.039600
		loss: 0.039600
		loss: 0.039600
	Overall the loss development was 0.498700 -> 0.039600

Training data for problem d-5-2.pddl in epoch 8:
model creation time: 15.506268501281738s
problem epoch data for epoch 8, problem epoch 1
	sampling search time: 15.532054424285889s
	during this search the following actions were chosen:
	training time: 73.01229691505432s
	during the training the following losses were computed:
		loss: 2.699200
		loss: 2.512600
		loss: 2.341300
		loss: 2.184300
		loss: 2.039300
		loss: 1.905000
		loss: 1.784900
		loss: 1.674000
		loss: 1.571900
		loss: 1.481000
		loss: 1.400400
		loss: 1.329600
		loss: 1.268600
		loss: 1.217400
		loss: 1.175300
		loss: 1.141100
		loss: 1.114200
		loss: 1.093000
		loss: 1.076800
		loss: 1.065000
		loss: 1.056800
		loss: 1.051800
		loss: 1.048800
		loss: 1.047200
		loss: 1.046500
		loss: 1.046300
		loss: 1.046200
		loss: 1.046000
		loss: 1.045400
		loss: 1.044200
		loss: 1.042500
		loss: 1.040400
		loss: 1.037900
		loss: 1.035000
		loss: 1.031900
		loss: 1.028500
		loss: 1.024900
		loss: 1.021200
		loss: 1.017500
		loss: 1.013900
		loss: 1.010100
		loss: 1.006300
		loss: 1.002500
		loss: 0.998800
		loss: 0.995100
		loss: 0.991400
		loss: 0.987800
		loss: 0.984200
		loss: 0.980800
		loss: 0.977400
		loss: 0.974100
		loss: 0.970800
		loss: 0.967500
		loss: 0.964300
		loss: 0.961100
		loss: 0.957900
		loss: 0.954700
		loss: 0.951500
		loss: 0.948400
		loss: 0.945200
		loss: 0.941900
		loss: 0.938600
		loss: 0.935200
		loss: 0.931800
		loss: 0.928400
		loss: 0.925100
		loss: 0.921700
		loss: 0.918300
		loss: 0.914900
		loss: 0.911600
		loss: 0.908300
		loss: 0.904900
		loss: 0.901400
		loss: 0.897900
		loss: 0.894400
		loss: 0.890900
		loss: 0.887500
		loss: 0.884000
		loss: 0.880500
		loss: 0.877000
		loss: 0.873500
		loss: 0.869700
		loss: 0.866100
		loss: 0.862300
		loss: 0.858500
		loss: 0.854900
		loss: 0.851100
		loss: 0.846800
		loss: 0.842300
		loss: 0.837300
		loss: 0.831900
		loss: 0.826800
		loss: 0.821500
		loss: 0.816300
		loss: 0.811600
		loss: 0.806700
		loss: 0.802200
		loss: 0.797500
		loss: 0.792300
		loss: 0.786600
		loss: 0.779400
		loss: 0.771100
		loss: 0.761300
		loss: 0.753900
		loss: 0.746700
		loss: 0.740400
		loss: 0.733800
		loss: 0.727300
		loss: 0.720300
		loss: 0.713200
		loss: 0.706800
		loss: 0.701300
		loss: 0.695900
		loss: 0.690900
		loss: 0.685300
		loss: 0.679800
		loss: 0.673900
		loss: 0.669000
		loss: 0.664200
		loss: 0.659700
		loss: 0.655100
		loss: 0.649900
		loss: 0.644800
		loss: 0.640100
		loss: 0.635500
		loss: 0.630900
		loss: 0.626500
		loss: 0.622000
		loss: 0.617200
		loss: 0.612800
		loss: 0.608600
		loss: 0.604300
		loss: 0.599800
		loss: 0.595200
		loss: 0.590900
		loss: 0.586700
		loss: 0.582100
		loss: 0.577300
		loss: 0.572600
		loss: 0.568400
		loss: 0.564600
		loss: 0.560400
		loss: 0.555900
		loss: 0.551600
		loss: 0.547400
		loss: 0.543300
		loss: 0.539300
		loss: 0.535900
		loss: 0.532600
		loss: 0.531500
		loss: 0.527900
		loss: 0.522700
		loss: 0.514500
		loss: 0.511500
		loss: 0.511900
		loss: 0.506700
		loss: 0.499400
		loss: 0.496100
		loss: 0.496100
		loss: 0.492300
		loss: 0.484600
		loss: 0.482200
		loss: 0.481900
		loss: 0.476900
		loss: 0.472200
		loss: 0.470600
		loss: 0.469100
		loss: 0.465800
		loss: 0.461300
		loss: 0.459300
		loss: 0.458800
		loss: 0.455400
		loss: 0.451800
		loss: 0.449400
		loss: 0.448100
		loss: 0.446100
		loss: 0.443300
		loss: 0.440700
		loss: 0.439100
		loss: 0.438100
		loss: 0.437000
		loss: 0.435000
		loss: 0.432600
		loss: 0.430100
		loss: 0.428500
		loss: 0.427500
		loss: 0.426400
		loss: 0.425000
		loss: 0.423100
		loss: 0.421300
		loss: 0.419700
		loss: 0.418200
		loss: 0.417000
		loss: 0.415800
		loss: 0.414600
		loss: 0.413400
		loss: 0.412400
		loss: 0.411500
		loss: 0.411400
		loss: 0.412300
		loss: 0.416200
		loss: 0.418300
		loss: 0.417300
		loss: 0.407500
		loss: 0.404700
		loss: 0.409100
		loss: 0.408700
		loss: 0.403400
		loss: 0.402500
		loss: 0.404800
		loss: 0.402300
		loss: 0.399000
		loss: 0.400300
		loss: 0.400600
		loss: 0.397400
		loss: 0.396500
		loss: 0.397600
		loss: 0.396000
		loss: 0.393900
		loss: 0.394100
		loss: 0.394500
		loss: 0.393700
		loss: 0.391700
		loss: 0.390900
		loss: 0.391000
		loss: 0.390500
		loss: 0.389400
		loss: 0.388400
		loss: 0.388100
		loss: 0.387900
		loss: 0.387000
		loss: 0.386200
		loss: 0.385800
		loss: 0.385500
		loss: 0.385000
		loss: 0.384300
		loss: 0.383600
		loss: 0.383100
		loss: 0.382800
		loss: 0.382500
		loss: 0.382100
		loss: 0.381500
		loss: 0.380700
		loss: 0.380100
		loss: 0.379700
		loss: 0.379400
		loss: 0.379100
		loss: 0.378600
		loss: 0.378000
		loss: 0.377500
		loss: 0.377100
		loss: 0.376800
		loss: 0.376600
		loss: 0.376300
		loss: 0.376000
		loss: 0.375700
		loss: 0.375200
		loss: 0.374800
		loss: 0.374300
		loss: 0.373900
		loss: 0.373500
		loss: 0.373100
		loss: 0.372700
		loss: 0.372400
		loss: 0.372100
		loss: 0.371800
		loss: 0.371700
		loss: 0.371600
		loss: 0.371700
		loss: 0.371800
		loss: 0.371900
		loss: 0.371800
		loss: 0.371200
		loss: 0.370600
		loss: 0.369700
		loss: 0.369100
		loss: 0.368600
		loss: 0.368500
		loss: 0.368500
		loss: 0.368600
		loss: 0.368900
		loss: 0.369000
		loss: 0.369000
		loss: 0.368600
		loss: 0.368000
		loss: 0.367300
		loss: 0.366700
		loss: 0.366200
		loss: 0.365900
		loss: 0.365700
		loss: 0.365700
		loss: 0.365900
		loss: 0.366200
		loss: 0.366700
		loss: 0.366800
		loss: 0.367100
		loss: 0.366600
		loss: 0.366000
		loss: 0.364900
		loss: 0.364100
	Overall the loss development was 2.699200 -> 0.364100

Training data for problem d-5-0.pddl in epoch 8:
model creation time: 14.700785398483276s
problem epoch data for epoch 8, problem epoch 1
	sampling search time: 27.105412483215332s
	during this search the following actions were chosen:
		unstack c e was chosen with probability 0.972548
		put-down c was chosen with probability 0.999941
		unstack e b was chosen with probability 0.999976
		put-down e was chosen with probability 0.954078
		unstack b a was chosen with probability 0.820372
		stack b e was chosen with probability 0.349592
		pick-up d was chosen with probability 0.885509
		stack d c was chosen with probability 0.999912
		unstack b e was chosen with probability 0.989305
		stack b d was chosen with probability 0.991804
		pick-up e was chosen with probability 0.992188
		stack e b was chosen with probability 0.960599
		pick-up a was chosen with probability 0.971984
		stack a e was chosen with probability 0.977741
	training time: 73.66447257995605s
	during the training the following losses were computed:
		loss: 0.977900
		loss: 0.950100
		loss: 0.743600
		loss: 0.821600
		loss: 0.729600
		loss: 0.672600
		loss: 0.687700
		loss: 0.640300
		loss: 0.574200
		loss: 0.553900
		loss: 0.551000
		loss: 0.513600
		loss: 0.473600
		loss: 0.457600
		loss: 0.451300
		loss: 0.430900
		loss: 0.401000
		loss: 0.383000
		loss: 0.378900
		loss: 0.370400
		loss: 0.356400
		loss: 0.355100
		loss: 0.362500
		loss: 0.362600
		loss: 0.357400
		loss: 0.356700
		loss: 0.359000
		loss: 0.356000
		loss: 0.350600
		loss: 0.348400
		loss: 0.348200
		loss: 0.346100
		loss: 0.342100
		loss: 0.339500
		loss: 0.338500
		loss: 0.336400
		loss: 0.333100
		loss: 0.330800
		loss: 0.330200
		loss: 0.329700
		loss: 0.328700
		loss: 0.328600
		loss: 0.328900
		loss: 0.328300
		loss: 0.327400
		loss: 0.327200
		loss: 0.327100
		loss: 0.326600
		loss: 0.326300
		loss: 0.326400
		loss: 0.326100
		loss: 0.325400
		loss: 0.324900
		loss: 0.324500
		loss: 0.323900
		loss: 0.323400
		loss: 0.323200
		loss: 0.322900
		loss: 0.322500
		loss: 0.322100
		loss: 0.321800
		loss: 0.321400
		loss: 0.321100
		loss: 0.321000
		loss: 0.320800
		loss: 0.320500
		loss: 0.320400
		loss: 0.320100
		loss: 0.319900
		loss: 0.319700
		loss: 0.319600
		loss: 0.319400
		loss: 0.319200
		loss: 0.319100
		loss: 0.318900
		loss: 0.318700
		loss: 0.318500
		loss: 0.318400
		loss: 0.318200
		loss: 0.318100
		loss: 0.317900
		loss: 0.317700
		loss: 0.317600
		loss: 0.317400
		loss: 0.317300
		loss: 0.317200
		loss: 0.317000
		loss: 0.316900
		loss: 0.316800
		loss: 0.316600
		loss: 0.316500
		loss: 0.316400
		loss: 0.316300
		loss: 0.316100
		loss: 0.316000
		loss: 0.315900
		loss: 0.315800
		loss: 0.315700
		loss: 0.315500
		loss: 0.315400
		loss: 0.315300
		loss: 0.315200
		loss: 0.315100
		loss: 0.315000
		loss: 0.314900
		loss: 0.314800
		loss: 0.314700
		loss: 0.314600
		loss: 0.314500
		loss: 0.314400
		loss: 0.314300
		loss: 0.314200
		loss: 0.314100
		loss: 0.314000
		loss: 0.313900
		loss: 0.313900
		loss: 0.313800
		loss: 0.313700
		loss: 0.313600
		loss: 0.313500
		loss: 0.313400
		loss: 0.313400
		loss: 0.313300
		loss: 0.313200
		loss: 0.313100
		loss: 0.313000
		loss: 0.313000
		loss: 0.312900
		loss: 0.312800
		loss: 0.312700
		loss: 0.312600
		loss: 0.312600
		loss: 0.312500
		loss: 0.312400
		loss: 0.312300
		loss: 0.312300
		loss: 0.312200
		loss: 0.312100
		loss: 0.312000
		loss: 0.312000
		loss: 0.311900
		loss: 0.311800
		loss: 0.311800
		loss: 0.311700
		loss: 0.311600
		loss: 0.311500
		loss: 0.311500
		loss: 0.311400
		loss: 0.311300
		loss: 0.311300
		loss: 0.311200
		loss: 0.311100
		loss: 0.311100
		loss: 0.311000
		loss: 0.311000
		loss: 0.310900
		loss: 0.310800
		loss: 0.310800
		loss: 0.310700
		loss: 0.310600
		loss: 0.310600
		loss: 0.310500
		loss: 0.310500
		loss: 0.310400
		loss: 0.310400
		loss: 0.310300
		loss: 0.310200
		loss: 0.310200
		loss: 0.310100
		loss: 0.310100
		loss: 0.310000
		loss: 0.310000
		loss: 0.309900
		loss: 0.309900
		loss: 0.309800
		loss: 0.309700
		loss: 0.309700
		loss: 0.309600
		loss: 0.309600
		loss: 0.309500
		loss: 0.309500
		loss: 0.309400
		loss: 0.309400
		loss: 0.309300
		loss: 0.309300
		loss: 0.309200
		loss: 0.309200
		loss: 0.309100
		loss: 0.309100
		loss: 0.309000
		loss: 0.309000
		loss: 0.308900
		loss: 0.308900
		loss: 0.308800
		loss: 0.308800
		loss: 0.308700
		loss: 0.308700
		loss: 0.308600
		loss: 0.308600
		loss: 0.308600
		loss: 0.308500
		loss: 0.308500
		loss: 0.308400
		loss: 0.308400
		loss: 0.308300
		loss: 0.308300
		loss: 0.308200
		loss: 0.308200
		loss: 0.308200
		loss: 0.308100
		loss: 0.308100
		loss: 0.308000
		loss: 0.308000
		loss: 0.307900
		loss: 0.307900
		loss: 0.307900
		loss: 0.307800
		loss: 0.307800
		loss: 0.307700
		loss: 0.307700
		loss: 0.307700
		loss: 0.307600
		loss: 0.307600
		loss: 0.307500
		loss: 0.307500
		loss: 0.307400
		loss: 0.307400
		loss: 0.307400
		loss: 0.307300
		loss: 0.307300
		loss: 0.307200
		loss: 0.307200
		loss: 0.307200
		loss: 0.307100
		loss: 0.307100
		loss: 0.307100
		loss: 0.307000
		loss: 0.307000
		loss: 0.306900
		loss: 0.306900
		loss: 0.306900
		loss: 0.306800
		loss: 0.306800
		loss: 0.306800
		loss: 0.306700
		loss: 0.306700
		loss: 0.306600
		loss: 0.306600
		loss: 0.306600
		loss: 0.306500
		loss: 0.306500
		loss: 0.306500
		loss: 0.306400
		loss: 0.306400
		loss: 0.306400
		loss: 0.306300
		loss: 0.306300
		loss: 0.306200
		loss: 0.306200
		loss: 0.306200
		loss: 0.306100
		loss: 0.306100
		loss: 0.306100
		loss: 0.306000
		loss: 0.306000
		loss: 0.306000
		loss: 0.305900
		loss: 0.305900
		loss: 0.305900
		loss: 0.305800
		loss: 0.305800
		loss: 0.305700
		loss: 0.305700
		loss: 0.305700
		loss: 0.305600
		loss: 0.305600
		loss: 0.305600
		loss: 0.305500
		loss: 0.305500
		loss: 0.305500
		loss: 0.305400
		loss: 0.305400
		loss: 0.305400
		loss: 0.305300
		loss: 0.305300
		loss: 0.305300
		loss: 0.305200
		loss: 0.305200
		loss: 0.305200
		loss: 0.305100
		loss: 0.305100
		loss: 0.305100
		loss: 0.305000
		loss: 0.305000
		loss: 0.305000
		loss: 0.304900
		loss: 0.304900
		loss: 0.304900
		loss: 0.304800
		loss: 0.304800
	Overall the loss development was 0.977900 -> 0.304800

Training data for problem d-5-1.pddl in epoch 8:
model creation time: 14.45096731185913s
problem epoch data for epoch 8, problem epoch 1
	sampling search time: 30.826382637023926s
	during this search the following actions were chosen:
		pick-up c was chosen with probability 0.942387
		put-down c was chosen with probability 0.986500
	training time: 73.49011087417603s
	during the training the following losses were computed:
		loss: 1.146500
		loss: 0.942800
		loss: 0.755000
		loss: 0.600400
		loss: 0.476900
		loss: 0.379000
		loss: 0.319300
		loss: 0.271200
		loss: 0.251300
		loss: 0.244400
		loss: 0.249500
		loss: 0.257600
		loss: 0.264000
		loss: 0.265800
		loss: 0.264000
		loss: 0.258000
		loss: 0.249300
		loss: 0.240600
		loss: 0.233500
		loss: 0.227800
		loss: 0.224300
		loss: 0.222600
		loss: 0.222100
		loss: 0.222000
		loss: 0.222000
		loss: 0.221800
		loss: 0.221100
		loss: 0.219600
		loss: 0.217400
		loss: 0.215000
		loss: 0.212600
		loss: 0.210400
		loss: 0.208400
		loss: 0.206800
		loss: 0.205300
		loss: 0.204100
		loss: 0.203100
		loss: 0.202400
		loss: 0.201700
		loss: 0.201000
		loss: 0.200400
		loss: 0.199800
		loss: 0.199200
		loss: 0.198600
		loss: 0.198100
		loss: 0.197500
		loss: 0.197000
		loss: 0.196500
		loss: 0.196000
		loss: 0.195500
		loss: 0.195100
		loss: 0.194700
		loss: 0.194300
		loss: 0.193900
		loss: 0.193600
		loss: 0.193300
		loss: 0.193000
		loss: 0.192800
		loss: 0.192500
		loss: 0.192300
		loss: 0.192100
		loss: 0.191900
		loss: 0.191700
		loss: 0.191500
		loss: 0.191300
		loss: 0.191100
		loss: 0.190900
		loss: 0.190700
		loss: 0.190500
		loss: 0.190300
		loss: 0.190200
		loss: 0.190000
		loss: 0.189900
		loss: 0.189700
		loss: 0.189600
		loss: 0.189400
		loss: 0.189300
		loss: 0.189200
		loss: 0.189000
		loss: 0.188900
		loss: 0.188800
		loss: 0.188700
		loss: 0.188600
		loss: 0.188500
		loss: 0.188400
		loss: 0.188300
		loss: 0.188200
		loss: 0.188100
		loss: 0.188000
		loss: 0.187900
		loss: 0.187800
		loss: 0.187700
		loss: 0.187600
		loss: 0.187500
		loss: 0.187400
		loss: 0.187300
		loss: 0.187200
		loss: 0.187200
		loss: 0.187100
		loss: 0.187000
		loss: 0.186900
		loss: 0.186800
		loss: 0.186800
		loss: 0.186700
		loss: 0.186600
		loss: 0.186500
		loss: 0.186500
		loss: 0.186500
		loss: 0.186500
		loss: 0.186700
		loss: 0.186300
		loss: 0.187300
		loss: 0.187300
		loss: 0.187200
		loss: 0.186200
		loss: 0.187200
		loss: 0.186700
		loss: 0.187700
		loss: 0.186000
		loss: 0.187200
		loss: 0.186700
		loss: 0.186100
		loss: 0.187000
		loss: 0.185900
		loss: 0.186300
		loss: 0.186300
		loss: 0.185700
		loss: 0.186300
		loss: 0.185700
		loss: 0.185700
		loss: 0.185900
		loss: 0.185400
		loss: 0.185700
		loss: 0.185400
		loss: 0.185300
		loss: 0.185400
		loss: 0.185100
		loss: 0.185200
		loss: 0.185100
		loss: 0.185000
		loss: 0.185100
		loss: 0.184800
		loss: 0.184800
		loss: 0.184800
		loss: 0.184700
		loss: 0.184700
		loss: 0.184600
		loss: 0.184500
		loss: 0.184500
		loss: 0.184400
		loss: 0.184400
		loss: 0.184300
		loss: 0.184300
		loss: 0.184200
		loss: 0.184300
		loss: 0.184300
		loss: 0.184200
		loss: 0.184100
		loss: 0.184000
		loss: 0.184000
		loss: 0.184000
		loss: 0.183900
		loss: 0.183900
		loss: 0.183800
		loss: 0.183800
		loss: 0.183800
		loss: 0.183700
		loss: 0.183700
		loss: 0.183600
		loss: 0.183500
		loss: 0.183500
		loss: 0.183400
		loss: 0.183400
		loss: 0.183400
		loss: 0.183300
		loss: 0.183300
		loss: 0.183300
		loss: 0.183200
		loss: 0.183300
		loss: 0.183300
		loss: 0.183100
		loss: 0.183200
		loss: 0.183000
		loss: 0.183100
		loss: 0.182900
		loss: 0.183000
		loss: 0.182800
		loss: 0.182900
		loss: 0.182800
		loss: 0.182800
		loss: 0.182700
		loss: 0.182700
		loss: 0.182600
		loss: 0.182600
		loss: 0.182500
		loss: 0.182500
		loss: 0.182400
		loss: 0.182400
		loss: 0.182300
		loss: 0.182300
		loss: 0.182200
		loss: 0.182300
		loss: 0.182300
		loss: 0.182100
		loss: 0.182600
		loss: 0.182900
		loss: 0.182200
		loss: 0.183000
		loss: 0.182400
		loss: 0.182600
		loss: 0.182100
		loss: 0.182600
		loss: 0.182000
		loss: 0.182500
		loss: 0.181800
		loss: 0.182300
		loss: 0.181800
		loss: 0.182200
		loss: 0.181700
		loss: 0.182000
		loss: 0.181700
		loss: 0.181800
		loss: 0.181600
		loss: 0.181600
		loss: 0.181500
		loss: 0.181500
		loss: 0.181400
		loss: 0.181400
		loss: 0.181400
		loss: 0.181200
		loss: 0.181300
		loss: 0.181100
		loss: 0.181200
		loss: 0.181100
		loss: 0.181100
		loss: 0.181000
		loss: 0.181100
		loss: 0.181100
		loss: 0.180900
		loss: 0.181300
		loss: 0.181400
		loss: 0.181000
		loss: 0.181400
		loss: 0.180900
		loss: 0.181100
		loss: 0.180800
		loss: 0.181100
		loss: 0.180700
		loss: 0.181000
		loss: 0.180600
		loss: 0.180900
		loss: 0.180500
		loss: 0.180800
		loss: 0.180500
		loss: 0.180600
		loss: 0.180400
		loss: 0.180500
		loss: 0.180300
		loss: 0.180400
		loss: 0.180300
		loss: 0.180300
		loss: 0.180200
		loss: 0.180200
		loss: 0.180100
		loss: 0.180100
		loss: 0.180000
		loss: 0.180100
		loss: 0.180000
		loss: 0.179900
		loss: 0.180000
		loss: 0.180100
		loss: 0.179800
		loss: 0.180300
		loss: 0.180400
		loss: 0.179900
		loss: 0.180400
		loss: 0.179800
		loss: 0.180100
		loss: 0.179700
		loss: 0.180100
		loss: 0.179700
		loss: 0.180000
		loss: 0.179600
		loss: 0.179800
		loss: 0.179600
		loss: 0.179700
		loss: 0.179500
		loss: 0.179600
		loss: 0.179400
		loss: 0.179500
		loss: 0.179400
		loss: 0.179300
		loss: 0.179300
		loss: 0.179200
		loss: 0.179200
		loss: 0.179200
		loss: 0.179200
		loss: 0.179100
		loss: 0.179100
		loss: 0.179100
	Overall the loss development was 1.146500 -> 0.179100

Epoch 9:
Training data for problem d-4-0.pddl in epoch 9:
model creation time: 10.369197130203247s
problem epoch data for epoch 9, problem epoch 1
	sampling search time: 22.4198899269104s
	during this search the following actions were chosen:
		pick-up b was chosen with probability 0.332302
		stack b a was chosen with probability 0.998159
		pick-up c was chosen with probability 0.995975
		stack c b was chosen with probability 0.998336
		pick-up d was chosen with probability 0.999452
		stack d c was chosen with probability 0.999735
	training time: 60.389193296432495s
	during the training the following losses were computed:
		loss: 0.218700
		loss: 0.217500
		loss: 0.216700
		loss: 0.215700
		loss: 0.214800
		loss: 0.214000
		loss: 0.213100
		loss: 0.212300
		loss: 0.211400
		loss: 0.210600
		loss: 0.209700
		loss: 0.208900
		loss: 0.208100
		loss: 0.207300
		loss: 0.206600
		loss: 0.205800
		loss: 0.205100
		loss: 0.204400
		loss: 0.203700
		loss: 0.203000
		loss: 0.202400
		loss: 0.201700
		loss: 0.201100
		loss: 0.200500
		loss: 0.199900
		loss: 0.199300
		loss: 0.198700
		loss: 0.198200
		loss: 0.197600
		loss: 0.197100
		loss: 0.196600
		loss: 0.196100
		loss: 0.195700
		loss: 0.195200
		loss: 0.194800
		loss: 0.194400
		loss: 0.194000
		loss: 0.193600
		loss: 0.193200
		loss: 0.192800
		loss: 0.192400
		loss: 0.192100
		loss: 0.191700
		loss: 0.191400
		loss: 0.191100
		loss: 0.190800
		loss: 0.190500
		loss: 0.190200
		loss: 0.189900
		loss: 0.189600
		loss: 0.189300
		loss: 0.189000
		loss: 0.188800
		loss: 0.188500
		loss: 0.188300
		loss: 0.188000
		loss: 0.187800
		loss: 0.187600
		loss: 0.187400
		loss: 0.187100
		loss: 0.186900
		loss: 0.186700
		loss: 0.186500
		loss: 0.186300
		loss: 0.186100
		loss: 0.185900
		loss: 0.185800
		loss: 0.185600
		loss: 0.185400
		loss: 0.185200
		loss: 0.185100
		loss: 0.184900
		loss: 0.184800
		loss: 0.184600
		loss: 0.184500
		loss: 0.184300
		loss: 0.184200
		loss: 0.184000
		loss: 0.183900
		loss: 0.183700
		loss: 0.183600
		loss: 0.183500
		loss: 0.183400
		loss: 0.183200
		loss: 0.183100
		loss: 0.183000
		loss: 0.182900
		loss: 0.182800
		loss: 0.182600
		loss: 0.182500
		loss: 0.182400
		loss: 0.182300
		loss: 0.182200
		loss: 0.182100
		loss: 0.182000
		loss: 0.181900
		loss: 0.181800
		loss: 0.181700
		loss: 0.181700
		loss: 0.181600
		loss: 0.181500
		loss: 0.181400
		loss: 0.181300
		loss: 0.181200
		loss: 0.181200
		loss: 0.181100
		loss: 0.181000
		loss: 0.180900
		loss: 0.180900
		loss: 0.180800
		loss: 0.180700
		loss: 0.180600
		loss: 0.180600
		loss: 0.180500
		loss: 0.180400
		loss: 0.180400
		loss: 0.180300
		loss: 0.180300
		loss: 0.180200
		loss: 0.180100
		loss: 0.180100
		loss: 0.180000
		loss: 0.180000
		loss: 0.179900
		loss: 0.179900
		loss: 0.179800
		loss: 0.179800
		loss: 0.179700
		loss: 0.179700
		loss: 0.179600
		loss: 0.179600
		loss: 0.179500
		loss: 0.179500
		loss: 0.179400
		loss: 0.179400
		loss: 0.179300
		loss: 0.179300
		loss: 0.179300
		loss: 0.179200
		loss: 0.179200
		loss: 0.179100
		loss: 0.179100
		loss: 0.179100
		loss: 0.179000
		loss: 0.179000
		loss: 0.179000
		loss: 0.178900
		loss: 0.178900
		loss: 0.178900
		loss: 0.178800
		loss: 0.178800
		loss: 0.178800
		loss: 0.178700
		loss: 0.178700
		loss: 0.178700
		loss: 0.178600
		loss: 0.178600
		loss: 0.178600
		loss: 0.178600
		loss: 0.178500
		loss: 0.178500
		loss: 0.178500
		loss: 0.178500
		loss: 0.178400
		loss: 0.178400
		loss: 0.178400
		loss: 0.178400
		loss: 0.178300
		loss: 0.178300
		loss: 0.178300
		loss: 0.178300
		loss: 0.178200
		loss: 0.178200
		loss: 0.178200
		loss: 0.178200
		loss: 0.178100
		loss: 0.178100
		loss: 0.178100
		loss: 0.178100
		loss: 0.178100
		loss: 0.178000
		loss: 0.178000
		loss: 0.178000
		loss: 0.178000
		loss: 0.178000
		loss: 0.177900
		loss: 0.177900
		loss: 0.177900
		loss: 0.177900
		loss: 0.177900
		loss: 0.177900
		loss: 0.177800
		loss: 0.177800
		loss: 0.177800
		loss: 0.177800
		loss: 0.177800
		loss: 0.177800
		loss: 0.177700
		loss: 0.177700
		loss: 0.177700
		loss: 0.177700
		loss: 0.177700
		loss: 0.177700
		loss: 0.177700
		loss: 0.177600
		loss: 0.177600
		loss: 0.177600
		loss: 0.177600
		loss: 0.177600
		loss: 0.177600
		loss: 0.177600
		loss: 0.177500
		loss: 0.177500
		loss: 0.177500
		loss: 0.177500
		loss: 0.177500
		loss: 0.177500
		loss: 0.177500
		loss: 0.177500
		loss: 0.177400
		loss: 0.177400
		loss: 0.177400
		loss: 0.177400
		loss: 0.177400
		loss: 0.177400
		loss: 0.177400
		loss: 0.177400
		loss: 0.177400
		loss: 0.177300
		loss: 0.177300
		loss: 0.177300
		loss: 0.177300
		loss: 0.177300
		loss: 0.177300
		loss: 0.177300
		loss: 0.177300
		loss: 0.177300
		loss: 0.177300
		loss: 0.177300
		loss: 0.177200
		loss: 0.177200
		loss: 0.177200
		loss: 0.177200
		loss: 0.177200
		loss: 0.177200
		loss: 0.177200
		loss: 0.177200
		loss: 0.177200
		loss: 0.177200
		loss: 0.177200
		loss: 0.177200
		loss: 0.177100
		loss: 0.177100
		loss: 0.177100
		loss: 0.177100
		loss: 0.177100
		loss: 0.177100
		loss: 0.177100
		loss: 0.177100
		loss: 0.177100
		loss: 0.177100
		loss: 0.177100
		loss: 0.177100
		loss: 0.177100
		loss: 0.177000
		loss: 0.177000
		loss: 0.177000
		loss: 0.177000
		loss: 0.177000
		loss: 0.177000
		loss: 0.177000
		loss: 0.177000
		loss: 0.177000
		loss: 0.177000
		loss: 0.177000
		loss: 0.177000
		loss: 0.177000
		loss: 0.177000
		loss: 0.177000
		loss: 0.177000
		loss: 0.176900
		loss: 0.176900
		loss: 0.176900
		loss: 0.176900
		loss: 0.176900
		loss: 0.176900
		loss: 0.176900
		loss: 0.176900
		loss: 0.176900
		loss: 0.176900
		loss: 0.176900
		loss: 0.176900
		loss: 0.176900
		loss: 0.176900
		loss: 0.176900
		loss: 0.176900
		loss: 0.176900
		loss: 0.176900
		loss: 0.176900
		loss: 0.176800
	Overall the loss development was 0.218700 -> 0.176800

Training data for problem d-4-2.pddl in epoch 9:
model creation time: 11.157109260559082s
problem epoch data for epoch 9, problem epoch 1
	sampling search time: 28.27302050590515s
	during this search the following actions were chosen:
		pick-up a was chosen with probability 0.995374
		stack a c was chosen with probability 0.764646
		pick-up d was chosen with probability 0.999310
		stack d a was chosen with probability 0.994016
	training time: 78.56018042564392s
	during the training the following losses were computed:
		loss: 2.800900
		loss: 2.589200
		loss: 2.389600
		loss: 2.200400
		loss: 2.021100
		loss: 1.851200
		loss: 1.690700
		loss: 1.539200
		loss: 1.396700
		loss: 1.263200
		loss: 1.140300
		loss: 1.026600
		loss: 0.922000
		loss: 0.826200
		loss: 0.741200
		loss: 0.667400
		loss: 0.603300
		loss: 0.550100
		loss: 0.512900
		loss: 0.486700
		loss: 0.470900
		loss: 0.471000
		loss: 0.476900
		loss: 0.487100
		loss: 0.498700
		loss: 0.509200
		loss: 0.515900
		loss: 0.516600
		loss: 0.510800
		loss: 0.499900
		loss: 0.485100
		loss: 0.468600
		loss: 0.451500
		loss: 0.434800
		loss: 0.419400
		loss: 0.405200
		loss: 0.392100
		loss: 0.379900
		loss: 0.368600
		loss: 0.357900
		loss: 0.347800
		loss: 0.339700
		loss: 0.333000
		loss: 0.326000
		loss: 0.318000
		loss: 0.309000
		loss: 0.299700
		loss: 0.290800
		loss: 0.282900
		loss: 0.276600
		loss: 0.271900
		loss: 0.268100
		loss: 0.264100
		loss: 0.258800
		loss: 0.251900
		loss: 0.244100
		loss: 0.236300
		loss: 0.229300
		loss: 0.223400
		loss: 0.218300
		loss: 0.213200
		loss: 0.207600
		loss: 0.201400
		loss: 0.194800
		loss: 0.188400
		loss: 0.182400
		loss: 0.177100
		loss: 0.172100
		loss: 0.167200
		loss: 0.161800
		loss: 0.155900
		loss: 0.150100
		loss: 0.144700
		loss: 0.139800
		loss: 0.135100
		loss: 0.130400
		loss: 0.125400
		loss: 0.120600
		loss: 0.116100
		loss: 0.111900
		loss: 0.107900
		loss: 0.104000
		loss: 0.100100
		loss: 0.096300
		loss: 0.092900
		loss: 0.089700
		loss: 0.086700
		loss: 0.083800
		loss: 0.081000
		loss: 0.078400
		loss: 0.075900
		loss: 0.073700
		loss: 0.071600
		loss: 0.069600
		loss: 0.067700
		loss: 0.065900
		loss: 0.064300
		loss: 0.062900
		loss: 0.061500
		loss: 0.060200
		loss: 0.059000
		loss: 0.057900
		loss: 0.056900
		loss: 0.055900
		loss: 0.055100
		loss: 0.054200
		loss: 0.053500
		loss: 0.052800
		loss: 0.052200
		loss: 0.051600
		loss: 0.051000
		loss: 0.050500
		loss: 0.050100
		loss: 0.049600
		loss: 0.049200
		loss: 0.048900
		loss: 0.048500
		loss: 0.048200
		loss: 0.047900
		loss: 0.047600
		loss: 0.047300
		loss: 0.047100
		loss: 0.046800
		loss: 0.046600
		loss: 0.046400
		loss: 0.046200
		loss: 0.046000
		loss: 0.045800
		loss: 0.045600
		loss: 0.045500
		loss: 0.045300
		loss: 0.045100
		loss: 0.045000
		loss: 0.044900
		loss: 0.044700
		loss: 0.044600
		loss: 0.044500
		loss: 0.044300
		loss: 0.044200
		loss: 0.044100
		loss: 0.044000
		loss: 0.043900
		loss: 0.043800
		loss: 0.043600
		loss: 0.043500
		loss: 0.043400
		loss: 0.043300
		loss: 0.043200
		loss: 0.043100
		loss: 0.043100
		loss: 0.043000
		loss: 0.042900
		loss: 0.042800
		loss: 0.042700
		loss: 0.042600
		loss: 0.042500
		loss: 0.042400
		loss: 0.042400
		loss: 0.042300
		loss: 0.042200
		loss: 0.042100
		loss: 0.042000
		loss: 0.042000
		loss: 0.041900
		loss: 0.041800
		loss: 0.041800
		loss: 0.041700
		loss: 0.041600
		loss: 0.041500
		loss: 0.041500
		loss: 0.041400
		loss: 0.041300
		loss: 0.041300
		loss: 0.041200
		loss: 0.041100
		loss: 0.041100
		loss: 0.041000
		loss: 0.041000
		loss: 0.040900
		loss: 0.040800
		loss: 0.040800
		loss: 0.040700
		loss: 0.040700
		loss: 0.040600
		loss: 0.040500
		loss: 0.040500
		loss: 0.040400
		loss: 0.040400
		loss: 0.040300
		loss: 0.040300
		loss: 0.040200
		loss: 0.040200
		loss: 0.040100
		loss: 0.040100
		loss: 0.040000
		loss: 0.040000
		loss: 0.039900
		loss: 0.039900
		loss: 0.039800
		loss: 0.039800
		loss: 0.039700
		loss: 0.039700
		loss: 0.039600
		loss: 0.039600
		loss: 0.039500
		loss: 0.039500
		loss: 0.039400
		loss: 0.039400
		loss: 0.039300
		loss: 0.039300
		loss: 0.039200
		loss: 0.039200
		loss: 0.039200
		loss: 0.039100
		loss: 0.039100
		loss: 0.039000
		loss: 0.039000
		loss: 0.039000
		loss: 0.038900
		loss: 0.038900
		loss: 0.038800
		loss: 0.038800
		loss: 0.038800
		loss: 0.038700
		loss: 0.038700
		loss: 0.038600
		loss: 0.038600
		loss: 0.038600
		loss: 0.038500
		loss: 0.038500
		loss: 0.038400
		loss: 0.038400
		loss: 0.038400
		loss: 0.038300
		loss: 0.038300
		loss: 0.038300
		loss: 0.038200
		loss: 0.038200
		loss: 0.038200
		loss: 0.038100
		loss: 0.038100
		loss: 0.038100
		loss: 0.038000
		loss: 0.038000
		loss: 0.038000
		loss: 0.037900
		loss: 0.037900
		loss: 0.037900
		loss: 0.037800
		loss: 0.037800
		loss: 0.037800
		loss: 0.037700
		loss: 0.037700
		loss: 0.037700
		loss: 0.037600
		loss: 0.037600
		loss: 0.037600
		loss: 0.037600
		loss: 0.037500
		loss: 0.037500
		loss: 0.037500
		loss: 0.037400
		loss: 0.037400
		loss: 0.037400
		loss: 0.037400
		loss: 0.037300
		loss: 0.037300
		loss: 0.037300
		loss: 0.037200
		loss: 0.037200
		loss: 0.037200
		loss: 0.037200
		loss: 0.037100
		loss: 0.037100
		loss: 0.037100
		loss: 0.037100
		loss: 0.037000
		loss: 0.037000
		loss: 0.037000
		loss: 0.037000
		loss: 0.036900
		loss: 0.036900
		loss: 0.036900
		loss: 0.036900
		loss: 0.036800
		loss: 0.036800
		loss: 0.036800
		loss: 0.036800
		loss: 0.036700
		loss: 0.036700
		loss: 0.036700
		loss: 0.036700
		loss: 0.036700
		loss: 0.036600
		loss: 0.036600
		loss: 0.036600
		loss: 0.036600
		loss: 0.036500
		loss: 0.036500
		loss: 0.036500
	Overall the loss development was 2.800900 -> 0.036500

Training data for problem d-4-1.pddl in epoch 9:
model creation time: 16.246031761169434s
problem epoch data for epoch 9, problem epoch 1
	sampling search time: 20.04852056503296s
	during this search the following actions were chosen:
	training time: 59.15238642692566s
	during the training the following losses were computed:
		loss: 0.434700
		loss: 0.260000
		loss: 0.160400
		loss: 0.179400
		loss: 0.197500
		loss: 0.160500
		loss: 0.122200
		loss: 0.104400
		loss: 0.102500
		loss: 0.108400
		loss: 0.114200
		loss: 0.115100
		loss: 0.110200
		loss: 0.102300
		loss: 0.095100
		loss: 0.091500
		loss: 0.091600
		loss: 0.093500
		loss: 0.094600
		loss: 0.093100
		loss: 0.089200
		loss: 0.084200
		loss: 0.079900
		loss: 0.076900
		loss: 0.075400
		loss: 0.074600
		loss: 0.073700
		loss: 0.072200
		loss: 0.070100
		loss: 0.067600
		loss: 0.065300
		loss: 0.063400
		loss: 0.062000
		loss: 0.061200
		loss: 0.060600
		loss: 0.060000
		loss: 0.059200
		loss: 0.058200
		loss: 0.057200
		loss: 0.056200
		loss: 0.055200
		loss: 0.054500
		loss: 0.053900
		loss: 0.053500
		loss: 0.053100
		loss: 0.052600
		loss: 0.052200
		loss: 0.051600
		loss: 0.051100
		loss: 0.050600
		loss: 0.050200
		loss: 0.049700
		loss: 0.049400
		loss: 0.049100
		loss: 0.048800
		loss: 0.048500
		loss: 0.048200
		loss: 0.047900
		loss: 0.047700
		loss: 0.047400
		loss: 0.047100
		loss: 0.046900
		loss: 0.046700
		loss: 0.046500
		loss: 0.046300
		loss: 0.046100
		loss: 0.046000
		loss: 0.045800
		loss: 0.045700
		loss: 0.045500
		loss: 0.045400
		loss: 0.045200
		loss: 0.045100
		loss: 0.045000
		loss: 0.044900
		loss: 0.044800
		loss: 0.044700
		loss: 0.044600
		loss: 0.044500
		loss: 0.044400
		loss: 0.044300
		loss: 0.044200
		loss: 0.044100
		loss: 0.044100
		loss: 0.044000
		loss: 0.043900
		loss: 0.043800
		loss: 0.043800
		loss: 0.043700
		loss: 0.043700
		loss: 0.043600
		loss: 0.043500
		loss: 0.043500
		loss: 0.043400
		loss: 0.043400
		loss: 0.043300
		loss: 0.043300
		loss: 0.043200
		loss: 0.043200
		loss: 0.043100
		loss: 0.043100
		loss: 0.043100
		loss: 0.043000
		loss: 0.043000
		loss: 0.042900
		loss: 0.042900
		loss: 0.042900
		loss: 0.042800
		loss: 0.042800
		loss: 0.042700
		loss: 0.042700
		loss: 0.042700
		loss: 0.042700
		loss: 0.042600
		loss: 0.042600
		loss: 0.042600
		loss: 0.042500
		loss: 0.042500
		loss: 0.042500
		loss: 0.042400
		loss: 0.042400
		loss: 0.042400
		loss: 0.042400
		loss: 0.042300
		loss: 0.042300
		loss: 0.042300
		loss: 0.042300
		loss: 0.042200
		loss: 0.042200
		loss: 0.042200
		loss: 0.042200
		loss: 0.042100
		loss: 0.042100
		loss: 0.042100
		loss: 0.042100
		loss: 0.042000
		loss: 0.042000
		loss: 0.042000
		loss: 0.042000
		loss: 0.041900
		loss: 0.041900
		loss: 0.041900
		loss: 0.041900
		loss: 0.041900
		loss: 0.041800
		loss: 0.041800
		loss: 0.041800
		loss: 0.041800
		loss: 0.041700
		loss: 0.041700
		loss: 0.041700
		loss: 0.041700
		loss: 0.041700
		loss: 0.041600
		loss: 0.041600
		loss: 0.041600
		loss: 0.041600
		loss: 0.041600
		loss: 0.041500
		loss: 0.041500
		loss: 0.041500
		loss: 0.041500
		loss: 0.041500
		loss: 0.041400
		loss: 0.041400
		loss: 0.041400
		loss: 0.041400
		loss: 0.041400
		loss: 0.041300
		loss: 0.041300
		loss: 0.041300
		loss: 0.041300
		loss: 0.041300
		loss: 0.041200
		loss: 0.041200
		loss: 0.041200
		loss: 0.041200
		loss: 0.041200
		loss: 0.041100
		loss: 0.041100
		loss: 0.041100
		loss: 0.041100
		loss: 0.041100
		loss: 0.041100
		loss: 0.041000
		loss: 0.041000
		loss: 0.041000
		loss: 0.041000
		loss: 0.041000
		loss: 0.040900
		loss: 0.040900
		loss: 0.040900
		loss: 0.040900
		loss: 0.040900
		loss: 0.040800
		loss: 0.040800
		loss: 0.040800
		loss: 0.040800
		loss: 0.040800
		loss: 0.040800
		loss: 0.040700
		loss: 0.040700
		loss: 0.040700
		loss: 0.040700
		loss: 0.040700
		loss: 0.040600
		loss: 0.040600
		loss: 0.040600
		loss: 0.040600
		loss: 0.040600
		loss: 0.040600
		loss: 0.040500
		loss: 0.040500
		loss: 0.040500
		loss: 0.040500
		loss: 0.040500
		loss: 0.040500
		loss: 0.040400
		loss: 0.040400
		loss: 0.040400
		loss: 0.040400
		loss: 0.040400
		loss: 0.040400
		loss: 0.040300
		loss: 0.040300
		loss: 0.040300
		loss: 0.040300
		loss: 0.040300
		loss: 0.040200
		loss: 0.040200
		loss: 0.040200
		loss: 0.040200
		loss: 0.040200
		loss: 0.040200
		loss: 0.040100
		loss: 0.040100
		loss: 0.040100
		loss: 0.040100
		loss: 0.040100
		loss: 0.040100
		loss: 0.040000
		loss: 0.040000
		loss: 0.040000
		loss: 0.040000
		loss: 0.040000
		loss: 0.040000
		loss: 0.039900
		loss: 0.039900
		loss: 0.039900
		loss: 0.039900
		loss: 0.039900
		loss: 0.039900
		loss: 0.039800
		loss: 0.039800
		loss: 0.039800
		loss: 0.039800
		loss: 0.039800
		loss: 0.039800
		loss: 0.039800
		loss: 0.039700
		loss: 0.039700
		loss: 0.039700
		loss: 0.039700
		loss: 0.039700
		loss: 0.039700
		loss: 0.039600
		loss: 0.039600
		loss: 0.039600
		loss: 0.039600
		loss: 0.039600
		loss: 0.039600
		loss: 0.039500
		loss: 0.039500
		loss: 0.039500
		loss: 0.039500
		loss: 0.039500
		loss: 0.039500
		loss: 0.039500
		loss: 0.039400
		loss: 0.039400
		loss: 0.039400
		loss: 0.039400
		loss: 0.039400
		loss: 0.039400
		loss: 0.039300
		loss: 0.039300
		loss: 0.039300
		loss: 0.039300
		loss: 0.039300
		loss: 0.039300
		loss: 0.039300
		loss: 0.039200
		loss: 0.039200
		loss: 0.039200
		loss: 0.039200
		loss: 0.039200
		loss: 0.039200
		loss: 0.039100
		loss: 0.039100
		loss: 0.039100
	Overall the loss development was 0.434700 -> 0.039100

Training data for problem d-5-2.pddl in epoch 9:
model creation time: 14.79995584487915s
problem epoch data for epoch 9, problem epoch 1
	sampling search time: 17.556295156478882s
	during this search the following actions were chosen:
	training time: 77.32821702957153s
	during the training the following losses were computed:
		loss: 2.779300
		loss: 2.640400
		loss: 2.463900
		loss: 2.313900
		loss: 2.160400
		loss: 2.018700
		loss: 1.892100
		loss: 1.772500
		loss: 1.663900
		loss: 1.566300
		loss: 1.479100
		loss: 1.401700
		loss: 1.334600
		loss: 1.277300
		loss: 1.229500
		loss: 1.190100
		loss: 1.157900
		loss: 1.132400
		loss: 1.113300
		loss: 1.099400
		loss: 1.089100
		loss: 1.083300
		loss: 1.080400
		loss: 1.078500
		loss: 1.077900
		loss: 1.077600
		loss: 1.078100
		loss: 1.078800
		loss: 1.079100
		loss: 1.078900
		loss: 1.078200
		loss: 1.076900
		loss: 1.075100
		loss: 1.073000
		loss: 1.070600
		loss: 1.067900
		loss: 1.064800
		loss: 1.061300
		loss: 1.057600
		loss: 1.053800
		loss: 1.050000
		loss: 1.046100
		loss: 1.042400
		loss: 1.038700
		loss: 1.035000
		loss: 1.031400
		loss: 1.028000
		loss: 1.024600
		loss: 1.021300
		loss: 1.018000
		loss: 1.014900
		loss: 1.011700
		loss: 1.008700
		loss: 1.005700
		loss: 1.002800
		loss: 1.000000
		loss: 0.997400
		loss: 0.994800
		loss: 0.992300
		loss: 0.989700
		loss: 0.987000
		loss: 0.984200
		loss: 0.981400
		loss: 0.978400
		loss: 0.975400
		loss: 0.972300
		loss: 0.969100
		loss: 0.965900
		loss: 0.962500
		loss: 0.959200
		loss: 0.955800
		loss: 0.952400
		loss: 0.949000
		loss: 0.945700
		loss: 0.942300
		loss: 0.938900
		loss: 0.935500
		loss: 0.932000
		loss: 0.928500
		loss: 0.925000
		loss: 0.921500
		loss: 0.917900
		loss: 0.914300
		loss: 0.910600
		loss: 0.906900
		loss: 0.903400
		loss: 0.900000
		loss: 0.896400
		loss: 0.892800
		loss: 0.889200
		loss: 0.885500
		loss: 0.881800
		loss: 0.878000
		loss: 0.874200
		loss: 0.870400
		loss: 0.866600
		loss: 0.863000
		loss: 0.859300
		loss: 0.855600
		loss: 0.851800
		loss: 0.848000
		loss: 0.844400
		loss: 0.840800
		loss: 0.837100
		loss: 0.833300
		loss: 0.829500
		loss: 0.825600
		loss: 0.821600
		loss: 0.817600
		loss: 0.813500
		loss: 0.809500
		loss: 0.805500
		loss: 0.801400
		loss: 0.797400
		loss: 0.793200
		loss: 0.789000
		loss: 0.784800
		loss: 0.780600
		loss: 0.776400
		loss: 0.772100
		loss: 0.767700
		loss: 0.763300
		loss: 0.759000
		loss: 0.754700
		loss: 0.750500
		loss: 0.746100
		loss: 0.741700
		loss: 0.737200
		loss: 0.733000
		loss: 0.728900
		loss: 0.724700
		loss: 0.720300
		loss: 0.716100
		loss: 0.711700
		loss: 0.707300
		loss: 0.703000
		loss: 0.698500
		loss: 0.693800
		loss: 0.689100
		loss: 0.684300
		loss: 0.679500
		loss: 0.674500
		loss: 0.669700
		loss: 0.665100
		loss: 0.660400
		loss: 0.655600
		loss: 0.650600
		loss: 0.645500
		loss: 0.640600
		loss: 0.636000
		loss: 0.632300
		loss: 0.624600
		loss: 0.619200
		loss: 0.615400
		loss: 0.608700
		loss: 0.603000
		loss: 0.599000
		loss: 0.593600
		loss: 0.588400
		loss: 0.582600
		loss: 0.577800
		loss: 0.574200
		loss: 0.568100
		loss: 0.562300
		loss: 0.557400
		loss: 0.552600
		loss: 0.547500
		loss: 0.542600
		loss: 0.538300
		loss: 0.534500
		loss: 0.530200
		loss: 0.524900
		loss: 0.519800
		loss: 0.516700
		loss: 0.513600
		loss: 0.507900
		loss: 0.501900
		loss: 0.497600
		loss: 0.494500
		loss: 0.491000
		loss: 0.486200
		loss: 0.481200
		loss: 0.476600
		loss: 0.472500
		loss: 0.468700
		loss: 0.465600
		loss: 0.464500
		loss: 0.466800
		loss: 0.471200
		loss: 0.459300
		loss: 0.447600
		loss: 0.451200
		loss: 0.450200
		loss: 0.439900
		loss: 0.438900
		loss: 0.440600
		loss: 0.433100
		loss: 0.430000
		loss: 0.431800
		loss: 0.426900
		loss: 0.422300
		loss: 0.424000
		loss: 0.421100
		loss: 0.416000
		loss: 0.416800
		loss: 0.415700
		loss: 0.411000
		loss: 0.410300
		loss: 0.410300
		loss: 0.406700
		loss: 0.404600
		loss: 0.404800
		loss: 0.403000
		loss: 0.400300
		loss: 0.399500
		loss: 0.399100
		loss: 0.397100
		loss: 0.395100
		loss: 0.394400
		loss: 0.393900
		loss: 0.392300
		loss: 0.390600
		loss: 0.389600
		loss: 0.389100
		loss: 0.388300
		loss: 0.387000
		loss: 0.385700
		loss: 0.384800
		loss: 0.384200
		loss: 0.383600
		loss: 0.382700
		loss: 0.381600
		loss: 0.380700
		loss: 0.379900
		loss: 0.379200
		loss: 0.378700
		loss: 0.378100
		loss: 0.377500
		loss: 0.376900
		loss: 0.376400
		loss: 0.375800
		loss: 0.375400
		loss: 0.375100
		loss: 0.375100
		loss: 0.375500
		loss: 0.376200
		loss: 0.377100
		loss: 0.376800
		loss: 0.375300
		loss: 0.372700
		loss: 0.370600
		loss: 0.369900
		loss: 0.370500
		loss: 0.371600
		loss: 0.372000
		loss: 0.371400
		loss: 0.369600
		loss: 0.368000
		loss: 0.367200
		loss: 0.367300
		loss: 0.368000
		loss: 0.368500
		loss: 0.368400
		loss: 0.367500
		loss: 0.366300
		loss: 0.365300
		loss: 0.364800
		loss: 0.364900
		loss: 0.365300
		loss: 0.365700
		loss: 0.365800
		loss: 0.365500
		loss: 0.364800
		loss: 0.364100
		loss: 0.363300
		loss: 0.362800
		loss: 0.362500
		loss: 0.362200
		loss: 0.362100
		loss: 0.362000
		loss: 0.361800
		loss: 0.361700
		loss: 0.361700
		loss: 0.361800
		loss: 0.362200
		loss: 0.363000
		loss: 0.364300
		loss: 0.365600
		loss: 0.366500
		loss: 0.365400
		loss: 0.363100
		loss: 0.360500
		loss: 0.359500
		loss: 0.359900
		loss: 0.360700
		loss: 0.361300
		loss: 0.361000
		loss: 0.360100
		loss: 0.359100
		loss: 0.358400
	Overall the loss development was 2.779300 -> 0.358400

Training data for problem d-5-0.pddl in epoch 9:
model creation time: 16.688247203826904s
problem epoch data for epoch 9, problem epoch 1
	sampling search time: 12.213541030883789s
	during this search the following actions were chosen:
		unstack c e was chosen with probability 0.987431
		put-down c was chosen with probability 0.999962
		unstack e b was chosen with probability 0.999531
		put-down e was chosen with probability 0.988300
		unstack b a was chosen with probability 0.890386
		stack b a was chosen with probability 0.346066
	training time: 76.08490896224976s
	during the training the following losses were computed:
		loss: 0.922700
		loss: 0.924900
		loss: 0.702200
		loss: 0.688300
		loss: 0.617200
		loss: 0.533300
		loss: 0.578700
		loss: 0.578900
		loss: 0.529500
		loss: 0.532200
		loss: 0.533100
		loss: 0.489300
		loss: 0.459700
		loss: 0.464200
		loss: 0.466600
		loss: 0.454200
		loss: 0.441800
		loss: 0.443100
		loss: 0.446000
		loss: 0.435400
		loss: 0.418300
		loss: 0.409500
		loss: 0.408400
		loss: 0.403600
		loss: 0.394200
		loss: 0.390300
		loss: 0.393400
		loss: 0.392500
		loss: 0.386100
		loss: 0.383600
		loss: 0.384700
		loss: 0.382300
		loss: 0.377500
		loss: 0.376400
		loss: 0.378000
		loss: 0.376900
		loss: 0.374700
		loss: 0.375000
		loss: 0.374900
		loss: 0.372500
		loss: 0.370600
		loss: 0.370500
		loss: 0.369800
		loss: 0.368200
		loss: 0.368000
		loss: 0.368300
		loss: 0.367500
		loss: 0.366600
		loss: 0.366500
		loss: 0.366200
		loss: 0.365400
		loss: 0.365300
		loss: 0.365500
		loss: 0.365200
		loss: 0.364900
		loss: 0.365000
		loss: 0.364800
		loss: 0.364300
		loss: 0.364200
		loss: 0.364100
		loss: 0.363900
		loss: 0.363700
		loss: 0.363700
		loss: 0.363500
		loss: 0.363200
		loss: 0.363000
		loss: 0.362800
		loss: 0.362600
		loss: 0.362400
		loss: 0.362300
		loss: 0.362100
		loss: 0.362000
		loss: 0.361800
		loss: 0.361600
		loss: 0.361500
		loss: 0.361400
		loss: 0.361300
		loss: 0.361200
		loss: 0.361100
		loss: 0.360900
		loss: 0.360800
		loss: 0.360700
		loss: 0.360600
		loss: 0.360500
		loss: 0.360400
		loss: 0.360200
		loss: 0.360100
		loss: 0.360000
		loss: 0.359900
		loss: 0.359800
		loss: 0.359700
		loss: 0.359600
		loss: 0.359500
		loss: 0.359400
		loss: 0.359300
		loss: 0.359200
		loss: 0.359100
		loss: 0.359000
		loss: 0.358900
		loss: 0.358800
		loss: 0.358700
		loss: 0.358600
		loss: 0.358500
		loss: 0.358400
		loss: 0.358300
		loss: 0.358200
		loss: 0.358200
		loss: 0.358100
		loss: 0.358000
		loss: 0.357900
		loss: 0.357800
		loss: 0.357700
		loss: 0.357700
		loss: 0.357600
		loss: 0.357500
		loss: 0.357400
		loss: 0.357300
		loss: 0.357300
		loss: 0.357200
		loss: 0.357100
		loss: 0.357000
		loss: 0.357000
		loss: 0.356900
		loss: 0.356800
		loss: 0.356700
		loss: 0.356700
		loss: 0.356600
		loss: 0.356500
		loss: 0.356500
		loss: 0.356400
		loss: 0.356300
		loss: 0.356300
		loss: 0.356200
		loss: 0.356100
		loss: 0.356100
		loss: 0.356000
		loss: 0.355900
		loss: 0.355900
		loss: 0.355800
		loss: 0.355700
		loss: 0.355700
		loss: 0.355600
		loss: 0.355500
		loss: 0.355500
		loss: 0.355400
		loss: 0.355400
		loss: 0.355300
		loss: 0.355200
		loss: 0.355200
		loss: 0.355100
		loss: 0.355100
		loss: 0.355000
		loss: 0.354900
		loss: 0.354900
		loss: 0.354800
		loss: 0.354800
		loss: 0.354700
		loss: 0.354600
		loss: 0.354600
		loss: 0.354500
		loss: 0.354500
		loss: 0.354400
		loss: 0.354300
		loss: 0.354300
		loss: 0.354200
		loss: 0.354200
		loss: 0.354100
		loss: 0.354100
		loss: 0.354000
		loss: 0.353900
		loss: 0.353900
		loss: 0.353800
		loss: 0.353800
		loss: 0.353700
		loss: 0.353600
		loss: 0.353600
		loss: 0.353500
		loss: 0.353400
		loss: 0.353400
		loss: 0.353300
		loss: 0.353200
		loss: 0.353200
		loss: 0.353100
		loss: 0.353000
		loss: 0.353000
		loss: 0.352900
		loss: 0.352800
		loss: 0.352800
		loss: 0.352700
		loss: 0.352600
		loss: 0.352600
		loss: 0.352500
		loss: 0.352500
		loss: 0.352400
		loss: 0.352300
		loss: 0.352300
		loss: 0.352200
		loss: 0.352200
		loss: 0.352100
		loss: 0.352100
		loss: 0.352000
		loss: 0.352000
		loss: 0.351900
		loss: 0.351900
		loss: 0.351800
		loss: 0.351800
		loss: 0.351700
		loss: 0.351700
		loss: 0.351600
		loss: 0.351600
		loss: 0.351500
		loss: 0.351500
		loss: 0.351400
		loss: 0.351400
		loss: 0.351300
		loss: 0.351300
		loss: 0.351200
		loss: 0.351200
		loss: 0.351200
		loss: 0.351100
		loss: 0.351100
		loss: 0.351000
		loss: 0.351000
		loss: 0.350900
		loss: 0.350900
		loss: 0.350800
		loss: 0.350800
		loss: 0.350800
		loss: 0.350700
		loss: 0.350700
		loss: 0.350600
		loss: 0.350600
		loss: 0.350500
		loss: 0.350500
		loss: 0.350500
		loss: 0.350400
		loss: 0.350400
		loss: 0.350300
		loss: 0.350300
		loss: 0.350300
		loss: 0.350200
		loss: 0.350200
		loss: 0.350100
		loss: 0.350100
		loss: 0.350100
		loss: 0.350000
		loss: 0.350000
		loss: 0.350000
		loss: 0.349900
		loss: 0.349900
		loss: 0.349800
		loss: 0.349800
		loss: 0.349800
		loss: 0.349700
		loss: 0.349700
		loss: 0.349700
		loss: 0.349600
		loss: 0.349600
		loss: 0.349600
		loss: 0.349500
		loss: 0.349500
		loss: 0.349400
		loss: 0.349400
		loss: 0.349400
		loss: 0.349300
		loss: 0.349300
		loss: 0.349300
		loss: 0.349200
		loss: 0.349200
		loss: 0.349200
		loss: 0.349100
		loss: 0.349100
		loss: 0.349000
		loss: 0.349000
		loss: 0.349000
		loss: 0.348900
		loss: 0.348900
		loss: 0.348900
		loss: 0.348800
		loss: 0.348800
		loss: 0.348800
		loss: 0.348700
		loss: 0.348700
		loss: 0.348700
		loss: 0.348600
		loss: 0.348600
		loss: 0.348600
		loss: 0.348500
		loss: 0.348500
		loss: 0.348500
		loss: 0.348400
		loss: 0.348400
		loss: 0.348400
		loss: 0.348300
		loss: 0.348300
		loss: 0.348300
		loss: 0.348200
		loss: 0.348200
		loss: 0.348200
		loss: 0.348100
	Overall the loss development was 0.922700 -> 0.348100

Training data for problem d-5-1.pddl in epoch 9:
model creation time: 14.85185170173645s
problem epoch data for epoch 9, problem epoch 1
	sampling search time: 14.42293906211853s
	during this search the following actions were chosen:
		pick-up c was chosen with probability 0.730794
		put-down c was chosen with probability 0.867475
	training time: 83.91630983352661s
	during the training the following losses were computed:
		loss: 0.865700
		loss: 0.832400
		loss: 0.637600
		loss: 0.599000
		loss: 0.499500
		loss: 0.373800
		loss: 0.356200
		loss: 0.313300
		loss: 0.252500
		loss: 0.247600
		loss: 0.255300
		loss: 0.249000
		loss: 0.245000
		loss: 0.258800
		loss: 0.270300
		loss: 0.266400
		loss: 0.257800
		loss: 0.255700
		loss: 0.251200
		loss: 0.238000
		loss: 0.226700
		loss: 0.222100
		loss: 0.218100
		loss: 0.211800
		loss: 0.207900
		loss: 0.208000
		loss: 0.207500
		loss: 0.204700
		loss: 0.203200
		loss: 0.204400
		loss: 0.204500
		loss: 0.202600
		loss: 0.202300
		loss: 0.203200
		loss: 0.202600
		loss: 0.201100
		loss: 0.201200
		loss: 0.201200
		loss: 0.199800
		loss: 0.198900
		loss: 0.198900
		loss: 0.198100
		loss: 0.196900
		loss: 0.196600
		loss: 0.196300
		loss: 0.195400
		loss: 0.194800
		loss: 0.194700
		loss: 0.194300
		loss: 0.193800
		loss: 0.193700
		loss: 0.193500
		loss: 0.193100
		loss: 0.192900
		loss: 0.192900
		loss: 0.192700
		loss: 0.192500
		loss: 0.192500
		loss: 0.192300
		loss: 0.192200
		loss: 0.192100
		loss: 0.192000
		loss: 0.191900
		loss: 0.191800
		loss: 0.191700
		loss: 0.191500
		loss: 0.191400
		loss: 0.191300
		loss: 0.191200
		loss: 0.191100
		loss: 0.191000
		loss: 0.190900
		loss: 0.190800
		loss: 0.190700
		loss: 0.190600
		loss: 0.190500
		loss: 0.190500
		loss: 0.190400
		loss: 0.190300
		loss: 0.190200
		loss: 0.190100
		loss: 0.190100
		loss: 0.190000
		loss: 0.189900
		loss: 0.189900
		loss: 0.189800
		loss: 0.189700
		loss: 0.189700
		loss: 0.189600
		loss: 0.189600
		loss: 0.189500
		loss: 0.189400
		loss: 0.189400
		loss: 0.189300
		loss: 0.189300
		loss: 0.189200
		loss: 0.189100
		loss: 0.189100
		loss: 0.189000
		loss: 0.189000
		loss: 0.188900
		loss: 0.188900
		loss: 0.188800
		loss: 0.188700
		loss: 0.188700
		loss: 0.188600
		loss: 0.188600
		loss: 0.188500
		loss: 0.188500
		loss: 0.188400
		loss: 0.188400
		loss: 0.188300
		loss: 0.188300
		loss: 0.188200
		loss: 0.188200
		loss: 0.188200
		loss: 0.188100
		loss: 0.188100
		loss: 0.188000
		loss: 0.188000
		loss: 0.187900
		loss: 0.187900
		loss: 0.187900
		loss: 0.187800
		loss: 0.187800
		loss: 0.187700
		loss: 0.187700
		loss: 0.187600
		loss: 0.187600
		loss: 0.187600
		loss: 0.187500
		loss: 0.187500
		loss: 0.187500
		loss: 0.187400
		loss: 0.187400
		loss: 0.187300
		loss: 0.187300
		loss: 0.187200
		loss: 0.187200
		loss: 0.187200
		loss: 0.187100
		loss: 0.187100
		loss: 0.187100
		loss: 0.187000
		loss: 0.187000
		loss: 0.186900
		loss: 0.186900
		loss: 0.186900
		loss: 0.186800
		loss: 0.186800
		loss: 0.186800
		loss: 0.186700
		loss: 0.186700
		loss: 0.186600
		loss: 0.186600
		loss: 0.186600
		loss: 0.186500
		loss: 0.186500
		loss: 0.186500
		loss: 0.186400
		loss: 0.186400
		loss: 0.186400
		loss: 0.186300
		loss: 0.186300
		loss: 0.186300
		loss: 0.186200
		loss: 0.186200
		loss: 0.186200
		loss: 0.186100
		loss: 0.186100
		loss: 0.186100
		loss: 0.186000
		loss: 0.186000
		loss: 0.185900
		loss: 0.185900
		loss: 0.185900
		loss: 0.185800
		loss: 0.185800
		loss: 0.185700
		loss: 0.185700
		loss: 0.185700
		loss: 0.185600
		loss: 0.185600
		loss: 0.185600
		loss: 0.185500
		loss: 0.185500
		loss: 0.185500
		loss: 0.185400
		loss: 0.185400
		loss: 0.185400
		loss: 0.185300
		loss: 0.185300
		loss: 0.185200
		loss: 0.185200
		loss: 0.185200
		loss: 0.185100
		loss: 0.185100
		loss: 0.185100
		loss: 0.185000
		loss: 0.185000
		loss: 0.185000
		loss: 0.184900
		loss: 0.184900
		loss: 0.184900
		loss: 0.184800
		loss: 0.184800
		loss: 0.184800
		loss: 0.184700
		loss: 0.184700
		loss: 0.184700
		loss: 0.184600
		loss: 0.184600
		loss: 0.184600
		loss: 0.184500
		loss: 0.184500
		loss: 0.184500
		loss: 0.184400
		loss: 0.184400
		loss: 0.184400
		loss: 0.184300
		loss: 0.184300
		loss: 0.184300
		loss: 0.184300
		loss: 0.184200
		loss: 0.184200
		loss: 0.184200
		loss: 0.184100
		loss: 0.184100
		loss: 0.184100
		loss: 0.184000
		loss: 0.184000
		loss: 0.184000
		loss: 0.183900
		loss: 0.183900
		loss: 0.183900
		loss: 0.183800
		loss: 0.183800
		loss: 0.183800
		loss: 0.183800
		loss: 0.183700
		loss: 0.183700
		loss: 0.183700
		loss: 0.183600
		loss: 0.183600
		loss: 0.183600
		loss: 0.183500
		loss: 0.183500
		loss: 0.183500
		loss: 0.183500
		loss: 0.183400
		loss: 0.183400
		loss: 0.183400
		loss: 0.183400
		loss: 0.183300
		loss: 0.183300
		loss: 0.183300
		loss: 0.183200
		loss: 0.183200
		loss: 0.183200
		loss: 0.183100
		loss: 0.183100
		loss: 0.183100
		loss: 0.183000
		loss: 0.183000
		loss: 0.183000
		loss: 0.183000
		loss: 0.182900
		loss: 0.182900
		loss: 0.182900
		loss: 0.182800
		loss: 0.182800
		loss: 0.182800
		loss: 0.182700
		loss: 0.182700
		loss: 0.182700
		loss: 0.182700
		loss: 0.182600
		loss: 0.182600
		loss: 0.182600
		loss: 0.182500
		loss: 0.182500
		loss: 0.182500
		loss: 0.182400
		loss: 0.182400
		loss: 0.182400
		loss: 0.182400
		loss: 0.182300
		loss: 0.182300
		loss: 0.182300
		loss: 0.182200
		loss: 0.182200
		loss: 0.182200
		loss: 0.182200
		loss: 0.182100
		loss: 0.182100
		loss: 0.182100
		loss: 0.182000
		loss: 0.182000
		loss: 0.182000
		loss: 0.182000
	Overall the loss development was 0.865700 -> 0.182000

Epoch 10:
Training data for problem d-4-0.pddl in epoch 10:
model creation time: 9.914218187332153s
problem epoch data for epoch 10, problem epoch 1
	sampling search time: 7.620170831680298s
	during this search the following actions were chosen:
		pick-up b was chosen with probability 0.326105
		stack b a was chosen with probability 0.997189
		pick-up c was chosen with probability 0.998210
		stack c b was chosen with probability 0.997547
		pick-up d was chosen with probability 0.999836
		stack d c was chosen with probability 0.999241
	training time: 71.33042669296265s
	during the training the following losses were computed:
		loss: 0.224800
		loss: 0.222200
		loss: 0.220800
		loss: 0.219900
		loss: 0.219100
		loss: 0.218400
		loss: 0.217700
		loss: 0.216900
		loss: 0.216100
		loss: 0.215300
		loss: 0.214600
		loss: 0.213800
		loss: 0.213000
		loss: 0.212200
		loss: 0.211500
		loss: 0.210700
		loss: 0.210000
		loss: 0.209300
		loss: 0.208600
		loss: 0.207900
		loss: 0.207200
		loss: 0.206600
		loss: 0.205900
		loss: 0.205300
		loss: 0.204700
		loss: 0.204100
		loss: 0.203400
		loss: 0.202800
		loss: 0.202300
		loss: 0.201700
		loss: 0.201100
		loss: 0.200600
		loss: 0.200000
		loss: 0.199500
		loss: 0.199000
		loss: 0.198500
		loss: 0.198000
		loss: 0.197500
		loss: 0.197100
		loss: 0.196600
		loss: 0.196200
		loss: 0.195700
		loss: 0.195300
		loss: 0.194900
		loss: 0.194500
		loss: 0.194100
		loss: 0.193700
		loss: 0.193300
		loss: 0.193000
		loss: 0.192600
		loss: 0.192300
		loss: 0.191900
		loss: 0.191600
		loss: 0.191300
		loss: 0.191000
		loss: 0.190700
		loss: 0.190400
		loss: 0.190100
		loss: 0.189900
		loss: 0.189600
		loss: 0.189400
		loss: 0.189100
		loss: 0.188900
		loss: 0.188600
		loss: 0.188400
		loss: 0.188200
		loss: 0.187900
		loss: 0.187700
		loss: 0.187500
		loss: 0.187300
		loss: 0.187100
		loss: 0.186900
		loss: 0.186700
		loss: 0.186500
		loss: 0.186400
		loss: 0.186200
		loss: 0.186000
		loss: 0.185800
		loss: 0.185700
		loss: 0.185500
		loss: 0.185300
		loss: 0.185200
		loss: 0.185000
		loss: 0.184900
		loss: 0.184700
		loss: 0.184600
		loss: 0.184500
		loss: 0.184300
		loss: 0.184200
		loss: 0.184100
		loss: 0.183900
		loss: 0.183800
		loss: 0.183700
		loss: 0.183600
		loss: 0.183400
		loss: 0.183300
		loss: 0.183200
		loss: 0.183100
		loss: 0.183000
		loss: 0.182900
		loss: 0.182800
		loss: 0.182700
		loss: 0.182600
		loss: 0.182500
		loss: 0.182400
		loss: 0.182300
		loss: 0.182200
		loss: 0.182100
		loss: 0.182000
		loss: 0.181900
		loss: 0.181900
		loss: 0.181800
		loss: 0.181700
		loss: 0.181600
		loss: 0.181500
		loss: 0.181500
		loss: 0.181400
		loss: 0.181300
		loss: 0.181200
		loss: 0.181200
		loss: 0.181100
		loss: 0.181000
		loss: 0.181000
		loss: 0.180900
		loss: 0.180800
		loss: 0.180800
		loss: 0.180700
		loss: 0.180600
		loss: 0.180600
		loss: 0.180500
		loss: 0.180500
		loss: 0.180400
		loss: 0.180400
		loss: 0.180300
		loss: 0.180300
		loss: 0.180200
		loss: 0.180200
		loss: 0.180100
		loss: 0.180100
		loss: 0.180000
		loss: 0.180000
		loss: 0.179900
		loss: 0.179900
		loss: 0.179800
		loss: 0.179800
		loss: 0.179700
		loss: 0.179700
		loss: 0.179600
		loss: 0.179600
		loss: 0.179600
		loss: 0.179500
		loss: 0.179500
		loss: 0.179500
		loss: 0.179400
		loss: 0.179400
		loss: 0.179300
		loss: 0.179300
		loss: 0.179300
		loss: 0.179200
		loss: 0.179200
		loss: 0.179200
		loss: 0.179100
		loss: 0.179100
		loss: 0.179100
		loss: 0.179000
		loss: 0.179000
		loss: 0.179000
		loss: 0.179000
		loss: 0.178900
		loss: 0.178900
		loss: 0.178900
		loss: 0.178800
		loss: 0.178800
		loss: 0.178800
		loss: 0.178800
		loss: 0.178700
		loss: 0.178700
		loss: 0.178700
		loss: 0.178700
		loss: 0.178600
		loss: 0.178600
		loss: 0.178600
		loss: 0.178600
		loss: 0.178500
		loss: 0.178500
		loss: 0.178500
		loss: 0.178500
		loss: 0.178400
		loss: 0.178400
		loss: 0.178400
		loss: 0.178400
		loss: 0.178400
		loss: 0.178300
		loss: 0.178300
		loss: 0.178300
		loss: 0.178300
		loss: 0.178300
		loss: 0.178200
		loss: 0.178200
		loss: 0.178200
		loss: 0.178200
		loss: 0.178200
		loss: 0.178200
		loss: 0.178100
		loss: 0.178100
		loss: 0.178100
		loss: 0.178100
		loss: 0.178100
		loss: 0.178000
		loss: 0.178000
		loss: 0.178000
		loss: 0.178000
		loss: 0.178000
		loss: 0.178000
		loss: 0.178000
		loss: 0.177900
		loss: 0.177900
		loss: 0.177900
		loss: 0.177900
		loss: 0.177900
		loss: 0.177900
		loss: 0.177800
		loss: 0.177800
		loss: 0.177800
		loss: 0.177800
		loss: 0.177800
		loss: 0.177800
		loss: 0.177800
		loss: 0.177800
		loss: 0.177700
		loss: 0.177700
		loss: 0.177700
		loss: 0.177700
		loss: 0.177700
		loss: 0.177700
		loss: 0.177700
		loss: 0.177700
		loss: 0.177600
		loss: 0.177600
		loss: 0.177600
		loss: 0.177600
		loss: 0.177600
		loss: 0.177600
		loss: 0.177600
		loss: 0.177600
		loss: 0.177500
		loss: 0.177500
		loss: 0.177500
		loss: 0.177500
		loss: 0.177500
		loss: 0.177500
		loss: 0.177500
		loss: 0.177500
		loss: 0.177500
		loss: 0.177500
		loss: 0.177400
		loss: 0.177400
		loss: 0.177400
		loss: 0.177400
		loss: 0.177400
		loss: 0.177400
		loss: 0.177400
		loss: 0.177400
		loss: 0.177400
		loss: 0.177400
		loss: 0.177400
		loss: 0.177300
		loss: 0.177300
		loss: 0.177300
		loss: 0.177300
		loss: 0.177300
		loss: 0.177300
		loss: 0.177300
		loss: 0.177300
		loss: 0.177300
		loss: 0.177300
		loss: 0.177300
		loss: 0.177300
		loss: 0.177300
		loss: 0.177200
		loss: 0.177200
		loss: 0.177200
		loss: 0.177200
		loss: 0.177200
		loss: 0.177200
		loss: 0.177200
		loss: 0.177200
		loss: 0.177200
		loss: 0.177200
		loss: 0.177200
		loss: 0.177200
		loss: 0.177200
		loss: 0.177200
		loss: 0.177200
		loss: 0.177100
		loss: 0.177100
		loss: 0.177100
		loss: 0.177100
		loss: 0.177100
		loss: 0.177100
	Overall the loss development was 0.224800 -> 0.177100

Training data for problem d-4-2.pddl in epoch 10:
model creation time: 10.493452310562134s
problem epoch data for epoch 10, problem epoch 1
	sampling search time: 8.601731538772583s
	during this search the following actions were chosen:
		pick-up a was chosen with probability 0.994759
		stack a c was chosen with probability 0.792358
		pick-up d was chosen with probability 0.998397
		stack d a was chosen with probability 0.989137
	training time: 66.48739790916443s
	during the training the following losses were computed:
		loss: 2.531800
		loss: 2.321300
		loss: 2.122400
		loss: 1.933600
		loss: 1.755100
		loss: 1.586700
		loss: 1.433200
		loss: 1.288100
		loss: 1.150500
		loss: 1.023400
		loss: 0.908800
		loss: 0.807500
		loss: 0.717700
		loss: 0.638800
		loss: 0.573500
		loss: 0.527400
		loss: 0.491000
		loss: 0.472300
		loss: 0.462100
		loss: 0.459800
		loss: 0.465200
		loss: 0.476400
		loss: 0.488900
		loss: 0.499500
		loss: 0.505600
		loss: 0.505700
		loss: 0.499300
		loss: 0.487800
		loss: 0.472700
		loss: 0.455400
		loss: 0.437700
		loss: 0.420400
		loss: 0.405500
		loss: 0.392500
		loss: 0.380600
		loss: 0.370100
		loss: 0.360400
		loss: 0.350900
		loss: 0.341400
		loss: 0.331600
		loss: 0.321200
		loss: 0.310700
		loss: 0.302100
		loss: 0.292700
		loss: 0.282600
		loss: 0.272800
		loss: 0.264400
		loss: 0.258100
		loss: 0.254000
		loss: 0.250900
		loss: 0.247500
		loss: 0.242400
		loss: 0.235500
		loss: 0.227600
		loss: 0.220000
		loss: 0.213500
		loss: 0.208200
		loss: 0.203600
		loss: 0.199200
		loss: 0.194200
		loss: 0.188400
		loss: 0.181900
		loss: 0.175500
		loss: 0.169500
		loss: 0.164400
		loss: 0.159900
		loss: 0.155500
		loss: 0.150900
		loss: 0.146000
		loss: 0.140900
		loss: 0.136000
		loss: 0.131800
		loss: 0.128000
		loss: 0.124200
		loss: 0.120200
		loss: 0.116000
		loss: 0.111900
		loss: 0.108200
		loss: 0.104900
		loss: 0.101700
		loss: 0.098500
		loss: 0.095300
		loss: 0.092200
		loss: 0.089300
		loss: 0.086700
		loss: 0.084300
		loss: 0.081900
		loss: 0.079600
		loss: 0.077400
		loss: 0.075300
		loss: 0.073500
		loss: 0.071700
		loss: 0.070000
		loss: 0.068400
		loss: 0.066800
		loss: 0.065300
		loss: 0.064000
		loss: 0.062800
		loss: 0.061600
		loss: 0.060400
		loss: 0.059400
		loss: 0.058400
		loss: 0.057500
		loss: 0.056600
		loss: 0.055800
		loss: 0.055100
		loss: 0.054400
		loss: 0.053700
		loss: 0.053100
		loss: 0.052500
		loss: 0.051900
		loss: 0.051400
		loss: 0.051000
		loss: 0.050500
		loss: 0.050100
		loss: 0.049700
		loss: 0.049300
		loss: 0.048900
		loss: 0.048600
		loss: 0.048300
		loss: 0.048000
		loss: 0.047700
		loss: 0.047400
		loss: 0.047100
		loss: 0.046900
		loss: 0.046700
		loss: 0.046500
		loss: 0.046200
		loss: 0.046000
		loss: 0.045900
		loss: 0.045700
		loss: 0.045500
		loss: 0.045300
		loss: 0.045200
		loss: 0.045000
		loss: 0.044900
		loss: 0.044700
		loss: 0.044600
		loss: 0.044400
		loss: 0.044300
		loss: 0.044200
		loss: 0.044100
		loss: 0.043900
		loss: 0.043800
		loss: 0.043700
		loss: 0.043600
		loss: 0.043500
		loss: 0.043400
		loss: 0.043300
		loss: 0.043200
		loss: 0.043100
		loss: 0.043000
		loss: 0.042900
		loss: 0.042800
		loss: 0.042700
		loss: 0.042600
		loss: 0.042600
		loss: 0.042500
		loss: 0.042400
		loss: 0.042300
		loss: 0.042200
		loss: 0.042200
		loss: 0.042100
		loss: 0.042000
		loss: 0.041900
		loss: 0.041900
		loss: 0.041800
		loss: 0.041700
		loss: 0.041600
		loss: 0.041600
		loss: 0.041500
		loss: 0.041400
		loss: 0.041400
		loss: 0.041300
		loss: 0.041300
		loss: 0.041200
		loss: 0.041100
		loss: 0.041100
		loss: 0.041000
		loss: 0.041000
		loss: 0.040900
		loss: 0.040800
		loss: 0.040800
		loss: 0.040700
		loss: 0.040700
		loss: 0.040600
		loss: 0.040600
		loss: 0.040500
		loss: 0.040500
		loss: 0.040400
		loss: 0.040400
		loss: 0.040300
		loss: 0.040300
		loss: 0.040200
		loss: 0.040200
		loss: 0.040100
		loss: 0.040100
		loss: 0.040000
		loss: 0.040000
		loss: 0.039900
		loss: 0.039900
		loss: 0.039800
		loss: 0.039800
		loss: 0.039700
		loss: 0.039700
		loss: 0.039700
		loss: 0.039600
		loss: 0.039600
		loss: 0.039500
		loss: 0.039500
		loss: 0.039400
		loss: 0.039400
		loss: 0.039400
		loss: 0.039300
		loss: 0.039300
		loss: 0.039200
		loss: 0.039200
		loss: 0.039200
		loss: 0.039100
		loss: 0.039100
		loss: 0.039100
		loss: 0.039000
		loss: 0.039000
		loss: 0.039000
		loss: 0.038900
		loss: 0.038900
		loss: 0.038800
		loss: 0.038800
		loss: 0.038800
		loss: 0.038700
		loss: 0.038700
		loss: 0.038700
		loss: 0.038600
		loss: 0.038600
		loss: 0.038600
		loss: 0.038500
		loss: 0.038500
		loss: 0.038500
		loss: 0.038400
		loss: 0.038400
		loss: 0.038400
		loss: 0.038400
		loss: 0.038300
		loss: 0.038300
		loss: 0.038300
		loss: 0.038200
		loss: 0.038200
		loss: 0.038200
		loss: 0.038100
		loss: 0.038100
		loss: 0.038100
		loss: 0.038100
		loss: 0.038000
		loss: 0.038000
		loss: 0.038000
		loss: 0.038000
		loss: 0.037900
		loss: 0.037900
		loss: 0.037900
		loss: 0.037800
		loss: 0.037800
		loss: 0.037800
		loss: 0.037800
		loss: 0.037700
		loss: 0.037700
		loss: 0.037700
		loss: 0.037700
		loss: 0.037600
		loss: 0.037600
		loss: 0.037600
		loss: 0.037600
		loss: 0.037500
		loss: 0.037500
		loss: 0.037500
		loss: 0.037500
		loss: 0.037500
		loss: 0.037400
		loss: 0.037400
		loss: 0.037400
		loss: 0.037400
		loss: 0.037300
		loss: 0.037300
		loss: 0.037300
		loss: 0.037300
		loss: 0.037300
		loss: 0.037200
		loss: 0.037200
		loss: 0.037200
		loss: 0.037200
		loss: 0.037100
		loss: 0.037100
		loss: 0.037100
		loss: 0.037100
		loss: 0.037100
		loss: 0.037000
		loss: 0.037000
		loss: 0.037000
		loss: 0.037000
		loss: 0.037000
		loss: 0.036900
	Overall the loss development was 2.531800 -> 0.036900

Training data for problem d-4-1.pddl in epoch 10:
model creation time: 15.91958999633789s
problem epoch data for epoch 10, problem epoch 1
	sampling search time: 17.21076774597168s
	during this search the following actions were chosen:
	training time: 64.13172793388367s
	during the training the following losses were computed:
		loss: 0.521000
		loss: 0.328700
		loss: 0.217600
		loss: 0.235600
		loss: 0.258200
		loss: 0.210200
		loss: 0.161100
		loss: 0.141400
		loss: 0.143400
		loss: 0.152500
		loss: 0.157700
		loss: 0.154800
		loss: 0.145300
		loss: 0.134700
		loss: 0.128500
		loss: 0.128600
		loss: 0.131900
		loss: 0.133300
		loss: 0.129900
		loss: 0.122600
		loss: 0.114600
		loss: 0.108700
		loss: 0.105700
		loss: 0.104300
		loss: 0.102700
		loss: 0.099900
		loss: 0.095900
		loss: 0.091300
		loss: 0.087400
		loss: 0.084700
		loss: 0.083100
		loss: 0.082000
		loss: 0.080900
		loss: 0.079200
		loss: 0.077100
		loss: 0.074900
		loss: 0.073000
		loss: 0.071500
		loss: 0.070500
		loss: 0.069600
		loss: 0.068600
		loss: 0.067600
		loss: 0.066300
		loss: 0.065000
		loss: 0.063800
		loss: 0.062800
		loss: 0.061900
		loss: 0.061100
		loss: 0.060400
		loss: 0.059700
		loss: 0.058900
		loss: 0.058100
		loss: 0.057400
		loss: 0.056700
		loss: 0.056100
		loss: 0.055500
		loss: 0.055100
		loss: 0.054600
		loss: 0.054200
		loss: 0.053700
		loss: 0.053300
		loss: 0.052900
		loss: 0.052500
		loss: 0.052100
		loss: 0.051800
		loss: 0.051500
		loss: 0.051200
		loss: 0.050900
		loss: 0.050700
		loss: 0.050400
		loss: 0.050200
		loss: 0.049900
		loss: 0.049700
		loss: 0.049500
		loss: 0.049300
		loss: 0.049100
		loss: 0.048900
		loss: 0.048800
		loss: 0.048600
		loss: 0.048400
		loss: 0.048300
		loss: 0.048100
		loss: 0.048000
		loss: 0.047900
		loss: 0.047700
		loss: 0.047600
		loss: 0.047500
		loss: 0.047400
		loss: 0.047300
		loss: 0.047200
		loss: 0.047100
		loss: 0.047000
		loss: 0.046900
		loss: 0.046800
		loss: 0.046700
		loss: 0.046600
		loss: 0.046500
		loss: 0.046400
		loss: 0.046400
		loss: 0.046300
		loss: 0.046200
		loss: 0.046100
		loss: 0.046000
		loss: 0.046000
		loss: 0.045900
		loss: 0.045800
		loss: 0.045800
		loss: 0.045700
		loss: 0.045600
		loss: 0.045600
		loss: 0.045500
		loss: 0.045400
		loss: 0.045400
		loss: 0.045300
		loss: 0.045300
		loss: 0.045200
		loss: 0.045100
		loss: 0.045100
		loss: 0.045000
		loss: 0.045000
		loss: 0.044900
		loss: 0.044900
		loss: 0.044800
		loss: 0.044800
		loss: 0.044800
		loss: 0.044700
		loss: 0.044700
		loss: 0.044600
		loss: 0.044600
		loss: 0.044600
		loss: 0.044500
		loss: 0.044500
		loss: 0.044400
		loss: 0.044400
		loss: 0.044400
		loss: 0.044300
		loss: 0.044300
		loss: 0.044300
		loss: 0.044200
		loss: 0.044200
		loss: 0.044200
		loss: 0.044100
		loss: 0.044100
		loss: 0.044100
		loss: 0.044000
		loss: 0.044000
		loss: 0.044000
		loss: 0.043900
		loss: 0.043900
		loss: 0.043900
		loss: 0.043800
		loss: 0.043800
		loss: 0.043800
		loss: 0.043800
		loss: 0.043700
		loss: 0.043700
		loss: 0.043700
		loss: 0.043600
		loss: 0.043600
		loss: 0.043600
		loss: 0.043500
		loss: 0.043500
		loss: 0.043500
		loss: 0.043500
		loss: 0.043400
		loss: 0.043400
		loss: 0.043400
		loss: 0.043400
		loss: 0.043300
		loss: 0.043300
		loss: 0.043300
		loss: 0.043200
		loss: 0.043200
		loss: 0.043200
		loss: 0.043200
		loss: 0.043100
		loss: 0.043100
		loss: 0.043100
		loss: 0.043100
		loss: 0.043000
		loss: 0.043000
		loss: 0.043000
		loss: 0.042900
		loss: 0.042900
		loss: 0.042900
		loss: 0.042900
		loss: 0.042800
		loss: 0.042800
		loss: 0.042800
		loss: 0.042800
		loss: 0.042700
		loss: 0.042700
		loss: 0.042700
		loss: 0.042700
		loss: 0.042600
		loss: 0.042600
		loss: 0.042600
		loss: 0.042600
		loss: 0.042500
		loss: 0.042500
		loss: 0.042500
		loss: 0.042500
		loss: 0.042400
		loss: 0.042400
		loss: 0.042400
		loss: 0.042400
		loss: 0.042300
		loss: 0.042300
		loss: 0.042300
		loss: 0.042300
		loss: 0.042200
		loss: 0.042200
		loss: 0.042200
		loss: 0.042200
		loss: 0.042100
		loss: 0.042100
		loss: 0.042100
		loss: 0.042100
		loss: 0.042000
		loss: 0.042000
		loss: 0.042000
		loss: 0.042000
		loss: 0.041900
		loss: 0.041900
		loss: 0.041900
		loss: 0.041900
		loss: 0.041800
		loss: 0.041800
		loss: 0.041800
		loss: 0.041800
		loss: 0.041700
		loss: 0.041700
		loss: 0.041700
		loss: 0.041700
		loss: 0.041600
		loss: 0.041600
		loss: 0.041600
		loss: 0.041600
		loss: 0.041600
		loss: 0.041500
		loss: 0.041500
		loss: 0.041500
		loss: 0.041500
		loss: 0.041400
		loss: 0.041400
		loss: 0.041400
		loss: 0.041400
		loss: 0.041300
		loss: 0.041300
		loss: 0.041300
		loss: 0.041300
		loss: 0.041200
		loss: 0.041200
		loss: 0.041200
		loss: 0.041200
		loss: 0.041200
		loss: 0.041100
		loss: 0.041100
		loss: 0.041100
		loss: 0.041100
		loss: 0.041000
		loss: 0.041000
		loss: 0.041000
		loss: 0.041000
		loss: 0.041000
		loss: 0.040900
		loss: 0.040900
		loss: 0.040900
		loss: 0.040900
		loss: 0.040800
		loss: 0.040800
		loss: 0.040800
		loss: 0.040800
		loss: 0.040700
		loss: 0.040700
		loss: 0.040700
		loss: 0.040700
		loss: 0.040700
		loss: 0.040600
		loss: 0.040600
		loss: 0.040600
		loss: 0.040600
		loss: 0.040600
		loss: 0.040500
		loss: 0.040500
		loss: 0.040500
		loss: 0.040500
		loss: 0.040400
		loss: 0.040400
		loss: 0.040400
		loss: 0.040400
		loss: 0.040400
		loss: 0.040300
		loss: 0.040300
		loss: 0.040300
		loss: 0.040300
		loss: 0.040300
		loss: 0.040200
		loss: 0.040200
		loss: 0.040200
	Overall the loss development was 0.521000 -> 0.040200

Training data for problem d-5-2.pddl in epoch 10:
model creation time: 28.59888482093811s
problem epoch data for epoch 10, problem epoch 1
	sampling search time: 29.02240824699402s
	during this search the following actions were chosen:
	training time: 97.41211318969727s
	during the training the following losses were computed:
		loss: 2.655400
		loss: 2.455100
		loss: 2.270600
		loss: 2.100700
		loss: 1.952500
		loss: 1.806100
		loss: 1.672200
		loss: 1.552700
		loss: 1.447200
		loss: 1.354400
		loss: 1.273800
		loss: 1.205800
		loss: 1.152800
		loss: 1.112200
		loss: 1.081300
		loss: 1.057300
		loss: 1.039400
		loss: 1.026400
		loss: 1.017500
		loss: 1.012200
		loss: 1.009600
		loss: 1.008700
		loss: 1.008600
		loss: 1.008700
		loss: 1.008500
		loss: 1.008500
		loss: 1.009000
		loss: 1.009400
		loss: 1.009300
		loss: 1.008500
		loss: 1.006900
		loss: 1.005000
		loss: 1.002800
		loss: 1.000500
		loss: 0.997700
		loss: 0.994400
		loss: 0.990700
		loss: 0.986800
		loss: 0.982800
		loss: 0.978700
		loss: 0.974400
		loss: 0.970000
		loss: 0.965500
		loss: 0.960700
		loss: 0.955700
		loss: 0.950700
		loss: 0.945500
		loss: 0.940400
		loss: 0.935200
		loss: 0.929700
		loss: 0.924400
		loss: 0.919500
		loss: 0.914400
		loss: 0.909300
		loss: 0.904300
		loss: 0.899200
		loss: 0.894100
		loss: 0.889300
		loss: 0.884600
		loss: 0.879800
		loss: 0.875100
		loss: 0.870400
		loss: 0.866000
		loss: 0.861600
		loss: 0.857200
		loss: 0.852800
		loss: 0.848300
		loss: 0.843800
		loss: 0.839200
		loss: 0.834500
		loss: 0.829800
		loss: 0.825200
		loss: 0.820800
		loss: 0.816500
		loss: 0.812300
		loss: 0.808100
		loss: 0.803900
		loss: 0.799800
		loss: 0.795800
		loss: 0.792000
		loss: 0.788100
		loss: 0.784200
		loss: 0.780400
		loss: 0.776700
		loss: 0.773000
		loss: 0.769300
		loss: 0.765600
		loss: 0.762000
		loss: 0.758400
		loss: 0.754800
		loss: 0.751200
		loss: 0.747800
		loss: 0.744300
		loss: 0.740900
		loss: 0.737500
		loss: 0.734100
		loss: 0.730700
		loss: 0.727300
		loss: 0.723900
		loss: 0.720500
		loss: 0.717000
		loss: 0.713700
		loss: 0.710300
		loss: 0.707000
		loss: 0.703600
		loss: 0.700200
		loss: 0.696800
		loss: 0.693400
		loss: 0.690100
		loss: 0.686700
		loss: 0.683300
		loss: 0.679800
		loss: 0.676500
		loss: 0.673100
		loss: 0.669700
		loss: 0.666200
		loss: 0.662800
		loss: 0.659400
		loss: 0.655900
		loss: 0.652600
		loss: 0.649300
		loss: 0.646100
		loss: 0.642800
		loss: 0.639500
		loss: 0.636100
		loss: 0.632800
		loss: 0.629400
		loss: 0.626200
		loss: 0.623200
		loss: 0.620600
		loss: 0.617700
		loss: 0.613400
		loss: 0.609500
		loss: 0.606300
		loss: 0.603600
		loss: 0.600700
		loss: 0.596700
		loss: 0.592700
		loss: 0.589100
		loss: 0.585900
		loss: 0.583300
		loss: 0.580400
		loss: 0.576800
		loss: 0.572600
		loss: 0.569100
		loss: 0.566500
		loss: 0.563900
		loss: 0.560400
		loss: 0.556400
		loss: 0.553000
		loss: 0.550600
		loss: 0.548100
		loss: 0.545200
		loss: 0.540900
		loss: 0.537300
		loss: 0.534600
		loss: 0.532200
		loss: 0.529400
		loss: 0.525400
		loss: 0.521800
		loss: 0.518400
		loss: 0.515300
		loss: 0.512600
		loss: 0.510400
		loss: 0.509900
		loss: 0.509300
		loss: 0.507800
		loss: 0.499600
		loss: 0.494800
		loss: 0.495700
		loss: 0.493100
		loss: 0.487000
		loss: 0.484800
		loss: 0.484800
		loss: 0.481300
		loss: 0.476400
		loss: 0.475400
		loss: 0.475200
		loss: 0.470700
		loss: 0.467100
		loss: 0.466000
		loss: 0.464600
		loss: 0.461700
		loss: 0.458700
		loss: 0.457300
		loss: 0.456500
		loss: 0.453800
		loss: 0.451000
		loss: 0.449300
		loss: 0.448400
		loss: 0.447000
		loss: 0.444400
		loss: 0.442000
		loss: 0.440200
		loss: 0.438900
		loss: 0.437600
		loss: 0.435900
		loss: 0.434200
		loss: 0.432200
		loss: 0.430200
		loss: 0.428400
		loss: 0.427000
		loss: 0.425700
		loss: 0.424500
		loss: 0.423600
		loss: 0.422600
		loss: 0.423000
		loss: 0.422600
		loss: 0.423100
		loss: 0.420100
		loss: 0.416200
		loss: 0.413600
		loss: 0.413900
		loss: 0.414900
		loss: 0.413600
		loss: 0.410700
		loss: 0.408500
		loss: 0.408100
		loss: 0.408500
		loss: 0.408000
		loss: 0.406900
		loss: 0.404800
		loss: 0.403100
		loss: 0.402500
		loss: 0.402500
		loss: 0.402500
		loss: 0.401800
		loss: 0.401100
		loss: 0.399500
		loss: 0.398100
		loss: 0.396900
		loss: 0.396300
		loss: 0.396000
		loss: 0.395800
		loss: 0.395700
		loss: 0.395200
		loss: 0.394400
		loss: 0.393200
		loss: 0.391900
		loss: 0.390900
		loss: 0.390200
		loss: 0.389800
		loss: 0.389600
		loss: 0.389800
		loss: 0.390200
		loss: 0.391400
		loss: 0.392200
		loss: 0.393200
		loss: 0.390500
		loss: 0.386700
		loss: 0.384600
		loss: 0.385400
		loss: 0.386900
		loss: 0.386500
		loss: 0.384400
		loss: 0.382300
		loss: 0.381900
		loss: 0.382800
		loss: 0.382900
		loss: 0.381800
		loss: 0.380200
		loss: 0.379300
		loss: 0.379400
		loss: 0.379600
		loss: 0.379400
		loss: 0.378500
		loss: 0.377400
		loss: 0.376700
		loss: 0.376500
		loss: 0.376600
		loss: 0.376400
		loss: 0.376200
		loss: 0.375600
		loss: 0.375000
		loss: 0.374400
		loss: 0.373800
		loss: 0.373200
		loss: 0.372800
		loss: 0.372400
		loss: 0.372100
		loss: 0.371900
		loss: 0.371600
		loss: 0.371400
		loss: 0.371000
		loss: 0.370800
		loss: 0.370500
		loss: 0.370500
		loss: 0.370400
		loss: 0.370400
		loss: 0.370100
		loss: 0.370100
		loss: 0.369500
		loss: 0.368900
		loss: 0.368000
		loss: 0.367300
		loss: 0.366900
		loss: 0.366900
		loss: 0.367000
		loss: 0.367200
		loss: 0.367800
	Overall the loss development was 2.655400 -> 0.367800

Training data for problem d-5-0.pddl in epoch 10:
model creation time: 26.765320301055908s
problem epoch data for epoch 10, problem epoch 1
	sampling search time: 20.674539804458618s
	during this search the following actions were chosen:
		unstack c e was chosen with probability 0.999901
		put-down c was chosen with probability 0.999900
		unstack e b was chosen with probability 0.999997
		put-down e was chosen with probability 0.976464
		unstack b a was chosen with probability 0.522803
		put-down b was chosen with probability 0.400318
		pick-up a was chosen with probability 0.250000
		put-down a was chosen with probability 0.999327
	training time: 89.40645599365234s
	during the training the following losses were computed:
		loss: 0.975300
		loss: 1.051300
		loss: 0.937700
		loss: 0.796900
		loss: 0.808600
		loss: 0.820100
		loss: 0.724100
		loss: 0.683000
		loss: 0.692700
		loss: 0.696900
		loss: 0.650300
		loss: 0.594900
		loss: 0.576800
		loss: 0.580800
		loss: 0.563200
		loss: 0.518800
		loss: 0.482300
		loss: 0.475800
		loss: 0.464100
		loss: 0.433700
		loss: 0.420600
		loss: 0.420800
		loss: 0.411500
		loss: 0.394000
		loss: 0.389600
		loss: 0.395000
		loss: 0.390700
		loss: 0.385100
		loss: 0.389800
		loss: 0.395100
		loss: 0.390500
		loss: 0.386400
		loss: 0.387900
		loss: 0.387000
		loss: 0.382200
		loss: 0.381000
		loss: 0.383600
		loss: 0.382800
		loss: 0.380300
		loss: 0.380600
		loss: 0.380900
		loss: 0.378200
		loss: 0.375600
		loss: 0.375700
		loss: 0.375200
		loss: 0.373400
		loss: 0.373200
		loss: 0.373800
		loss: 0.372900
		loss: 0.371800
		loss: 0.371800
		loss: 0.371300
		loss: 0.370200
		loss: 0.370100
		loss: 0.370400
		loss: 0.370000
		loss: 0.369700
		loss: 0.369900
		loss: 0.369600
		loss: 0.369000
		loss: 0.369000
		loss: 0.368900
		loss: 0.368600
		loss: 0.368700
		loss: 0.368700
		loss: 0.368400
		loss: 0.368300
		loss: 0.368300
		loss: 0.368000
		loss: 0.367900
		loss: 0.368000
		loss: 0.367800
		loss: 0.367700
		loss: 0.367700
		loss: 0.367600
		loss: 0.367400
		loss: 0.367400
		loss: 0.367300
		loss: 0.367200
		loss: 0.367200
		loss: 0.367100
		loss: 0.367000
		loss: 0.367000
		loss: 0.366900
		loss: 0.366800
		loss: 0.366800
		loss: 0.366700
		loss: 0.366700
		loss: 0.366600
		loss: 0.366500
		loss: 0.366500
		loss: 0.366400
		loss: 0.366300
		loss: 0.366300
		loss: 0.366200
		loss: 0.366200
		loss: 0.366100
		loss: 0.366000
		loss: 0.366000
		loss: 0.365900
		loss: 0.365900
		loss: 0.365800
		loss: 0.365800
		loss: 0.365700
		loss: 0.365700
		loss: 0.365600
		loss: 0.365600
		loss: 0.365500
		loss: 0.365400
		loss: 0.365400
		loss: 0.365300
		loss: 0.365300
		loss: 0.365300
		loss: 0.365200
		loss: 0.365200
		loss: 0.365100
		loss: 0.365100
		loss: 0.365000
		loss: 0.365000
		loss: 0.364900
		loss: 0.364900
		loss: 0.364800
		loss: 0.364800
		loss: 0.364800
		loss: 0.364700
		loss: 0.364700
		loss: 0.364600
		loss: 0.364600
		loss: 0.364500
		loss: 0.364500
		loss: 0.364500
		loss: 0.364400
		loss: 0.364400
		loss: 0.364300
		loss: 0.364300
		loss: 0.364200
		loss: 0.364200
		loss: 0.364200
		loss: 0.364100
		loss: 0.364100
		loss: 0.364000
		loss: 0.364000
		loss: 0.364000
		loss: 0.363900
		loss: 0.363900
		loss: 0.363800
		loss: 0.363800
		loss: 0.363800
		loss: 0.363700
		loss: 0.363700
		loss: 0.363600
		loss: 0.363600
		loss: 0.363500
		loss: 0.363500
		loss: 0.363500
		loss: 0.363400
		loss: 0.363400
		loss: 0.363300
		loss: 0.363300
		loss: 0.363300
		loss: 0.363200
		loss: 0.363200
		loss: 0.363200
		loss: 0.363100
		loss: 0.363100
		loss: 0.363000
		loss: 0.363000
		loss: 0.363000
		loss: 0.362900
		loss: 0.362900
		loss: 0.362800
		loss: 0.362800
		loss: 0.362800
		loss: 0.362700
		loss: 0.362700
		loss: 0.362600
		loss: 0.362600
		loss: 0.362600
		loss: 0.362500
		loss: 0.362500
		loss: 0.362500
		loss: 0.362400
		loss: 0.362400
		loss: 0.362300
		loss: 0.362300
		loss: 0.362300
		loss: 0.362200
		loss: 0.362200
		loss: 0.362200
		loss: 0.362100
		loss: 0.362100
		loss: 0.362000
		loss: 0.362000
		loss: 0.362000
		loss: 0.361900
		loss: 0.361900
		loss: 0.361900
		loss: 0.361800
		loss: 0.361800
		loss: 0.361800
		loss: 0.361700
		loss: 0.361700
		loss: 0.361600
		loss: 0.361600
		loss: 0.361600
		loss: 0.361500
		loss: 0.361500
		loss: 0.361500
		loss: 0.361400
		loss: 0.361400
		loss: 0.361400
		loss: 0.361300
		loss: 0.361300
		loss: 0.361200
		loss: 0.361200
		loss: 0.361200
		loss: 0.361100
		loss: 0.361100
		loss: 0.361100
		loss: 0.361000
		loss: 0.361000
		loss: 0.361000
		loss: 0.360900
		loss: 0.360900
		loss: 0.360900
		loss: 0.360800
		loss: 0.360800
		loss: 0.360800
		loss: 0.360700
		loss: 0.360700
		loss: 0.360700
		loss: 0.360600
		loss: 0.360600
		loss: 0.360500
		loss: 0.360500
		loss: 0.360500
		loss: 0.360400
		loss: 0.360400
		loss: 0.360400
		loss: 0.360300
		loss: 0.360300
		loss: 0.360300
		loss: 0.360200
		loss: 0.360200
		loss: 0.360200
		loss: 0.360100
		loss: 0.360100
		loss: 0.360100
		loss: 0.360000
		loss: 0.360000
		loss: 0.360000
		loss: 0.359900
		loss: 0.359900
		loss: 0.359900
		loss: 0.359900
		loss: 0.359800
		loss: 0.359800
		loss: 0.359800
		loss: 0.359700
		loss: 0.359700
		loss: 0.359700
		loss: 0.359600
		loss: 0.359600
		loss: 0.359600
		loss: 0.359500
		loss: 0.359500
		loss: 0.359500
		loss: 0.359400
		loss: 0.359400
		loss: 0.359400
		loss: 0.359300
		loss: 0.359300
		loss: 0.359300
		loss: 0.359200
		loss: 0.359200
		loss: 0.359200
		loss: 0.359100
		loss: 0.359100
		loss: 0.359100
		loss: 0.359000
		loss: 0.359000
		loss: 0.359000
		loss: 0.359000
		loss: 0.358900
		loss: 0.358900
		loss: 0.358900
		loss: 0.358800
		loss: 0.358800
		loss: 0.358800
		loss: 0.358700
		loss: 0.358700
		loss: 0.358700
		loss: 0.358600
		loss: 0.358600
		loss: 0.358600
		loss: 0.358500
		loss: 0.358500
		loss: 0.358500
		loss: 0.358500
		loss: 0.358400
	Overall the loss development was 0.975300 -> 0.358400

Training data for problem d-5-1.pddl in epoch 10:
model creation time: 20.503724336624146s
problem epoch data for epoch 10, problem epoch 1
	sampling search time: 20.698673009872437s
	during this search the following actions were chosen:
		pick-up c was chosen with probability 0.956715
		put-down c was chosen with probability 0.980106
	training time: 79.94180059432983s
	during the training the following losses were computed:
		loss: 0.949400
		loss: 0.772000
		loss: 0.571900
		loss: 0.469000
		loss: 0.347000
		loss: 0.294900
		loss: 0.270000
		loss: 0.237500
		loss: 0.221900
		loss: 0.226600
		loss: 0.222600
		loss: 0.215200
		loss: 0.217600
		loss: 0.228100
		loss: 0.235600
		loss: 0.234400
		loss: 0.232800
		loss: 0.235400
		loss: 0.236000
		loss: 0.230200
		loss: 0.221600
		loss: 0.216400
		loss: 0.214700
		loss: 0.211800
		loss: 0.206600
		loss: 0.203100
		loss: 0.202700
		loss: 0.202900
		loss: 0.201500
		loss: 0.200000
		loss: 0.200200
		loss: 0.201000
		loss: 0.200500
		loss: 0.199400
		loss: 0.199100
		loss: 0.199400
		loss: 0.198800
		loss: 0.197600
		loss: 0.197100
		loss: 0.196900
		loss: 0.196300
		loss: 0.195500
		loss: 0.195000
		loss: 0.194900
		loss: 0.194500
		loss: 0.193900
		loss: 0.193500
		loss: 0.193400
		loss: 0.193100
		loss: 0.192700
		loss: 0.192400
		loss: 0.192200
		loss: 0.192000
		loss: 0.191700
		loss: 0.191500
		loss: 0.191300
		loss: 0.191200
		loss: 0.190900
		loss: 0.190700
		loss: 0.190600
		loss: 0.190400
		loss: 0.190200
		loss: 0.190000
		loss: 0.189900
		loss: 0.189700
		loss: 0.189500
		loss: 0.189400
		loss: 0.189300
		loss: 0.189100
		loss: 0.189000
		loss: 0.188900
		loss: 0.188800
		loss: 0.188700
		loss: 0.188600
		loss: 0.188500
		loss: 0.188400
		loss: 0.188300
		loss: 0.188200
		loss: 0.188200
		loss: 0.188100
		loss: 0.188000
		loss: 0.187900
		loss: 0.187900
		loss: 0.187800
		loss: 0.187700
		loss: 0.187600
		loss: 0.187600
		loss: 0.187500
		loss: 0.187400
		loss: 0.187400
		loss: 0.187300
		loss: 0.187200
		loss: 0.187200
		loss: 0.187100
		loss: 0.187000
		loss: 0.187000
		loss: 0.186900
		loss: 0.186800
		loss: 0.186800
		loss: 0.186700
		loss: 0.186700
		loss: 0.186600
		loss: 0.186600
		loss: 0.186500
		loss: 0.186500
		loss: 0.186400
		loss: 0.186400
		loss: 0.186300
		loss: 0.186200
		loss: 0.186200
		loss: 0.186100
		loss: 0.186100
		loss: 0.186100
		loss: 0.186000
		loss: 0.186000
		loss: 0.185900
		loss: 0.185900
		loss: 0.185800
		loss: 0.185800
		loss: 0.185700
		loss: 0.185700
		loss: 0.185700
		loss: 0.185600
		loss: 0.185600
		loss: 0.185500
		loss: 0.185500
		loss: 0.185400
		loss: 0.185400
		loss: 0.185400
		loss: 0.185300
		loss: 0.185300
		loss: 0.185200
		loss: 0.185200
		loss: 0.185200
		loss: 0.185100
		loss: 0.185100
		loss: 0.185100
		loss: 0.185000
		loss: 0.185000
		loss: 0.184900
		loss: 0.184900
		loss: 0.184900
		loss: 0.184800
		loss: 0.184800
		loss: 0.184800
		loss: 0.184700
		loss: 0.184700
		loss: 0.184700
		loss: 0.184600
		loss: 0.184600
		loss: 0.184600
		loss: 0.184500
		loss: 0.184500
		loss: 0.184500
		loss: 0.184400
		loss: 0.184400
		loss: 0.184300
		loss: 0.184300
		loss: 0.184300
		loss: 0.184200
		loss: 0.184200
		loss: 0.184200
		loss: 0.184100
		loss: 0.184100
		loss: 0.184100
		loss: 0.184000
		loss: 0.184000
		loss: 0.184000
		loss: 0.183900
		loss: 0.183900
		loss: 0.183900
		loss: 0.183800
		loss: 0.183800
		loss: 0.183800
		loss: 0.183700
		loss: 0.183700
		loss: 0.183700
		loss: 0.183700
		loss: 0.183600
		loss: 0.183600
		loss: 0.183600
		loss: 0.183500
		loss: 0.183500
		loss: 0.183500
		loss: 0.183400
		loss: 0.183400
		loss: 0.183400
		loss: 0.183300
		loss: 0.183300
		loss: 0.183300
		loss: 0.183200
		loss: 0.183200
		loss: 0.183200
		loss: 0.183100
		loss: 0.183100
		loss: 0.183100
		loss: 0.183000
		loss: 0.183000
		loss: 0.183000
		loss: 0.182900
		loss: 0.182900
		loss: 0.182900
		loss: 0.182900
		loss: 0.182800
		loss: 0.182800
		loss: 0.182800
		loss: 0.182700
		loss: 0.182700
		loss: 0.182700
		loss: 0.182600
		loss: 0.182600
		loss: 0.182600
		loss: 0.182500
		loss: 0.182500
		loss: 0.182500
		loss: 0.182500
		loss: 0.182400
		loss: 0.182400
		loss: 0.182400
		loss: 0.182300
		loss: 0.182300
		loss: 0.182300
		loss: 0.182200
		loss: 0.182200
		loss: 0.182200
		loss: 0.182100
		loss: 0.182100
		loss: 0.182100
		loss: 0.182100
		loss: 0.182000
		loss: 0.182000
		loss: 0.182000
		loss: 0.181900
		loss: 0.181900
		loss: 0.181900
		loss: 0.181800
		loss: 0.181800
		loss: 0.181800
		loss: 0.181800
		loss: 0.181700
		loss: 0.181700
		loss: 0.181700
		loss: 0.181600
		loss: 0.181600
		loss: 0.181600
		loss: 0.181500
		loss: 0.181500
		loss: 0.181500
		loss: 0.181400
		loss: 0.181400
		loss: 0.181400
		loss: 0.181400
		loss: 0.181300
		loss: 0.181300
		loss: 0.181300
		loss: 0.181200
		loss: 0.181200
		loss: 0.181200
		loss: 0.181100
		loss: 0.181100
		loss: 0.181100
		loss: 0.181100
		loss: 0.181000
		loss: 0.181000
		loss: 0.181000
		loss: 0.180900
		loss: 0.180900
		loss: 0.180900
		loss: 0.180800
		loss: 0.180800
		loss: 0.180800
		loss: 0.180800
		loss: 0.180700
		loss: 0.180700
		loss: 0.180700
		loss: 0.180600
		loss: 0.180600
		loss: 0.180600
		loss: 0.180500
		loss: 0.180500
		loss: 0.180500
		loss: 0.180500
		loss: 0.180400
		loss: 0.180400
		loss: 0.180400
		loss: 0.180300
		loss: 0.180300
		loss: 0.180300
		loss: 0.180300
		loss: 0.180200
		loss: 0.180200
		loss: 0.180200
		loss: 0.180100
		loss: 0.180100
		loss: 0.180100
		loss: 0.180000
		loss: 0.180000
		loss: 0.180000
		loss: 0.180000
		loss: 0.179900
	Overall the loss development was 0.949400 -> 0.179900

